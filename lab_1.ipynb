{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "lab_1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zRJY63VoJd5g",
        "FQ4jJiT4RUFE",
        "P11u-2VnRUFM",
        "wShj0RtLRUFT",
        "ZRCyQpM7RUFb",
        "MXAMjlGTRUFi",
        "lf839fZ3RUFl",
        "YPkjV7fDRUFq",
        "4kTQTu7oRUFu",
        "OAy1EhBGSpsV",
        "HvlcxHKkRUFy",
        "AYWRIj1nm8D7",
        "3moeyM_joRtS",
        "d_mfICSEoRtX",
        "nQ04uOz2oRtg",
        "Z90jNc5voRtj",
        "dtdFlaGRVP5q",
        "va9EPNj5jUMT",
        "cCGkugoKjUMg",
        "VSePSrfcjUMl",
        "DV8EpzEtjUMr",
        "S-MpNToLVP6g",
        "gLFlS2hfpmDm",
        "OAn4CYT6wPuo",
        "HWAz5qmi06Lb",
        "zXbGtWONLU_y",
        "ydWHqqU0iBo1",
        "gGinV5P1njhF",
        "zxn-Lp2zrAxl",
        "QPVBeNKXsndD",
        "7XC9Z28dRUF3",
        "j7GtcTvtEIfm",
        "fkRhSnSEHDlx",
        "JANglyWdHDme",
        "cRistjOJHDmi",
        "ZP8g4WVbD9hm",
        "h2colG80RUF6",
        "SzAGE4I3RUF7"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanaa11/media-opinion-analyzer/blob/main/lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP84NAIiRUEq"
      },
      "source": [
        "## Лабораторная работа 1. Введение в машинное обучение.\n",
        "\n",
        "![](https://newapplift-production.s3.amazonaws.com/comfy/cms/files/files/000/001/201/original/machine-learning-robots-dilbert.gif)\n",
        "\n",
        "Результат лабораторной работы − отчет. Мы предпочитаем принимать отчеты в формате ноутбуков Jupyter (ipynb-файл). Постарайтесь сделать ваш отчет интересным рассказом, последовательно отвечающим на вопросы из заданий. Помимо ответов на вопросы, в отчете так же должен быть код, однако чем меньше кода, тем лучше всем: нам − меньше проверять, вам —  проще найти ошибку или дополнить эксперимент. При проверке оценивается четкость ответов на вопросы, аккуратность отчета и кода.\n",
        "\n",
        "\n",
        "### Оценивание и штрафы\n",
        "\n",
        "* Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи)\n",
        "* Максимально допустимая оценка за работу — 15 баллов\n",
        "* Сдавать задание после указанного срока сдачи нельзя\n",
        "* «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов и понижают карму (подробнее о плагиате см. на странице курса)\n",
        "* Если вы нашли решение какого-то из заданий в открытом источнике, необходимо прислать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник)\n",
        "* Не оцениваются задания с удалёнными формулировкам\n",
        "* Не оценивается лабораторная работа целиком, если она была выложена в открытый источник"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_j9r9iaRUE8"
      },
      "source": [
        "### Метрика качества\n",
        "\n",
        "Обучение и оценка качества модели производится на независимых множествах примеров. Как правило, имеющующиеся примеры разбивают на два подмножества: обучающее (train) и тестовое (test). Выбор пропорции разбиения — компромисс. Действительно, большой размер обучения ведет к более качественным алгоритмам, но бОльшему шуму при оценке модели на тесте. И наоборот, большой размер тестовой выборки ведет к менее шумной оценке качества, однако обученные модели получаются менее точными.\n",
        "\n",
        "Многие модели классификации предсказывают оценку принадлежности положительному классу $\\tilde{y}(x) \\in R$ (например, вероятность принадлежности классу 1). После этого принимают решение о классе объекта путем сравнения оценки с некоторым порогом $\\theta$:\n",
        "\n",
        "$$y(x) = \n",
        "\\begin{cases}\n",
        "+1, &\\text{если} \\; \\tilde{y}(x) \\geq \\theta \\\\\n",
        "-1, &\\text{если} \\; \\tilde{y}(x) < \\theta\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "В этом случае можно рассматривать метрики, которые умеют работать с исходным ответом классификатора. В задании мы будем работать с метрикой AUC-ROC, которую в данном случае можно считать как долю неправильно упорядоченных пар объектов, отсортированных по возрастанию предсказанной оценки принадлежности классу 1 (более подробно можно узнать на следующих лекциях или, например, [здесь](https://github.com/esokolov/ml-course-msu/blob/master/ML15/lecture-notes/Sem05_metrics.pdf)). Детального понимания принципов работы метрики AUC-ROC для выполнения этой лабораторной не требуется."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Yna3LOfRUE_"
      },
      "source": [
        "### Подбор гиперпараметров модели\n",
        "\n",
        "В задачах машинного обучения следует различать параметры модели и гиперпараметры (структурные параметры). Обычно параметры модели настраиваются в ходе обучения (например, веса в линейной модели), в то время как гиперпараметры задаются заранее (например, значение силы регуляризации в линейной модели). Каждая модель, как правило, имеет множество гиперпараметров и нет универсальных наборов гиперпараметров, оптимально работающих во всех задачах, поэтому для каждой задачи нужно подбирать свой набор.\n",
        "\n",
        "Для оптимизации гиперпараметров модели часто используют _перебор по сетке (grid search)_: для каждого гиперпараметра выбирается несколько значений, далее перебираются все комбинации значений и выбирается комбинация, на которой модель показывает лучшее качество (с точки зрения оптимизируемой метрики). Однако, в этом случае нужно грамотно оценивать построенную модель, а именно делать разбиение на обучающую и тестовую выборку.\n",
        "\n",
        "В этом случае сравнение большого числа моделей при переборе гиперпараметров приводит к ситуации, когда лучшая на тестовой подвыборке модель не сохраняет свои качества на новых данных. Можно сказать, что происходит _переобучение_ на тестовую выборку.\n",
        "\n",
        "Для устранения описанной выше проблемы, **можно разбить данные на 3 непересекающихся подвыборки: обучение, валидация и тест**. Валидационную подвыборку используют для сравнения моделей, а тестовую — для окончательной оценки качества и сравнения семейств моделей с подобранными гиперпараметрами.\n",
        "\n",
        "**Другой способ сравнения моделей — [кросс-валидация](http://bit.ly/1CHXsNH)**. \n",
        "\n",
        "Существуют различные **схемы кросс-валидации**:\n",
        "  - Leave-One-Out\n",
        "  - K-Fold\n",
        "  - Многократное случайное разбиение выборки\n",
        "  \n",
        "Кросс-валидация вычислительно затратна, особенно если вы делаете перебор по сетке с очень большим числом комбинации. С учетом конечности времени на выполнение задания, возникает ряд компромиссов: \n",
        "  - сетку гиперпараметров можно делать более разреженной, перебирая меньше значений каждого гиперпараметра; однако, не стоит забывать, что в таком случае можно пропустить хорошую комбинацию гиперпараметров;\n",
        "  - кросс-валидацию можно делать с меньшим числом разбиений или фолдов, но в таком случае оценка качества становится более шумной и увеличивается риск выбрать неоптимальный набор гиперпараметров из-за случайности разбиения;\n",
        "  - гиперпараметры можно оптимизировать последовательно (жадно) — один за другим, а не перебирать все комбинации; такая стратегия не всегда приводит к оптимальному набору;\n",
        "  - перебирать не все комбинации гиперпараметров, а небольшое число случайно выбранных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7gJIgbLRUFC"
      },
      "source": [
        "В этой лабораторной работе мы научимся обучать модели машинного обучения, корректно ставить эксперименты, подбирать гиперпараметры, сравнивать и смешивать модели. Вам предлагается решить задачу бинарной классификации, а именно построить алгоритм, предсказывающий победу команды в компьютерной игре Dota2.\n",
        " \n",
        "Более подробно про данные можно почитать на странице первого конкурсного [соревнования](https://www.kaggle.com/t/f2f20fc510f042dfa9751a03c6108805). Целевой признак записан в переменной radiant_win. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RbRJk2vRUFD"
      },
      "source": [
        "### Обучение классификаторов на вещественных признаках"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRJY63VoJd5g"
      },
      "source": [
        "#### Импорты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSpu1jfEJcl7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ4jJiT4RUFE"
      },
      "source": [
        "#### Загрузка данных\n",
        "\n",
        "Загрузите набор данных *train.csv*, *gold.csv* и *lh.csv*. Чтобы лучше понимать, с чем вы работаете/корректно ли вы загрузили данные можно вывести несколько первых строк на экран."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOvqo8vCRj0V",
        "outputId": "3cf232f7-205f-40d3-dba4-6ce5d53232c3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYEVJOlKRUFG"
      },
      "source": [
        "path_to_data = '/content/drive/MyDrive/lab1_data/'\n",
        "train_df = pd.read_csv(path_to_data + 'train.csv')\n",
        "gold_df = pd.read_csv(path_to_data + 'gold.csv')\n",
        "lh_df = pd.read_csv(path_to_data + 'lh.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "T6HLdrWwRUFH",
        "outputId": "8f93d7ba-c6be-4a6d-fc3e-9e030238b0f7"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mid</th>\n",
              "      <th>radiant_won</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24969</th>\n",
              "      <td>49939</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24970</th>\n",
              "      <td>49940</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24971</th>\n",
              "      <td>49941</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24972</th>\n",
              "      <td>49945</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24973</th>\n",
              "      <td>49946</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24974 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         mid  radiant_won\n",
              "0          0            1\n",
              "1          1            0\n",
              "2          2            1\n",
              "3          4            1\n",
              "4          5            1\n",
              "...      ...          ...\n",
              "24969  49939            0\n",
              "24970  49940            1\n",
              "24971  49941            1\n",
              "24972  49945            0\n",
              "24973  49946            0\n",
              "\n",
              "[24974 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uP6nv7ecRUFK",
        "outputId": "940b468a-df5a-4f1b-e506-a71aea4cfdbc"
      },
      "source": [
        "gold_df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mid</th>\n",
              "      <th>times</th>\n",
              "      <th>player_0</th>\n",
              "      <th>player_1</th>\n",
              "      <th>player_2</th>\n",
              "      <th>player_3</th>\n",
              "      <th>player_4</th>\n",
              "      <th>player_5</th>\n",
              "      <th>player_6</th>\n",
              "      <th>player_7</th>\n",
              "      <th>player_8</th>\n",
              "      <th>player_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>750</td>\n",
              "      <td>350</td>\n",
              "      <td>389</td>\n",
              "      <td>437</td>\n",
              "      <td>428</td>\n",
              "      <td>398</td>\n",
              "      <td>344</td>\n",
              "      <td>654</td>\n",
              "      <td>287</td>\n",
              "      <td>1056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>957</td>\n",
              "      <td>1071</td>\n",
              "      <td>633</td>\n",
              "      <td>655</td>\n",
              "      <td>1080</td>\n",
              "      <td>669</td>\n",
              "      <td>1147</td>\n",
              "      <td>1164</td>\n",
              "      <td>438</td>\n",
              "      <td>1360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>180</td>\n",
              "      <td>1161</td>\n",
              "      <td>1527</td>\n",
              "      <td>782</td>\n",
              "      <td>1103</td>\n",
              "      <td>1346</td>\n",
              "      <td>1058</td>\n",
              "      <td>1479</td>\n",
              "      <td>1574</td>\n",
              "      <td>587</td>\n",
              "      <td>2072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>240</td>\n",
              "      <td>1571</td>\n",
              "      <td>2033</td>\n",
              "      <td>932</td>\n",
              "      <td>1515</td>\n",
              "      <td>2058</td>\n",
              "      <td>1760</td>\n",
              "      <td>1767</td>\n",
              "      <td>2387</td>\n",
              "      <td>737</td>\n",
              "      <td>2283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>300</td>\n",
              "      <td>1721</td>\n",
              "      <td>2313</td>\n",
              "      <td>1082</td>\n",
              "      <td>1790</td>\n",
              "      <td>2699</td>\n",
              "      <td>2087</td>\n",
              "      <td>1986</td>\n",
              "      <td>2898</td>\n",
              "      <td>887</td>\n",
              "      <td>3302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499475</th>\n",
              "      <td>49947</td>\n",
              "      <td>360</td>\n",
              "      <td>2640</td>\n",
              "      <td>1356</td>\n",
              "      <td>4493</td>\n",
              "      <td>3186</td>\n",
              "      <td>2720</td>\n",
              "      <td>2244</td>\n",
              "      <td>1236</td>\n",
              "      <td>2150</td>\n",
              "      <td>2232</td>\n",
              "      <td>2850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499476</th>\n",
              "      <td>49947</td>\n",
              "      <td>420</td>\n",
              "      <td>3176</td>\n",
              "      <td>1854</td>\n",
              "      <td>5259</td>\n",
              "      <td>3336</td>\n",
              "      <td>3299</td>\n",
              "      <td>2706</td>\n",
              "      <td>1449</td>\n",
              "      <td>2541</td>\n",
              "      <td>2621</td>\n",
              "      <td>3345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499477</th>\n",
              "      <td>49947</td>\n",
              "      <td>480</td>\n",
              "      <td>3760</td>\n",
              "      <td>2005</td>\n",
              "      <td>6313</td>\n",
              "      <td>3487</td>\n",
              "      <td>3450</td>\n",
              "      <td>3171</td>\n",
              "      <td>1600</td>\n",
              "      <td>3360</td>\n",
              "      <td>3184</td>\n",
              "      <td>3865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499478</th>\n",
              "      <td>49947</td>\n",
              "      <td>540</td>\n",
              "      <td>4041</td>\n",
              "      <td>2155</td>\n",
              "      <td>7999</td>\n",
              "      <td>4242</td>\n",
              "      <td>3724</td>\n",
              "      <td>3541</td>\n",
              "      <td>2271</td>\n",
              "      <td>3883</td>\n",
              "      <td>3453</td>\n",
              "      <td>4513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499479</th>\n",
              "      <td>49947</td>\n",
              "      <td>600</td>\n",
              "      <td>4371</td>\n",
              "      <td>2655</td>\n",
              "      <td>9069</td>\n",
              "      <td>4518</td>\n",
              "      <td>4494</td>\n",
              "      <td>3951</td>\n",
              "      <td>2421</td>\n",
              "      <td>4423</td>\n",
              "      <td>3963</td>\n",
              "      <td>4969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>499480 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          mid  times  player_0  ...  player_7  player_8  player_9\n",
              "0           0     60       750  ...       654       287      1056\n",
              "1           0    120       957  ...      1164       438      1360\n",
              "2           0    180      1161  ...      1574       587      2072\n",
              "3           0    240      1571  ...      2387       737      2283\n",
              "4           0    300      1721  ...      2898       887      3302\n",
              "...       ...    ...       ...  ...       ...       ...       ...\n",
              "499475  49947    360      2640  ...      2150      2232      2850\n",
              "499476  49947    420      3176  ...      2541      2621      3345\n",
              "499477  49947    480      3760  ...      3360      3184      3865\n",
              "499478  49947    540      4041  ...      3883      3453      4513\n",
              "499479  49947    600      4371  ...      4423      3963      4969\n",
              "\n",
              "[499480 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dX-jnGZqRUFL",
        "outputId": "e819407f-e9a0-4ae7-b110-670ac4ee7545"
      },
      "source": [
        "lh_df"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mid</th>\n",
              "      <th>times</th>\n",
              "      <th>player_0</th>\n",
              "      <th>player_1</th>\n",
              "      <th>player_2</th>\n",
              "      <th>player_3</th>\n",
              "      <th>player_4</th>\n",
              "      <th>player_5</th>\n",
              "      <th>player_6</th>\n",
              "      <th>player_7</th>\n",
              "      <th>player_8</th>\n",
              "      <th>player_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>180</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>240</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>300</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>19</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499475</th>\n",
              "      <td>49947</td>\n",
              "      <td>360</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>27</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>19</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499476</th>\n",
              "      <td>49947</td>\n",
              "      <td>420</td>\n",
              "      <td>31</td>\n",
              "      <td>9</td>\n",
              "      <td>35</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "      <td>26</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>24</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499477</th>\n",
              "      <td>49947</td>\n",
              "      <td>480</td>\n",
              "      <td>39</td>\n",
              "      <td>9</td>\n",
              "      <td>46</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "      <td>31</td>\n",
              "      <td>5</td>\n",
              "      <td>29</td>\n",
              "      <td>28</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499478</th>\n",
              "      <td>49947</td>\n",
              "      <td>540</td>\n",
              "      <td>41</td>\n",
              "      <td>9</td>\n",
              "      <td>61</td>\n",
              "      <td>8</td>\n",
              "      <td>37</td>\n",
              "      <td>36</td>\n",
              "      <td>5</td>\n",
              "      <td>31</td>\n",
              "      <td>30</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499479</th>\n",
              "      <td>49947</td>\n",
              "      <td>600</td>\n",
              "      <td>45</td>\n",
              "      <td>10</td>\n",
              "      <td>65</td>\n",
              "      <td>10</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>5</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>499480 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          mid  times  player_0  ...  player_7  player_8  player_9\n",
              "0           0     60         1  ...         7         1         2\n",
              "1           0    120         1  ...        14         1         6\n",
              "2           0    180         2  ...        18         1         9\n",
              "3           0    240         2  ...        29         1        10\n",
              "4           0    300         2  ...        36         1        19\n",
              "...       ...    ...       ...  ...       ...       ...       ...\n",
              "499475  49947    360        25  ...        21        19        21\n",
              "499476  49947    420        31  ...        27        24        27\n",
              "499477  49947    480        39  ...        29        28        34\n",
              "499478  49947    540        41  ...        31        30        42\n",
              "499479  49947    600        45  ...        37        37        48\n",
              "\n",
              "[499480 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P11u-2VnRUFM"
      },
      "source": [
        "#### 1\n",
        "\n",
        "Иногда в данных встречаются пропуски. Способ обозначения пропусков либо прописывается в описании к данным, либо на месте пропуска после чтения данных оказывается значение [NaN](https://docs.scipy.org/doc/numpy-1.13.0/user/misc.html). Более подробно о работе с пропусками в Pandas можно прочитать например [здесь](http://pandas.pydata.org/pandas-docs/stable/missing_data.html). \n",
        "\n",
        "В данном датасете пропущенные значения обозначены как \"-1\". \n",
        "\n",
        "**Задание 1** (1 балл) \n",
        "\n",
        "Проанализируйте датасет и найдите все признаки, имеющие пропущенные значения (опишите свои наблюдения). \n",
        "\n",
        "Предобработайте текущий датасет так, что бы в нём не осталось пропусков (обоснуйте свой выбор метода предобработки)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE27BbHWRUFN"
      },
      "source": [
        "***Решение задания 1:***\n",
        "\n",
        "В датасете нет пропусков, но если бы были: \n",
        "\n",
        "*В train.csv:* \n",
        "\n",
        "Строки с пропусками убрать из датасета, т.к. по ним всё равно ничего нельзя предсказать/обучить. Если нет значения в `mid`, нельзя сопоставить отклику `radiant_won` предикторы. А если нет значения в `radiant_won`, то не известен отклик для набора предикторов. \n",
        "\n",
        "*В gold.csv и lh.csv*: \n",
        "\n",
        "Если нет значения в `mid`, то не известно, к какой команде относятся данные -> не известен отклик и не понятно, к чему \"подклеивать\". Следовательно, строки с пропусками в колонке `mid` удалить. \n",
        "\n",
        "Если нет значения признака у игрока (одного или нескольких) в любой из таблиц, то можно заменить пропуск: \n",
        "   \n",
        "   * Средним значением по строке - средним по команде. \n",
        "   * Значением в предыдущий момент времени для того же игрока. \n",
        "   * Значением в следующий момент времени для того же игрока.\n",
        "   * Средним значением между значениями в предыдущий и последующий моменты времени для того же игрока. \n",
        "\n",
        "Я использую (примерно) замену средним, реализуя это с помощью `pd.DataFrame.interpolate` (см. пример кода). \n",
        "   \n",
        "Если пропущенно значение в колонке `times`, то заменю пропуск значением из предыдущей записи той же команды плюс 60 секунд (т.к. можно увидеть эту закономерность в столбце).\n",
        "\n",
        "\n",
        "Для примера кода возьму небольшой кусочек от `lh_df`, искусственно сделаю в нем немного пропусков и поборюсь с ними:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk7usw9vRUFP",
        "outputId": "76370118-7d16-43ab-9b40-1b2f111b04db"
      },
      "source": [
        "# искусственный кусочек с пропусками\n",
        "\n",
        "mydf = lh_df[:20]\n",
        "mydf = mydf.replace([13, 7, 63], -1)\n",
        "mydf = mydf.replace(180, -1)\n",
        "mydf['mid'][6, 15] = [-1, -1]\n",
        "\n",
        "mydf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mid</th>\n",
              "      <th>times</th>\n",
              "      <th>player_0</th>\n",
              "      <th>player_1</th>\n",
              "      <th>player_2</th>\n",
              "      <th>player_3</th>\n",
              "      <th>player_4</th>\n",
              "      <th>player_5</th>\n",
              "      <th>player_6</th>\n",
              "      <th>player_7</th>\n",
              "      <th>player_8</th>\n",
              "      <th>player_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>240</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>300</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>19</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>360</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>24</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-1</td>\n",
              "      <td>420</td>\n",
              "      <td>3</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>30</td>\n",
              "      <td>16</td>\n",
              "      <td>21</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>480</td>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>35</td>\n",
              "      <td>16</td>\n",
              "      <td>28</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>4</td>\n",
              "      <td>37</td>\n",
              "      <td>2</td>\n",
              "      <td>43</td>\n",
              "      <td>40</td>\n",
              "      <td>25</td>\n",
              "      <td>30</td>\n",
              "      <td>72</td>\n",
              "      <td>2</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>600</td>\n",
              "      <td>4</td>\n",
              "      <td>43</td>\n",
              "      <td>3</td>\n",
              "      <td>57</td>\n",
              "      <td>41</td>\n",
              "      <td>34</td>\n",
              "      <td>35</td>\n",
              "      <td>75</td>\n",
              "      <td>2</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>-1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>240</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "      <td>-1</td>\n",
              "      <td>19</td>\n",
              "      <td>-1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>300</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>24</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-1</td>\n",
              "      <td>360</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>29</td>\n",
              "      <td>25</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>420</td>\n",
              "      <td>4</td>\n",
              "      <td>37</td>\n",
              "      <td>9</td>\n",
              "      <td>21</td>\n",
              "      <td>37</td>\n",
              "      <td>26</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>480</td>\n",
              "      <td>4</td>\n",
              "      <td>48</td>\n",
              "      <td>-1</td>\n",
              "      <td>24</td>\n",
              "      <td>41</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>540</td>\n",
              "      <td>5</td>\n",
              "      <td>54</td>\n",
              "      <td>14</td>\n",
              "      <td>28</td>\n",
              "      <td>47</td>\n",
              "      <td>46</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>600</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>14</td>\n",
              "      <td>28</td>\n",
              "      <td>47</td>\n",
              "      <td>49</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mid  times  player_0  player_1  ...  player_6  player_7  player_8  player_9\n",
              "0     0     60         1         2  ...         2        -1         1         2\n",
              "1     0    120         1         5  ...         6        14         1         6\n",
              "2     0     -1         2        10  ...         9        18         1         9\n",
              "3     0    240         2        -1  ...        12        29         1        10\n",
              "4     0    300         2        15  ...        -1        36         1        19\n",
              "5     0    360         2        20  ...        17        42         1        31\n",
              "6    -1    420         3        26  ...        21        52         1        31\n",
              "7     0    480         4        36  ...        28        -1         2        36\n",
              "8     0    540         4        37  ...        30        72         2        38\n",
              "9     0    600         4        43  ...        35        75         2        46\n",
              "10    1     60         1         2  ...         3         1         2         5\n",
              "11    1    120         1         5  ...         4         1         8         8\n",
              "12    1     -1         1        -1  ...         9         1        14        -1\n",
              "13    1    240         1        20  ...        10         1        15        17\n",
              "14    1    300         1        23  ...        12         2        16        18\n",
              "15   -1    360         4        29  ...        14         2        18        20\n",
              "16    1    420         4        37  ...        14         2        25        29\n",
              "17    1    480         4        48  ...        16         2        25        34\n",
              "18    1    540         5        54  ...        20         2        27        39\n",
              "19    1    600         5        -1  ...        23         3        30        39\n",
              "\n",
              "[20 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKjtMNkkRUFQ",
        "outputId": "8f015e75-c9ad-41e7-f0fd-de466f1d8a0a"
      },
      "source": [
        "# чтобы было проще с ними работать, заменю -1 на NaN\n",
        "mydf = mydf.replace(-1, np.NaN)\n",
        "\n",
        "# посмотрю, где сколько пропусков  \n",
        "mydf.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mid         2\n",
              "times       2\n",
              "player_0    0\n",
              "player_1    3\n",
              "player_2    1\n",
              "player_3    3\n",
              "player_4    1\n",
              "player_5    3\n",
              "player_6    1\n",
              "player_7    2\n",
              "player_8    0\n",
              "player_9    1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6BQ4YyORUFR",
        "outputId": "af883ad7-05d5-4d25-a59d-363f513da090"
      },
      "source": [
        "# выброшу строки с пропущенными значениями в `mid`\n",
        "mydf = mydf.dropna(subset=['mid'])\n",
        "# почему-то после этой операции значения в `mid` стали float, поэтому так:\n",
        "mydf['mid'] = mydf['mid'].astype(int)\n",
        "mydf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mid</th>\n",
              "      <th>times</th>\n",
              "      <th>player_0</th>\n",
              "      <th>player_1</th>\n",
              "      <th>player_2</th>\n",
              "      <th>player_3</th>\n",
              "      <th>player_4</th>\n",
              "      <th>player_5</th>\n",
              "      <th>player_6</th>\n",
              "      <th>player_7</th>\n",
              "      <th>player_8</th>\n",
              "      <th>player_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>2</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>2</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>480.0</td>\n",
              "      <td>4</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>36.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>4</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>2</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>4</td>\n",
              "      <td>43.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>2</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>240.0</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>300.0</td>\n",
              "      <td>1</td>\n",
              "      <td>23.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>420.0</td>\n",
              "      <td>4</td>\n",
              "      <td>37.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>25</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>480.0</td>\n",
              "      <td>4</td>\n",
              "      <td>48.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>25</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>540.0</td>\n",
              "      <td>5</td>\n",
              "      <td>54.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>27</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>600.0</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>30</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mid  times  player_0  player_1  ...  player_6  player_7  player_8  player_9\n",
              "0     0   60.0         1       2.0  ...       2.0       NaN         1       2.0\n",
              "1     0  120.0         1       5.0  ...       6.0      14.0         1       6.0\n",
              "2     0    NaN         2      10.0  ...       9.0      18.0         1       9.0\n",
              "3     0  240.0         2       NaN  ...      12.0      29.0         1      10.0\n",
              "4     0  300.0         2      15.0  ...       NaN      36.0         1      19.0\n",
              "5     0  360.0         2      20.0  ...      17.0      42.0         1      31.0\n",
              "7     0  480.0         4      36.0  ...      28.0       NaN         2      36.0\n",
              "8     0  540.0         4      37.0  ...      30.0      72.0         2      38.0\n",
              "9     0  600.0         4      43.0  ...      35.0      75.0         2      46.0\n",
              "10    1   60.0         1       2.0  ...       3.0       1.0         2       5.0\n",
              "11    1  120.0         1       5.0  ...       4.0       1.0         8       8.0\n",
              "12    1    NaN         1       NaN  ...       9.0       1.0        14       NaN\n",
              "13    1  240.0         1      20.0  ...      10.0       1.0        15      17.0\n",
              "14    1  300.0         1      23.0  ...      12.0       2.0        16      18.0\n",
              "16    1  420.0         4      37.0  ...      14.0       2.0        25      29.0\n",
              "17    1  480.0         4      48.0  ...      16.0       2.0        25      34.0\n",
              "18    1  540.0         5      54.0  ...      20.0       2.0        27      39.0\n",
              "19    1  600.0         5       NaN  ...      23.0       3.0        30      39.0\n",
              "\n",
              "[18 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxZ5LAshRUFS"
      },
      "source": [
        "Здесь прохожусь по каждой игре отдельно, чтобы данные других игр не учитывались при замене пропущенных значений для одной игры. \n",
        "\n",
        "Для заполнения основных пропусков ипользую `interpolate()` с `method='linear'` (значение параметра по умолчанию).\n",
        "\n",
        "И привожу всё обратно к `int`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3pRAWnORUFS",
        "outputId": "560ba4e8-50f5-4e6e-bb1e-e6408b9d4a14"
      },
      "source": [
        "filled_mydf = pd.DataFrame()\n",
        "for i in mydf['mid'].unique():\n",
        "    mid_filled = mydf[mydf['mid'] == i].interpolate(limit_direction=\"both\").astype(int)\n",
        "    filled_mydf = pd.concat([filled_mydf, mid_filled])\n",
        "    \n",
        "filled_mydf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mid</th>\n",
              "      <th>times</th>\n",
              "      <th>player_0</th>\n",
              "      <th>player_1</th>\n",
              "      <th>player_2</th>\n",
              "      <th>player_3</th>\n",
              "      <th>player_4</th>\n",
              "      <th>player_5</th>\n",
              "      <th>player_6</th>\n",
              "      <th>player_7</th>\n",
              "      <th>player_8</th>\n",
              "      <th>player_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>180</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>240</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>300</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>19</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>360</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>24</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>480</td>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>35</td>\n",
              "      <td>16</td>\n",
              "      <td>28</td>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>4</td>\n",
              "      <td>37</td>\n",
              "      <td>2</td>\n",
              "      <td>43</td>\n",
              "      <td>40</td>\n",
              "      <td>25</td>\n",
              "      <td>30</td>\n",
              "      <td>72</td>\n",
              "      <td>2</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>600</td>\n",
              "      <td>4</td>\n",
              "      <td>43</td>\n",
              "      <td>3</td>\n",
              "      <td>57</td>\n",
              "      <td>41</td>\n",
              "      <td>34</td>\n",
              "      <td>35</td>\n",
              "      <td>75</td>\n",
              "      <td>2</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>180</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>240</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>19</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>300</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>24</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>420</td>\n",
              "      <td>4</td>\n",
              "      <td>37</td>\n",
              "      <td>9</td>\n",
              "      <td>21</td>\n",
              "      <td>37</td>\n",
              "      <td>26</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>480</td>\n",
              "      <td>4</td>\n",
              "      <td>48</td>\n",
              "      <td>11</td>\n",
              "      <td>24</td>\n",
              "      <td>41</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>540</td>\n",
              "      <td>5</td>\n",
              "      <td>54</td>\n",
              "      <td>14</td>\n",
              "      <td>28</td>\n",
              "      <td>47</td>\n",
              "      <td>46</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>600</td>\n",
              "      <td>5</td>\n",
              "      <td>54</td>\n",
              "      <td>14</td>\n",
              "      <td>28</td>\n",
              "      <td>47</td>\n",
              "      <td>49</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mid  times  player_0  player_1  ...  player_6  player_7  player_8  player_9\n",
              "0     0     60         1         2  ...         2        14         1         2\n",
              "1     0    120         1         5  ...         6        14         1         6\n",
              "2     0    180         2        10  ...         9        18         1         9\n",
              "3     0    240         2        12  ...        12        29         1        10\n",
              "4     0    300         2        15  ...        14        36         1        19\n",
              "5     0    360         2        20  ...        17        42         1        31\n",
              "7     0    480         4        36  ...        28        57         2        36\n",
              "8     0    540         4        37  ...        30        72         2        38\n",
              "9     0    600         4        43  ...        35        75         2        46\n",
              "10    1     60         1         2  ...         3         1         2         5\n",
              "11    1    120         1         5  ...         4         1         8         8\n",
              "12    1    180         1        12  ...         9         1        14        12\n",
              "13    1    240         1        20  ...        10         1        15        17\n",
              "14    1    300         1        23  ...        12         2        16        18\n",
              "16    1    420         4        37  ...        14         2        25        29\n",
              "17    1    480         4        48  ...        16         2        25        34\n",
              "18    1    540         5        54  ...        20         2        27        39\n",
              "19    1    600         5        54  ...        23         3        30        39\n",
              "\n",
              "[18 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wShj0RtLRUFT"
      },
      "source": [
        "#### 2\n",
        "\n",
        "В начале мы будем работать только с вещественными признаками. \n",
        "\n",
        "Возьмите из *gold.csv* и *lh.csv* данные по 600 секунде для каждого матча и подклейте их к *train.csv* (см. [булево индексирование](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing) и [join](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html?highlight=join#pandas.DataFrame.join))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "MBdRDSByRUFU",
        "outputId": "63246cd1-d2fe-4e9d-f872-7ddd70dd821e"
      },
      "source": [
        "# подклеиваю gold\n",
        "train_df = train_df.join(gold_df[gold_df['times'] == 600].set_index('mid'), on='mid')\n",
        "# подклеиваю lh, добавляя к колонкам суффикс '_lh'\n",
        "train_df = train_df.join(lh_df[lh_df['times'] == 600].set_index('mid'), on='mid', lsuffix='_lh')\n",
        "# убираю колонки про время\n",
        "train_df = train_df.drop(columns=['times_lh', 'times'])\n",
        "train_df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mid</th>\n",
              "      <th>radiant_won</th>\n",
              "      <th>player_0_lh</th>\n",
              "      <th>player_1_lh</th>\n",
              "      <th>player_2_lh</th>\n",
              "      <th>player_3_lh</th>\n",
              "      <th>player_4_lh</th>\n",
              "      <th>player_5_lh</th>\n",
              "      <th>player_6_lh</th>\n",
              "      <th>player_7_lh</th>\n",
              "      <th>player_8_lh</th>\n",
              "      <th>player_9_lh</th>\n",
              "      <th>player_0</th>\n",
              "      <th>player_1</th>\n",
              "      <th>player_2</th>\n",
              "      <th>player_3</th>\n",
              "      <th>player_4</th>\n",
              "      <th>player_5</th>\n",
              "      <th>player_6</th>\n",
              "      <th>player_7</th>\n",
              "      <th>player_8</th>\n",
              "      <th>player_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3454</td>\n",
              "      <td>5206</td>\n",
              "      <td>2613</td>\n",
              "      <td>4426</td>\n",
              "      <td>5755</td>\n",
              "      <td>4072</td>\n",
              "      <td>3997</td>\n",
              "      <td>5917</td>\n",
              "      <td>1725</td>\n",
              "      <td>6384</td>\n",
              "      <td>4</td>\n",
              "      <td>43</td>\n",
              "      <td>3</td>\n",
              "      <td>57</td>\n",
              "      <td>41</td>\n",
              "      <td>34</td>\n",
              "      <td>35</td>\n",
              "      <td>75</td>\n",
              "      <td>2</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2477</td>\n",
              "      <td>5760</td>\n",
              "      <td>3816</td>\n",
              "      <td>4353</td>\n",
              "      <td>5759</td>\n",
              "      <td>7659</td>\n",
              "      <td>5066</td>\n",
              "      <td>2748</td>\n",
              "      <td>4440</td>\n",
              "      <td>4623</td>\n",
              "      <td>5</td>\n",
              "      <td>63</td>\n",
              "      <td>14</td>\n",
              "      <td>28</td>\n",
              "      <td>47</td>\n",
              "      <td>49</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3604</td>\n",
              "      <td>1948</td>\n",
              "      <td>8581</td>\n",
              "      <td>4390</td>\n",
              "      <td>2869</td>\n",
              "      <td>3096</td>\n",
              "      <td>2301</td>\n",
              "      <td>5130</td>\n",
              "      <td>2530</td>\n",
              "      <td>2491</td>\n",
              "      <td>34</td>\n",
              "      <td>6</td>\n",
              "      <td>69</td>\n",
              "      <td>42</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>56</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3675</td>\n",
              "      <td>4103</td>\n",
              "      <td>5154</td>\n",
              "      <td>3030</td>\n",
              "      <td>2076</td>\n",
              "      <td>3920</td>\n",
              "      <td>3494</td>\n",
              "      <td>3392</td>\n",
              "      <td>4458</td>\n",
              "      <td>2220</td>\n",
              "      <td>30</td>\n",
              "      <td>41</td>\n",
              "      <td>45</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>37</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4252</td>\n",
              "      <td>2412</td>\n",
              "      <td>2545</td>\n",
              "      <td>4264</td>\n",
              "      <td>2544</td>\n",
              "      <td>4752</td>\n",
              "      <td>5389</td>\n",
              "      <td>4954</td>\n",
              "      <td>3954</td>\n",
              "      <td>2992</td>\n",
              "      <td>42</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>42</td>\n",
              "      <td>24</td>\n",
              "      <td>53</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24969</th>\n",
              "      <td>49939</td>\n",
              "      <td>0</td>\n",
              "      <td>4262</td>\n",
              "      <td>7316</td>\n",
              "      <td>3996</td>\n",
              "      <td>3863</td>\n",
              "      <td>2199</td>\n",
              "      <td>5718</td>\n",
              "      <td>3876</td>\n",
              "      <td>4296</td>\n",
              "      <td>4497</td>\n",
              "      <td>2520</td>\n",
              "      <td>49</td>\n",
              "      <td>74</td>\n",
              "      <td>30</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>47</td>\n",
              "      <td>5</td>\n",
              "      <td>35</td>\n",
              "      <td>39</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24970</th>\n",
              "      <td>49940</td>\n",
              "      <td>1</td>\n",
              "      <td>7250</td>\n",
              "      <td>3984</td>\n",
              "      <td>6380</td>\n",
              "      <td>2954</td>\n",
              "      <td>6243</td>\n",
              "      <td>3095</td>\n",
              "      <td>5105</td>\n",
              "      <td>1811</td>\n",
              "      <td>4823</td>\n",
              "      <td>2471</td>\n",
              "      <td>48</td>\n",
              "      <td>2</td>\n",
              "      <td>54</td>\n",
              "      <td>12</td>\n",
              "      <td>61</td>\n",
              "      <td>26</td>\n",
              "      <td>71</td>\n",
              "      <td>4</td>\n",
              "      <td>49</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24971</th>\n",
              "      <td>49941</td>\n",
              "      <td>1</td>\n",
              "      <td>2873</td>\n",
              "      <td>4727</td>\n",
              "      <td>4655</td>\n",
              "      <td>4923</td>\n",
              "      <td>3645</td>\n",
              "      <td>5978</td>\n",
              "      <td>2801</td>\n",
              "      <td>3875</td>\n",
              "      <td>4644</td>\n",
              "      <td>5213</td>\n",
              "      <td>31</td>\n",
              "      <td>54</td>\n",
              "      <td>42</td>\n",
              "      <td>52</td>\n",
              "      <td>7</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>16</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24972</th>\n",
              "      <td>49945</td>\n",
              "      <td>0</td>\n",
              "      <td>2325</td>\n",
              "      <td>1813</td>\n",
              "      <td>2530</td>\n",
              "      <td>4807</td>\n",
              "      <td>5542</td>\n",
              "      <td>2242</td>\n",
              "      <td>2359</td>\n",
              "      <td>5997</td>\n",
              "      <td>5523</td>\n",
              "      <td>2044</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>37</td>\n",
              "      <td>67</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>61</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24973</th>\n",
              "      <td>49946</td>\n",
              "      <td>0</td>\n",
              "      <td>4134</td>\n",
              "      <td>3141</td>\n",
              "      <td>4086</td>\n",
              "      <td>4405</td>\n",
              "      <td>3517</td>\n",
              "      <td>2887</td>\n",
              "      <td>7450</td>\n",
              "      <td>3634</td>\n",
              "      <td>5431</td>\n",
              "      <td>5451</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>15</td>\n",
              "      <td>23</td>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>72</td>\n",
              "      <td>4</td>\n",
              "      <td>51</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24974 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         mid  radiant_won  player_0_lh  ...  player_7  player_8  player_9\n",
              "0          0            1         3454  ...        75         2        46\n",
              "1          1            0         2477  ...         3        30        39\n",
              "2          2            1         3604  ...        56        13        12\n",
              "3          4            1         3675  ...        23        37         6\n",
              "4          5            1         4252  ...        53        12        14\n",
              "...      ...          ...          ...  ...       ...       ...       ...\n",
              "24969  49939            0         4262  ...        35        39         4\n",
              "24970  49940            1         7250  ...         4        49         5\n",
              "24971  49941            1         2873  ...        10        16        53\n",
              "24972  49945            0         2325  ...        61        49         2\n",
              "24973  49946            0         4134  ...         4        51        36\n",
              "\n",
              "[24974 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bWVO6t_RUFV"
      },
      "source": [
        "**Задание 2** (1 балл)\n",
        "\n",
        "Постройте для команд radiant и dire различные агригаты по игрокам на 600 секунде. Опишите какие именно агригаты вы построили и почему."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1_DpbzwRUFW"
      },
      "source": [
        "***Решение задания 2:***\n",
        "\n",
        "И для *gold*, и для *lh* возьму суммарное значение по каждой команде, так как это опишет команды как целое. Среднее брать не будет смысла, так как это сумма/5 - линейная зависимость. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "mKDtEDP4RUFW",
        "outputId": "ff64d016-dd89-481a-9d09-f58fd9ea8c15"
      },
      "source": [
        "train_df['rad_gold_sum'] = train_df.iloc[:, 12:17].apply(lambda x: sum(x), axis=1)\n",
        "train_df['dire_gold_sum'] = train_df.iloc[:, 17:22].apply(lambda x: sum(x), axis=1)\n",
        "train_df['rad_lh_sum'] = train_df.iloc[:, 2:7].apply(lambda x: sum(x), axis=1)\n",
        "train_df['dire_lh_sum'] = train_df.iloc[:, 7:12].apply(lambda x: sum(x), axis=1)\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mid</th>\n",
              "      <th>radiant_won</th>\n",
              "      <th>player_0_lh</th>\n",
              "      <th>player_1_lh</th>\n",
              "      <th>player_2_lh</th>\n",
              "      <th>player_3_lh</th>\n",
              "      <th>player_4_lh</th>\n",
              "      <th>player_5_lh</th>\n",
              "      <th>player_6_lh</th>\n",
              "      <th>player_7_lh</th>\n",
              "      <th>player_8_lh</th>\n",
              "      <th>player_9_lh</th>\n",
              "      <th>player_0</th>\n",
              "      <th>player_1</th>\n",
              "      <th>player_2</th>\n",
              "      <th>player_3</th>\n",
              "      <th>player_4</th>\n",
              "      <th>player_5</th>\n",
              "      <th>player_6</th>\n",
              "      <th>player_7</th>\n",
              "      <th>player_8</th>\n",
              "      <th>player_9</th>\n",
              "      <th>rad_gold_sum</th>\n",
              "      <th>dire_gold_sum</th>\n",
              "      <th>rad_lh_sum</th>\n",
              "      <th>dire_lh_sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3454</td>\n",
              "      <td>5206</td>\n",
              "      <td>2613</td>\n",
              "      <td>4426</td>\n",
              "      <td>5755</td>\n",
              "      <td>4072</td>\n",
              "      <td>3997</td>\n",
              "      <td>5917</td>\n",
              "      <td>1725</td>\n",
              "      <td>6384</td>\n",
              "      <td>4</td>\n",
              "      <td>43</td>\n",
              "      <td>3</td>\n",
              "      <td>57</td>\n",
              "      <td>41</td>\n",
              "      <td>34</td>\n",
              "      <td>35</td>\n",
              "      <td>75</td>\n",
              "      <td>2</td>\n",
              "      <td>46</td>\n",
              "      <td>148</td>\n",
              "      <td>192</td>\n",
              "      <td>21454</td>\n",
              "      <td>22095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2477</td>\n",
              "      <td>5760</td>\n",
              "      <td>3816</td>\n",
              "      <td>4353</td>\n",
              "      <td>5759</td>\n",
              "      <td>7659</td>\n",
              "      <td>5066</td>\n",
              "      <td>2748</td>\n",
              "      <td>4440</td>\n",
              "      <td>4623</td>\n",
              "      <td>5</td>\n",
              "      <td>63</td>\n",
              "      <td>14</td>\n",
              "      <td>28</td>\n",
              "      <td>47</td>\n",
              "      <td>49</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>39</td>\n",
              "      <td>157</td>\n",
              "      <td>144</td>\n",
              "      <td>22165</td>\n",
              "      <td>24536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3604</td>\n",
              "      <td>1948</td>\n",
              "      <td>8581</td>\n",
              "      <td>4390</td>\n",
              "      <td>2869</td>\n",
              "      <td>3096</td>\n",
              "      <td>2301</td>\n",
              "      <td>5130</td>\n",
              "      <td>2530</td>\n",
              "      <td>2491</td>\n",
              "      <td>34</td>\n",
              "      <td>6</td>\n",
              "      <td>69</td>\n",
              "      <td>42</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>56</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>174</td>\n",
              "      <td>99</td>\n",
              "      <td>21392</td>\n",
              "      <td>15548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3675</td>\n",
              "      <td>4103</td>\n",
              "      <td>5154</td>\n",
              "      <td>3030</td>\n",
              "      <td>2076</td>\n",
              "      <td>3920</td>\n",
              "      <td>3494</td>\n",
              "      <td>3392</td>\n",
              "      <td>4458</td>\n",
              "      <td>2220</td>\n",
              "      <td>30</td>\n",
              "      <td>41</td>\n",
              "      <td>45</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>37</td>\n",
              "      <td>6</td>\n",
              "      <td>143</td>\n",
              "      <td>101</td>\n",
              "      <td>18038</td>\n",
              "      <td>17484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4252</td>\n",
              "      <td>2412</td>\n",
              "      <td>2545</td>\n",
              "      <td>4264</td>\n",
              "      <td>2544</td>\n",
              "      <td>4752</td>\n",
              "      <td>5389</td>\n",
              "      <td>4954</td>\n",
              "      <td>3954</td>\n",
              "      <td>2992</td>\n",
              "      <td>42</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>42</td>\n",
              "      <td>24</td>\n",
              "      <td>53</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>96</td>\n",
              "      <td>145</td>\n",
              "      <td>16017</td>\n",
              "      <td>22041</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mid  radiant_won  player_0_lh  ...  dire_gold_sum  rad_lh_sum  dire_lh_sum\n",
              "0    0            1         3454  ...            192       21454        22095\n",
              "1    1            0         2477  ...            144       22165        24536\n",
              "2    2            1         3604  ...             99       21392        15548\n",
              "3    4            1         3675  ...            101       18038        17484\n",
              "4    5            1         4252  ...            145       16017        22041\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-kTQ6aKRUFX"
      },
      "source": [
        "Так же посчитаю для каждой команды стандартное отклонение для *lh* и  *gold*. Полагаю, что это будет показывать разброс \"активности\" игроков команды: маленькая дисперсия - все играют примерно одинаково, большая - у игроков или разные стратегии, или навыки игры и т.п. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "3F5kqaIzRUFY",
        "outputId": "751d5d8f-2591-401b-e0f3-f1122e013515"
      },
      "source": [
        "train_df['rad_gold_std'] = train_df.iloc[:, 12:17].apply(lambda x: np.std(x), axis=1)\n",
        "train_df['dire_gold_std'] = train_df.iloc[:, 17:22].apply(lambda x: np.std(x), axis=1)\n",
        "train_df['rad_lh_std'] = train_df.iloc[:, 2:7].apply(lambda x: np.std(x), axis=1)\n",
        "train_df['dire_lh_std'] = train_df.iloc[:, 7:12].apply(lambda x: np.std(x), axis=1)\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mid</th>\n",
              "      <th>radiant_won</th>\n",
              "      <th>player_0_lh</th>\n",
              "      <th>player_1_lh</th>\n",
              "      <th>player_2_lh</th>\n",
              "      <th>player_3_lh</th>\n",
              "      <th>player_4_lh</th>\n",
              "      <th>player_5_lh</th>\n",
              "      <th>player_6_lh</th>\n",
              "      <th>player_7_lh</th>\n",
              "      <th>player_8_lh</th>\n",
              "      <th>player_9_lh</th>\n",
              "      <th>player_0</th>\n",
              "      <th>player_1</th>\n",
              "      <th>player_2</th>\n",
              "      <th>player_3</th>\n",
              "      <th>player_4</th>\n",
              "      <th>player_5</th>\n",
              "      <th>player_6</th>\n",
              "      <th>player_7</th>\n",
              "      <th>player_8</th>\n",
              "      <th>player_9</th>\n",
              "      <th>rad_gold_sum</th>\n",
              "      <th>dire_gold_sum</th>\n",
              "      <th>rad_lh_sum</th>\n",
              "      <th>dire_lh_sum</th>\n",
              "      <th>rad_gold_std</th>\n",
              "      <th>dire_gold_std</th>\n",
              "      <th>rad_lh_std</th>\n",
              "      <th>dire_lh_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3454</td>\n",
              "      <td>5206</td>\n",
              "      <td>2613</td>\n",
              "      <td>4426</td>\n",
              "      <td>5755</td>\n",
              "      <td>4072</td>\n",
              "      <td>3997</td>\n",
              "      <td>5917</td>\n",
              "      <td>1725</td>\n",
              "      <td>6384</td>\n",
              "      <td>4</td>\n",
              "      <td>43</td>\n",
              "      <td>3</td>\n",
              "      <td>57</td>\n",
              "      <td>41</td>\n",
              "      <td>34</td>\n",
              "      <td>35</td>\n",
              "      <td>75</td>\n",
              "      <td>2</td>\n",
              "      <td>46</td>\n",
              "      <td>148</td>\n",
              "      <td>192</td>\n",
              "      <td>21454</td>\n",
              "      <td>22095</td>\n",
              "      <td>22.014541</td>\n",
              "      <td>23.465720</td>\n",
              "      <td>1141.490149</td>\n",
              "      <td>1652.958439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2477</td>\n",
              "      <td>5760</td>\n",
              "      <td>3816</td>\n",
              "      <td>4353</td>\n",
              "      <td>5759</td>\n",
              "      <td>7659</td>\n",
              "      <td>5066</td>\n",
              "      <td>2748</td>\n",
              "      <td>4440</td>\n",
              "      <td>4623</td>\n",
              "      <td>5</td>\n",
              "      <td>63</td>\n",
              "      <td>14</td>\n",
              "      <td>28</td>\n",
              "      <td>47</td>\n",
              "      <td>49</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>39</td>\n",
              "      <td>157</td>\n",
              "      <td>144</td>\n",
              "      <td>22165</td>\n",
              "      <td>24536</td>\n",
              "      <td>21.228283</td>\n",
              "      <td>15.574338</td>\n",
              "      <td>1243.561820</td>\n",
              "      <td>1584.853987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3604</td>\n",
              "      <td>1948</td>\n",
              "      <td>8581</td>\n",
              "      <td>4390</td>\n",
              "      <td>2869</td>\n",
              "      <td>3096</td>\n",
              "      <td>2301</td>\n",
              "      <td>5130</td>\n",
              "      <td>2530</td>\n",
              "      <td>2491</td>\n",
              "      <td>34</td>\n",
              "      <td>6</td>\n",
              "      <td>69</td>\n",
              "      <td>42</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>56</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>174</td>\n",
              "      <td>99</td>\n",
              "      <td>21392</td>\n",
              "      <td>15548</td>\n",
              "      <td>20.932272</td>\n",
              "      <td>18.269100</td>\n",
              "      <td>2297.686193</td>\n",
              "      <td>1044.474720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3675</td>\n",
              "      <td>4103</td>\n",
              "      <td>5154</td>\n",
              "      <td>3030</td>\n",
              "      <td>2076</td>\n",
              "      <td>3920</td>\n",
              "      <td>3494</td>\n",
              "      <td>3392</td>\n",
              "      <td>4458</td>\n",
              "      <td>2220</td>\n",
              "      <td>30</td>\n",
              "      <td>41</td>\n",
              "      <td>45</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>37</td>\n",
              "      <td>6</td>\n",
              "      <td>143</td>\n",
              "      <td>101</td>\n",
              "      <td>18038</td>\n",
              "      <td>17484</td>\n",
              "      <td>14.568459</td>\n",
              "      <td>11.408769</td>\n",
              "      <td>1031.575223</td>\n",
              "      <td>740.839092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4252</td>\n",
              "      <td>2412</td>\n",
              "      <td>2545</td>\n",
              "      <td>4264</td>\n",
              "      <td>2544</td>\n",
              "      <td>4752</td>\n",
              "      <td>5389</td>\n",
              "      <td>4954</td>\n",
              "      <td>3954</td>\n",
              "      <td>2992</td>\n",
              "      <td>42</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>42</td>\n",
              "      <td>24</td>\n",
              "      <td>53</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>96</td>\n",
              "      <td>145</td>\n",
              "      <td>16017</td>\n",
              "      <td>22041</td>\n",
              "      <td>14.905033</td>\n",
              "      <td>16.024980</td>\n",
              "      <td>862.443876</td>\n",
              "      <td>847.347013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mid  radiant_won  player_0_lh  ...  dire_gold_std   rad_lh_std  dire_lh_std\n",
              "0    0            1         3454  ...      23.465720  1141.490149  1652.958439\n",
              "1    1            0         2477  ...      15.574338  1243.561820  1584.853987\n",
              "2    2            1         3604  ...      18.269100  2297.686193  1044.474720\n",
              "3    4            1         3675  ...      11.408769  1031.575223   740.839092\n",
              "4    5            1         4252  ...      16.024980   862.443876   847.347013\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phF-qjpbRUFZ"
      },
      "source": [
        "Я долго думала и не сообразила, надо ли после создания агрегатов убирать исходные признаки. Решила, что все убирать не буду, но уберу все признаки для `player_0` и `player_5`, чтобы убрать линейную зависимость, возникшую при добавлении суммы по командам. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCDXt8qRRUFZ"
      },
      "source": [
        "train_df = train_df.drop(columns=['player_0', 'player_0_lh', 'player_5', 'player_5_lh'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "ZSJmt9QeRUFa",
        "outputId": "d0ea318e-5988-46c8-ddee-2ffb85ef6af8"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mid</th>\n",
              "      <th>radiant_won</th>\n",
              "      <th>player_1_lh</th>\n",
              "      <th>player_2_lh</th>\n",
              "      <th>player_3_lh</th>\n",
              "      <th>player_4_lh</th>\n",
              "      <th>player_6_lh</th>\n",
              "      <th>player_7_lh</th>\n",
              "      <th>player_8_lh</th>\n",
              "      <th>player_9_lh</th>\n",
              "      <th>player_1</th>\n",
              "      <th>player_2</th>\n",
              "      <th>player_3</th>\n",
              "      <th>player_4</th>\n",
              "      <th>player_6</th>\n",
              "      <th>player_7</th>\n",
              "      <th>player_8</th>\n",
              "      <th>player_9</th>\n",
              "      <th>rad_gold_sum</th>\n",
              "      <th>dire_gold_sum</th>\n",
              "      <th>rad_lh_sum</th>\n",
              "      <th>dire_lh_sum</th>\n",
              "      <th>rad_gold_std</th>\n",
              "      <th>dire_gold_std</th>\n",
              "      <th>rad_lh_std</th>\n",
              "      <th>dire_lh_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5206</td>\n",
              "      <td>2613</td>\n",
              "      <td>4426</td>\n",
              "      <td>5755</td>\n",
              "      <td>3997</td>\n",
              "      <td>5917</td>\n",
              "      <td>1725</td>\n",
              "      <td>6384</td>\n",
              "      <td>43</td>\n",
              "      <td>3</td>\n",
              "      <td>57</td>\n",
              "      <td>41</td>\n",
              "      <td>35</td>\n",
              "      <td>75</td>\n",
              "      <td>2</td>\n",
              "      <td>46</td>\n",
              "      <td>148</td>\n",
              "      <td>192</td>\n",
              "      <td>21454</td>\n",
              "      <td>22095</td>\n",
              "      <td>22.014541</td>\n",
              "      <td>23.465720</td>\n",
              "      <td>1141.490149</td>\n",
              "      <td>1652.958439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5760</td>\n",
              "      <td>3816</td>\n",
              "      <td>4353</td>\n",
              "      <td>5759</td>\n",
              "      <td>5066</td>\n",
              "      <td>2748</td>\n",
              "      <td>4440</td>\n",
              "      <td>4623</td>\n",
              "      <td>63</td>\n",
              "      <td>14</td>\n",
              "      <td>28</td>\n",
              "      <td>47</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>39</td>\n",
              "      <td>157</td>\n",
              "      <td>144</td>\n",
              "      <td>22165</td>\n",
              "      <td>24536</td>\n",
              "      <td>21.228283</td>\n",
              "      <td>15.574338</td>\n",
              "      <td>1243.561820</td>\n",
              "      <td>1584.853987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1948</td>\n",
              "      <td>8581</td>\n",
              "      <td>4390</td>\n",
              "      <td>2869</td>\n",
              "      <td>2301</td>\n",
              "      <td>5130</td>\n",
              "      <td>2530</td>\n",
              "      <td>2491</td>\n",
              "      <td>6</td>\n",
              "      <td>69</td>\n",
              "      <td>42</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>56</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>174</td>\n",
              "      <td>99</td>\n",
              "      <td>21392</td>\n",
              "      <td>15548</td>\n",
              "      <td>20.932272</td>\n",
              "      <td>18.269100</td>\n",
              "      <td>2297.686193</td>\n",
              "      <td>1044.474720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4103</td>\n",
              "      <td>5154</td>\n",
              "      <td>3030</td>\n",
              "      <td>2076</td>\n",
              "      <td>3494</td>\n",
              "      <td>3392</td>\n",
              "      <td>4458</td>\n",
              "      <td>2220</td>\n",
              "      <td>41</td>\n",
              "      <td>45</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>37</td>\n",
              "      <td>6</td>\n",
              "      <td>143</td>\n",
              "      <td>101</td>\n",
              "      <td>18038</td>\n",
              "      <td>17484</td>\n",
              "      <td>14.568459</td>\n",
              "      <td>11.408769</td>\n",
              "      <td>1031.575223</td>\n",
              "      <td>740.839092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2412</td>\n",
              "      <td>2545</td>\n",
              "      <td>4264</td>\n",
              "      <td>2544</td>\n",
              "      <td>5389</td>\n",
              "      <td>4954</td>\n",
              "      <td>3954</td>\n",
              "      <td>2992</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>53</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>96</td>\n",
              "      <td>145</td>\n",
              "      <td>16017</td>\n",
              "      <td>22041</td>\n",
              "      <td>14.905033</td>\n",
              "      <td>16.024980</td>\n",
              "      <td>862.443876</td>\n",
              "      <td>847.347013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mid  radiant_won  player_1_lh  ...  dire_gold_std   rad_lh_std  dire_lh_std\n",
              "0    0            1         5206  ...      23.465720  1141.490149  1652.958439\n",
              "1    1            0         5760  ...      15.574338  1243.561820  1584.853987\n",
              "2    2            1         1948  ...      18.269100  2297.686193  1044.474720\n",
              "3    4            1         4103  ...      11.408769  1031.575223   740.839092\n",
              "4    5            1         2412  ...      16.024980   862.443876   847.347013\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRCyQpM7RUFb"
      },
      "source": [
        "#### подготовка\n",
        "\n",
        "Сейчас и далее будем рассматривать следующие алгоритмы:\n",
        " - [Logistic Regression Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
        " - [C-Support Vector Classification](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
        " - [Multi-layer Perceptron Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93MzwrjpRUFb"
      },
      "source": [
        "Разделю данные на обучающую и тестовую выборку."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqbgTUiHRUFc"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_df.drop(columns=['mid', 'radiant_won']), train_df['radiant_won'], test_size=0.2, random_state=1234)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rCn4qB1H5fI",
        "outputId": "d35077fc-e2fd-4272-fb30-42b968f8c741"
      },
      "source": [
        "len(X_train), len(X_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19979, 4995)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGje5dYyRUFd"
      },
      "source": [
        "Посмотрю, сбалансированы ли классы. В изначальных данных: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpoSyNJaRUFe",
        "outputId": "9cbec8c6-8575-4bc0-d917-73898981af70"
      },
      "source": [
        "train_df['radiant_won'].value_counts()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    12974\n",
              "0    12000\n",
              "Name: radiant_won, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMkCt348RUFf"
      },
      "source": [
        "В обучающей и тестовой выборках:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o_NjUmwRUFg",
        "outputId": "a16b58b6-e513-45ad-e22d-d3b0dd6fa1e0"
      },
      "source": [
        "y_train.value_counts(), y_test.value_counts()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1    10407\n",
              " 0     9572\n",
              " Name: radiant_won, dtype: int64, 1    2567\n",
              " 0    2428\n",
              " Name: radiant_won, dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVFMdtT_RUFh"
      },
      "source": [
        "Все хорошо, везде классы сбалансированы. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXAMjlGTRUFi"
      },
      "source": [
        "#### 3\n",
        "\n",
        "**Задание 3** (1.5 балла) \n",
        "\n",
        "Для каждого алгоритма выберете один гиперпараметр и подберите его оптимальное значение. Для подбора гиперпараметров воспользуйтесь перебором по сетке, который реализован в классе [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV). В качестве схемы кросс-валидации используйте 5-Fold CV, которую можно задать с помощью класса [KFoldCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold).\n",
        "\n",
        "Постройте график среднего значения качества по кросс-валидации алгоритма при заданном значении гиперпараметра, на котором также отобразите доверительный интервал. Для получения значения качества на каждом фолде, среднего значение качества и другой полезной информации можно воспользоваться полем [*cv results_*](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)\n",
        "\n",
        "У какого алгоритма наибольшее среднее значение качества? Наибольший доверительный интервал?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSJiHId0bPL-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaF5FtxvRUFj"
      },
      "source": [
        "***Решение задания 3:***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_1stzjPRUFk"
      },
      "source": [
        "Согласно документации к GridSearchCV, там по умолчанию используется 5-fold кросс-валидация (и для классификатора используется StratifiedKFold вместо KFold, чтобы сохранить соотношение классов). Поэтому для осуществления 5-fold CV просто ничего не меняю в модели. \n",
        "\n",
        "Иcпользую `scoring='roc-auc'`. \n",
        "\n",
        "*Чтобы модели обучались за терпимое время, буду использовать по 4000 элементов от исходных данных.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw7AhB8xX-r6"
      },
      "source": [
        "data_part=4000\n",
        "test_part=1000"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf839fZ3RUFl"
      },
      "source": [
        "##### 3 LogReg\n",
        "**3.1. Logistic Regression Classifier**\n",
        "\n",
        "Буду подбирать значение для `C` - inverse of regularization strength. \n",
        "\n",
        "Хотела сначала оставить всё остальное дефолтное( `penalty='l2'`, `solver='lbfgs'`, `tol=1e-4`), но так алгоритм не сходился и ругался на масштаб признаков. Поменяла `solver` на `liblinear`: сошлось!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4FwfrqZRUFm",
        "outputId": "02350f42-38b1-46d9-9193-c7ed487d1b79"
      },
      "source": [
        "# Инициализирую модель\n",
        "logreg_model = LogisticRegression(penalty='l2', \n",
        "                                  tol=0.0001, \n",
        "                                  C=1.0, \n",
        "                                  solver='liblinear', \n",
        "                                  random_state=1234,\n",
        "                                  max_iter=100)\n",
        "\n",
        "# Тестируемые значения гиперпараметрa \n",
        "logreg_params_set = {\n",
        "'C': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 1e2, 1e3, 1e4]\n",
        "}\n",
        "\n",
        "# Кросс-валидация\n",
        "logreg_CV = GridSearchCV(estimator=logreg_model,\n",
        "                         param_grid=logreg_params_set,\n",
        "                         scoring='roc_auc',\n",
        "                         return_train_score=True)\n",
        "\n",
        "logreg_CV.fit(X_train[:data_part], y_train[:data_part])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=1234, solver='liblinear',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100.0, 1000.0,\n",
              "                               10000.0]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjnP8sHZRUFn"
      },
      "source": [
        "Лучший параметр и значение критерия качества на нём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHEYZE46RUFo",
        "outputId": "15a82be4-c727-4f02-e760-a116ca974a1a"
      },
      "source": [
        "logreg_CV.best_params_ , logreg_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'C': 10}, 0.7129001759427966)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTUpYL7HRUFo"
      },
      "source": [
        "График среднего значения качества:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "gHxowzOoRUFp",
        "outputId": "4ab744b7-646c-4df2-fcbb-569fd7abd1a8"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(logreg_params_set['C'], logreg_CV.cv_results_['mean_train_score'], 'bo-', label='train')\n",
        "plt.plot(logreg_params_set['C'], logreg_CV.cv_results_['mean_test_score'], 'go-', label='test')\n",
        "\n",
        "plt.fill_between(logreg_params_set['C'], \n",
        "                 logreg_CV.cv_results_['mean_train_score']-logreg_CV.cv_results_['std_train_score'], \n",
        "                 logreg_CV.cv_results_['mean_train_score']+logreg_CV.cv_results_['std_train_score'], \n",
        "                 color='blue', alpha=0.1)\n",
        "plt.fill_between(logreg_params_set['C'], \n",
        "                 logreg_CV.cv_results_['mean_test_score']-logreg_CV.cv_results_['std_test_score'], \n",
        "                 logreg_CV.cv_results_['mean_test_score']+logreg_CV.cv_results_['std_test_score'], \n",
        "                 color='green', alpha=0.1)\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('C'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('Logistic Regression')\n",
        "plt.xscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F3t1AZNbzoP"
      },
      "source": [
        "Оценка качества на части (1000 элементов) тестовой выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfZJ8yESaqZT",
        "outputId": "6714fa00-4bd2-433a-f50a-576de2e73688"
      },
      "source": [
        "lr_test_score = roc_auc_score(y_true=y_test[:test_part], y_score=logreg_CV.best_estimator_.predict(X_test[:test_part]))\n",
        "lr_test_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6837360122584026"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPkjV7fDRUFq"
      },
      "source": [
        "##### 3 SVC\n",
        "**3.2. C-Support Vector Classification**\n",
        "\n",
        "Буду так же подбирать значение для `C` - inverse of regularization strength. \n",
        "\n",
        "Остальные параметры оставляю по умолчанию. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxa4zSqLRUFq",
        "outputId": "306d6538-e3a6-484c-b5ed-d1ef3a3699a4"
      },
      "source": [
        "# Инициализирую модель\n",
        "svc_model = SVC(C=1.0, \n",
        "                kernel='rbf',\n",
        "                gamma='scale',\n",
        "                shrinking=True,\n",
        "                tol=0.001,\n",
        "                random_state=1234)\n",
        "\n",
        "# Тестируемые значения гиперпараметрa \n",
        "svc_params_set = {\n",
        "'C': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 1e2, 1e3, 1e4]\n",
        "}\n",
        "\n",
        "# Кросс-валидация\n",
        "svc_CV = GridSearchCV(estimator=svc_model,\n",
        "                      param_grid=svc_params_set,\n",
        "                      scoring='roc_auc',\n",
        "                      return_train_score=True,\n",
        "                      verbose=3)\n",
        "\n",
        "svc_CV.fit(X_train[:data_part], y_train[:data_part])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] C=0.0001 ........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........ C=0.0001, score=(train=0.706, test=0.747), total=   0.9s\n",
            "[CV] C=0.0001 ........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........ C=0.0001, score=(train=0.719, test=0.693), total=   0.9s\n",
            "[CV] C=0.0001 ........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........ C=0.0001, score=(train=0.710, test=0.732), total=   0.8s\n",
            "[CV] C=0.0001 ........................................................\n",
            "[CV] ........ C=0.0001, score=(train=0.718, test=0.700), total=   0.8s\n",
            "[CV] C=0.0001 ........................................................\n",
            "[CV] ........ C=0.0001, score=(train=0.721, test=0.691), total=   0.8s\n",
            "[CV] C=0.001 .........................................................\n",
            "[CV] ......... C=0.001, score=(train=0.706, test=0.747), total=   0.8s\n",
            "[CV] C=0.001 .........................................................\n",
            "[CV] ......... C=0.001, score=(train=0.719, test=0.693), total=   0.9s\n",
            "[CV] C=0.001 .........................................................\n",
            "[CV] ......... C=0.001, score=(train=0.710, test=0.732), total=   0.8s\n",
            "[CV] C=0.001 .........................................................\n",
            "[CV] ......... C=0.001, score=(train=0.718, test=0.699), total=   0.8s\n",
            "[CV] C=0.001 .........................................................\n",
            "[CV] ......... C=0.001, score=(train=0.720, test=0.692), total=   0.8s\n",
            "[CV] C=0.01 ..........................................................\n",
            "[CV] .......... C=0.01, score=(train=0.706, test=0.747), total=   0.8s\n",
            "[CV] C=0.01 ..........................................................\n",
            "[CV] .......... C=0.01, score=(train=0.719, test=0.693), total=   0.9s\n",
            "[CV] C=0.01 ..........................................................\n",
            "[CV] .......... C=0.01, score=(train=0.710, test=0.732), total=   0.9s\n",
            "[CV] C=0.01 ..........................................................\n",
            "[CV] .......... C=0.01, score=(train=0.718, test=0.699), total=   0.8s\n",
            "[CV] C=0.01 ..........................................................\n",
            "[CV] .......... C=0.01, score=(train=0.720, test=0.692), total=   0.8s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ........... C=0.1, score=(train=0.707, test=0.744), total=   0.8s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ........... C=0.1, score=(train=0.720, test=0.694), total=   0.8s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ........... C=0.1, score=(train=0.711, test=0.732), total=   0.8s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ........... C=0.1, score=(train=0.718, test=0.702), total=   0.8s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ........... C=0.1, score=(train=0.722, test=0.688), total=   0.8s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ............. C=1, score=(train=0.709, test=0.745), total=   0.7s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ............. C=1, score=(train=0.722, test=0.693), total=   0.7s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ............. C=1, score=(train=0.713, test=0.730), total=   0.7s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ............. C=1, score=(train=0.719, test=0.703), total=   0.7s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ............. C=1, score=(train=0.725, test=0.683), total=   0.7s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ............ C=10, score=(train=0.713, test=0.743), total=   0.7s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ............ C=10, score=(train=0.727, test=0.689), total=   0.7s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ............ C=10, score=(train=0.716, test=0.730), total=   0.7s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ............ C=10, score=(train=0.724, test=0.705), total=   0.7s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ............ C=10, score=(train=0.729, test=0.677), total=   0.7s\n",
            "[CV] C=100.0 .........................................................\n",
            "[CV] ......... C=100.0, score=(train=0.723, test=0.737), total=   0.9s\n",
            "[CV] C=100.0 .........................................................\n",
            "[CV] ......... C=100.0, score=(train=0.734, test=0.683), total=   0.9s\n",
            "[CV] C=100.0 .........................................................\n",
            "[CV] ......... C=100.0, score=(train=0.724, test=0.732), total=   0.9s\n",
            "[CV] C=100.0 .........................................................\n",
            "[CV] ......... C=100.0, score=(train=0.732, test=0.698), total=   0.9s\n",
            "[CV] C=100.0 .........................................................\n",
            "[CV] ......... C=100.0, score=(train=0.735, test=0.680), total=   0.9s\n",
            "[CV] C=1000.0 ........................................................\n",
            "[CV] ........ C=1000.0, score=(train=0.737, test=0.729), total=   1.7s\n",
            "[CV] C=1000.0 ........................................................\n",
            "[CV] ........ C=1000.0, score=(train=0.746, test=0.683), total=   1.8s\n",
            "[CV] C=1000.0 ........................................................\n",
            "[CV] ........ C=1000.0, score=(train=0.739, test=0.727), total=   1.8s\n",
            "[CV] C=1000.0 ........................................................\n",
            "[CV] ........ C=1000.0, score=(train=0.746, test=0.686), total=   1.8s\n",
            "[CV] C=1000.0 ........................................................\n",
            "[CV] ........ C=1000.0, score=(train=0.749, test=0.683), total=   1.8s\n",
            "[CV] C=10000.0 .......................................................\n",
            "[CV] ....... C=10000.0, score=(train=0.765, test=0.714), total=   9.6s\n",
            "[CV] C=10000.0 .......................................................\n",
            "[CV] ....... C=10000.0, score=(train=0.769, test=0.688), total=   8.8s\n",
            "[CV] C=10000.0 .......................................................\n",
            "[CV] ....... C=10000.0, score=(train=0.765, test=0.711), total=   9.5s\n",
            "[CV] C=10000.0 .......................................................\n",
            "[CV] ....... C=10000.0, score=(train=0.769, test=0.688), total=   9.9s\n",
            "[CV] C=10000.0 .......................................................\n",
            "[CV] ....... C=10000.0, score=(train=0.772, test=0.671), total=  10.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=1234, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100.0, 1000.0,\n",
              "                               10000.0]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zJ6sZXtRUFr"
      },
      "source": [
        "Лучший параметр и значение критерия качества на нём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61JXEzX9RUFr",
        "outputId": "6dbf7782-2639-451f-a0e1-c9bb45a6e310"
      },
      "source": [
        "svc_CV.best_params_ , svc_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'C': 0.001}, 0.7125971285634678)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ig92RUBRUFs"
      },
      "source": [
        "График среднего значения качества:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "-3QCq4ZNRUFt",
        "outputId": "06203e28-339e-4586-97c7-7fb8033fb90f"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(svc_params_set['C'], svc_CV.cv_results_['mean_train_score'], 'bo-', label='train')\n",
        "plt.plot(svc_params_set['C'], svc_CV.cv_results_['mean_test_score'], 'go-', label='test')\n",
        "\n",
        "plt.fill_between(svc_params_set['C'], \n",
        "                 svc_CV.cv_results_['mean_train_score']-svc_CV.cv_results_['std_train_score'], \n",
        "                 svc_CV.cv_results_['mean_train_score']+svc_CV.cv_results_['std_train_score'], \n",
        "                 color='blue', alpha=0.1)\n",
        "plt.fill_between(svc_params_set['C'], \n",
        "                 svc_CV.cv_results_['mean_test_score']-svc_CV.cv_results_['std_test_score'], \n",
        "                 svc_CV.cv_results_['mean_test_score']+svc_CV.cv_results_['std_test_score'], \n",
        "                 color='green', alpha=0.1)\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('C'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('SVC')\n",
        "plt.xscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HnETetlcSm6"
      },
      "source": [
        "Оценка качества на части (1000 элементов) тестовой выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3IuLlzdcSm8",
        "outputId": "3fdf5660-3438-4277-80b4-9fd6d5b80200"
      },
      "source": [
        "svc_test_score = roc_auc_score(y_true=y_test[:test_part], y_score=svc_CV.best_estimator_.predict(X_test[:test_part]))\n",
        "svc_test_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kTQTu7oRUFu"
      },
      "source": [
        "##### 3 MLPC\n",
        "**3.3. Multi-layer Perceptron classifier**\n",
        "\n",
        "Буду так же подбирать параметр, отвечающий за регуляризацию: `alpha`.\n",
        "\n",
        "C остальными параметрами по умолчанию алгоритм не сходился, поэтому я попробовала заменить функцию активации на `logistic` вместо `relu` - заработало. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56JJr5OaRUFu",
        "outputId": "deb92116-6c52-4230-d69e-e510c92d73f5"
      },
      "source": [
        "# Инициализирую модель\n",
        "mlpc_model = MLPClassifier(alpha=0.0001,\n",
        "                           activation='logistic',\n",
        "                           solver='adam',\n",
        "                           learning_rate='constant', \n",
        "                           learning_rate_init=0.001,\n",
        "                           tol=0.0001,\n",
        "                           max_iter=200,\n",
        "                           random_state=1234)\n",
        "\n",
        "# Тестируемые значения гиперпараметрa \n",
        "mlpc_params_set = {\n",
        "'alpha': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 1e2, 1e3, 1e4, 1e5]\n",
        "}\n",
        "\n",
        "# Кросс-валидация\n",
        "mlpc_CV = GridSearchCV(estimator=mlpc_model,\n",
        "                       param_grid=mlpc_params_set,\n",
        "                       scoring='roc_auc',\n",
        "                       return_train_score=True,\n",
        "                       verbose=3)\n",
        "\n",
        "mlpc_CV.fit(X_train[:data_part], y_train[:data_part])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV] alpha=0.0001 ....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... alpha=0.0001, score=(train=0.675, test=0.727), total=   1.0s\n",
            "[CV] alpha=0.0001 ....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... alpha=0.0001, score=(train=0.695, test=0.661), total=   1.1s\n",
            "[CV] alpha=0.0001 ....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... alpha=0.0001, score=(train=0.679, test=0.693), total=   0.6s\n",
            "[CV] alpha=0.0001 ....................................................\n",
            "[CV] .... alpha=0.0001, score=(train=0.678, test=0.665), total=   0.7s\n",
            "[CV] alpha=0.0001 ....................................................\n",
            "[CV] .... alpha=0.0001, score=(train=0.694, test=0.644), total=   0.8s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ..... alpha=0.001, score=(train=0.691, test=0.728), total=   0.5s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ..... alpha=0.001, score=(train=0.702, test=0.673), total=   0.7s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ..... alpha=0.001, score=(train=0.681, test=0.693), total=   1.2s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ..... alpha=0.001, score=(train=0.696, test=0.690), total=   1.2s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ..... alpha=0.001, score=(train=0.698, test=0.674), total=   0.8s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] ...... alpha=0.01, score=(train=0.669, test=0.712), total=   1.4s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] ...... alpha=0.01, score=(train=0.676, test=0.662), total=   0.9s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] ...... alpha=0.01, score=(train=0.690, test=0.721), total=   0.8s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] ...... alpha=0.01, score=(train=0.691, test=0.699), total=   0.9s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] ...... alpha=0.01, score=(train=0.685, test=0.661), total=   1.2s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.685, test=0.739), total=   1.3s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.693, test=0.688), total=   0.8s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.697, test=0.716), total=   1.1s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.675, test=0.680), total=   0.9s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.687, test=0.666), total=   0.7s\n",
            "[CV] alpha=1 .........................................................\n",
            "[CV] ......... alpha=1, score=(train=0.690, test=0.736), total=   0.9s\n",
            "[CV] alpha=1 .........................................................\n",
            "[CV] ......... alpha=1, score=(train=0.695, test=0.679), total=   0.6s\n",
            "[CV] alpha=1 .........................................................\n",
            "[CV] ......... alpha=1, score=(train=0.679, test=0.712), total=   0.9s\n",
            "[CV] alpha=1 .........................................................\n",
            "[CV] ......... alpha=1, score=(train=0.698, test=0.685), total=   0.7s\n",
            "[CV] alpha=1 .........................................................\n",
            "[CV] ......... alpha=1, score=(train=0.678, test=0.645), total=   0.9s\n",
            "[CV] alpha=10 ........................................................\n",
            "[CV] ........ alpha=10, score=(train=0.690, test=0.715), total=   1.1s\n",
            "[CV] alpha=10 ........................................................\n",
            "[CV] ........ alpha=10, score=(train=0.706, test=0.682), total=   0.7s\n",
            "[CV] alpha=10 ........................................................\n",
            "[CV] ........ alpha=10, score=(train=0.693, test=0.714), total=   1.3s\n",
            "[CV] alpha=10 ........................................................\n",
            "[CV] ........ alpha=10, score=(train=0.700, test=0.688), total=   0.8s\n",
            "[CV] alpha=10 ........................................................\n",
            "[CV] ........ alpha=10, score=(train=0.710, test=0.672), total=   1.4s\n",
            "[CV] alpha=100.0 .....................................................\n",
            "[CV] ..... alpha=100.0, score=(train=0.702, test=0.736), total=   1.4s\n",
            "[CV] alpha=100.0 .....................................................\n",
            "[CV] ..... alpha=100.0, score=(train=0.711, test=0.675), total=   1.6s\n",
            "[CV] alpha=100.0 .....................................................\n",
            "[CV] ..... alpha=100.0, score=(train=0.709, test=0.732), total=   1.4s\n",
            "[CV] alpha=100.0 .....................................................\n",
            "[CV] ..... alpha=100.0, score=(train=0.714, test=0.693), total=   1.4s\n",
            "[CV] alpha=100.0 .....................................................\n",
            "[CV] ..... alpha=100.0, score=(train=0.714, test=0.688), total=   1.5s\n",
            "[CV] alpha=1000.0 ....................................................\n",
            "[CV] .... alpha=1000.0, score=(train=0.705, test=0.744), total=   0.9s\n",
            "[CV] alpha=1000.0 ....................................................\n",
            "[CV] .... alpha=1000.0, score=(train=0.717, test=0.692), total=   1.1s\n",
            "[CV] alpha=1000.0 ....................................................\n",
            "[CV] .... alpha=1000.0, score=(train=0.709, test=0.732), total=   0.8s\n",
            "[CV] alpha=1000.0 ....................................................\n",
            "[CV] .... alpha=1000.0, score=(train=0.713, test=0.699), total=   0.8s\n",
            "[CV] alpha=1000.0 ....................................................\n",
            "[CV] .... alpha=1000.0, score=(train=0.715, test=0.680), total=   0.9s\n",
            "[CV] alpha=10000.0 ...................................................\n",
            "[CV] ... alpha=10000.0, score=(train=0.702, test=0.747), total=   1.1s\n",
            "[CV] alpha=10000.0 ...................................................\n",
            "[CV] ... alpha=10000.0, score=(train=0.719, test=0.691), total=   1.1s\n",
            "[CV] alpha=10000.0 ...................................................\n",
            "[CV] ... alpha=10000.0, score=(train=0.710, test=0.732), total=   0.8s\n",
            "[CV] alpha=10000.0 ...................................................\n",
            "[CV] ... alpha=10000.0, score=(train=0.718, test=0.701), total=   0.8s\n",
            "[CV] alpha=10000.0 ...................................................\n",
            "[CV] ... alpha=10000.0, score=(train=0.720, test=0.692), total=   1.0s\n",
            "[CV] alpha=100000.0 ..................................................\n",
            "[CV] .. alpha=100000.0, score=(train=0.519, test=0.551), total=   0.9s\n",
            "[CV] alpha=100000.0 ..................................................\n",
            "[CV] .. alpha=100000.0, score=(train=0.441, test=0.494), total=   0.9s\n",
            "[CV] alpha=100000.0 ..................................................\n",
            "[CV] .. alpha=100000.0, score=(train=0.448, test=0.405), total=   0.9s\n",
            "[CV] alpha=100000.0 ..................................................\n",
            "[CV] .. alpha=100000.0, score=(train=0.501, test=0.504), total=   0.9s\n",
            "[CV] alpha=100000.0 ..................................................\n",
            "[CV] .. alpha=100000.0, score=(train=0.446, test=0.425), total=   0.9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   50.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='logistic', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=200, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_state=1234, shuffle=True,\n",
              "                                     solver='adam', tol=0.0001,\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100.0,\n",
              "                                   1000.0, 10000.0, 100000.0]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iq_2cwTRUFv"
      },
      "source": [
        "Лучший параметр и значение критерия качества на нём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_RmWohORUFv",
        "outputId": "a31701e1-6e05-4276-d99b-38c3aa01aea5"
      },
      "source": [
        "mlpc_CV.best_params_ , mlpc_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'alpha': 10000.0}, 0.7123729736837163)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNwoV2d_RUFw"
      },
      "source": [
        "График среднего значения качества:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "m5qOPsOMRUFw",
        "outputId": "62b9d093-d5dd-4311-fe42-6eb3efa833d6"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(mlpc_params_set['alpha'], mlpc_CV.cv_results_['mean_train_score'], 'bo-', label='train')\n",
        "plt.plot(mlpc_params_set['alpha'], mlpc_CV.cv_results_['mean_test_score'], 'go-', label='test')\n",
        "\n",
        "plt.fill_between(mlpc_params_set['alpha'], \n",
        "                 mlpc_CV.cv_results_['mean_train_score']-mlpc_CV.cv_results_['std_train_score'], \n",
        "                 mlpc_CV.cv_results_['mean_train_score']+mlpc_CV.cv_results_['std_train_score'], \n",
        "                 color='blue', alpha=0.1)\n",
        "plt.fill_between(mlpc_params_set['alpha'], \n",
        "                 mlpc_CV.cv_results_['mean_test_score']-mlpc_CV.cv_results_['std_test_score'], \n",
        "                 mlpc_CV.cv_results_['mean_test_score']+mlpc_CV.cv_results_['std_test_score'], \n",
        "                 color='green', alpha=0.1)\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('alpha'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('MLPClassifier')\n",
        "plt.xscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ-_i8Kxcg4S"
      },
      "source": [
        "Оценка качества на части (1000 элементов) тестовой выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slZLejiMcg4U",
        "outputId": "6725e9ff-a3fa-40b3-b5cd-33f98c9953a2"
      },
      "source": [
        "mlpc_test_score = roc_auc_score(y_true=y_test[:test_part], y_score=mlpc_CV.best_estimator_.predict(X_test[:test_part]))\n",
        "mlpc_test_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAy1EhBGSpsV"
      },
      "source": [
        "##### 3 Сравнение\n",
        "\n",
        "Сравню модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "IomyPpZfRUFx",
        "outputId": "14f49726-b20c-49b9-eef3-aba673546678"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(logreg_params_set['C'], logreg_CV.cv_results_['mean_test_score'], 'go-', label='logreg test')\n",
        "plt.fill_between(logreg_params_set['C'], \n",
        "                 logreg_CV.cv_results_['mean_test_score']-logreg_CV.cv_results_['std_test_score'], \n",
        "                 logreg_CV.cv_results_['mean_test_score']+logreg_CV.cv_results_['std_test_score'], \n",
        "                 color='green', alpha=0.1)\n",
        "\n",
        "plt.plot(svc_params_set['C'], svc_CV.cv_results_['mean_test_score'], 'bo-', label='SVC test')\n",
        "plt.fill_between(svc_params_set['C'], \n",
        "                 svc_CV.cv_results_['mean_test_score']-svc_CV.cv_results_['std_test_score'], \n",
        "                 svc_CV.cv_results_['mean_test_score']+svc_CV.cv_results_['std_test_score'], \n",
        "                 color='blue', alpha=0.1)\n",
        "\n",
        "plt.plot(mlpc_params_set['alpha'], mlpc_CV.cv_results_['mean_test_score'], 'mo-', label='MLPClassifier test')\n",
        "plt.fill_between(mlpc_params_set['alpha'], \n",
        "                 mlpc_CV.cv_results_['mean_test_score']-mlpc_CV.cv_results_['std_test_score'], \n",
        "                 mlpc_CV.cv_results_['mean_test_score']+mlpc_CV.cv_results_['std_test_score'], \n",
        "                 color='magenta', alpha=0.1)\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('C/alpha'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('Сравнение')\n",
        "plt.xscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja88tkmcdIdD"
      },
      "source": [
        "Наилучшее качество в кросс-валидации:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfdwGBnKd3VO",
        "outputId": "332661f6-58d0-4fda-e58f-6f69bc591ca6"
      },
      "source": [
        "print('logreg best score:', logreg_CV.best_score_)\n",
        "print('SVC best score:', svc_CV.best_score_)\n",
        "print('MLPClassifier best score:', mlpc_CV.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logreg best score: 0.7129001759427966\n",
            "SVC best score: 0.7125971285634678\n",
            "MLPClassifier best score: 0.7123729736837163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK1HXJVIdQtp"
      },
      "source": [
        "Отклонение:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LNDyCMYeFwE",
        "outputId": "17a0d8ff-7bf9-468b-b7c2-2bedd6021184"
      },
      "source": [
        "print('logreg std for best parameter:', logreg_CV.cv_results_['std_test_score'][5])\n",
        "print('SVC std for best parameter:', svc_CV.cv_results_['std_test_score'][1])\n",
        "print('MLPClassifier std for best parameter:', mlpc_CV.cv_results_['std_test_score'][8])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logreg std for best parameter: 0.02186876120240726\n",
            "SVC std for best parameter: 0.022515888176235337\n",
            "MLPClassifier std for best parameter: 0.02254986300340215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK6fc_S_dUBB"
      },
      "source": [
        "Качество на части (1000) тестовой выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmD8WvvIdA9d",
        "outputId": "74d85395-e62f-4b66-fe87-06ee70683c9e"
      },
      "source": [
        "print('logreg test score:', lr_test_score)\n",
        "print('SVC test score:', svc_test_score)\n",
        "print('MLPClassifier test score:', mlpc_test_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logreg test score: 0.6837360122584026\n",
            "SVC test score: 0.5\n",
            "MLPClassifier test score: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neQr2zSnWSE2"
      },
      "source": [
        "*Вывод:* Наилучшее среднее значение качества и наименьшее отклоненение у логистической регрессии. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvlcxHKkRUFy"
      },
      "source": [
        "#### 4\n",
        "\n",
        "При обучении алгоритмов стоит обращать внимание не только на их качество, но и каким образом они работают с данными. В этой задаче получилось так, что некоторые из используемых алгоритмов чувствительны к масштабу признаков. Чтобы убедиться, что это могло повлиять на качество, давайте посмотрим на значения самих признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1ABk-k1RUFy"
      },
      "source": [
        "**Задание 4** (1 балл) \n",
        "\n",
        "Посмотрите на значения признаков по gold и lh. В чем заключается особенность данных? На какие из рассматриваемых алгоритмов это может повлиять? Может ли масштабирование повлиять на работу этих алгоритмов?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erfT8d-aT8Qy"
      },
      "source": [
        "***Решение задания 4:***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "PtZRrlDjRUFz",
        "outputId": "9b42acb0-c64f-49e5-95ea-3387e1d9c320"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>player_1_lh</th>\n",
              "      <th>player_2_lh</th>\n",
              "      <th>player_3_lh</th>\n",
              "      <th>player_4_lh</th>\n",
              "      <th>player_6_lh</th>\n",
              "      <th>player_7_lh</th>\n",
              "      <th>player_8_lh</th>\n",
              "      <th>player_9_lh</th>\n",
              "      <th>player_1</th>\n",
              "      <th>player_2</th>\n",
              "      <th>player_3</th>\n",
              "      <th>player_4</th>\n",
              "      <th>player_6</th>\n",
              "      <th>player_7</th>\n",
              "      <th>player_8</th>\n",
              "      <th>player_9</th>\n",
              "      <th>rad_gold_sum</th>\n",
              "      <th>dire_gold_sum</th>\n",
              "      <th>rad_lh_sum</th>\n",
              "      <th>dire_lh_sum</th>\n",
              "      <th>rad_gold_std</th>\n",
              "      <th>dire_gold_std</th>\n",
              "      <th>rad_lh_std</th>\n",
              "      <th>dire_lh_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13674</th>\n",
              "      <td>3420</td>\n",
              "      <td>2310</td>\n",
              "      <td>3765</td>\n",
              "      <td>4450</td>\n",
              "      <td>3378</td>\n",
              "      <td>4927</td>\n",
              "      <td>5349</td>\n",
              "      <td>3936</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>32</td>\n",
              "      <td>3</td>\n",
              "      <td>42</td>\n",
              "      <td>47</td>\n",
              "      <td>37</td>\n",
              "      <td>130</td>\n",
              "      <td>149</td>\n",
              "      <td>19394</td>\n",
              "      <td>21242</td>\n",
              "      <td>19.728152</td>\n",
              "      <td>16.191356</td>\n",
              "      <td>1046.554232</td>\n",
              "      <td>759.302469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17458</th>\n",
              "      <td>4947</td>\n",
              "      <td>3257</td>\n",
              "      <td>5934</td>\n",
              "      <td>4500</td>\n",
              "      <td>3264</td>\n",
              "      <td>3917</td>\n",
              "      <td>4400</td>\n",
              "      <td>3830</td>\n",
              "      <td>30</td>\n",
              "      <td>21</td>\n",
              "      <td>47</td>\n",
              "      <td>38</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>49</td>\n",
              "      <td>48</td>\n",
              "      <td>146</td>\n",
              "      <td>146</td>\n",
              "      <td>21233</td>\n",
              "      <td>18371</td>\n",
              "      <td>12.890306</td>\n",
              "      <td>17.959955</td>\n",
              "      <td>1192.407749</td>\n",
              "      <td>507.613396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11599</th>\n",
              "      <td>3830</td>\n",
              "      <td>4631</td>\n",
              "      <td>5042</td>\n",
              "      <td>3459</td>\n",
              "      <td>2123</td>\n",
              "      <td>4683</td>\n",
              "      <td>3189</td>\n",
              "      <td>3443</td>\n",
              "      <td>39</td>\n",
              "      <td>50</td>\n",
              "      <td>56</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>48</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>152</td>\n",
              "      <td>110</td>\n",
              "      <td>19131</td>\n",
              "      <td>18364</td>\n",
              "      <td>22.685678</td>\n",
              "      <td>16.260381</td>\n",
              "      <td>1000.703233</td>\n",
              "      <td>1027.595718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9886</th>\n",
              "      <td>2523</td>\n",
              "      <td>4805</td>\n",
              "      <td>5571</td>\n",
              "      <td>2751</td>\n",
              "      <td>2006</td>\n",
              "      <td>4653</td>\n",
              "      <td>4436</td>\n",
              "      <td>3747</td>\n",
              "      <td>6</td>\n",
              "      <td>41</td>\n",
              "      <td>62</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>31</td>\n",
              "      <td>50</td>\n",
              "      <td>20</td>\n",
              "      <td>164</td>\n",
              "      <td>111</td>\n",
              "      <td>20647</td>\n",
              "      <td>16938</td>\n",
              "      <td>22.885803</td>\n",
              "      <td>17.022338</td>\n",
              "      <td>1246.425545</td>\n",
              "      <td>1131.953815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14010</th>\n",
              "      <td>5129</td>\n",
              "      <td>2523</td>\n",
              "      <td>6194</td>\n",
              "      <td>2222</td>\n",
              "      <td>4230</td>\n",
              "      <td>7731</td>\n",
              "      <td>2439</td>\n",
              "      <td>2279</td>\n",
              "      <td>49</td>\n",
              "      <td>16</td>\n",
              "      <td>57</td>\n",
              "      <td>3</td>\n",
              "      <td>52</td>\n",
              "      <td>37</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>131</td>\n",
              "      <td>144</td>\n",
              "      <td>18272</td>\n",
              "      <td>20458</td>\n",
              "      <td>22.444598</td>\n",
              "      <td>14.661514</td>\n",
              "      <td>1676.872637</td>\n",
              "      <td>1968.690489</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       player_1_lh  player_2_lh  ...   rad_lh_std  dire_lh_std\n",
              "13674         3420         2310  ...  1046.554232   759.302469\n",
              "17458         4947         3257  ...  1192.407749   507.613396\n",
              "11599         3830         4631  ...  1000.703233  1027.595718\n",
              "9886          2523         4805  ...  1246.425545  1131.953815\n",
              "14010         5129         2523  ...  1676.872637  1968.690489\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09MBo-S5T965"
      },
      "source": [
        "У признаков разный порядок значений: от единиц для золота конкретного игрока до 20 тыс. для суммарного количества монстров. \n",
        "\n",
        "Масштаб данных влияет на алгоритмы: \n",
        "\n",
        "*   *Logistic Regression:* так как в методе фигурирует скалярное произведение вектора признаков на вектор весов, то слагаемые $w_ix_i$ с \"большими\" компонентами в векторе признаков будут давать больший вклад в общую сумму, что будет влиять на подбор соответствующих им весов $w_i$. При этом в [документации](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression) сказано, что solvers 'liblinear', 'lbfgs', 'newton-cg' are robust to unscaled datasets. Однако при попытке использовать в предыдущем задании 'lbfgs' были ворнинги о том, что алгоритм не сходится с советом отмасштабировать данные. \n",
        "\n",
        "*   *SVC:* Аналогично - скалярное произведение вектора признаков на вектор весов в margin. Большие компоненты дают больший вклад в расстояние, доминируюя над признаками меньшего масштаба, и влияют на подбор весов. \n",
        "\n",
        "*   *MLPClassifier:* Во-первых, в нейронах в слоях происходят линейный преобразования над входными данными, что приводит к тому же, что и в предыдущих двух случаях. Во-вторых, неотмасштабированные данные могут приводить к затуханию градиента - градиент по весу, соответствующему большой по абс. величине компоненте становится близок к нулю, и этот вес не обновляется либо обновляется очень мало. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHSHPS5JRUFz"
      },
      "source": [
        "Масштабирование признаков можно выполнить, например, одним из следующих способов:\n",
        " - $x_{new} = \\dfrac{x - \\mu}{\\sigma}$, где $\\mu, \\sigma$ — среднее и стандартное отклонение значения признака по всей выборке (см. функцию [scale](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html))\n",
        " - $x_{new} = \\dfrac{x - x_{min}}{x_{max} - x_{min}}$, где $[x_{min}, x_{max}]$ — минимальный интервал значений признака\n",
        "\n",
        "Похожие схемы масштабирования приведены в классах [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) и [MinMaxScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler).\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmC4O-5FRUF0"
      },
      "source": [
        "#### 5\n",
        "\n",
        "**Задание 5** (1 балл) \n",
        "\n",
        "Отмасштабируйте все вещественные признаки одним из указанных выше способов и подберите оптимальные значения гиперпараметров аналогично пункту выше.\n",
        "\n",
        "Изменилось ли качество алгоритмов и почему?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYWRIj1nm8D7"
      },
      "source": [
        "#### StandartScaler\n",
        "Выберу масштабирование первым способом - с помощью StandartScaler. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWvJxbwem8EM"
      },
      "source": [
        "scaler = StandardScaler() \n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train) \n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIOid5i9owW8"
      },
      "source": [
        "Повторяю всё то же и с теми же настройками, что в 3 задании: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6WdZR6NoRs-"
      },
      "source": [
        "# Так же использую только часть данных для обучения моделей. \n",
        "data_part=4000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3moeyM_joRtS"
      },
      "source": [
        "##### 5 StandartScaler LogReg\n",
        "**5.1.1. Logistic Regression Classifier**\n",
        "\n",
        "Буду подбирать значение для `C` - inverse of regularization strength. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtFJpElXoRtT",
        "outputId": "3bc8de59-d9dc-40ee-caa4-5c9598d029e7"
      },
      "source": [
        "# Инициализирую модель\n",
        "logreg_model = LogisticRegression(penalty='l2', \n",
        "                                  tol=0.0001, \n",
        "                                  C=1.0, \n",
        "                                  solver='liblinear', \n",
        "                                  random_state=1234,\n",
        "                                  max_iter=100)\n",
        "\n",
        "# Тестируемые значения гиперпараметрa \n",
        "logreg_params_set = {\n",
        "'C': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 1e2, 1e3, 1e4]\n",
        "}\n",
        "\n",
        "# Кросс-валидация\n",
        "sc_logreg_CV = GridSearchCV(estimator=logreg_model,\n",
        "                         param_grid=logreg_params_set,\n",
        "                         scoring='roc_auc',\n",
        "                         return_train_score=True)\n",
        "\n",
        "sc_logreg_CV.fit(X_train_scaled[:data_part], y_train[:data_part])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=1234, solver='liblinear',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100.0, 1000.0,\n",
              "                               10000.0]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-CtX10-oRtU"
      },
      "source": [
        "Лучший набор параметров и значение критерия качества на нём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0UqDjhXoRtV",
        "outputId": "5401dbc3-097e-45e2-e67c-450cee22b86e"
      },
      "source": [
        "sc_logreg_CV.best_params_ , sc_logreg_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'C': 0.1}, 0.7127536613007244)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h09jo61xoRtW"
      },
      "source": [
        "График среднего значения качества:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "KKfzZljpoRtW",
        "outputId": "3b2f04a3-6520-48d0-c0a6-17ef7c507e64"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(logreg_params_set['C'], sc_logreg_CV.cv_results_['mean_train_score'], 'bo-', label='scaled train')\n",
        "plt.plot(logreg_params_set['C'], sc_logreg_CV.cv_results_['mean_test_score'], 'go-', label='scaled test')\n",
        "\n",
        "plt.fill_between(logreg_params_set['C'], \n",
        "                 sc_logreg_CV.cv_results_['mean_test_score']-sc_logreg_CV.cv_results_['std_test_score'], \n",
        "                 sc_logreg_CV.cv_results_['mean_test_score']+sc_logreg_CV.cv_results_['std_test_score'], \n",
        "                 color='green', alpha=0.1)\n",
        "\n",
        "plt.plot(logreg_params_set['C'], logreg_CV.cv_results_['mean_train_score'], 'mo-', label='train')\n",
        "plt.plot(logreg_params_set['C'], logreg_CV.cv_results_['mean_test_score'], 'ro-', label='test')\n",
        "\n",
        "plt.fill_between(logreg_params_set['C'], \n",
        "                 logreg_CV.cv_results_['mean_test_score']-logreg_CV.cv_results_['std_test_score'], \n",
        "                 logreg_CV.cv_results_['mean_test_score']+logreg_CV.cv_results_['std_test_score'], \n",
        "                 color='red', alpha=0.1)\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('C'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('Logistic Regression')\n",
        "plt.xscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOlxeCZLptGq"
      },
      "source": [
        "Изменилось на:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5mC3puTumxl",
        "outputId": "732786ea-d87f-45e5-9835-cefd85f09058"
      },
      "source": [
        "sc_logreg_CV.best_score_ - logreg_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.00014651464207227072"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCCAvFD3d2qN"
      },
      "source": [
        "Оценка качества на части (1000 элементов) тестовой выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC8BDjN7d2qQ",
        "outputId": "90705278-1281-4dfb-c97a-3ac939beee57"
      },
      "source": [
        "sc_lr_test_score = roc_auc_score(y_true=y_test[:test_part], y_score=sc_logreg_CV.best_estimator_.predict(X_test[:test_part]))\n",
        "sc_lr_test_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6316518037535357"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2rO7Vl1d_0j"
      },
      "source": [
        "На тестовых данных качество изменилось на:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5Lnhx57d_0k",
        "outputId": "276eef5a-cb83-4c89-ea16-1ad7b4dc5fbc"
      },
      "source": [
        "sc_lr_test_score - lr_test_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.05208420850486695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH9V3inpUBXX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_mfICSEoRtX"
      },
      "source": [
        "##### 5 StandartScaler SVC\n",
        "**5.1.2. C-Support Vector Classification**\n",
        "\n",
        "Буду так же подбирать значение для `C` - inverse of regularization strength. \n",
        "\n",
        "Остальные параметры оставляю по умолчанию. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhKVnzhBoRtY",
        "outputId": "abedf141-c455-4e80-802d-2dace97324f7"
      },
      "source": [
        "# Инициализирую модель\n",
        "svc_model = SVC(C=1.0, \n",
        "                kernel='rbf',\n",
        "                gamma='scale',\n",
        "                shrinking=True,\n",
        "                tol=0.001,\n",
        "                random_state=1234)\n",
        "\n",
        "# Тестируемые значения гиперпараметрa \n",
        "svc_params_set = {\n",
        "'C': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 1e2, 1e3, 1e4]\n",
        "}\n",
        "\n",
        "# Кросс-валидация\n",
        "sc_svc_CV = GridSearchCV(estimator=svc_model,\n",
        "                      param_grid=svc_params_set,\n",
        "                      scoring='roc_auc',\n",
        "                      return_train_score=True,\n",
        "                      verbose=3)\n",
        "\n",
        "sc_svc_CV.fit(X_train_scaled[:data_part], y_train[:data_part])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] C=0.0001 ........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........ C=0.0001, score=(train=0.698, test=0.726), total=   0.9s\n",
            "[CV] C=0.0001 ........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........ C=0.0001, score=(train=0.707, test=0.681), total=   0.9s\n",
            "[CV] C=0.0001 ........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........ C=0.0001, score=(train=0.701, test=0.716), total=   0.9s\n",
            "[CV] C=0.0001 ........................................................\n",
            "[CV] ........ C=0.0001, score=(train=0.710, test=0.678), total=   0.9s\n",
            "[CV] C=0.0001 ........................................................\n",
            "[CV] ........ C=0.0001, score=(train=0.714, test=0.656), total=   0.9s\n",
            "[CV] C=0.001 .........................................................\n",
            "[CV] ......... C=0.001, score=(train=0.698, test=0.726), total=   0.9s\n",
            "[CV] C=0.001 .........................................................\n",
            "[CV] ......... C=0.001, score=(train=0.708, test=0.683), total=   0.9s\n",
            "[CV] C=0.001 .........................................................\n",
            "[CV] ......... C=0.001, score=(train=0.701, test=0.715), total=   0.9s\n",
            "[CV] C=0.001 .........................................................\n",
            "[CV] ......... C=0.001, score=(train=0.710, test=0.678), total=   0.9s\n",
            "[CV] C=0.001 .........................................................\n",
            "[CV] ......... C=0.001, score=(train=0.714, test=0.656), total=   0.9s\n",
            "[CV] C=0.01 ..........................................................\n",
            "[CV] .......... C=0.01, score=(train=0.699, test=0.726), total=   0.9s\n",
            "[CV] C=0.01 ..........................................................\n",
            "[CV] .......... C=0.01, score=(train=0.708, test=0.683), total=   0.9s\n",
            "[CV] C=0.01 ..........................................................\n",
            "[CV] .......... C=0.01, score=(train=0.701, test=0.714), total=   0.9s\n",
            "[CV] C=0.01 ..........................................................\n",
            "[CV] .......... C=0.01, score=(train=0.710, test=0.678), total=   0.9s\n",
            "[CV] C=0.01 ..........................................................\n",
            "[CV] .......... C=0.01, score=(train=0.714, test=0.656), total=   0.9s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ........... C=0.1, score=(train=0.723, test=0.733), total=   0.8s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ........... C=0.1, score=(train=0.731, test=0.687), total=   0.8s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ........... C=0.1, score=(train=0.724, test=0.721), total=   0.8s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ........... C=0.1, score=(train=0.734, test=0.685), total=   0.8s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ........... C=0.1, score=(train=0.737, test=0.663), total=   0.8s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ............. C=1, score=(train=0.817, test=0.720), total=   0.8s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ............. C=1, score=(train=0.819, test=0.685), total=   0.8s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ............. C=1, score=(train=0.815, test=0.716), total=   0.8s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ............. C=1, score=(train=0.826, test=0.680), total=   0.8s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ............. C=1, score=(train=0.823, test=0.664), total=   0.8s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ............ C=10, score=(train=0.969, test=0.639), total=   1.1s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ............ C=10, score=(train=0.964, test=0.661), total=   1.1s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ............ C=10, score=(train=0.968, test=0.641), total=   1.1s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ............ C=10, score=(train=0.971, test=0.618), total=   1.1s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ............ C=10, score=(train=0.966, test=0.615), total=   1.1s\n",
            "[CV] C=100.0 .........................................................\n",
            "[CV] ......... C=100.0, score=(train=1.000, test=0.602), total=   2.1s\n",
            "[CV] C=100.0 .........................................................\n",
            "[CV] ......... C=100.0, score=(train=1.000, test=0.617), total=   2.1s\n",
            "[CV] C=100.0 .........................................................\n",
            "[CV] ......... C=100.0, score=(train=1.000, test=0.586), total=   2.1s\n",
            "[CV] C=100.0 .........................................................\n",
            "[CV] ......... C=100.0, score=(train=1.000, test=0.571), total=   2.0s\n",
            "[CV] C=100.0 .........................................................\n",
            "[CV] ......... C=100.0, score=(train=1.000, test=0.582), total=   2.1s\n",
            "[CV] C=1000.0 ........................................................\n",
            "[CV] ........ C=1000.0, score=(train=1.000, test=0.602), total=   2.2s\n",
            "[CV] C=1000.0 ........................................................\n",
            "[CV] ........ C=1000.0, score=(train=1.000, test=0.615), total=   2.2s\n",
            "[CV] C=1000.0 ........................................................\n",
            "[CV] ........ C=1000.0, score=(train=1.000, test=0.586), total=   2.2s\n",
            "[CV] C=1000.0 ........................................................\n",
            "[CV] ........ C=1000.0, score=(train=1.000, test=0.569), total=   2.1s\n",
            "[CV] C=1000.0 ........................................................\n",
            "[CV] ........ C=1000.0, score=(train=1.000, test=0.581), total=   2.1s\n",
            "[CV] C=10000.0 .......................................................\n",
            "[CV] ....... C=10000.0, score=(train=1.000, test=0.602), total=   2.2s\n",
            "[CV] C=10000.0 .......................................................\n",
            "[CV] ....... C=10000.0, score=(train=1.000, test=0.615), total=   2.2s\n",
            "[CV] C=10000.0 .......................................................\n",
            "[CV] ....... C=10000.0, score=(train=1.000, test=0.586), total=   2.2s\n",
            "[CV] C=10000.0 .......................................................\n",
            "[CV] ....... C=10000.0, score=(train=1.000, test=0.569), total=   2.1s\n",
            "[CV] C=10000.0 .......................................................\n",
            "[CV] ....... C=10000.0, score=(train=1.000, test=0.581), total=   2.1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=1234, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100.0, 1000.0,\n",
              "                               10000.0]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVBoHSBQoRtd"
      },
      "source": [
        "Лучший набор параметров и значение критерия качества на нём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcQHMOtgoRte",
        "outputId": "3af68d6f-5ab7-4f0b-b4e4-d272b04b38e0"
      },
      "source": [
        "sc_svc_CV.best_params_ , sc_svc_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'C': 0.1}, 0.6977528160239432)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q283YahOoRtf"
      },
      "source": [
        "График среднего значения качества:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "2n7FE3e4oRtf",
        "outputId": "7812c122-0a81-4b36-fc3e-3f64f1333115"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(svc_params_set['C'], sc_svc_CV.cv_results_['mean_train_score'], 'bo-', label='scaled train')\n",
        "plt.plot(svc_params_set['C'], sc_svc_CV.cv_results_['mean_test_score'], 'go-', label='scaled test')\n",
        "\n",
        "plt.fill_between(svc_params_set['C'], \n",
        "                 sc_svc_CV.cv_results_['mean_test_score']-sc_svc_CV.cv_results_['std_test_score'], \n",
        "                 sc_svc_CV.cv_results_['mean_test_score']+sc_svc_CV.cv_results_['std_test_score'], \n",
        "                 color='green', alpha=0.1)\n",
        "\n",
        "plt.plot(svc_params_set['C'], svc_CV.cv_results_['mean_train_score'], 'mo-', label='train')\n",
        "plt.plot(svc_params_set['C'], svc_CV.cv_results_['mean_test_score'], 'ro-', label='test')\n",
        "\n",
        "plt.fill_between(svc_params_set['C'], \n",
        "                 svc_CV.cv_results_['mean_test_score']-svc_CV.cv_results_['std_test_score'], \n",
        "                 svc_CV.cv_results_['mean_test_score']+svc_CV.cv_results_['std_test_score'], \n",
        "                 color='red', alpha=0.1)\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('C'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('SVC')\n",
        "plt.xscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q78G64P2rBCT"
      },
      "source": [
        "Качество изменилось на: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6h6ettruunA",
        "outputId": "2beccaab-0e80-4182-e8b4-1e73bd36eb09"
      },
      "source": [
        "sc_svc_CV.best_score_ - svc_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.014844312539524562"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ04uOz2oRtg"
      },
      "source": [
        "##### 5 StandartScaler MLPC\n",
        "**5.1.3. Multi-layer Perceptron classifier**\n",
        "\n",
        "Буду так же подбирать параметр, отвечающий за регуляризацию: `alpha`.\n",
        "\n",
        "C остальными параметрами по умолчанию алгоритм не сходился, поэтому я попробовала заменить функцию активации на `logistic` вместо `relu` - заработало. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ayQrhKooRtg",
        "outputId": "7decfcb2-1f15-4e1a-dbc3-4ffa09844965"
      },
      "source": [
        "# Инициализирую модель\n",
        "mlpc_model = MLPClassifier(alpha=0.0001,\n",
        "                           activation='logistic',\n",
        "                           solver='adam',\n",
        "                           learning_rate='constant', \n",
        "                           learning_rate_init=0.001,\n",
        "                           tol=0.0001,\n",
        "                           max_iter=200,\n",
        "                           random_state=1234)\n",
        "\n",
        "# Тестируемые значения гиперпараметрa \n",
        "mlpc_params_set = {\n",
        "'alpha': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 1e2, 1e3, 1e4]\n",
        "}\n",
        "\n",
        "# Кросс-валидация\n",
        "sc_mlpc_CV = GridSearchCV(estimator=mlpc_model,\n",
        "                       param_grid=mlpc_params_set,\n",
        "                       scoring='roc_auc',\n",
        "                       return_train_score=True,\n",
        "                       verbose=3)\n",
        "\n",
        "sc_mlpc_CV.fit(X_train_scaled[:data_part], y_train[:data_part])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] alpha=0.0001 ....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... alpha=0.0001, score=(train=0.716, test=0.743), total=   1.7s\n",
            "[CV] alpha=0.0001 ....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... alpha=0.0001, score=(train=0.726, test=0.703), total=   1.6s\n",
            "[CV] alpha=0.0001 ....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... alpha=0.0001, score=(train=0.719, test=0.730), total=   1.6s\n",
            "[CV] alpha=0.0001 ....................................................\n",
            "[CV] .... alpha=0.0001, score=(train=0.725, test=0.706), total=   1.4s\n",
            "[CV] alpha=0.0001 ....................................................\n",
            "[CV] .... alpha=0.0001, score=(train=0.731, test=0.680), total=   1.6s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ..... alpha=0.001, score=(train=0.716, test=0.743), total=   1.7s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ..... alpha=0.001, score=(train=0.726, test=0.703), total=   1.5s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ..... alpha=0.001, score=(train=0.719, test=0.730), total=   1.6s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ..... alpha=0.001, score=(train=0.725, test=0.706), total=   1.5s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ..... alpha=0.001, score=(train=0.731, test=0.680), total=   1.6s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] ...... alpha=0.01, score=(train=0.716, test=0.743), total=   1.6s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] ...... alpha=0.01, score=(train=0.726, test=0.703), total=   1.6s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] ...... alpha=0.01, score=(train=0.719, test=0.730), total=   1.6s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] ...... alpha=0.01, score=(train=0.725, test=0.706), total=   1.5s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] ...... alpha=0.01, score=(train=0.731, test=0.680), total=   1.7s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.716, test=0.744), total=   1.7s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.726, test=0.701), total=   1.6s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.719, test=0.730), total=   1.6s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.725, test=0.707), total=   1.9s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.731, test=0.682), total=   2.5s\n",
            "[CV] alpha=1 .........................................................\n",
            "[CV] ......... alpha=1, score=(train=0.713, test=0.745), total=   1.7s\n",
            "[CV] alpha=1 .........................................................\n",
            "[CV] ......... alpha=1, score=(train=0.724, test=0.700), total=   1.5s\n",
            "[CV] alpha=1 .........................................................\n",
            "[CV] ......... alpha=1, score=(train=0.716, test=0.729), total=   1.6s\n",
            "[CV] alpha=1 .........................................................\n",
            "[CV] ......... alpha=1, score=(train=0.723, test=0.707), total=   1.9s\n",
            "[CV] alpha=1 .........................................................\n",
            "[CV] ......... alpha=1, score=(train=0.728, test=0.679), total=   2.1s\n",
            "[CV] alpha=10 ........................................................\n",
            "[CV] ........ alpha=10, score=(train=0.698, test=0.735), total=   1.0s\n",
            "[CV] alpha=10 ........................................................\n",
            "[CV] ........ alpha=10, score=(train=0.709, test=0.689), total=   0.9s\n",
            "[CV] alpha=10 ........................................................\n",
            "[CV] ........ alpha=10, score=(train=0.702, test=0.719), total=   0.8s\n",
            "[CV] alpha=10 ........................................................\n",
            "[CV] ........ alpha=10, score=(train=0.708, test=0.696), total=   0.8s\n",
            "[CV] alpha=10 ........................................................\n",
            "[CV] ........ alpha=10, score=(train=0.715, test=0.667), total=   0.8s\n",
            "[CV] alpha=100.0 .....................................................\n",
            "[CV] ..... alpha=100.0, score=(train=0.696, test=0.736), total=   0.9s\n",
            "[CV] alpha=100.0 .....................................................\n",
            "[CV] ..... alpha=100.0, score=(train=0.707, test=0.684), total=   0.9s\n",
            "[CV] alpha=100.0 .....................................................\n",
            "[CV] ..... alpha=100.0, score=(train=0.699, test=0.718), total=   1.0s\n",
            "[CV] alpha=100.0 .....................................................\n",
            "[CV] ..... alpha=100.0, score=(train=0.706, test=0.694), total=   0.8s\n",
            "[CV] alpha=100.0 .....................................................\n",
            "[CV] ..... alpha=100.0, score=(train=0.713, test=0.666), total=   0.8s\n",
            "[CV] alpha=1000.0 ....................................................\n",
            "[CV] .... alpha=1000.0, score=(train=0.534, test=0.535), total=   0.9s\n",
            "[CV] alpha=1000.0 ....................................................\n",
            "[CV] .... alpha=1000.0, score=(train=0.442, test=0.412), total=   0.9s\n",
            "[CV] alpha=1000.0 ....................................................\n",
            "[CV] .... alpha=1000.0, score=(train=0.699, test=0.716), total=   1.0s\n",
            "[CV] alpha=1000.0 ....................................................\n",
            "[CV] .... alpha=1000.0, score=(train=0.641, test=0.612), total=   0.9s\n",
            "[CV] alpha=1000.0 ....................................................\n",
            "[CV] .... alpha=1000.0, score=(train=0.300, test=0.345), total=   0.9s\n",
            "[CV] alpha=10000.0 ...................................................\n",
            "[CV] ... alpha=10000.0, score=(train=0.505, test=0.514), total=   0.9s\n",
            "[CV] alpha=10000.0 ...................................................\n",
            "[CV] ... alpha=10000.0, score=(train=0.399, test=0.422), total=   1.0s\n",
            "[CV] alpha=10000.0 ...................................................\n",
            "[CV] ... alpha=10000.0, score=(train=0.446, test=0.407), total=   1.0s\n",
            "[CV] alpha=10000.0 ...................................................\n",
            "[CV] ... alpha=10000.0, score=(train=0.386, test=0.376), total=   1.0s\n",
            "[CV] alpha=10000.0 ...................................................\n",
            "[CV] ... alpha=10000.0, score=(train=0.447, test=0.451), total=   0.9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='logistic', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=200, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_state=1234, shuffle=True,\n",
              "                                     solver='adam', tol=0.0001,\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100.0,\n",
              "                                   1000.0, 10000.0]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmA1-6gcoRth"
      },
      "source": [
        "Лучший набор параметров и значение критерия качества на нём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJBjQfxvoRti",
        "outputId": "18f082f5-5e15-44c1-d18d-994c4f2483e3"
      },
      "source": [
        "sc_mlpc_CV.best_params_ , sc_mlpc_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'alpha': 0.1}, 0.7127599226102147)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvVMPlFPoRti"
      },
      "source": [
        "График среднего значения качества:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "ZfdOr3K0oRtj",
        "outputId": "96579baf-ecc9-4c8a-c9cb-a1516511050a"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(mlpc_params_set['alpha'], sc_mlpc_CV.cv_results_['mean_train_score'], 'bo-', label='scaled train')\n",
        "plt.plot(mlpc_params_set['alpha'], sc_mlpc_CV.cv_results_['mean_test_score'], 'go-', label='scaled test')\n",
        "\n",
        "plt.fill_between(mlpc_params_set['alpha'], \n",
        "                 sc_mlpc_CV.cv_results_['mean_test_score']-sc_mlpc_CV.cv_results_['std_test_score'], \n",
        "                 sc_mlpc_CV.cv_results_['mean_test_score']+sc_mlpc_CV.cv_results_['std_test_score'], \n",
        "                 color='green', alpha=0.1)\n",
        "\n",
        "plt.plot(mlpc_params_set['alpha'], mlpc_CV.cv_results_['mean_train_score'][:-1], 'mo-', label='train')\n",
        "plt.plot(mlpc_params_set['alpha'], mlpc_CV.cv_results_['mean_test_score'][:-1], 'ro-', label='test')\n",
        "\n",
        "plt.fill_between(mlpc_params_set['alpha'], \n",
        "                 mlpc_CV.cv_results_['mean_test_score'][:-1]-mlpc_CV.cv_results_['std_test_score'][:-1], \n",
        "                 mlpc_CV.cv_results_['mean_test_score'][:-1]+mlpc_CV.cv_results_['std_test_score'][:-1], \n",
        "                 color='red', alpha=0.1)\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('alpha'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('MLPClassifier')\n",
        "plt.xscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxIPmcPOriCm"
      },
      "source": [
        "Изменилось на: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtXjlnt1uCQ7",
        "outputId": "78c263d6-e2cf-44ff-f7cc-c027b542d71a"
      },
      "source": [
        "sc_mlpc_CV.best_score_ - mlpc_CV.best_score_ "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0003869489264983761"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z90jNc5voRtj"
      },
      "source": [
        "##### 5 StandartScaler Сравнение\n",
        "\n",
        "Сравню модели. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "Ij1DeXq1oRtk",
        "outputId": "3c8624a3-2e2e-4572-8717-6c450ec55cc2"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(logreg_params_set['C'], sc_logreg_CV.cv_results_['mean_test_score'], 'go-', label='logreg test')\n",
        "plt.fill_between(logreg_params_set['C'], \n",
        "                 sc_logreg_CV.cv_results_['mean_test_score']-sc_logreg_CV.cv_results_['std_test_score'], \n",
        "                 sc_logreg_CV.cv_results_['mean_test_score']+sc_logreg_CV.cv_results_['std_test_score'], \n",
        "                 color='green', alpha=0.1)\n",
        "\n",
        "plt.plot(svc_params_set['C'], sc_svc_CV.cv_results_['mean_test_score'], 'bo-', label='SVC test')\n",
        "plt.fill_between(svc_params_set['C'], \n",
        "                 sc_svc_CV.cv_results_['mean_test_score']-sc_svc_CV.cv_results_['std_test_score'], \n",
        "                 sc_svc_CV.cv_results_['mean_test_score']+sc_svc_CV.cv_results_['std_test_score'], \n",
        "                 color='blue', alpha=0.1)\n",
        "\n",
        "plt.plot(mlpc_params_set['alpha'][:], sc_mlpc_CV.cv_results_['mean_test_score'][:], 'mo-', label='MLPClassifier test')\n",
        "plt.fill_between(mlpc_params_set['alpha'][:], \n",
        "                 sc_mlpc_CV.cv_results_['mean_test_score'][:]-sc_mlpc_CV.cv_results_['std_test_score'][:], \n",
        "                 sc_mlpc_CV.cv_results_['mean_test_score'][:]+sc_mlpc_CV.cv_results_['std_test_score'][:], \n",
        "                 color='magenta', alpha=0.1)\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('C/alpha'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('Сравнение')\n",
        "plt.xscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAG9CAYAAABQ/9HFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9eXxkVZn//37urTV70ulUeqHpZhtkcfmxqKMztiICskm3K4jg1urIOIjI0DqKIggirjN+VZxx3FBUaBEVRRRbv36VEXAbQNBma3pJ0kuWTmep5Z7fH6duUqlUkkrq1pY871ff193OPffcqkrVp5/zLGKMQVEURVEURakNnGoPQFEURVEURZlExZmiKIqiKEoNoeJMURRFURSlhlBxpiiKoiiKUkOoOFMURVEURakhVJwpiqIoiqLUECrOFEVRFEVRaggVZ4qi1Dwicr6I3C8iwyKyW0R+LCIvrPa4FEVRyoGKM0VRahoRuQz4NPBRIAGsAf4PcG41x6UoilIuVJwpilKziEgrcDXwTmPMFmPMQWNMyhjzA2PMe0XkQyJyq4h8W0QOiMjvReRZOddfKSKPZc89LCLn5Zy7WEQyWWvckIjcIyKrsufWi8iOvLH8WkQuztl/k4j8RUT6ReQuETk055wRkSNy9q8Rka9kt9dmz4ey+ydn96/JaX+WiPxRRAZE5Dci8szgXlVFUWodFWeKotQyzwdiwPdmaXMu8F2gA/gmcLuIhLPnHgP+AWgFPgx8Q0RW5Fz7W2NME9AFjAPvLmZQInIu8D5gA7Ac+L/At4p8pnw+DuzM6fs5wJeBtwHLgC8Cd4hIdIH9K4pSZ6g4UxSlllkG7DXGpGdp84Ax5lZjTAr4JFbMPQ/AGPNdY8wuY4xnjPk28Dfg5AJ9ONllX5HjejtwnTHmL9mxfRR4dq71rBhE5CxAgJ/lHN4EfNEY8z/GmIwx5qtY4fi8+fStKEr9ouJMUZRaZh/Q6U8BzsDT/oYxxgN2ACsBROQNOdODA8BxQGfOtc/LHh8A1gFfyTm30r8u2yZXHB0KfCbn3H6syFqV0+b3OecvLzBuF7gOuCLv+KHAe/LufYj/TIqiLH5UnCmKUsv8Fms1esUsbQ7xN0TEAVYDu7JWrC8BlwDLjDFtwINYEeVzb/Z4DPgGU8XZLmNMm78A9+acexp4W+55Y0zcGPObnDb/X861NxYY90XAo8aYe/OOPw1cm9d3gzFmodOmiqLUGSrOFEWpWYwxg8AHgc+JyCtEpEFEwiJyhojckG12gohsyFrXLsWKuXuBRsAAewBE5I1Yy1nBWwEZrP9YMXwB2Cwix2b7bhWRV83z8d4PbC5w/EvA20XkuWJpFJEzRaR5nv0rilKnqDhTFKWmMcZ8ArgM+Des0Hoaaw27Pdvk+8BrgH7gQmBDNqLzYeATWOtbL3A88P/yun++iAwDg1jn/kuKHNP3gI8Bt4jIENYid8Y8H+2Hxpi/Fej7fuCtwH9kn2kbcPE8+1YUpY4RY0y1x6AoirIgRORDwBHGmNdXeyyKoihBoZYzRVEURVGUGkLFmaIoiqIoSg2h05qKoiiKoig1RFktZyJyuog8KiLbROTKAuc/lc1B9EcR+Ws2n49/LpNz7o5yjlNRFEVRFKVWKJvlTERc4K/AqdikkPcBr8tGUBVq/8/Ac4wxb8ruD2fLqhRFZ2enWbt2bcnjVmbm4MGDNDY2VnsYShXQ937pou/90kXf+/LywAMP7DXGFEzfM1vW7VI5GdhmjHkcQERuwdbAKyjOgNcBVy30ZmvXruX+++9f6OVKEWzdupX169dXexhKFdD3fumi7/3SRd/78iIiT810rpzTmqvIKauCtZ6tKtQwm8l7HXBPzuGYiNwvIveKyGzZwRVFURRFURYN5bSczYfXArcaYzI5xw41xuwUkcOAe0Tkf40xj+VeJCKbsEWCSSQSbN26tWIDXooMDw/ra7xE0fd+6aLv/dJF3/vqUU5xtpOcmnfYenc7Z2j7WuCduQeMMTuz68dFZCvwHOCxvDY3ATcBnHjiiUbNr+VFTdxLF33vly763i9d9L2vHuWc1rwPOFJE1olIBCvApkVdisjRQDu2xIp/rF1EotntTuAFzOyrpiiKoiiKsmgom+XMGJMWkUuAuwAX+LIx5iERuRq43xjjC7XXAreYqWGjzwC+KCIeVkBeP1OUp6IoiqIoymKirD5nxpg7gTvzjn0wb/9DBa77DbZIsaIoiqIoypJCyzcpiqIoiqLUECrOFEVRFEVRaggVZ4qiKIqiKDWEijNFURRFUZQaQsWZoiiKoihKDaHiTFEURVEUpYZQcaYoiqIoilJDqDhTFEVRFEWpIVScKYqiKIqi1BBlrRCgKIsBz3gTSy6CzHmtSBFtiuinGn1VHVND5x1sETpFUZQKoOJsPnjAfiBT7YGUCcPsP1gpYHcA/cynnclbB9E2e94zHhkvY9cmg+d5pL00aZMmnUmTyqTsec+b3sds2kbALxU7l1gymDmFkjGm+H5k9rEV0xdY8ZY7ruRokif/8OT0hgVemvmcFyOzj8cw52s9W9+mqA/OTF3L1P4FTMxgonYhBCZk1/njMJjiPrN1QDKT5PH9j1d7GEoVWMrvfdgNs7plddX+I6vibD5kgL1ApNoDqRIGGJtH+2I/08W0K7KNMQZPvCmCyzMeKS9F2rOCK+2lSXkp256pYsURB0FwQy5O2CEkoUnRMxPV/hEO+P6+sMxFRIhGo4UvmOu9KSRc5nN9BSj0zNPwgDTIsMAQU4VjBCvaYgbCOaJtno4jtWjRFBEioaX6pbe0Wcrv/UhyZNrvQyVRcTZfHCBW7UFUCQFm+H0uN8aYScFlPDzPbqe8lLVyZddpky74B+WIYxfHwXVdwhIO7oew9n5PS6LQl5GIIKFgHrRaX3azUsyQHAp/Yxrsf9zGQQ7ajiYslKEc0RbJEW1ukfesERxR9+Slir731UHFmVJVjDETgmtiitHLTFi30l56QnQVwhUXEcEVl5AbIupUST0qSxfBfpNmhZiPwVhrWwpkTBBP/BPWahvJirYoJVnbFEVZfKg4U8qC70DvCy5/O+Wlpli7PONNs3QJMmnpEodwKExUVHQpdYjDhBvElOncrLVNDgoyOFW0EZ7F2qYoypJAxZkyL/IFl2c868dlsv5cWStXxmSmTV/lii7XcYmGomoyV5Ymuda2fB+8DJAEZ8SZGuTi5Ii2aI5oKxCQoChKfaPibAlijMFgpggsY8yEX1fas+Iq42Um116G8cw4T/Q/MbMTvePiOA4xidWkY7Oi1AWuXUwkT7QZbEDCAUEGcqxtABHwop6dIlVrm6LUPSrO6hhfTE0ILCYFVsbLWOd4Y6zflpeeEFv5+bry8cWWiEyZWnTEoTHSWKGnUxRlCtkpT8KFrW0yLjaSNNfa5mbTf/hTpOH6DEhQlKWGirMaIN+ClbvOeBkyZCac5H0rlsfUpKiF/LZEZNpUYilRijUZZacoyszWNj/9x6AGJChKPaHiLCAmRFXOdGGu0PKnCn0rlp9/y49CnCmfii+ucq1YITc0cUxRFGVG5gpIGBFkaPb0H3hM5jfM/8qZbX8+bYvZV5QlhIqzeeAZj6GxIVKSmuKLNdtUoS+6/KnCCaHlOLjiahSioiiVp4j0H86oDUiQpODuKOy8lp+8d8p/MPOrO8xW7WGutvmVL/Kte3n7RnLGNce1xsmzNjpTt02rTSysKJVExdk8yHgZ9o3uIxQKTQitUqcKFaVW8DwwHmQ88DJCJgOZDKRSdunfL4RDEAqD4xpcF1x1OF98ZK1tE1OkLpjG4spQlFIua46Oi98vdC73WF75vWmCMvdcRuAAZFZnVKApFUXF2TwRhGhIrV1K/WCMFV5eBjyTFV5pSGUgnYJ0SkinBC/7wyRir0Hs77S4BmNgeFjwMtlSVtkGjkAobIhEDZGwFW5uyOA64Li2L0UpmSpNeRoMjIG7yyWzKqO/mErF0I+aotQxs1u7hExaSGeLKxgDjjM5YyRicFx7LBozswopGYVYFPJNFMZAOgOjo8LBYZno2/Nsv6GQIRwxRKMQClnhFnJVuCl1RAzMqMHZ6eCt9jQ9iVIRVJwpSg2Sa+3KeGC8rLUrnbV0ZddTrF3Za31rlyNWDEXKWLdYBMIT3yJT54SMsWMfHxfGRgSPHKMbEA5DOGwIZ61ujjsp3ByNGFRqiTjIqFiBtkoFmlJ+VJwpSoWZy9qVToltYwAMIrIga1e1EYGQa5fpjkD2+ZMpGBsTPCNTmrguRCLW6haJkPVvM7ghFW5KdTBxg4wIzm4Hb6WnKUeUsqLiTFEColhrV8azwqWgtcuxPlzulC/+MjlZVxnXsYt1tJ76jJ6BdNpa3TxPsn5wk35u4aghEpn0c9MABaUSmAaDHMwKtBUq0JTyoeJsHhgDY6MCkZxkr0VaLuZsJ8X9ABdzv6LaLOBexlgH8lKpZWvPFPKf38txqJ/D2gXi/0McK7rqwdpVKzgCTthOfeb7uXnGvvYHDwoHNEBBqTCmMSvQehy8bhVoSnlQcTYP0mnY0xsilrR/jcYU8WU/W26fnDZz9WNyfItma1NcP3MLQWNkWl/JJOycId/R7PebmVr5sZxrnKDWrlrBEXBCvq+bBigolWdCoPU5eAlPE+YqgaPirEh6b+7lsc2PY3aMM94VIr6pi9ipbdUeVhmZ/NEbu3uA0Zv6aOhzGe96dAk8+1Tu/e7dtH09yrKBDva17WfgwnGe96pTqz2sipD77I+0/armn72YAIVk0gYoZIwVerkBCqGQIRIzhEPwg923cePD17FrZCerGlax+Vmb2bB2Q0Wfp5pseXIL1/3pOnaO7GTVn5fW80959hnee9NobBF6RzDLzaISaFv+soXrf309uw7sYuUfV3LlC69kwzOWyHuf8+yHtB7CR0/5KBccf0HFxyH5GZ7rlRNPPNHcf//9Zem79+ZeHt30KN5IThWAqNB4xYpFL1LG7h7g4A27YTznc7JEnh2sODnkC8uIpWITx8bCYzz99n01LVKCYKk9e8az06VeBu7s28K937uDi372BroGu+hr7eNrp36Ns9561pIQKFue3MLlv7uc0czoxLG4G+fGk29c9M8/32eXYcFr9RaNQNvyly1ccfcVjKZznj8U54ZTb1j0Aq3QszeEG7jp7JvKItBE5AFjzIkFz6k4m5vfrv0t40+NTz8RF6KntBbfUakvdRXeqvF7BmGswI1jQvRFLUDOsEz+Ou+6aefz+vTbz9Bu2n0KXTPnvWa/h+3SkPSSJL1xnIcyRNLTc1Ek3SR7D9s/Nfu4Yep+9ph1J5ycDxWTne2ecm02T3n2mCCTtQ4nrpPsOdvex/YjU46Lse0nZtVzzsuUviaLYfv3EgQxQjQZxSngUJORDANNA2ScDJ7jTaz97Yzj4U2cK7AtBs9v53pTzhkxtj/XPzbzYhyPjOvhOWbKMbtt8Fz/XpP3Mdm2xjV44rez542Yif3E/R287a63EUtPFaafPufT7F2/d9prUoj5Vg0pVFu3HBQzrj/u+yNJLznteMSJ8JxlzynHsGqGP+z7w7yfXTJiC8cvgioCf+j5A8lMged3Izyne5G/9zM8+6Gth/LkpU8Gfr/ZxJlOaxbB+PYCwgxg1JC8d3hefVXdr2W+9y8kzLLHU38amd5v/trfmOF8frOJF2imjODT+mf6izpbWyBNmpSXJGVSpLwkSZJ2bcaza/vHaTAclz6OQoQzYfan94GYSZ3kYPdnGMNEvb/8Wn/ZfZN/rtA6/3yh1y2vneScM5IVAbnXOjnHsn2JwHF3H13w2R3jsOfZ/UhGcDwH8UA8wck4OF4YN7stnmSPC5LObnuO3fec7H62rZGJ/pyMIMauHc/B8WrD4zqWivHPP/xnftr0U/as3MOe7j2kooUjZOZdxmgB//FaSKmkYq8pJE784yFZ3D8bC3r2ELYslAMmXN8Gj0LixD/uOos7HHqmZ98+uL3CI1FxVhTRNdGCljMnEaL9u0dVYUSVo/9Vf8XrTU877iRCtH/nyCqMaGaMMQym++kZ20XP+E56xnbRm133jO+iZ2wnfeM9pMzUP8CIE6U7upJEdCWJ2Eq6oyvpjq2iO7qSvW/ay/KB5dPutbdtHy/66qsq9WhV4ZH7fsXygc5px/e27eMF155TsXEYY2wx7oyBDBjPru2+wfjb2TYm2w4vZ9u/NnsNHlPaTeknA8Of2FXQktUw3sB5Xz3P7giEV4WJHBkhekTULkdGiRwWwYnXhqBcKCd9/yR2jOyYdnx1w2puPeXWKoyociz42U12irPTw3TUr0A7+Usns/PAzmnHVzWv4ruv+m4VRlQ5Znr2Na1rKj4WFWdFcNi1hxX0OYtv6qreoCpEfFNXQZ+zajz7gfQQPWM76RnfRe/EercVYuO76B3bxZg3OuWakIToiq4gEV3JM1tPoDu6iu6sAEtkBVh7eNmMUz33Xng3zV8Ym+Z3NXDhDNbURcTAheM18ewiYjOyu9kp2wrcc/9XnyK6d/p09nhnipbrjiG+d5TQ7nGS28ZJbkty8NcHwTeiCYQPCU+KtSMidr0ughOrD9G2+VmbC/pdbX7W5iqOqjIs+NkFTJPB2evgiYdpr0+BduULryzoc3blC6+s4qgqQ6Fnbwg3cO0p11Z8LOpzViR+tGZyxzjOkojWnMSP1sz0pXC7wmV59tHMSEFLV8/4Lnqz2wczU6eQHRw6o4kpli5r+fIF2Co6Ip24UpopXqM1l96zj909wNDHduAmJ8VUJuLR8q+rib60jZERobXNo63d5q0zKUNye5Lxv1mxNv63cca3jZN8Mgm+4dmZQbQdFsGJ1J5oKyZicbFS0rN7IAcFL+FhWuvz93VKtGazRmuWK1pTAwICYuRAigd+vJu2FbG5Gy8iftRzG5997KP0jO+kO7qKdx3+Ps7s3lj09UlvfNLC5U855li/esZ2MZQemHbdssjyCaGVyAqwRHTFxLHlkW5Cjhp/K8GOwT+zuvWZ1R5GRfH/U+L1paf9h8wYpgm0QpikIflUjljLCrfkU0k7pQrgQGRNZHJ61Bdu66JIpBJ2wtl58IkHOW5dYd9LZQY8cIYdMisymJb6/Y196L6HOPakY6s9jKowPD7MEcuOwJHy/cdJAwKUBfOjntv48CPvmZgu3D2+gw8/8h4AzuzeSMpLsWe8Z8LS1Tu+e5r1a39qenRbW7jDWryiq3h268lTrF/dsZV0RVcQcaIVfVZFySV2atuMFmIRaGgwDA44wMwCTSJC9EgruHLxkh7JJ5JTrWx/SzL882HrOwfgQuTQyKRY84Xb2ggSrr5oU2bBAa/Js2WexMM0169AU6qDijNlGp7xGE4PMZga4BPbPjTNj2vMG+WDf/kXPrXtavYm+/Dwppxvcpsnphef0Xx8QetX3G2o5CMpSuAUK9AK4UQcYn8XI/Z3U63w3rgVbbnTo2OPjHHgpwcmIzpDEFkbmT49ukZFW03h2ES1zi4Hb5WHaVKBphSPirNFjDGGg5lhBlP9dkkPMJDaz2BqILvfz0Cqn6GUXQ+m7fGh1MA0wZVPyqT4+2XrSeT4dyWiK+iOraIp1FyhJ1SU6lKKQCuEE3WIHR0jdnSeaBvzSD6enDI1OvbwGAfuyhFtYYiuy7OyHRGxoi2koq0quDkCbbWHaVCBphSHirM6wBjDqDfCUGrAiqissBpMTRdbVojZ40PpAdJmehoMn0a3idZwO63hdtpC7ayMraY13EFruM0eD7XziW0foj+1b9q1K6KrufoZnynnYytKXRC0QCuEE3OIHRMjdkyeaBvNirbs1Oj4tnHG/jzGgTsPTI4vLEQOi0yxskWPiBI+JIy4Mw908AeD7PnkHtzdLttWbGP5ZctpPXseSbcViwsmbnB2OmRWZyBe7QEp9UBZxZmInA58BhsI/5/GmOvzzn8KeHF2twHoMsa0Zc9dBPxb9tw1xpivlnOsc3Hz/97M5rvfx44DT9P9+Pyd4n2S3vikwCpkzcoTXkOpAQbS/SS9mdMXxJy4FVjhdlpCbRze+HeTAisrvOy+FV5+u7AzPVVAPq64U3zO/Pu96/D3zfvZFWWx4gu0oUEHz/PoWBa8QCuEE3eIHRsjdmyeaBvxGH9sauToyB9GGPrh0OSYo1nRljc9Gl4dZuhHQ/T8Ww9mzFapSO9K0/NvPQAq0BZCCEzU4O5wyRySgaUVU6YsgLKJMxFxgc8BpwI7gPtE5A5jzMN+G2PMu3Pa/zPwnOx2B3AVcCLWaP9A9tr+co13Nm7+35vZ9INNjKRsRnzfKX44PcRJ7S8oKLYmrFx51qx8/61cwhKhLSuoWsPtHNpwGC2hNtryrFlt4XZawtnjoTaibvn+0n0BWkq0pqIsBUQgHjcMH7AWtEoJtEI4DQ7x4+PEj59qpskMZyYsbb5wG7l/hKEf5Ii2mNgEvXnFD8yYoe+jfbhtLhIRJCw2BUiYKWv/nEQEQvMvY1UL+FbD9O40oRWhYKyGYVuhYUKgabyTMgvltJydDGwzxjwOICK3AOcCD8/Q/nVYQQZwGnC3MWZ/9tq7gdOBb5VxvDPy/p+/f0KY+Yx5o1z718JJ+UISoiXUNmHN6o6t4uim47OiK0dshdonLV7hNuJOQ01+kZ3ZvZEzuzcuyXQKijIffAtaLQi0QrhNLvFnxok/s4Boy7Gy9X+l8P+DM/sz7HjL9Oz5MyJ2WtUXaxPrSIFjM62DapMVk/424cLCcfAHgxNWQyBYq2HYuqlMCLS5Jy+UJUo5xdkq4Omc/R3Acws1FJFDgXXAPbNcu6oMYyyK2epqfezYL0yzZjW6TTUpshRlvvzo7iifvamJnr5T6O7yeNemYc48dfFXRyiVWhZohXCbXOLPjhN/thVtB356gPSu6f6qbqfLqn9fhUkaTMrMvi6mTc7aO+jN2V/QFBJwqZ7UZA66LGbMsOeTe4KZ0o3kWNBWq0BTClMrAQGvBW41xmTmbJmDiGwCNgEkEgm2bt1ahqFBV7SL3vHe6ccjXRwfO9zuGCA5yEBykOnpVBcHqcwoOwb/XO1hKBXiF1sTfPY/jmF83FZY2N3r8qEbmtg/sp0Xr5/+96BMZ+9eeLof3FBlyk4FhbxecD7jIOOTozZRQ/JNSR5vf7w6gzJY0ZTGTrn6S96+pGTy2Ext09l2Bc7JTilYVzW1O8WDTzwY3PN4wC4wEVOzH46xg2M8dN9D1R5GVfA8j12hXVW7fznF2U7gkJz91dljhXgt8M68a9fnXbs1/yJjzE3ATWArBKxfvz6/SSB8YtknpvicgXWKf/cRH1pS03w6rbn4ODgi9O112JNd+va5E9v3/DpKKjX1V2N83OUznz2O3993JG2thrZWj7YWj7ZWQ3ubR2uLR3v2eFOjwam9qkQV5+BBobm5PixoE7wZBrus31Vqd4rwivCSidbc9uJtBa2G4RVhnrHuGcHebBwEsRa0WjGV5KAVAspbIWA2yvlxuA84UkTWYcXWa4Hz8xuJyNFAO/DbnMN3AR8Vkfbs/suAqlXc9etqTURrqlO8UuOMjcOeve6k8NrnZLfdnG2HkdHpXzyxmCHRmSGVKtAxkEzBk9tD9A86DA4JmUxhxeG6htYWkxVv3oSYa2/Nirg2kxVzk+eamxafoGtsrK8pTp/Ws1tpPbuVB594MHhRUsMsv2z5FJ8zsEESyy9bHvzNonbK1NlpE9XWokBTqkPZPgrGmLSIXIIVWi7wZWPMQyJyNXC/MeaObNPXAreYnCKfxpj9IvIRrMADuNoPDqgWFxx/AeetffWSrK2p1A6pFOzZl7VyZYWW3XbYk7V69e11ODA8XeFEIoblyzy6OjP83RFpXvhcj+Wddt8et/uNDVZAnPaqZezunV40fkXC43tfs3+OxsCBYWFwyKF/UBgcdOgfdBgYFAaGHAYGHAaGhIFBh6d2uPz5oRADgw7pGQSd4+QIujaPtpYcQddqJoVdq0dbm23X0lz7gs73QTPGsKzTqxuBthTxrYN7PrlnwoLWurG1fFbDGDDKRCUBpv/JKUuQsup0Y8ydwJ15xz6Yt/+hGa79MvDlsg1OUWqIdBr29ReeXuzb5x936R+crkJCrmF5VlitXZPmpOf4ostj+TKP5Z0ZujqtiJmPKHjXpmE+fEMLYzl+R7Go4V2bhif2RaCl2dDSnOGQIkN2jLHTqQODQv+AY0WcL+gGs9tZQbdjl8uDf7FWunR6ZkHX0pxrlcuKuKxFrt2fem2btOK1NBvcOX4EJ4MhnECCIRoaDAeHBXBUoNU4vtXQeIbHXvIYqR0zmJGDIg4yKlagrVSBpqgRtWhuvhk2bw6xY8chSy5qbalH7JXyI+150D8gE1auSf8uN0d0OezrdzBm6q+14xg6O6zQWtnt8azjUjmCy7d0ZWhrKY/lyD7jUKACBayga2o0NDUaVq+cvUyYjzEwMir0D/hWOofBQcla6SbF3MCgw64eh4cftYIu32ducgyTgm7COpfjM7d9p8MP7opPXL+71+XDN7QAQ4EINGMcOperQKt1xBFazm5h/3/tJ703TaizfD+ZJm6QEbHF0ld6UOPWYKW8qDgrgptvhk2bYGQk2C/qeuBHd0enWE+W0rPDzM9vzBAvfG5y2nTinuy+v71vf+EpvI72yenEZxyVtmJrWWaKxauj3ZvTulNuzjx1nDNPHa96MIgINDYYGhvmJ+hGR2VCuPXnWueGHAYGJrd7+hwe+Zudch1PFlZMY+PCZ29qKvlz39BgGDko7EUFWj3Qek4r+2/az9CPhui4qKOs9zINBjkoOD0OXrcKtKWMirMieP/7YWRqDlrGxoWrb2zmvj9MJqkxc6XhmeP8nJfPdX2p5wsc+/kvo1OmtSD77B9v5v/9LjItAjz/h6bQD8+0NtMalN7HtGvEzH5+hj7u+Ems4PO/75qWAldAa4s34dd1+FpfdFkLl7+9rMMjHJ5+fyVY/ISwDQ2Gld3FCTqA0TF43mnLp1kyAXr6gvm1bGgwjIwIe/eoQKt1okdGiR4TZeiO8oszsIXS5aDg9GYFmn42liQqzopg+ww5aEdHhV/fm5dBcI4/pLn+zub6ki71/FzkXz86VrjD0THh93+aPXtiIXAama8AACAASURBVDGYf2za/rQLSu8j/0e2oEidoY+R0Zlf0CsuOTDFr2t5h0c0/yWZSRDnROpLEeOZ6VhOHA0m28DkPaAYmTjmt8FMdjflWN61E31mDMmh8akfYAEjOQ8ggAgmr83EUgTFJG8ulINqej9F3GuGfsIR6O7KsLt3+tdjLGoYS2UIB/DNGY3BgWHIeIZlnbUb1GCMIePNKwXlgqjlxN0t57Sw5/o9jD02RuSwCmSNbQAZFugBL1FdgeaZ4v9jowSHirMiWLMGnnpq+vEVXR4//XpVg0jLzssu7GB3X4GIvS6Pu766uJ8dZn7+7uUZNr586vN7GWt1AStqBMkKE18Y2V2vkFgRM/U6KDylkXedcUCyeXgc/wIxEz90fo4ecScvFHHAmTw3kcdHwMleJxPrbJudDo0rm23iTF+/eWL3PRBjMF5W8WXbiMmuPSbEqJHs5dkXI/dxjDGTQtFvLH5ju+uR90OVfS0nBKHk9DHDD5oh7z4FuOStB/jIx1sZG598E0KuYXTM4bL3t/OxD/UTj5WesT4Wsz5onoFly7wJgTbX+CqJYf7izOSq/0VA7PQY3AD93+un41/Kbz0DIArSL3ieh7e8OgLNGEMynaz8jWuAeDhe1H8Ey4WKsyK49lrf52zyWCzm8c4rDpBcW/7/UVaTd15xgGv+rYWxsckfqcX07J7x8DyPjMmQ8TKTlqKsSNp0GXzsQ8umPn/ccNnmJK1Hd0z88U6IGXJF0NQ/7Nz9/OsKHSvUV6HrKoHb69KyvK20TkzeUuiYydFjuW28nCVn3xeAUwRhftsCL5Uha13z75G7Dbz5ZdAmcN1NsLMPVnXB5ncKB8fhyutiXPqvK/jap6GtpbSXBIAWOHgQokno6qLmLGiP73ycNW1rqj2M6tIOB190kIN3HmTNB9cgToX+/tqBA9jPcicVF2jb3e0c1nFYZW+qACrOiuICm4OWzZsNO3ZAYkWGSy4b5oyzx6o7sArgP+N/fLKJ3t1u3T27MQbPeKS9tBVixptinXLEIeJGaAg1EHbChN0wruPiiovruGy60KGzEa6/HnbtgpUr4corhQ0bGqr8ZHVIkdOb8zG4zNl2FhGYLxQlr91558N5r83uJ8EZB1LQEYV/+gic92b45qdhxcrinms2GhutQOvthUSi9gSaAomNCf5yyV8Y/J9B2p5f4n9U5kMTsA/7Geus3G2V6qLirEguuADO25jm//7paZa3L60f5jPOHuOMs8foeeJButcdV+3hTMEXXxkvY9c55VkNBldcwk6YWChG1I0SdsM44hByQriOW1Rpjg0b7KLUIZK3noW5hF4GwIMzVsM3DoU3vgPOeRt8+xNw+OqcfkLYPFXz/HZtbLTWeRVotUnn6Z24jS49t/VUVpwJ0AzszW4vq9ytleqh4kypeSaEl5eZIr7ATvOFnTDRkBVeESdiLV851i9FCQwHiMILXgq33gavfz2cfQl846vwrGeApIBxcMaAgzmzqk6OaJtFdDU0qAWtVnHjLp0v72TPD/dw5EeOxI1X8LvFF2h92M9P++zNlfpHxZlSdSaEV574MhgcrJUr7IZpDDcScSMTFi/f+qUo1eCZz4Tbb4fzz4dXvRb+67/gH/7BnvOtbKRB0tgC12N2IcOEQDMO9ls455tYpzhrl+6N3fR+t5d9d++j65yuyt5cgBagN7uvAm1Ro+JMKTu+073v9+VHy/l+XyGx4qshav2+fNHlW79qOcReWdocdpgVaBdcAG94A3z2s3D22dmTDhABEwEacqZN00yKtqxgk4NMmtkcaAzDwWH7O6wCrXZo+/s2It0Rem/rrbw4A/v5aMJ+MFysWFMWJSrOlJLx8yBlzKTfly+8DGZCfDVGGom6UUJOCMfJWr5UfCl1Tnc33HYbXHwxvOMdsH8/XHTRLBdkLWUGoCkntUgqK9iSIKPQ5MHIXug7mI3iDE9eq4lJq4O4QuK8BDu+tIPkviSRZRXIeZaPgxVou5ic7lQWHSrOlFnxjDfhdG+Mx2hqdCIpoW/9csQh7IRpCBeOeCzG6V5R6pm2NvjWt+Dtb4f3vc8KtEsvnUdSaGGqlS3rbx7NwPCgnQld0ZT1ZRthMqrUnxYNo6V+KkRiY4KnP/80fXf0sfqNq+e+oBw4QCOwE1iNFWvKokLF2RLBT/DpC60pomuWODVXrMhyHAdHHFpjrUTdKI44uI5rrWAqvhSFeBz+8z/hve+FG2+EvXvhIx8pcUrShYYO64O2KwUrDwFHsFOjKSAJjGaX9NTr1MpWHpqe0UTjMY303tZbPXEG9j1uBHYAa4CllURg0aPirA6ZtGSZKbm7ZhJaub5dvqDy/br8Y444iFgrmL8IMmXKccD5Gx3xCmXHVpQ6JByGT30Kli2DL3zBWtA+8xmIlDj75QcJ7NwJq1ZlpzjD2B9kP6tDhknR5lvYRrCBCX6OOTd7ncbRlET3xm4e+8hjjGwboeGIKqoiF/sZeBor0OLVG4oSLCrOqszUaUMzRWjNhCPOxJSh78OVb+HKF1pq3VKUyiACH/gAdHbCNdfAwIC1qDU2ltZvrkBbuRLcfIHlZpcok9NchokABJJYseZb2vwABP+6MGplK5Ku87p47NrH6N3Sy7or1lV3MCGsKNuOCrRFhIqzAJlmzSpi2jBXaIXc0ITQ8qcLC4ksdaBXlNrnHe+Ajg47zfnqV8PXv273S8EXaH61imkCLR/Biq4w9ke7NXvcw1rYsnnZJkRbbskr35dNmUY0EaX9H9rp3dLL2svXVq6c00yEgBiTFrRYdYejlI6Ks3niGcNwcrhgQdRSpw0VRVlcvOY10N5uhdorXmGDBlatKq1Pv5JA0QKtENlkuhNWNj/rfK4vmz816gHDs/SVW5/UX8sM+zMtdUhiY4JH3vUIg/cN0vbcClYMmIkw9r3wBVq0usNRSkPF2TwIOSFWNHXT3KzThoqiFMfLXgbf/KZNtXHuuXb7qKNK67OhIQCBVgg/iCDXyvYUcASz1yb18rbnWjJ5bfMF3lwUEoAOFRV/y89Yzl8b/krvbb21Ic4AfN9GX6BVIdOHEgwqzuaBiNAQaSSupn5FUebBc59rc6FdcAGcdx587Wtwwgml9Vk2gVaIcv7fc66i9DOJQV/k5a5nEn9z3R+mirhcYRejoMBzG1yWn7Gcvh/0ccTVR+DGaiTKIsJUC5r+XtUlKs4URVEqwDHHTJZ7es1r4Etfghe/uLQ+fYHmR3GWVaCVi0pMbRZr9csXfwex07szONknNibova2XfT/bR9dZVagYMBNR7LifBg5BBVodonNxiqIoFeLQQ61AO+wwO835ve+V3mdDAySTsGMHZDJzt1+S+NOefv63MNbCFMUKrwZszrAmbMb9VmztyjayhVIL0/7CdiKJCL1bemduVC1iWKG5g6k58JS6QC1niqIAYIz9cfc8uzbGbvvr4eGpbf1Yltztmfr1z+e2m2l7rvPF9jWfe1WS5cvh1lvhTW+CSy6xudDe/ObS+mxogNFRK9BWr65TC1otMofPlrhC1yu62PnlnaT2pwh31JiJKo6Nwt2BrSSgv/h1g75VirLI8bxJweVvm6yfTa5wchwIhWwi1cbGyW3HsX5Nhx46eZ1/be56pu3cY543+3ap540p/r7zFZWl5inLpaUFvvENK84++EFbTeCKK0oTjvG4CrTA8cti+elFCtC9sZsdX9xB3x19rLq4xFDcchDHRt36pZ70c1EXqDhTlDolX3D5U1r5osN1rdCKxew6ErHHXNcKL389W5khEYgustD8uUSlv22MFU+Dg9DcHJzlLRaDL34RNm+Gz34W9u2D664rTVSpQAsYwYqbJDOmpmg6tonGZ9hyTjUpzsBO245gi6WvRAVaHaDiTFFqCH8KsZClK39qznWtZSsSsUsoZJdcweW61Z/Gq1XmM9XZ3W3FaV+ftaAFJXpcFz72MVvu6bOfhf5++Pd/t8JtoahAC5gmoJdZ84YlNiZ4/JrHGXl8hIbDarTIZQM2wGE3VqCpx3lNo+JMUSqAL7pyBVfuVFsu4fB0S1e+4HIcFV2VRMRm9w+H7RRvNFp6vczcvv/1X61Au+oqK9D++7+tlW6hxOM2ivPpp61AC+k3/cIpwmKceEWCx6993JZzurzK5ZxmoxGbUHg3sAIVaDWM/skqSgnkO9H7Vq58S5cvqnwLl7/OFVz+tlK7NDdb3zs/MjIeYB3Dt7zFCsB3vxte+Urrk7Z8+cL789Ns+BY0FWgLpAgf/+iKKO0vzJZzes/a2q780oQVaL1AN3VboWGxo3+u88TzYHy88LlcX5X5nJuLUvqd69piHaJhesReUBQaYy1+txV6vRzHWlMKOdHnCi4VXYuHWMwKtF27bJ3LIAMFNmyw5Z7e+lZb7umb37T3Wij5UZwq0BaAi43aTDPrL2ZiY4JHLn2EofuHaD2pdeaGtUATMIQVZglUoNUg+qc6D1zXfnHONB01l0P1TIKjUOh/sdeWct/8+891bseO0usC5lOKaK0G+ZauWhSRSvkJh+GQQ6C3F4aGoKkpuM/Ci18M3/42vOENVqDdfLNNYLtQ8n3QVKAtgCZgkFl/MTtf3omz2aHn1p7aF2dg87kNYIVZFyrQagz9M50HjgOJRLVHUT0cJ1grgaLUM45jAwXCYdizxwq0oJzvTzjBJqg9/3zYuBG+8hVbAmqhqEArkTiwb/YmocYQnad3sueHezjy6iNxonVgLm8B+rG+Z52oQKsh6uDToyiKUpuIQGentSiPjEAqFVzfRx0F3/++9Ts7/3z46U9L6y8et35yO3ZAWjPGz48igz8SGxOkB9Lsu2cOJVdLNAP7mVN8KpVFxZmiKEqJtLRY37BUCsbGgut31Spb7unoo23AwLe/XVp/vkB7+mkVaPMihPU9m6OIevs/tBNeHqb3thos5zQTgp223YsVaUpNoOJMURQlAPxAAcexVrSg6OiA73wHXvACuOwy+PznS+svHrd+syrQ5oFg84TNYRl1Qg6JVyTY97N9pPoDNKOWG8Fa0Pqw05xK1VFxpiiKEhB+oEA8DgcOBBfw0tho/c7OOQeuuQY+8pHS+laBtgAaKaqAeOKVCUzK0PeDvrIPKVB8C1oPNvhBqSoqzhRFUQLEdWHlSptU9sCBmaO750s0Cv/xH3DxxfCFL9h8aKUIK1+gbd8erK/coiXKnNOaYMs5NfxdQ31Nbfo4WAvabmyqDaVqqDhTFEUJGD9QYOVKmxswKPHjutZydvnl8N3vwpvfbKMwF0o8bi1wTz+tAm1OIhQVzSgidG/sZuj+IUafLOHNqRYO1oK2i6LEqFIeVJwpiqKUCT9QIJkMLlBAxFrNPvpR+PnPbSTnwMDC+1OBViQO1npWhLWy67wuEOjdUofWM7DP2kBRz6qUBxVniqIoZSQeL0+gwEUX2eCAP/zBlnvq6SltjKACbU4amTMoACC2Mkbb37fRc1sPpt4ybfuEAAPMUBFHKS8qzhRFUcpMJFKeQIGzz4avfc36jb3iFfD44wvvKxazaxVosxAHMsU1TWxMMPbkGEMP1LnzVhlK9ilzo+JMURSlAviBAh0dwQYK/OM/Wv+zgwetQPvf/114XyrQ5iCCtSYVwfKXL8eJOfUZGODjYEs81anxr54pqzgTkdNF5FER2SYiV87Q5tUi8rCIPCQi38w5nhGRP2aXO8o5TkVRlEogYjP+r1hhAwWCSmPxrGfZZLXxuJ3i/PWvF96XCrRZCFNUMlqAUHOIztM66bujDy9Zx571aSDAxMpKcZRNnImIC3wOOAM4BnidiByT1+ZIYDPwAmPMscClOadHjTHPzi7nlGuciqIolaa11fqhjY/bJQgOP9wKtFWr4MIL4Uc/WnhfuQKtXl2mykYjkCyuqV/Oaf8v6jj1fghNq1EFymk5OxnYZox53BiTBG4Bzs1r81bgc8aYfgBjTJ1l7VMURVkYfqAAlJYOI5cVK+C22+CZz4S3vQ2+/vWF9+ULtGTSTpkqWRoo2u+s/UXthDvD9NxaQrRGtYlhxVkdG//qESlXJImIvBI43Rjzluz+hcBzjTGX5LS5Hfgr8AKssfhDxpifZM+lgT9ijarXG2NuL3CPTcAmgEQiccItt9xSlmdRLMPDwzQ1NVV7GEoV0Pe+vKRS1gfNCei/y2NjDtdccyy/+90yLrroCc4//ymkiBxdhRgdHSYSaSIUglAomPHVNQZrOSv2vfo88EOseaK5XIMqD8NjwzTFmqwwC6Ne6gHz4he/+AFjzImFzlX7Ty0EHAmsB1YDvxKR440xA8ChxpidInIYcI+I/K8x5rHci40xNwE3AZx44olm/fr1FR38UmPr1q3oa7w00fe+vBgDe/fCvn3Q1BSMSPvOd2wtzq9+dR2uu44Pf3hh/T700FaOOWY9IyM2qGHFisnUG0sSD9iGTdRaBAc2HeCB7z3AUduOYuXrV5ZzZIGz9aGtrD92vU2nEQFWVXlAS4hy6uCdwCE5+6uzx3LZAdxhjEkZY57AWtGOBDDG7MyuHwe2As8p41gVRVGqhh8o0N0dXKBAOAyf+Qy89a3w5S/DP/+znaJc6PgaG624e+opKySDijatO/xktEUGSzQd30TDkXVazsknik2poUlpK0Y5xdl9wJEisk5EIsBrgfyoy9uxVjNEpBM4CnhcRNpFJJpz/AXAw2Ucq6IoStVpa4M1a2w1gSACBRwHrroK3vc+GyzwxjeWlgg3EoHmZti/3+ZWCyqYoe5oomhxJiIkNiYY/N0go9vrsJyTjwABJlFWZqds4swYkwYuAe4C/gJ8xxjzkIhcLSJ+9OVdwD4ReRj4BfBeY8w+4BnA/SLyp+zx640xKs4URVn0NDTA2rV2qjOIigIi8M53wo03wq9+Ba9+tRVXpfTX1GTH9+ST0N+/BCM648zLQT6xIQFQ/9azOg46rTfK6nNmjLkTuDPv2Adztg1wWXbJbfMb4Phyjk1RFKVWiUSsBW33bjvNGUQsxuteB+3t8E//BBs2wM0327QbCyUatVOnfX12jImEHfeSIDy/5rFVMVqf30rvbb0ceumhyEKjM6pJGDiADYZYKu9zFdHYC0VRlBokFLLiqbUVhoaC8fE6/XQrynp64Nxz4W9/K60/x7HTnMmktaINDS0RK9o8ktH6dG/sZvSJUQ784UC5RlV+HEDTqlQEFWeKoig1iuNYi1QiEVygwPOfD7feavt6xSvg978vvc943C67dtklqMoHNU0DRSejBVh+Zrac05Y6ntqMAf1oOacKoOJMURSlxmlvt4XTgwoUOO44GyDQ2mp90LZuLb1P14WWFptQ98knrZhc1DQyr+jFUEuIZacuo+/7fXipOg11dbGBEEs1EKSCqDhTFEWpAxobbUUBY4KpKLB2rRVo69bBxRfb7SBoaLC+Zzt2QG8vZIrMpl93RJm3BSmxMUFqf6q+yzm52LQaSllRcaYoilInRKM2UCASCaakUleXLfd0wglwySU2H1oQhELWinbggLWiBVWeqqYIY9NLzIOO9R2El4XrO2rTn9qsU+NfvaDiTFEUpY7wAwV88VOqA35Liw0SOO00+MAH4OMfD86pv6HBjvepp2DPnkWWuNbBCpUi850BOGGHrnO72Hv3XlKD87iwlnCwwmys2gNZ3Kg4UxRFqTMcx1q9urpshGSpU4exGHzxizbdxqc/DVdeGdx0ZDhsIzr7+61IG1tMP+rzSEbrk9iYwIwb9vxoT1mGVBHC2GLoStlQcaYoilKHiEwGCoyMLLw0k08oZK1ml1wC3/gGnH02nHQSnHbaizj5ZNiypbSxNjXZ9ZNP2iS4iyLlRgyYp4htflYz8cPj9T21GcWKs8XqT1gDqDhTFEWpY5qarHN/JlO6b5cIbN4M550Hf/qTTYthjLBzJ1xxRWkCDSbLP+3ZY8s/lSooq84CkrGKCIkNCQbvHWT06Tp1xhNsMESdDr8eUHGmKIpS50SjNpIzHA4mhcXvfjf92OgoXH996X2LWIGWycATT8DgYB1b0ULYKb55+tIlNtpyTn1b+gIfUsWIAgPVHsTiRcWZoijKIiAUgtWrrYN/qZn6d+2a3/GFEIvZ9CC7d9t+U3XqHz/fZLQA8UPitD63ld4tvZh6VaYRbLWAen3fahwVZ4qiKIsEv6JAV5eN5FyoU//KlYWPu66d7gwKx7FicmzM+qIdqMfKRvNMRuuT2JhgZNsIB/5cjw+dRYCRag9icaLiTFEUZREhAh0dNt3G6OjC/LquvNKWY8olErGpMc4+2wYOBOkvFo9bS9rOndaSVleJayMsqJzR8rOWI1Gp78AAP+eZEjgqzhRFURYhzc02Ye1CAgU2bIAbbrACT8SwahV84hNw7702WODTn4azzoKHHw5uvH75p4MHrRVtpF4sMhEmHeTnQbg1TOdLO+m7vY7LOYWwpZy0nFPgqDhTFEVZpMRiVqCFQvOvKLBhgw0MuOuuX/K739n91lb4zGdsJYHeXnj5y+1+kIXOGxpsYMP27dDXVweJawWIsyDfq8QrE6T2pej/ZR2bnxys75kSKCrOFEVRFjHhsM2F1tRUeqCAz2mnwS9+Aaefbi1s554Lf/tb6f36hELW8jcwYK1oNZ+4doF+Zx3rOwi1h+i5rSfwIVUMf2qzTuMaahUVZ4qiKIscx4Hu7tIDBXLp6IAvfAE+/3mb+f+00+x+UP5ifuJax7H9799fw1a0GAuqNelEbDmnfT/dR3ooQPNjJXGxwrTWBXSdoeJMURRlCZAbKDAyElzqinPOgXvugRe9CD7yEXjlK621KygiESvS9u61U53jtejftMCgAIDujd14Yx577qzjck4hoI6DTmsRFWeKoihLiOZmm7A2lSq9ooBPV5f1Q/v0p+GRR+ClL4WvfCU4S5dvRTPGCr+BgRpLXOsno12A1bD5Oc3E18XpvbXOozYHWJD1UCmMijNFUZQlRixmBZrrzj9QYCZE4FWvgp//HE4+Gd7/fltIfefOYPoHWwmhsdEGI+zYUWOJaxuZdzJayJZz2phg4LcDjO2s07lBLecUOCrOFEVRliC5gQIHDgRniVq5Em6+GT72MfjDH+AlL4Fbbgmuf8ex1r9k0pZ/GhoKpt+SaWTBhcATG2w5p97v1bH1LAwMVnsQiwcVZ4qiKEsU17WBAsuWBRcoANaK9vrXw89+BscfD+95D7zhDdATYFBiPG6XXbts4tog03ksiPDCL40fGqflpBZ6b6vjck5RrN9ZPSUQrmFUnCmKoixhRKCz01q8ggwUAJtj7Tvfgauvht/8Bk45Bb73veCsaPmJa4Oaol0QC0xG69O9sZuRv44w/GAAleurgWQXzXkWCCrOFEVRFFparJhKpYLNK+Y48OY3w09/CocdBpdcAps22ejLoGhosFGd27dbf7SqlH8SrGP8AsXt8rOXIxGp78CACDYwQCkZFWeKoigKYKcJDz3UCqqgyycdfjjcfrsNFPjZz6wv2p13Btd/KGQrGAwN2bxoQUWizosmFizOwm1hlr10Gb3f78VL12nYYwQbFFBLgRp1ioozRVEUZQI/UCAeD97Z3nXhn/4JfvxjO4361rdaS1p/gNWLGhvtfZ56ylrnKpq4doHJaH0SGxOk9qTo/1Wdl3Oq05nZWkLFmaIoijIF17XiadkyO0UYtLP90UfDD34Al19u16ecYq1pQREO24jO/fsrnLjW9ztbIMtesoxQW4je2+p4ajOKlnMKABVniqIoyjREYPly68uVTAY/zRkOw7vfDT/8IbS3w0UX2ajOoKx1+Ylr+/srkLjWxSakXaDPmxNx6Dq7i70/2Ut6uNrhpwskhJ3WXEDON2USFWeKoijKjDgOrF1rpwuHhoK3oh1/vPU9u+QSG9l5yinwq18F17+fuLavzyauTZZbNDRRkjBJbEzYck4/quNyTi5azqlEVJwpiqIosxIKwYoV1hetHFa0aBQ2b7YBA7GYrSzwvvcFlxojN3Htk09akVk2K1oDJeX6ajmxhdjaWH1PbcawCWl1anPBqDhTFEVRiqKxsbxWtBNOsCk33vIW+NrX4NRT4X/+J7j+/cS1u3fb5LVlSVxbQhF0yJZz2pBg4DcDjO2q03JODpAG6nT4tYCKM0VRFKVoym1Fi8fhwx+GW2+11q2NG+1+UKkxXNda0cbGbPmnA0FPv4Wxv6wlCLTEhgQY6Lu9L6hRVZ4QWs6pBFScKYqiKPOmsRHWrbNCpxxWtOc9z0ZwXngh3HQTnH66rdUZFPG4nU7duTPgxLUCxCkp11fDugZaTqjzck4xtJxTCag4UxRFURaE60IiYa1oqVTwVrTGRrjuOvjWt6z/2TnnwPXXB5caIxSylREOHLC+aIGNv5GSE7EmNiY4+MhBhh+q06RhfimraiQDXgSoOFMURVFKwvdFa26GwcHgrWj/+I9wzz3wqlfBv/87nHkmPPhgcP03NFih9tRTsGdPAIlrS0xGC9B1dhcSlvoODAij5ZwWiIozRVEUpWR8K5pfnzNoK1pLC3zyk/CVr8C+fVagfepTwRVqD4ftPfr7rUgrqb5oJIDxdIRZdsoy+m7vq99yTlFgBBscoMwLFWeKoihKYORa0crhi3bqqfDzn8NZZ8GNN9qpzkcfDaZvP3GtiJ3m3L/firSxMTuV6i/J5NQllZpc0mlIG0i7kElaX7ZMxlrj/MWYyWU2EhsTJPuSDPy6zs1PAaVEWUqEqj0ARVEUZXHhW9Gam23aivFxO3UoJZQ2yqWjAz73OTjjDJsf7fTT4YorYNMme+9SiUSsJW3fPlufczaMmXyu3G3ZC+4ImOjU47Ph5JhLRIAjl+E0h3jsqz0MH9YxcTy3r9zt3Otn2s69Pr+f3OMi4GUCqNiQAraDWVNiPxVGxFpSq4WKM0VRFKUsNDRYK9revXa6MB63oicozjoLnvtcuPJKuOYa+MlP7FTnYYeV3reItQKWcr3TA2YefeRaqrc6aQAAIABJREFU0owBIg7NL13O0I97kfE0TsP0n2z/GmOm+spN66vA9qz3xloB5xKnxeAchJRDINO9lcLzrBXVqdL8ooozRVEUpWzkW9GSyWCtaMuXw3/+J2zZAh/4gJ32fP/74eKLq/fDCmAWIEILWcRaz0ww+L3djPxyL61ndQczuCJxhux7VSqCdT+bj1CtNsNVDpJVnzNFURSl7PhWND91RVCO/GCFzMaN1hft+c+3Iu01r4Gnnw7uHvMmzGQ6iRKIP7uV8KoYg3fWb9SmiVqhp+Wciqes4kxETheRR0Vkm4hcOUObV4vIwyLykIh8M+f4RSLyt+xyUTnHqSiKopSf3IjOdNrmLgsyx+qKFfD1r8PHPw5/+pMton7zzWWsozkbAqbEZLRgyzm1nJFg5L5+UnsCSvBWaVxsMto6HX41KJs4ExEX+BxwBnAM8DoROSavzZHAZuAFxphjgUuzxzuAq4DnAicDV4lIe7nGqiiKolQO34rW2loeK9r551sr2rOeZQMFLrzQTqlWGtMIEkC0auuZCfBg6Md1bD0TkDrNp1sNymk5OxnYZox53BiTBG4Bzs1r81bgc8aYfgBjjF9I7DTgbmPM/uy5u4HTyzhWRVEUpYK4LnR1WStaJhO8Fe2QQ+Db37aBAr/9rbWi+fU6K8VC/M4KEVnTQOy4ZobqeGoTf2qzTlO2VZpyBgSsAnJn/HdgLWG5HAUgIv8Pa/j8kDHmJzNcuyr/BiKyCdgEkEgk2Lp1a1BjVwowPDysr/ESRd/7pUul3vt02i6OE1ywAMDJJ8PnPx/n4x8/mn/5l1ZuuWUvl176KO3tAZrrZkHGgVLTUQDyD+B+Hh787VZYV3p/xTCaHubBnq3BdeiBeYi68Hb3PNi1q3r3r3a0Zgg4ElgPrAZ+JSLHF3uxMeYm4CaAE0880axfv74MQ1R8tm7dir7GSxN975culXzvR0ft9GMmE2xE57HHWsvZl74EN9zQydvf3sl118HZZwfT/2y4T9spvVJ/bdMbk2y76bd0/c9qup5/eCBjm4sHe7ZyXPf64DocB6LgVTbodEEMD8MRR1Qv4rect90JHJKzvzp7LJcdwB3GmJQx5gngr1ixVsy1iqIoyiIiHodDD4W2tuB90VwX3v52mwttzRq7/Y532CoA5cRroOSgAIBQe4SmF3Qw9JNeTKZOwx4jIAexwQHKrJRTnN0HHCki60QkArwWuCOvze1Yqxki0omd5nwcuAt4mYi0ZwMBXpY9piiKoixiXNfmLjv0UGtBGx4O1k/sqKPg+9+H974XfvxjeMlL4Kc/Da7/acRBAvKzanl5gvSeJCP39QfTYaXxKxCMVncY9UDZxJkxJg1cghVVfwG+Y4x5SESuFpFzss3uAvaJyMPAL4D3GmP2GWP2Ax/BCrz7gKuzxxRFUZQlQDxuIzrb24O3ooXDcOml8MMfQmcnvPGNdn9wMLh7+JgAnYea/nEZTpNb3znPIiB1Xiq0EpR1NtUYc6cx5ihjzOHGmGuzxz5ojLkju22MMZcZY44xxhxvjLkl59ovG2OOyC7/Xc5xKoqiKLWH45TXinbccXDnnfCud9kKA6ecAr/8ZXD9AzYZrUMgCVidqEvzS7s4cM8evNE6nRsMg4wRyFTvYqYOYiYURVGUpUy+FS2ZDK7vSAT+9V/tVGdjo82R9upXw0knwerVNtpzy5YSbhBQMlqf1jMTmFGPA78IoOjlDGz5MZx0JrzsrBdx0pl2P1Cc2p3a3LLFvudHHw3r1tkkxtVgVoOriDQA7wHWGGPemk0a+3fGmB9WZHSKoiiKwqQVranJRnQOD1sxFVRE53OeY4MFNm2Ce+6ZPL5zJ1x+OezYAS99KYRC1i/OdSe38485jl2HQnZ8psEW/zYBFP6OP7uV0IooQ3f20PryROkd5rHlx3D5NTA6BiDs6LH7ABvOCOYeJgLOIGRagukvKLZssUmLR7PCcft2+3kAuOCCyo5lrtnw/wYeAJ6f3d8JfBdQcaYoiqJUHN+Ktn8/7N0LsZi1fgXV96OPTj8+Pg4f+5hd5ovjZEWbA24IXH8/V8i5OeIubz19W1gfTvC8327nssvGGW+ITm+bvdfEcSdHQPr3C+W0zRGYV33CF2aTjI7BB2+EWHRhr2shZAy8Tuy0b41w1VWTwsxnZATe//7aE2eHG2NeIyKvAzDGjIgEmR5QURRFUeaH41hH/sbG4K1osyUevekmmyg3k5lc/OS5njf1nL+dToOXgcw+SDt2O51d/GvSfn+5fXiT16fSMJ7MXpeGu6Wbv2c7rX/u4yeNh0xcn84dV852KoASUvsG4M3vLb2femT79srfcy5xlhSROFlXRhE5HC1dqiiKotQA5bCirVxppzLzWbUKzjxz4f06T2NTSQQSvdnAk29o5g3pXq765iFzN8cKwSmiLU8IpjOQScMr3gK9BdzZujrhm/8exNj9AYGkILMywD5L5PWvh76+6cfXrKn8WOb6mFwF/AQ4RERuBl4AXFzuQSmKoihKMfhWtKYma/U6eLC06gJXXjnV7wisCLzyytLGaRpAhgisLk/LyxP0fXwb49uGiR7RNGd7x7FLeI5pxA9emutzZonH4KpL4dijShx0HnIwK87iwfa7UD7wgenvfUMDXHtt5ccyY7SmiDhAO7ABK8i+BZxojNlakZEpiqIoSpHEYsFEdG7YADfcYC1lInZ9ww32eEkEmIwWoOVlXeASeM6zDWfAjf8Gq7tBxLC62+4HFQyQi3FBhoPvd6Hkv/dr1tip7Er7m8EsGt4Y44nIFcaY7wA/quCYFEVRFGXe5FrRSvFF27AhADGWhwkTSK4zn1BHhMbndzD0416Wv/MwxA3OHXzDGXZ5sOeXwdbWzCcKzgHILKNmEnv5732t19b8mYhcLiKHiEiHv1RkZIqiKIqyAGIxm7i2o8P+yAaZF23BhAAXCNB61npmN+m+JCMP1GnKfQFMNimtMoW5Zr9fk12/M+eYAQ4rz3AURVEUpXSCsqIFhp+MNgkElPqj6R+X4TS6DN3ZS+PJ7cF0WmFMGGTQ+uQpk8xqOTPGrCuwqDBTFEVR6oJcK1rQ1QXmi2kACSCthY8Tc2l+6XIO/LyOyzlFbGAAAb4ui4FZxZmIhEXkXSJya3a5RERqKGWcoiiKosyOb0Vbu9buB12js1iCqBCQT8vLE3gjGYZ/Wb5yTmVHarecU7WYy+fs88AJwP/5/9u78/CqynP//+97Z54YZNgoIEkAIUwFjCjS2qh1QootaI9c+LVUW/BUi/VUKmodatE6tJbjVEv9Wey3fB2OWkXlKFpNtSgIIqgQkEFAoExBhgBJIHl+f6y9MYSEBMjeaw+f13XtK1lrr+HOXrngzjPcT+h1amifiIhIXMnM9GbgtW/vtaJVRbtqZzotOuYMIHtwG1I7ZbT4rM1oculgcTpsLlKaGnN2mnPuG3W23zazxZEMSEREJFICAa+LMzsbNm2K8li0ALhMvEXQW6gPygJG64uClP91HQfKq0ltF4HmuUhLC5XUaMHxePGuqZazmtCqAACYWSEQpx3bIiIiHr9a0VwWLT6+qtXwINTArjfit/WMANhev4OIHU0lZ5OAd8ys1Mz+CbwN/CLyYYmIiERWuBWtoMBrOYvKWLQWLkYLkFGYQ0bvXHa+Fr/JmcuAwE5atBZcPDtit6Zz7h9m1hPoFdq13DmntTVFRCRhZGR4rWg7dnhrK2ZkeK9IcBGaUtf64iBbfr+KqtV7yCjMicxNIikFqMRbvTvT51hiQFOzNa8FspxznzjnPgGyzeyn0QlNREQkOuq3ou3eHaFWtDS8/3lbuPWs1QVBbzmnOG49IxAqqyFNTgj4iXPu0fCGc+4rM/sJ3sxNERGRhJKR4dVF++or2LrVS9ScO/RrY8Lv1f9a/5hAAAJ7gIxDj2nsvOYck9ounZwzwss5FWABv6rtHrtw12ZNW2JmOSe/NJWcpZiZOef9/WBmKWguhYiIJDAzrxUtNxdqar5uQavbklZ/X22dlrDw9/W/OhdK8DoAm71kpP4xDV3zSPeoe07GuUH2zClj+/s7yBzU9pD3mpqN2tAxNbWwJ8otWYG9cKA8NHEiiTWVnL0OPGtmfwptTwjtExERSWjpkWqKaI3XrZl7/JeqmyTWnNieuQ+mEHh/M/nfb3tYAnmk5LKhLty1e+HEE48/xqNSFUrMglG+bz3hFk6/NJWc3QSMB/4ztP0m8EREIxIREUlkLZj01e3mDOSk0GF4B7bO2sopd/ckNSvluK4dCHj14KIqC9iDNyng+MKPa02trVnrnHvcOXcpXpL2gXNOdc5ERESOVQAv+djf8pcOjg5Ss7uG8tnlLX/xaDC8chpJvpxTU7M1S82slZmdAHwE/NnM/hCd0ERERBJUDhFJztqc2YaMEzPY9MKmlr94tGQASb6cU1M9qq2dc7uAUcBfnXOnA+dGPiwREZEElkVE1tuxgNFxVEe2l26nelt1y98gGtLxujYjkLzGi6aSs1QzOxH4AfBqFOIRERFJfOl4XXgREBzlLee05eUtkblBNBiQxMs5NZWc3QW8Aax0zs0Pra25IvJhiYiIJLDU0KuFi9EC5PbOJbdvLptfiOOCtJnAV34H4Z+mJgT8j3NugHPup6Ht1c650dEJTUREJIFlAxHqeQyODrJ78W72rIzTkvupeEs5JemCkUleg1dERMQn2cCByFy64/c6QoD4bj0L4I09S0JKzkRERPyQgVc2IhKXDmbQ9qy2bH5xM642QjeJtEy8WZtxGv7xUHImIiLihzS+rusVAZ1Gd6JqfRU7P9wZmRtEWgrejM1KvwOJvqbqnN1jZm3qbLc1symRD0tERCTBhYvRRqhrs/2F7QlkB+K7azMV2O13ENHXVMvZRc65g6XgnHNfAcMjG5KIiEiSyCVi9bxSsr3lnLa8uoWayjhd3CcT2ElEZrXGsqaSsxQzywhvmFkWXi+5iIiIHK9MIlKMNiw4OkjNrhrK34zj5ZxqSbrlnJpKzmYA/zCzq83saryFz5+KfFgiIiJJoAUXQW9I22FtSe+UHt9dm2l4rWdJJPVIbzrn7jOzT/h6yabfOOfeiHxYIiIiSSAVL/mowRsA38IsxQh+L8j6J9ZTXV5NersIZ4ORkAFUELHPKBY1OVvTOfe/zrkbQy8lZiIiIi0pm4iuIxkcHcQdcGyZGafLOYWXuUqimmdNzdbcbWa7Qq9KM6sxs13RCk5ERCTh5RCxGZsAuX1yySnKie+uzXS8mmdJoqnlm/Kcc62cc62ALGA08FhUIhMREUkGUehpDF4aZPfHu9m7Kk5XE0/HmxQQwRbGWNLsIrTO8xJwQQTjERERSS7h5CyClfCD3wt6yzm9GMetZwG8sWdJ4IgTAsxsVJ3NAFBMUtbqFRERiRDD65vaT8Ra0TI6ZdD2m95yTvk35mNmTZ8UazKAr4A2fD0OLUE11XL23TqvC/Dq9F7S3Iub2YVmttzMVprZ5AbeH2dmW81sUej14zrv1dTZP7O59xQREYk7ESxGGxYcHaRyXSU758dpXYpUvM+o2u9AIq+pUho/OtYLm1kK8ChwHrAemG9mM51zS+sd+qxz7roGLrHPOTfwWO8vIiISNyK4CHpY+4vaE5gcYPPzm2kzpE3TJ8SiFLxmogQvh99Ut2YmcDXQF6+OMQDOuauace0hwErn3OrQtZ7Ba3Wrn5yJiIgktyhMCkjNSaXDRR3Y+upWetzVg5TMOCwalok3a7MdCd21ecTkDPi/wDK8Ls27gLFAWTOv3Rn4ss72euD0Bo4bbWZnAZ8DNzjnwudkmtkCvAnG94YmIxzCzMYD4wGCwSClpaXNDE2ORUVFhT7jJKVnn7z07KOomsgnHMXAi/De9PfgW0c+tKKygtIlpREO6BjU4mUXSZyc9XDOXWZmlzjnnjKz/we814L3fwV42jlXZWYT8JaGOif0Xjfn3AYzKwTeNrNPnXOr6p7snJsGTAMoLi52JSUlLRia1FdaWoo+4+SkZ5+89OyjaDPebMSsyN2itlctc6fOJe/DPPpf0/+Ix5YuKaWkb0nkgjlW+/Bqw3XyO5DIaWpCQHh44g4z6we0Bjo289obgK51truE9h3knCt3zlWFNp8ATq3z3obQ19VAKTComfcVERGJPxEuRgsQSA3Q8Xsd2f72dvZvj9OiYZl4484iuGC835pKzqaZWVvgV8BMvPFi9zXz2vOBnmZWYGbpwOWhaxxkZifW2RxJqMvUzNqaWUbo+/bAMDRWTUREElkaUemqC44O4vbH+XJODq8FLUE1NVvzidC37wKF9d83sx86555q5NwDZnYd8Abe/IonnXNLzOwuYIFzbiYw0cxG4v2tsB0YFzq9CPiTmdXiJZD3NjDLU0REJHGk83XiEcEkLbdvLjm9c9j84mY6j+scuRtFUhrexIBcvwOJjKbGnDXlerxxYg1yzs0CZtXbd3ud728Gbm7gvPeBI3eGi4iIJJIoFKMFMDOCo4Osvns1e7/YS3ZBduRuFikZeOPzDnD8mUwMavbyTY1I4LkSIiIiUZZDVNaP7Pi9jmBxvpwTwB6/A4iM403OIlwyT0REJIlk4pWKiPRtTsqkzbA2bH5xM87F6X/l4eWcEpBazkRERGJFFIrRhnUa3YnKNZXsWrArejdtSWlAFQm5nNPxJmdzWiQKERER8abPpRGVMhHth7cnkBlg8wtx3LUZwBt7lmCOmJyZ2T1m1qbOdlszmxLebmRNTBERETlWuUSlNSg1N5X2F7ZnyytbqK2KQl9qJISXc4rTntnGNNVydpFzbkd4wzn3FTA8siGJiIgksWyiVmA1ODrIgR0HKH+7PDo3bGkpeBMoqpo6ML40lZylhIvBAphZFgm/FryIiIiP0olaS1Dbs9qS1iEtvrs2U4E4HTbXmKaSsxnAP8zsajO7GniTI9Q1ExERkeOUhve/cxQStEBqgOAlQcrfKmf/V3G6nFMGsJOozHKNliMmZ865+4ApeBX7i4DfOOfuj0ZgIiIiScnwujajlCsFL/WWc9r66tbo3LClBfASs0q/A2k5zZmt+THwT7zFxz+OaDQiIiIStWK0ALn9csk+JZtNL2yKzg0jIbycU4JoarbmD4APgUuBHwDzzOzSaAQmIiKStDKIWjddeDmnXfN3sW9tnK4mHl7OKUoTKSKtqZazW4HTnHM/dM5dCQwBbot8WCIiIkksisVoAYLfD8b3ck7hkvhxmlvW11RyFnDObamzXd6Mc0REROR4pOAlaAeic7vMzpm0GdqGzc/H8XJO6cB2v4NoGU0lWq+b2RtmNs7MxgGvAbMiH5aIiEiSyyVq487Aq3m2b80+di2M07oU6XgtZ3E66bSuRpMzMzPgIeBPwIDQa5pz7qYoxSYiIpK8sojqGKoOF3dIjOWc9vodxPFLbewN55wzs1nOuf7Ai1GMSURERKI87iw1L5V257djy8tb6HFnj+jevKVk4HVttvY7kOPTVLfmQjM7LSqRiIiIyNfS8Aa6R3EIWKfRnTiw4wDb34nTwVupeOuSxvlyTk0lZ6cDH5jZKjP7xMw+NbNPohGYiIhIUgsXo43CIuhhbb/dlkBOgKXXLoUL4IMhH8TfDM4UvLIacazRbs2QC6IShYiIiBwuF9hM1Fa13vrKVlylw9V4zXVVG6pY/svlAARHBaMTxPHKxCtIewJfl9iIM0dMzpxza6MViIiIiNQTpaQsbPW9qw8mZmG1+2pZfe/q+EnOAnglSCrxJlXEIdUsExERiVVp0b1d1caGB2s1tj9mpQK7/Q7i2Ck5ExERiVVRLkabcVLDTXWN7Y9ZmcBOorYEVktTciYiIhLLorgIeuHkQgJZh6YGlmIUTi6MTgAtxfASszhdzknJmYiISCzLJmotZ8FRQXrd34uMzhlgkJKTgqtxpJ0Q5f7VlpCONzEgDik5ExERiWXRXgR9VJChHw6FN+DMxWeS3SubZTcso7o8ijU9WkIGXkmNKCW2LUnJmYiISCxLxRt75sP4qZSsFPo80of9O/azfNLy+FsU3YjL5ZyUnImIiMSycDFanxb0zu2TS+HkQsrfKOffM/7tTxDHKrycU5xRciYiIhLrojgpoCFdftKFtt9qy8o7V7J3VRw1RaXhLeUUZz2ySs5ERERiXQZRXWOzPgsYvaf2JpARoOxnZdTuj6MaFQFgj99BHB0lZyIiIrEuHd+XIsrolEGvB3qxe/Fu1vx+jb/BHI1M4Ct8TW6PlpIzERGRWBcgqsVoG9NheAc6Xd6JdY+sY8fcOKlTkYLXJRxHixwoORMREYkHufg67iysx109yOyWSdnEMvbvjIGAmiMFr6xGnFByJiIiEg+ygBq/g4DUnFT6PNyHqk1VrLh1hd/hNE+4azNOhsopORMREYkH6cTMuKlWg1uRf0M+W/6+hc1/3+x3OE0L4CVmlX4H0jxKzkREROJBGr4Vo23IyT87mVbFrfj85s+pXB8HWU8qsMvvIJpHyZmIiEi88LneWV2B1ABFDxeBg7KJZbiaGGnWa0wmXnIWA13DTVFyJiIiEi+iuAh6c2SdnEXPKT3ZOW8n6x5d53c4R2Z43cL7/A6kaUrORERE4oXPxWgbErw0SIeRHVjz+zXsWhzj/YbpQBxUAFFyJiIiEi9iaFJAmJlxym9PIb1jOmXXlVGzN4b7DTPwVguIka7hxig5ExERiRcBvLFTMZZcpLVJo/d/92bfF/tYeedKv8M5MgNifHnQiCZnZnahmS03s5VmNrmB98eZ2VYzWxR6/bjOez80sxWh1w8jGaeIiEjciJFitPW1PbMtXf+zK/+e8W+2vr7V73AaF655FsNSI3VhM0sBHgXOA9YD881spnNuab1Dn3XOXVfv3BOAO4BivAbcj0LnxvjHKSIiEmGZxEw5jfoKJhXw1XtfsfzG5bQa1IqMYIbfIR0uFdiNt5xTDIYHkW05GwKsdM6tds5VA88AlzTz3AuAN51z20MJ2ZvAhRGKU0REJH6k+x1A4wLpAYoeKaJ2Xy3L/msZrjbGBsiFBfDGnsWoSCZnnYEv62yvD+2rb7SZfWJmz5tZ16M8V0REJLnEWDHa+nJ65ND99u58VfoVG/6ywe9wGpaJN2szRnPHiHVrNtMrwNPOuSozmwA8BZzT3JPNbDwwHiAYDFJaWhqRIMVTUVGhzzhJ6dknLz37GLUfL7GwyN2iorKC0iWlx3byqcDpsPI3K1kZXAkFLRlZC6kF1hLRz/BYRTI52wB0rbPdJbTvIOdceZ3NJ4D765xbUu/c0vo3cM5NA6YBFBcXu5KSkvqHSAsqLS1Fn3Fy0rNPXnr2MWoXsAlvckCElC4ppaRvyTGfXz2tmvnnzid9ajqDXx1MSmZKywXXEvYBeUBHvwM5XCS7NecDPc2swMzSgcuBmXUPMLMT62yOBMpC378BnG9mbc2sLXB+aJ+IiIjE6ED2utLbp9P7wd7sKdvDF/d+4Xc4h8sEdhKT3cMRazlzzh0ws+vwkqoU4Enn3BIzuwtY4JybCUw0s5F4i1FsB8aFzt1uZr/BS/AA7nLObY9UrCIiInElze8Amqfdue04adxJrP/zek445wROOOsEv0P6muElZvvw1iyNIREdc+acmwXMqrfv9jrf3wzc3Mi5TwJPRjI+ERGRuFS3GG2MJ2rdf9WdHXN2sOznyzjtrdNIOyGGAk7Daz2LseRMKwSIiIjEoxxishhtfSlZKRQ9UsT+7ftZ/svlOBdDUyQzgAogxlacUnImIiISj7KIuaSiMXn98ii4qYBt/7uNTc9s8jucr4VnasZYzTMlZyIiIvEohovRNqTrhK60GdaGFbevYO/qGFrcMh2v5lkMUXImIiISj1LxxkzF4GzDhljA6D21N4H0AGUTy6jdHyOBp+NNCoihLmIlZyIiIvEqG6j2O4jmyzwpk1PuPYXdH+9m7dS1fofztQDe2LMYoeRMREQkXuXgFaOKIx2/25HgZUHWPrSWHR/GSH9iBvAVMbOck5IzERGReJVOzCQUR6Pnb3qS2TWTZROXcWBXDGSXqXjdmjHSCqnkTEREJF6l4804jLMELTUvlaKHiqjcWMmKX63wOxxPCrDb7yA8Ss5ERETileEVo42Bxqej1bq4Nd2u78bmFzaz+eXNfofjfY47iIlEV8mZiIhIPMslpmYaHo1u13ej1eBWfD75cyo3VPobTACvbpzPYYCSMxERkfiWSdyU06gvkBqg6OEiqIGy68twNT43W6XiLefkMyVnIiIi8SxOJwWEZeVn0eM3Pdj5wU6+fPxLf4PJxBt35vPKC0rORERE4lm4GG2cLOXUkE4/6ESHizvwxQNfsPtTH0flhydX7PMvBFByJiIiEv/iZBH0xpgZp9x3Cmnt0lh67VJq9vmYaabh+3JOSs5ERETiXTZxOWOzrrS2aRRNLWLfqn2s+vUq/wLJwFsI3cdxfErORERE4l2cLYLemLbfakuXCV3Y+H83sm32Nv8CMf9uDUrORERE4l+cFqNtSOFNheT0yWH5jcup3hojJfujTMmZiIhIvAsXo43jcWdhgYwAfR7tQ82eGpb91zKcS4CM8ygpORMREUkEcVyMtr6cU3Io/FUh29/ezobpG/wOJ+qUnImIiCSCTBKiWzOs87jOnHDOCayespo9n+/xO5yoUnImIiKSCNL8DqBlmRm9ft+LlOwUll67lNqqOF0G4RgoORMREUkEqaFXHBejrS+jYwa9ft+LPUv38MX9X/gdTtQoORMREUkUOUCCTXBsf357Tvo/J/Hl41/y1Xtf+R1OVCg5ExERSRQ5xH0x2oZ0v6M7Wd2zKPt5Gfu/SpBZD0eg5ExERCRRJEgx2vpSslLo80gf9m/bz+c3fZ7w5TWUnImIiCSKNLz/2RMwd8kbkEfBLwvY+tpWNj23ye9wIkrJmYiISKIwIIuEqXdWX9drutJ6aGtW3raSfWv2+R1OxCg5ExFOSbnmAAAerUlEQVQRSSQ5JGxyZilG0X8XQQqU/ayM2gOJWV5DyZmIiEgiyQQSM2cBILNzJqfcewq7Fu5i7X+v9TuciFByJiIikkgSdFJAXcFLggRHBVk7dS07F+z0O5wWp+RMREQkkaTgTQxIoGK0Del5d08yO2dSNrGMAxWJVT9EyZmIiEiiySXhitHWl9oqlaKHi6j8spKVt630O5wWpeRMREQk0WST8C1nAK1Pa023n3Vj03Ob2PLKFr/DaTFKzkRERBJNOglZ66wh3W7oRt6gPD6f/DmVGyv9DqdFKDkTERFJNAlcjLa+QFqAooeKqK2uZdnPl+Fq4/+HVnImIiKSaAyvazPBx52FZRdm0/OunuyYs4Mvp33pdzjHTcmZiIhIIkrQRdAb0+nyTrS/qD1f3PsFuz/b7Xc4x0XJmYiISCLKICm6NcPMjF739yLthDTKriujZl/8zohQciYiIpKIkqAYbX1pJ6TRe2pv9q7Yy6opq/wO55gpORMREUlE4WK0SdS1CXDCWSfQ5cdd2Dh9I+X/KPc7nGOi5ExERCRR5ZKwi6AfScHNBeQU5bDsv5ZRvS3+ZkVENDkzswvNbLmZrTSzyUc4brSZOTMrDm3nm9k+M1sUej0eyThFREQSUpIUo60vJTOFokeKOLD7AMv+axnOxdfgu4glZ2aWAjwKXAT0AcaYWZ8GjssDrgfm1XtrlXNuYOh1TaTiFBERSVhpfgfgn9zeuXS/pTvb/7GdjX/d6Hc4RyWSLWdDgJXOudXOuWrgGeCSBo77DXAfkBhlfUVERGJFEhWjbUjnqzrT9tttWXXXKvas3ON3OM2WGsFrdwbqVoJbD5xe9wAzGwx0dc69ZmaT6p1fYGYfA7uAXznn3qt/AzMbD4wHCAaDlJaWtmD4Ul9FRYU+4ySlZ5+89OwTwH685MyO7rSKygpKl5RGIKAouwb4GOZfPR/+m+a1JtYCPja2RTI5OyIzCwAPAuMaePvfwMnOuXIzOxV4ycz6Oud21T3IOTcNmAZQXFzsSkpKIht0kistLUWfcXLSs09eevYJYCewGW9ywFEoXVJKSd+SCAQUfdumbuOzqz6j62td6X5r96ZPqAB64Nu0yUjedgPQtc52l9C+sDygH1BqZmuAM4CZZlbsnKtyzpUDOOc+AlYBp0QwVhERkcSUZMVoG9L+gvacOPZEvvzjl3z1/ld+h9OkSCZn84GeZlZgZunA5cDM8JvOuZ3OufbOuXznXD4wFxjpnFtgZh1CEwows0KgJ7A6grGKiIgkpjSOukszEfW4swdZ+Vksm7iM/Ttiu75IxJIz59wB4DrgDaAMeM45t8TM7jKzkU2cfhbwiZktAp4HrnHObY9UrCIiIgkrBW+1gCQrRltfSrZXXqN6azWf3/x5TJfXiOiYM+fcLGBWvX23N3JsSZ3vXwBeiGRsIiIiSSMXb+yZbyPNY0Orga3I/0U+X9z3BZvP3UynSzv5HVKDtEKAiIhIossi6VvOwk6+9mRan96aFbeuYN+6fX6H0yAlZyIiIokuCRdBb4ylGEUPFYFB2c/KqD1Q63dIh1FyJiIikuhS8caexV4e4ovMLpmccs8p7Fqwi3UPr/M7nMMoORMREUl0hrfOZmxPUoyq4KggHb/XkTV/WMOuhbuaPiGKlJyJiIgkgxw07qyenvf0JKNTBkt/tpQDFbHz4Sg5ExERSQYZqFuznrTWaRQ9VETl2kpW3rHS73AOUnImIiKSDNJRMdoGtDmjDSdfezKbntnE1llb/Q4HSPqKJyIiIkkigNd6dgD9719P/i/y2f7udpZOXErabWlUb64mo2sGhfcUEhwbjHo8ajkTERFJFjloUkADAukBOo7siNvnqN5UDQ6q1lWxfPxyNs/YHP14on5HERER8UcWUON3ELFpw182HLavdm8tq2+N/tLeSs5ERESSRToQu0tK+qpqY1XD+9c1vD+SlJyJiIgkizRUjLYRGSdlNLz/5Ib3R5KSMxERkWSSA1T7HUTsKZxcSCDr0LQokB2g8O7CqMei5ExERCSZ5KBxZw0IjgrS6/5eZHTOAPNazHpN6+XLbE1NphUREUkmGnfWqOCoIMFRQagAeuBbE5ZazkRERJJJut8BSFOUnImIiCSTcDFa1TuLWUrOREREkk0uSs5imJIzERGRZKNitDFNyZmIiEiySUOLoMcwJWciIiLJRsVoY1pCl9LYv38/69evp7Ky0u9QEkLr1q0pKyvzO4xGZWZm0qVLF9LS0vwORUQk9mUD+4BMvwOR+hI6OVu/fj15eXnk5+djpvbb47V7927y8vL8DqNBzjnKy8tZv349BQUFfocjIhL7coDdfgchDUnobs3KykratWunxCwJmBnt2rVTK6mISHNloGK0MSqhkzNAiVkS0bMWETkK4UkBStBiTsInZyIiItKAAN54swN+ByL1KTmLsNzcXL9DAGDRokXMmjXrmM7dsWMHjz32WAtHJCIivlMx2pik5KyOGZ/OIH9qPoFfB8ifms+MT2f4HdJBNTXHVy1QyZmIiBwmExWjjUFKzkJmfDqD8a+MZ+3OtTgca3euZfwr41ssQXPOMWnSJPr160f//v159tlnAaitreWnP/0pvXv35rzzzmP48OE8//zzAOTn53PTTTcxePBg/ud//ofZs2czdOhQBg8ezGWXXUZFRQUAs2bNonfv3px66qlMnDiRESNGHHLv6upqbr/9dp599lkGDhzIs88+y549e7jqqqsYMmQIgwYN4uWXXwZgyZIlDBkyhIEDBzJgwABWrFjB5MmTWbVqFcOGDWPSpEkt8nmIiEgM0CLoMSmhS2nU9fPXf86iTYsafX/u+rlU1VQdsm/v/r1c/fLV/PmjPzd4zsBOA5l64dRm3f/FF19k0aJFLF68mG3btnHaaadx1llnMWfOHNasWcPSpUvZsmULRUVFXHXVVQfPa9euHQsXLmTbtm2MGjWKt956i5ycHO677z4efPBBfvnLXzJhwgTeffddCgoKGDNmzGH3Tk9P56677mLBggU88sgjANxyyy2cc845PPnkk+zYsYMhQ4bwne98h8cff5zrr7+esWPHUl1dTU1NDffeey+fffYZc+bMidlSGiIicgxS8SYG1KLmmhiSNMlZU+onZk3tP1r/+te/GDNmDCkpKQSDQb797W8zf/58/vWvf3HZZZcRCATo1KkTZ5999iHn/cd//AcAc+fOZenSpQwbNgzwWsOGDh3KsmXLKCwsPFjba8yYMUybNq3JeGbPns3MmTP53e9+B3hlR9atW8fQoUO5++67Wb9+PaNGjaJnz54t8vOLiEiMygb2omK0MSRpkrOmWrjyp+azdufaw/Z3a92N0nGlEYqqaTk5OYDXLXreeefx9NNPH/L+okWNtwYeiXOOF154gV69eh2yv6ioiNNPP53XXnuN4cOH86c//YnCwsJjC15ERGJfDrDL7yCkLjVihtx97t1kp2Ufsi87LZu7z727Ra7/rW99i2effZaamhq2bt3Ku+++y5AhQxg2bBgvvPACtbW1bN68mdLS0gbPP+OMM5gzZw4rV64EYM+ePXz++ef06tWL1atXs2bNGoCDY9nqy8vLY/fur0tBX3DBBTz88MM45xW4+fjjjwFYvXo1hYWFTJw4kUsuuYRPPvnksHNFRCSBpKNaZzFGyVnI2P5jmfbdaXRr3Q3D6Na6G9O+O42x/ce2yPW///3vM2DAAL7xjW9wzjnncP/999OpUydGjx5Nly5d6NOnD1dccQWDBw+mdevWh53foUMHpk+fzpgxYxgwYMDBLs2srCwee+wxLrzwQk499VTy8vIaPP/ss89m6dKlBycE3Hbbbezfv58BAwbQt29fbrvtNgCee+45+vXrx8CBA/nss8+48soradeuHcOGDeP000/XhAARkUSTjorRxhgLt5zEu+LiYrdgwYJD9pWVlVFUVORTRM1XUVFBbm4u5eXlDBkyhDlz5tCpU6ejPt85x7XXXkvPnj254YYbWjzOWF5bMyxennm8KS0tpaSkxO8wxAd69kniS7ySGnVmb5YuKaWkb4lPAfmsAuhBRJuwzOwj51xxQ+8lzZizWDZixAh27NhBdXU1t91221ElZgB//vOfeeqpp6iurmbQoEFMmDAhQpGKiEhCygXKUWmNGKHkLAY0Ns6suW644YaItJSJiEiSyMArpyExQWPOREREkp0mBcQUJWciIiLJLlyMVks5xQQlZyIiIuLVO6v2OwgBJWciIiICXnKmlrOYENHkzMwuNLPlZrbSzCYf4bjRZubMrLjOvptD5y03swsiGWck3X333fTt25cBAwYwcOBA5s2bx69//WtuvvnmQ45btGjRwRIQFRUVTJgwge7du3PqqadSUlLCvHnzDrv2Pffcc8xxTZ8+nY0bNx7z+SIikmDS/A5AwiKWnJlZCvAocBHQBxhjZn0aOC4PuB6YV2dfH+ByoC9wIfBY6HoRNWMG5OdDIOB9nTHj+K73wQcf8Oqrr7Jw4UI++eQT3nrrLbp27cqYMWMOq+T/zDPPHFy0/Mc//jEnnHACK1as4KOPPuIvf/kL27ZtO+z6Ss5ERKTFqBhtzIhkKY0hwErn3GoAM3sGuARYWu+43wD3AXVLz18CPOOcqwK+MLOVoet9EKlgZ8yA8eNh715ve+1abxtg7DEuEvDvf/+b9u3bk5GRAUD79u0Pvte2bVvmzZvH6aefDniV+d944w1WrVrFvHnzmDFjBoGAlzsXFBQcXNg8bPLkyezbt4+BAwfSt29fZsyYwd/+9jceeughqqurOf3003nssccAuPrqq1mwYAFmxlVXXUXXrl1ZsGABY8eOJSsriw8++ICsrKxj+yFFRCQxGN7i5/tRvTOfRTI564xXczhsPXB63QPMbDDQ1Tn3mplNqnfu3Hrndq5/AzMbD4wHCAaDh9ULa9269cE1IW+6KYNPP228oXD+/BSqquyQfXv3wtVXOx5/vOFO+P79a7nvvqpGrzl06FDuvPNOevToQUlJCaNHj+ab3/wmAKNGjeKvf/0rffr04cMPP6RNmzZ06tSJWbNm0a9fP/aGs8RG3HrrrTzyyCO89957ACxYsIAZM2bw+uuvk5aWxg033MATTzxBUVER69at44MPvLx2x44dtGnThkGDBjFlyhQGDx7MgQMHmrV2Zk1NTcyvsVlZWXncdePkcBUVFfpck5SefZKpAQ4AAaiorKB0SanPAfmkFvCxc8m3IrRmFgAeBMYd6zWcc9OAaeAt31R/iZGysrKDyw2lp0PKETpGqxrJsaqqjJSUhj+m9HTIy2v8z4u8vDw+/vhj3nvvPd555x1+9KMfce+99zJu3DiuvPJKzjzzTB5++GFeeeUVxo4dS15eHllZWaSmpjZ7maTwcXPnzmXx4sWcc845AOzbt48uXbrwgx/8gLVr13LLLbdw8cUXc/755xMIBEhJSSEnJ+eolmOKh+WbMjMzGTRokN9hJBwt4ZO89OyTzD5gHZCn5ZsivXzTkUQyOdsAdK2z3SW0LywP6AeUmhlAJ2CmmY1sxrlHberUI7+fn+91ZdbXrRsczx+NKSkplJSUUFJSQv/+/XnqqacYN24cXbt2paCggH/+85+88MILB1u2+vbty+LFi6mpqSHlSNlkPc45fvjDH/Lb3/72sPcWL17MG2+8weOPP85zzz3Hk08+eew/kIiIJK7wuDPxVSRzwvlATzMrMLN0vAH+M8NvOud2OufaO+fynXP5eN2YI51zC0LHXW5mGWZWAPQEPoxgrNx9N2RnH7ovO9vbf6yWL1/OihUrDm4vWrSIbt26HdweM2YMN9xwA4WFhXTp0gWA7t27U1xczB133EF4Ufo1a9bw2muvHXb9tLQ09u/fD8C5557L888/z5YtWwDYvn07a9euZdu2bdTW1jJ69GimTJnCwoULAa/FLda7KEVEJMpS8JptVFLDVxFrOXPOHTCz64A38B73k865JWZ2F7DAOTfzCOcuMbPn8CYPHACudc5F9FclPOj/1lth3To4+WQvMTvWyQDgjdX42c9+xo4dO0hNTaVHjx5Mmzbt4PuXXXYZEydO5OGHHz7kvCeeeIJf/OIX9OjRg6ysLNq3b88DDzxw2PXHjx/PgAEDGDx4MDNmzGDKlCmcf/751NbWkpaWxqOPPkpWVhY/+tGPqK31Fk0Lt6yNGzeOa665RhMCRETkULmA/nb3lYVbZ+JdcXGxW7BgwSH7ysrKDtYOk+MXD2PO9MwjQ+OOkpeefRKqADZC6VqNOYtk/6KZfeScK27oPa0QICIiIl/TIui+U3ImIiIiX0tD2YHP9PGLiIjI1wzIQq1nPlJyJiIiIofKQcmZj3wrQisiIiIxKjyBv+IIx4STN6vz1RrZDtTbVi21I1JyJiIiIofKBDLwZiy6I7xq633f0KumzqvucfU5jpy01U/umnrFMXVrRpiZccUVVxzcPnDgAB06dGDEiBEATJ8+neuuu+6w8/Lz8+nfvz8DBgzg/PPPZ9OmTYBXO23ChAl0796dU089lZKSEubNmwdAbm5ui8X9+OOP89e//hWAZcuWMXDgQL75zW+yatUqzjzzzOO69tSpU5tcO7QxL730EkuXLj2u+4uISDMF+LowbRreTM4MvOQtC6/7MxdvzZ/WQFugHdABCAIn4q3x0w0oAArxEr5T8MrL9wC6h/YXhI47GW+NoC54q2qfFLpOx9C1W4Xum8nXkxccXlXUarwlqCrwarVVNPEKH7MH2Bs6dx++d+mq5ayOzTM2s/rW1VStqyLj5AwK7y4kODZ4XNfMycnhs88+Y9++fWRlZfHmm2/SufNha7g36J133qF9+/bccsst3HPPPTz00EP8+Mc/pqCggBUrVhAIBPjiiy8ikqxcc801B79/6aWXuPTSS7n++uvJy8vj/fffb/Z1nHM45wgEvv47YOrUqVxxxRVk11+SoRleeuklRowYQZ8+fY76XBERiSGRbOE6Umtfc1r9fG59U8tZyOYZm1k+fjlVa6vAQdXaKpaPX87mGZuP+9rDhw8/uPzS008/zZgxY47q/LPOOouVK1eyatUq5s2bx5QpUw4mOwUFBVx88cWHHF9RUcG5557L4MGD6d+/Py+//DIAe/bs4eKLL+Yb3/gG/fr149lnnwVg8uTJ9OnThwEDBnDjjTcCcOedd/K73/2OWbNmMXXqVP74xz8evE/dFroHHniA0047jQEDBnDHHXcA3nJTvXr14sorr6Rfv358+eWXB49/6KGH2LhxI2effTZnn302ALNnz2bo0KEMHjyYyy67jIqKigbjev/995k5cyaTJk1i4MCBrFq16qg+RxERSRLhcW7H2urXHl+Ts6RpOVvx8xVULGp8ZOOuubtwVYe2Y9burWXZ1cvY+OeNDZ6TOzCXnlN7Nnnvyy+/nLvuuosRI0bwySefcNVVV/Hee+81O/ZXX32V/v37s2TJEgYOHNjkguiZmZn8/e9/p1WrVmzbto0zzjiDkSNH8vrrr3PSSScdTBR37txJeXk5f//731m2bBlmxo4dOw651vDhw7nmmmvIzc1lwoQJh7w3e/ZsVqxYwYcffohzjpEjR/Luu+9y8skns2LFCp566inOOOOMQ86ZOHEiDz744MFWwW3btjFlyhTeeustcnJyuO+++3jwwQe59tprD4urTZs2jBw5khEjRnDppZc2+/MTERGJJ2o5C6mfmDW1/2gMGDCANWvW8PTTTzN8+PBmn3f22WczcOBAdu3axc0339zs85xz3HLLLQwYMIDvfOc7bNiwgc2bN9O/f3/efPNNbrrpJt577z1at25N69atyczM5Oqrr+bFF188qq7G2bNnM3v2bAYNGsTgwYNZtmzZwYXeu3Xrdlhi1pC5c+eydOlShg0bxsCBA3nqqadYu3btccUlIiISz5Km5aypFq4P8j/wujTryeiWwaDSQcd9/5EjR3LjjTdSWlpKeXl5s84Jty6F9e3bl8WLF1NTU3PE1rMZM2awdetWPvroI9LS0sjPz6eyspJTTjmFhQsXMmvWLH71q19x7rnncvvtt/Phhx/yj3/8g+eff55HHnmEt99+u1nxOee4+eabD2tRW7NmDTk5Oc2+xnnnncfTTz992HvHGpeIiEg8U8tZSOHdhQSyD/04AtkBCu8ubJHrX3XVVdxxxx3079//mK/RvXt3iouLueOOOwgvWL9mzZqD3ZRhO3fupGPHjqSlpfHOO++wdu1aADZu3Eh2djZXXHEFkyZNYuHChVRUVLBz506GDx/OH/7wBxYvXtzseC644AKefPLJg2PENmzYwJYtW5o8Ly8vj927dwNwxhlnMGfOHFauXAl44+I+//zzRuOqe66IiEgiSpqWs6aEZ2W29GzNsC5dujBx4sQG35s+fTovvfTSwe25c+c2ep0nnniCX/ziF/To0YOsrCzat2/PAw88cMgxY8eO5bvf/S79+/enuLiY3r17A/Dpp58yadIkAoEAaWlp/PGPf2T37t1ccsklVFZW4pzjwQcfbPbPdP7551NWVsbQoUMBb6LA3/72tybHxI0fP54LL7yQk046iXfeeYfp06czZswYqqq8lsspU6aQl5fXYFyXX345P/nJT3jooYd4/vnn6d69e7PjFRERiQcWboGJd8XFxW7BggWH7CsrK6OoqMiniBLP7t27ycvL8zuMI9Izj4zS0lJKSkr8DkN8oGefvPTsI8vMPnLOFTf0nro1RURERGKIkjMRERGRGJLwyVmidNtK0/SsRUQkESR0cpaZmUl5ebn+004CzjnKy8vJzMz0OxQREZHjktCzNbt06cL69evZunWr36EkhMrKyphOfjIzM+nSpYvfYYiIiByXhE7O0tLSKCgo8DuMhFFaWsqgQcdfkFdEREQal9DdmiIiIiLxRsmZiIiISAxRciYiIiISQxJmhQAz2wqs9TuOBNce2OZ3EOILPfvkpWefvPTsI6ubc65DQ28kTHImkWdmCxpbakISm5598tKzT1569v5Rt6aIiIhIDFFyJiIiIhJDlJzJ0ZjmdwDiGz375KVnn7z07H2iMWciIiIiMUQtZyIiIiIxRMmZiIiISAxRciYiIiISQ5SciYiIiMQQJWfSIsysyMweN7Pnzew//Y5HosfMCs3s/zOz5/2ORSJPzzs56d/46FJyJpjZk2a2xcw+q7f/QjNbbmYrzWzyka7hnCtzzl0D/AAYFsl4peW00LNf7Zy7OrKRSiQdze+BnnfiOMrnrn/jo0jJmQBMBy6su8PMUoBHgYuAPsAYM+tjZv3N7NV6r46hc0YCrwGzohu+HIfptMCzl7g3nWb+HkQ/NImg6RzFc9e/8dGT6ncA4j/n3Ltmll9v9xBgpXNuNYCZPQNc4pz7LTCikevMBGaa2WvA/4tcxNJSWurZS3w7mt8DYGl0o5NIOdrnrn/jo0ctZ9KYzsCXdbbXh/Y1yMxKzOwhM/sT+qsq3h3ts29nZo8Dg8zs5kgHJ1HT4O+BnnfCa+y569/4KFLLmbQI51wpUOpzGOID51w5cI3fcUh06HknJ/0bH11qOZPGbAC61tnuEtoniU/PXkC/B8lKzz0GKDmTxswHeppZgZmlA5cDM32OSaJDz15AvwfJSs89Big5E8zsaeADoJeZrTezq51zB4DrgDeAMuA559wSP+OUlqdnL6Dfg2Sl5x67zDnndwwiIiIiEqKWMxEREZEYouRMREREJIYoORMRERGJIUrORERERGKIkjMRERGRGKLkTERERCSGKDkTkYRlZp3M7BkzW2VmH5nZLDM7JfTe/5pZlyOcO93MLm3i+k0eIyJytLS2pogkJDMz4O/AU865y0P7vgEEzexLoJ1zbr2fMYqINEQtZyKSqM4G9jvnHg/vcM4tds69B5QQWsTZzG43s/lm9pmZTQsldYcwszVmdr+ZfWpmH5pZjzpvn2Vm75vZ6nArmpnlmtk/zGxh6JxLIvmDikhiUXImIomqH/BRI+9dBLwe+v4R59xpzrl+QBYwopFzdjrn+gOPAFPr7D8R+GbovHtD+yqB7zvnBuMlib9vKOkTEWmIkjMRSUbDgH+Fvj/bzOaZ2afAOUDfRs55us7XoXX2v+Scq3XOLQWCoX0G3GNmnwBvAZ3rvCcickQacyYiiWoJcNhgfTMrBL50zlWbWSbwGFDsnPvSzO4EMhu5nmvk+6q6lw99HQt0AE51zu03szVHuK6IyCHUciYiieptIMPMxod3mNkA4P/wdZdmOGHaZma5NJDM1fEfdb5+0MS9WwNbQonZ2UC3ow1eRJKXWs5EJCE555yZfR+YamY34Y0DW4P3R+l/ho7ZYWZ/Bj4DNgHzj3DJtqFuyipgTBO3nwG8EuoqXQAsO56fRUSSiznnmj5KRCQBmFkGMMc5V3yU563B6/rcFpHARETqUMuZiCQN51wVcFSJmYhItKnlTERERCSGaEKAiIiISAxRciYiIiISQ5SciYiIiMQQJWciIiIiMUTJmYiIiEgM+f8BPkPgvBTUqhkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kof-4TmuoRtk"
      },
      "source": [
        "*Вывод:* Качество немного упало на логистической регрессии, значительно упало на SVC и немного возросло на MLPClassifier. Однако на SVM заметно уменьшилось время обучения (не замеряла, просто по ощущениям). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u0Q4Bb0hgQI",
        "outputId": "a3655e6f-de05-4a17-f45c-525b04ca949d"
      },
      "source": [
        "print('logreg best score:', sc_logreg_CV.best_score_)\n",
        "print('SVC best score:', sc_svc_CV.best_score_)\n",
        "print('MLPClassifier best score:', sc_mlpc_CV.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logreg best score: 0.7127536613007244\n",
            "SVC best score: 0.6977528160239432\n",
            "MLPClassifier best score: 0.7127599226102147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK1l_CzUhgQi",
        "outputId": "f8be5896-cc63-46af-f9ba-f9ea6331a6dc"
      },
      "source": [
        "print('logreg std for best parameter:', sc_logreg_CV.cv_results_['std_test_score'][5])\n",
        "print('SVC std for best parameter:', sc_svc_CV.cv_results_['std_test_score'][5])\n",
        "print('MLPClassifier std for best parameter:', sc_mlpc_CV.cv_results_['std_test_score'][5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logreg std for best parameter: 0.022001033941762154\n",
            "SVC std for best parameter: 0.016735323583517463\n",
            "MLPClassifier std for best parameter: 0.023774952615061296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGOPpL9DhgQj"
      },
      "source": [
        "Качество по прежнему наилучшее у логистической регрессии. Отклонения у моделей не изменились заметно. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtdFlaGRVP5q"
      },
      "source": [
        "#### MinMax\n",
        "*Попробую с MinMaxScaler*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04xFZ_6jjUL6"
      },
      "source": [
        "scaler = MinMaxScaler() \n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_mmscaled = scaler.transform(X_train) \n",
        "X_test_mmscaled = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxB7D0e7jUMS"
      },
      "source": [
        "Повторяю всё то же и с теми же настройками, что в 3 задании: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7-Pix1djUMS"
      },
      "source": [
        "# Так же использую только часть данных для обучения моделей. \n",
        "data_part=4000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va9EPNj5jUMT"
      },
      "source": [
        "##### 5 MinMax LogReg\n",
        "**5.2.1. Logistic Regression Classifier**\n",
        "\n",
        "Буду подбирать значение для `C` - inverse of regularization strength. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vssr-hcijUMU",
        "outputId": "ba291d42-a7a2-4f37-a59e-e81322bdca3b"
      },
      "source": [
        "# Инициализирую модель\n",
        "logreg_model = LogisticRegression(penalty='l2', \n",
        "                                  tol=0.0001, \n",
        "                                  C=1.0, \n",
        "                                  solver='liblinear', \n",
        "                                  random_state=1234,\n",
        "                                  max_iter=100)\n",
        "\n",
        "# Тестируемые значения гиперпараметрa \n",
        "logreg_params_set = {\n",
        "'C': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 1e2, 1e3, 1e4]\n",
        "}\n",
        "\n",
        "# Кросс-валидация\n",
        "mmsc_logreg_CV = GridSearchCV(estimator=logreg_model,\n",
        "                         param_grid=logreg_params_set,\n",
        "                         scoring='roc_auc',\n",
        "                         return_train_score=True)\n",
        "\n",
        "mmsc_logreg_CV.fit(X_train_mmscaled[:data_part], y_train[:data_part])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=1234, solver='liblinear',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100.0, 1000.0,\n",
              "                               10000.0]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y3WFyftjUMW"
      },
      "source": [
        "Лучший набор параметров и значение критерия качества на нём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haIbLJiGjUMX",
        "outputId": "f3d27b0c-38f5-4a62-93ea-a41c56377b35"
      },
      "source": [
        "mmsc_logreg_CV.best_params_ , mmsc_logreg_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'C': 10000.0}, 0.7125545516589339)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ5x6yH2jUMd"
      },
      "source": [
        "График среднего значения качества:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "joKsXVbxjUMd",
        "outputId": "3ffff8e7-727e-438d-ef88-d1ed1582eb38"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(logreg_params_set['C'], mmsc_logreg_CV.cv_results_['mean_train_score'], 'bo-', label='minmax scaled train')\n",
        "plt.plot(logreg_params_set['C'], mmsc_logreg_CV.cv_results_['mean_test_score'], 'go-', label='minmax scaled test')\n",
        "\n",
        "plt.fill_between(logreg_params_set['C'], \n",
        "                 mmsc_logreg_CV.cv_results_['mean_test_score']-mmsc_logreg_CV.cv_results_['std_test_score'], \n",
        "                 mmsc_logreg_CV.cv_results_['mean_test_score']+mmsc_logreg_CV.cv_results_['std_test_score'], \n",
        "                 color='green', alpha=0.1)\n",
        "\n",
        "plt.plot(logreg_params_set['C'], logreg_CV.cv_results_['mean_train_score'], 'mo-', label='train')\n",
        "plt.plot(logreg_params_set['C'], logreg_CV.cv_results_['mean_test_score'], 'ro-', label='test')\n",
        "\n",
        "plt.fill_between(logreg_params_set['C'], \n",
        "                 logreg_CV.cv_results_['mean_test_score']-logreg_CV.cv_results_['std_test_score'], \n",
        "                 logreg_CV.cv_results_['mean_test_score']+logreg_CV.cv_results_['std_test_score'], \n",
        "                 color='red', alpha=0.1)\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('C'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('Logistic Regression')\n",
        "plt.xscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQEx3QlMjUMf"
      },
      "source": [
        "Изменилось на:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wXBpZ8njUMf",
        "outputId": "3f17ef85-6f44-4ac2-d373-4dfd3e7e7aa7"
      },
      "source": [
        "mmsc_logreg_CV.best_score_ - logreg_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.00034562428386275545"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkFWIl-TfkaV"
      },
      "source": [
        "Оценка качества на части (1000 элементов) тестовой выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4scwmAmofkat",
        "outputId": "622642bb-aeba-47c4-c012-5b58ed4f1402"
      },
      "source": [
        "mmsc_lr_test_score = roc_auc_score(y_true=y_test[:test_part], y_score=mmsc_logreg_CV.best_estimator_.predict(X_test[:test_part]))\n",
        "mmsc_lr_test_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5657108793323492"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79VUZKxnfkaw"
      },
      "source": [
        "На тестовых данных качество изменилось на:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI6fgjoqfkax",
        "outputId": "e3275398-1d52-4106-b0fd-d957d813ee08"
      },
      "source": [
        "mmsc_lr_test_score - lr_test_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.11802513292605343"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCGkugoKjUMg"
      },
      "source": [
        "##### 5 MinMax SVC\n",
        "**5.2.2. C-Support Vector Classification**\n",
        "\n",
        "Буду так же подбирать значение для `C` - inverse of regularization strength. \n",
        "\n",
        "Остальные параметры оставляю по умолчанию. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iakkd1snjUMh",
        "outputId": "485ff3e2-030c-46b5-d274-77137535484f"
      },
      "source": [
        "# Инициализирую модель\n",
        "svc_model = SVC(C=1.0, \n",
        "                kernel='rbf',\n",
        "                gamma='scale',\n",
        "                shrinking=True,\n",
        "                tol=0.001,\n",
        "                random_state=1234)\n",
        "\n",
        "# Тестируемые значения гиперпараметрa \n",
        "svc_params_set = {\n",
        "'C': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 1e2, 1e3, 1e4]\n",
        "}\n",
        "\n",
        "# Кросс-валидация\n",
        "mmsc_svc_CV = GridSearchCV(estimator=svc_model,\n",
        "                      param_grid=svc_params_set,\n",
        "                      scoring='roc_auc',\n",
        "                      return_train_score=True,\n",
        "                      verbose=3)\n",
        "\n",
        "mmsc_svc_CV.fit(X_train_mmscaled[:data_part], y_train[:data_part])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] C=0.0001 ........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........ C=0.0001, score=(train=0.687, test=0.713), total=   0.9s\n",
            "[CV] C=0.0001 ........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........ C=0.0001, score=(train=0.696, test=0.665), total=   0.9s\n",
            "[CV] C=0.0001 ........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........ C=0.0001, score=(train=0.690, test=0.703), total=   0.9s\n",
            "[CV] C=0.0001 ........................................................\n",
            "[CV] ........ C=0.0001, score=(train=0.699, test=0.663), total=   0.9s\n",
            "[CV] C=0.0001 ........................................................\n",
            "[CV] ........ C=0.0001, score=(train=0.701, test=0.649), total=   0.9s\n",
            "[CV] C=0.001 .........................................................\n",
            "[CV] ......... C=0.001, score=(train=0.688, test=0.713), total=   0.9s\n",
            "[CV] C=0.001 .........................................................\n",
            "[CV] ......... C=0.001, score=(train=0.696, test=0.668), total=   0.9s\n",
            "[CV] C=0.001 .........................................................\n",
            "[CV] ......... C=0.001, score=(train=0.689, test=0.701), total=   0.9s\n",
            "[CV] C=0.001 .........................................................\n",
            "[CV] ......... C=0.001, score=(train=0.698, test=0.664), total=   0.9s\n",
            "[CV] C=0.001 .........................................................\n",
            "[CV] ......... C=0.001, score=(train=0.701, test=0.647), total=   0.9s\n",
            "[CV] C=0.01 ..........................................................\n",
            "[CV] .......... C=0.01, score=(train=0.688, test=0.713), total=   0.9s\n",
            "[CV] C=0.01 ..........................................................\n",
            "[CV] .......... C=0.01, score=(train=0.696, test=0.668), total=   0.9s\n",
            "[CV] C=0.01 ..........................................................\n",
            "[CV] .......... C=0.01, score=(train=0.689, test=0.701), total=   0.9s\n",
            "[CV] C=0.01 ..........................................................\n",
            "[CV] .......... C=0.01, score=(train=0.699, test=0.664), total=   0.9s\n",
            "[CV] C=0.01 ..........................................................\n",
            "[CV] .......... C=0.01, score=(train=0.702, test=0.647), total=   0.9s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ........... C=0.1, score=(train=0.711, test=0.723), total=   0.8s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ........... C=0.1, score=(train=0.720, test=0.678), total=   0.8s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ........... C=0.1, score=(train=0.713, test=0.715), total=   0.8s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ........... C=0.1, score=(train=0.722, test=0.674), total=   0.8s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ........... C=0.1, score=(train=0.726, test=0.658), total=   0.8s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ............. C=1, score=(train=0.786, test=0.722), total=   0.8s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ............. C=1, score=(train=0.790, test=0.683), total=   0.8s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ............. C=1, score=(train=0.785, test=0.713), total=   0.8s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ............. C=1, score=(train=0.795, test=0.674), total=   0.8s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ............. C=1, score=(train=0.795, test=0.659), total=   0.8s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ............ C=10, score=(train=0.921, test=0.669), total=   1.1s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ............ C=10, score=(train=0.919, test=0.672), total=   1.0s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ............ C=10, score=(train=0.921, test=0.663), total=   1.0s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ............ C=10, score=(train=0.926, test=0.639), total=   1.0s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ............ C=10, score=(train=0.918, test=0.621), total=   1.0s\n",
            "[CV] C=100.0 .........................................................\n",
            "[CV] ......... C=100.0, score=(train=0.997, test=0.608), total=   2.6s\n",
            "[CV] C=100.0 .........................................................\n",
            "[CV] ......... C=100.0, score=(train=0.997, test=0.625), total=   2.6s\n",
            "[CV] C=100.0 .........................................................\n",
            "[CV] ......... C=100.0, score=(train=0.998, test=0.576), total=   2.6s\n",
            "[CV] C=100.0 .........................................................\n",
            "[CV] ......... C=100.0, score=(train=0.997, test=0.581), total=   2.4s\n",
            "[CV] C=100.0 .........................................................\n",
            "[CV] ......... C=100.0, score=(train=0.998, test=0.577), total=   2.5s\n",
            "[CV] C=1000.0 ........................................................\n",
            "[CV] ........ C=1000.0, score=(train=1.000, test=0.610), total=   3.4s\n",
            "[CV] C=1000.0 ........................................................\n",
            "[CV] ........ C=1000.0, score=(train=1.000, test=0.623), total=   3.5s\n",
            "[CV] C=1000.0 ........................................................\n",
            "[CV] ........ C=1000.0, score=(train=1.000, test=0.571), total=   3.4s\n",
            "[CV] C=1000.0 ........................................................\n",
            "[CV] ........ C=1000.0, score=(train=1.000, test=0.571), total=   3.2s\n",
            "[CV] C=1000.0 ........................................................\n",
            "[CV] ........ C=1000.0, score=(train=1.000, test=0.566), total=   3.3s\n",
            "[CV] C=10000.0 .......................................................\n",
            "[CV] ....... C=10000.0, score=(train=1.000, test=0.610), total=   3.4s\n",
            "[CV] C=10000.0 .......................................................\n",
            "[CV] ....... C=10000.0, score=(train=1.000, test=0.623), total=   3.5s\n",
            "[CV] C=10000.0 .......................................................\n",
            "[CV] ....... C=10000.0, score=(train=1.000, test=0.571), total=   3.4s\n",
            "[CV] C=10000.0 .......................................................\n",
            "[CV] ....... C=10000.0, score=(train=1.000, test=0.571), total=   3.2s\n",
            "[CV] C=10000.0 .......................................................\n",
            "[CV] ....... C=10000.0, score=(train=1.000, test=0.566), total=   3.4s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=1234, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100.0, 1000.0,\n",
              "                               10000.0]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un4Z9HebjUMi"
      },
      "source": [
        "Лучший набор параметров и значение критерия качества на нём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOcrS3nHjUMi",
        "outputId": "dfcf488b-a63f-4673-f1ea-c91ab076f979"
      },
      "source": [
        "mmsc_svc_CV.best_params_ , sc_svc_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'C': 1}, 0.6977528160239432)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j6UoMKsjUMj"
      },
      "source": [
        "График среднего значения качества:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "Olyq6oaTjUMj",
        "outputId": "285050f3-eda5-4d64-82a1-b4ba5ec8fb8d"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(svc_params_set['C'], mmsc_svc_CV.cv_results_['mean_train_score'], 'bo-', label='minmax scaled train')\n",
        "plt.plot(svc_params_set['C'], mmsc_svc_CV.cv_results_['mean_test_score'], 'go-', label='minmax scaled test')\n",
        "\n",
        "plt.fill_between(svc_params_set['C'], \n",
        "                 mmsc_svc_CV.cv_results_['mean_test_score']-mmsc_svc_CV.cv_results_['std_test_score'], \n",
        "                 mmsc_svc_CV.cv_results_['mean_test_score']+mmsc_svc_CV.cv_results_['std_test_score'], \n",
        "                 color='green', alpha=0.1)\n",
        "\n",
        "plt.plot(svc_params_set['C'], svc_CV.cv_results_['mean_train_score'], 'mo-', label='train')\n",
        "plt.plot(svc_params_set['C'], svc_CV.cv_results_['mean_test_score'], 'ro-', label='test')\n",
        "\n",
        "plt.fill_between(svc_params_set['C'], \n",
        "                 svc_CV.cv_results_['mean_test_score']-svc_CV.cv_results_['std_test_score'], \n",
        "                 svc_CV.cv_results_['mean_test_score']+svc_CV.cv_results_['std_test_score'], \n",
        "                 color='red', alpha=0.1)\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('C'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('SVC')\n",
        "plt.xscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYUWek5ijUMk"
      },
      "source": [
        "Качестсво изменилось на: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_zZslMRjUMk",
        "outputId": "e50bda7e-ff51-4a91-e838-0d4825fb6c90"
      },
      "source": [
        "mmsc_svc_CV.best_score_ - svc_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.022449299046402693"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSePSrfcjUMl"
      },
      "source": [
        "##### 5 MinMax MLPC\n",
        "**5.2.3. Multi-layer Perceptron classifier**\n",
        "\n",
        "Буду так же подбирать параметр, отвечающий за регуляризацию: `alpha`.\n",
        "\n",
        "C остальными параметрами по умолчанию алгоритм не сходился, поэтому я попробовала заменить функцию активации на `logistic` вместо `relu` - заработало. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEe7Y7TPjUMl",
        "outputId": "6965f99f-51c1-4f2a-e767-f0ee5f02d88b"
      },
      "source": [
        "# Инициализирую модель\n",
        "mlpc_model = MLPClassifier(alpha=0.0001,\n",
        "                           activation='logistic',\n",
        "                           solver='adam',\n",
        "                           learning_rate='constant', \n",
        "                           learning_rate_init=0.001,\n",
        "                           tol=0.0001,\n",
        "                           max_iter=200,\n",
        "                           random_state=1234)\n",
        "\n",
        "# Тестируемые значения гиперпараметрa \n",
        "mlpc_params_set = {\n",
        "'alpha': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 1e2, 1e3, 1e4]\n",
        "}\n",
        "\n",
        "# Кросс-валидация\n",
        "mmsc_mlpc_CV = GridSearchCV(estimator=mlpc_model,\n",
        "                       param_grid=mlpc_params_set,\n",
        "                       scoring='roc_auc',\n",
        "                       return_train_score=True,\n",
        "                       verbose=3)\n",
        "\n",
        "mmsc_mlpc_CV.fit(X_train_mmscaled[:data_part], y_train[:data_part])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] alpha=0.0001 ....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... alpha=0.0001, score=(train=0.709, test=0.742), total=   4.4s\n",
            "[CV] alpha=0.0001 ....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... alpha=0.0001, score=(train=0.721, test=0.703), total=   4.3s\n",
            "[CV] alpha=0.0001 ....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    8.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... alpha=0.0001, score=(train=0.714, test=0.721), total=   4.1s\n",
            "[CV] alpha=0.0001 ....................................................\n",
            "[CV] .... alpha=0.0001, score=(train=0.722, test=0.705), total=   5.4s\n",
            "[CV] alpha=0.0001 ....................................................\n",
            "[CV] .... alpha=0.0001, score=(train=0.727, test=0.674), total=   4.4s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ..... alpha=0.001, score=(train=0.709, test=0.742), total=   4.2s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ..... alpha=0.001, score=(train=0.721, test=0.703), total=   4.2s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ..... alpha=0.001, score=(train=0.714, test=0.721), total=   4.1s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ..... alpha=0.001, score=(train=0.722, test=0.705), total=   5.5s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ..... alpha=0.001, score=(train=0.727, test=0.674), total=   4.4s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] ...... alpha=0.01, score=(train=0.709, test=0.741), total=   4.3s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] ...... alpha=0.01, score=(train=0.720, test=0.702), total=   4.4s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] ...... alpha=0.01, score=(train=0.713, test=0.722), total=   4.2s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] ...... alpha=0.01, score=(train=0.722, test=0.704), total=   5.5s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] ...... alpha=0.01, score=(train=0.726, test=0.674), total=   4.4s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.702, test=0.734), total=   4.2s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.716, test=0.696), total=   5.3s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.707, test=0.720), total=   4.4s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.715, test=0.698), total=   5.4s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.720, test=0.670), total=   4.4s\n",
            "[CV] alpha=1 .........................................................\n",
            "[CV] ......... alpha=1, score=(train=0.680, test=0.713), total=   0.9s\n",
            "[CV] alpha=1 .........................................................\n",
            "[CV] ......... alpha=1, score=(train=0.690, test=0.672), total=   2.0s\n",
            "[CV] alpha=1 .........................................................\n",
            "[CV] ......... alpha=1, score=(train=0.682, test=0.700), total=   1.0s\n",
            "[CV] alpha=1 .........................................................\n",
            "[CV] ......... alpha=1, score=(train=0.690, test=0.669), total=   1.4s\n",
            "[CV] alpha=1 .........................................................\n",
            "[CV] ......... alpha=1, score=(train=0.696, test=0.647), total=   1.1s\n",
            "[CV] alpha=10 ........................................................\n",
            "[CV] ........ alpha=10, score=(train=0.665, test=0.681), total=   1.6s\n",
            "[CV] alpha=10 ........................................................\n",
            "[CV] ........ alpha=10, score=(train=0.681, test=0.652), total=   1.9s\n",
            "[CV] alpha=10 ........................................................\n",
            "[CV] ........ alpha=10, score=(train=0.669, test=0.693), total=   1.7s\n",
            "[CV] alpha=10 ........................................................\n",
            "[CV] ........ alpha=10, score=(train=0.688, test=0.668), total=   1.9s\n",
            "[CV] alpha=10 ........................................................\n",
            "[CV] ........ alpha=10, score=(train=0.693, test=0.648), total=   1.7s\n",
            "[CV] alpha=100.0 .....................................................\n",
            "[CV] ..... alpha=100.0, score=(train=0.671, test=0.710), total=   0.9s\n",
            "[CV] alpha=100.0 .....................................................\n",
            "[CV] ..... alpha=100.0, score=(train=0.683, test=0.654), total=   0.9s\n",
            "[CV] alpha=100.0 .....................................................\n",
            "[CV] ..... alpha=100.0, score=(train=0.668, test=0.689), total=   1.0s\n",
            "[CV] alpha=100.0 .....................................................\n",
            "[CV] ..... alpha=100.0, score=(train=0.671, test=0.648), total=   0.8s\n",
            "[CV] alpha=100.0 .....................................................\n",
            "[CV] ..... alpha=100.0, score=(train=0.693, test=0.644), total=   0.8s\n",
            "[CV] alpha=1000.0 ....................................................\n",
            "[CV] .... alpha=1000.0, score=(train=0.536, test=0.517), total=   0.9s\n",
            "[CV] alpha=1000.0 ....................................................\n",
            "[CV] .... alpha=1000.0, score=(train=0.505, test=0.461), total=   0.9s\n",
            "[CV] alpha=1000.0 ....................................................\n",
            "[CV] .... alpha=1000.0, score=(train=0.630, test=0.637), total=   1.0s\n",
            "[CV] alpha=1000.0 ....................................................\n",
            "[CV] .... alpha=1000.0, score=(train=0.597, test=0.580), total=   0.9s\n",
            "[CV] alpha=1000.0 ....................................................\n",
            "[CV] .... alpha=1000.0, score=(train=0.453, test=0.482), total=   0.9s\n",
            "[CV] alpha=10000.0 ...................................................\n",
            "[CV] ... alpha=10000.0, score=(train=0.507, test=0.506), total=   0.9s\n",
            "[CV] alpha=10000.0 ...................................................\n",
            "[CV] ... alpha=10000.0, score=(train=0.464, test=0.501), total=   1.0s\n",
            "[CV] alpha=10000.0 ...................................................\n",
            "[CV] ... alpha=10000.0, score=(train=0.486, test=0.440), total=   1.0s\n",
            "[CV] alpha=10000.0 ...................................................\n",
            "[CV] ... alpha=10000.0, score=(train=0.453, test=0.479), total=   1.0s\n",
            "[CV] alpha=10000.0 ...................................................\n",
            "[CV] ... alpha=10000.0, score=(train=0.514, test=0.507), total=   1.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  2.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='logistic', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=200, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_state=1234, shuffle=True,\n",
              "                                     solver='adam', tol=0.0001,\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100.0,\n",
              "                                   1000.0, 10000.0]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSltr-XpjUMm"
      },
      "source": [
        "Лучший набор параметров и значение критерия качества на нём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huSvbowZjUMn",
        "outputId": "f6d051fa-4f49-4187-ca51-ef784f149809"
      },
      "source": [
        "mmsc_mlpc_CV.best_params_ , sc_mlpc_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'alpha': 0.001}, 0.7127599226102147)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMtd_rWQjUMn"
      },
      "source": [
        "График среднего значения качества:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "JAIiFbXrjUMn",
        "outputId": "e69f32c5-4104-4acc-8175-8d6fe50ec844"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(mlpc_params_set['alpha'], mmsc_mlpc_CV.cv_results_['mean_train_score'], 'bo-', label='minmax scaled train')\n",
        "plt.plot(mlpc_params_set['alpha'], mmsc_mlpc_CV.cv_results_['mean_test_score'], 'go-', label='minmax scaled test')\n",
        "\n",
        "plt.fill_between(mlpc_params_set['alpha'], \n",
        "                 mmsc_mlpc_CV.cv_results_['mean_test_score']-mmsc_mlpc_CV.cv_results_['std_test_score'], \n",
        "                 mmsc_mlpc_CV.cv_results_['mean_test_score']+mmsc_mlpc_CV.cv_results_['std_test_score'], \n",
        "                 color='green', alpha=0.1)\n",
        "\n",
        "plt.plot(mlpc_params_set['alpha'], mlpc_CV.cv_results_['mean_train_score'][:-1], 'mo-', label='train')\n",
        "plt.plot(mlpc_params_set['alpha'], mlpc_CV.cv_results_['mean_test_score'][:-1], 'ro-', label='test')\n",
        "\n",
        "plt.fill_between(mlpc_params_set['alpha'], \n",
        "                 mlpc_CV.cv_results_['mean_test_score'][:-1]-mlpc_CV.cv_results_['std_test_score'][:-1], \n",
        "                 mlpc_CV.cv_results_['mean_test_score'][:-1]+mlpc_CV.cv_results_['std_test_score'][:-1], \n",
        "                 color='red', alpha=0.1)\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('alpha'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('MLPClassifier')\n",
        "plt.xscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8bEECl-jUMp"
      },
      "source": [
        "Качество изменилось на: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoaCscvljUMr",
        "outputId": "38152612-0c2b-4791-c874-dc6899500f1a"
      },
      "source": [
        "mmsc_mlpc_CV.best_score_ - mlpc_CV.best_score_ "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0034424679577487183"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV8EpzEtjUMr"
      },
      "source": [
        "##### MinMax Сравнение\n",
        "\n",
        "Сравню модели. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "lEZb26MojUMs",
        "outputId": "ccac501e-a92d-4088-f431-57ca83138111"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(logreg_params_set['C'], mmsc_logreg_CV.cv_results_['mean_test_score'], 'go-', label='logreg test')\n",
        "plt.fill_between(logreg_params_set['C'], \n",
        "                 mmsc_logreg_CV.cv_results_['mean_test_score']-mmsc_logreg_CV.cv_results_['std_test_score'], \n",
        "                 mmsc_logreg_CV.cv_results_['mean_test_score']+mmsc_logreg_CV.cv_results_['std_test_score'], \n",
        "                 color='green', alpha=0.1)\n",
        "\n",
        "plt.plot(svc_params_set['C'], mmsc_svc_CV.cv_results_['mean_test_score'], 'bo-', label='SVC test')\n",
        "plt.fill_between(svc_params_set['C'], \n",
        "                 mmsc_svc_CV.cv_results_['mean_test_score']-mmsc_svc_CV.cv_results_['std_test_score'], \n",
        "                 mmsc_svc_CV.cv_results_['mean_test_score']+mmsc_svc_CV.cv_results_['std_test_score'], \n",
        "                 color='blue', alpha=0.1)\n",
        "\n",
        "plt.plot(mlpc_params_set['alpha'][:], sc_mlpc_CV.cv_results_['mean_test_score'][:], 'mo-', label='MLPClassifier test')\n",
        "plt.fill_between(mlpc_params_set['alpha'][:], \n",
        "                 mmsc_mlpc_CV.cv_results_['mean_test_score'][:]-mmsc_mlpc_CV.cv_results_['std_test_score'][:], \n",
        "                 mmsc_mlpc_CV.cv_results_['mean_test_score'][:]+mmsc_mlpc_CV.cv_results_['std_test_score'][:], \n",
        "                 color='magenta', alpha=0.1)\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('C/alpha'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('Сравнение')\n",
        "plt.xscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XaVeWIGjUMt"
      },
      "source": [
        "*Вывод:* Качество так же немного упало на логистической регрессии, еще больше упало на SVC и немного немного упало на MLPClassifier. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxOPWxNwjUMt",
        "outputId": "c5ab9219-2ea3-4bcd-851f-164832bdd3f2"
      },
      "source": [
        "print('logreg best score:', mmsc_logreg_CV.best_score_)\n",
        "print('SVC best score:', mmsc_svc_CV.best_score_)\n",
        "print('MLPClassifier best score:', mmsc_mlpc_CV.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logreg best score: 0.7125545516589339\n",
            "SVC best score: 0.6901478295170651\n",
            "MLPClassifier best score: 0.7089305057259676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqjVYxmljUMv"
      },
      "source": [
        "#### 5 Вывод\n",
        "\n",
        "Качество по прежнему наилучшее у логистической регрессии.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Мне кажется, такой эффект со снижением качества моделей может быть из-за неточностей их настройки и пока не известных мне особенностей solver алгоритмов. Однако, надеюсь, стандартизированные данные позволят перебрать больше параметров моделей и значительно улучшить качетсво (в задании 3, без масштабирования данных, некоторые комбинации параметров моделей вели к ошибками и ворнингам про то, что алгоритм не сходится). Проверю это в задании 6. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-MpNToLVP6g"
      },
      "source": [
        "#### 6\n",
        "\n",
        "**Задание 6** (1.5 балла) \n",
        "\n",
        "Теперь сделайте перебор нескольких гиперпараметров по сетке и найдите оптимальные комбинации (лучшее среднее значение качества) для каждого алгоритма. Какие гиперпараметры вы настраивали? Удалось ли улучшить качество алгоритмов?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLFlS2hfpmDm"
      },
      "source": [
        "##### 6 LogReg "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIGGGHX2sYYL"
      },
      "source": [
        "**6.1. Logistic Regression Classifier**\n",
        "\n",
        "Так как разные solver-ы поддерживают разные регуляризации, и перебирать комбинации становится сложно по причине того, что некоторые комбинации не работают, я сделаю несколько переборов параметоов: \n",
        "\n",
        "1. `solver`=`liblinear`, переберу силу регуляризации `C`, регуляризацию `penalty` (l2, l1) и добавление свободного члена `fit_intercept` (True, False).\n",
        "\n",
        "2. `solver` = `saga` (единственный, поддерживающий elasticnet регуляризацию), переберу `C`, `penalty` (l1, l2, elasticnet), `l1_ratio` (для elastic net) и `fit_intercept`. \n",
        "\n",
        "Использую данные, стандартизированные с `StandartScaler`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJy5PWdtnEpz"
      },
      "source": [
        "* Первая, с `liblinear`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZzJZraDsYYV",
        "outputId": "e303e544-0f6a-483b-add0-c3e27c05e261"
      },
      "source": [
        "logreg_model = LogisticRegression(tol=0.0001, \n",
        "                                  solver='liblinear', \n",
        "                                  random_state=1234,\n",
        "                                  max_iter=100)\n",
        "\n",
        "f1_logreg_params_set = {\n",
        "'C': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 1e2, 1e3, 1e4],\n",
        "'penalty':['l1', 'l2'],\n",
        "'fit_intercept':[True, False]\n",
        "}\n",
        "\n",
        "f1_logreg_CV = GridSearchCV(estimator=logreg_model,\n",
        "                         param_grid=f1_logreg_params_set,\n",
        "                         scoring='roc_auc',\n",
        "                         return_train_score=True)\n",
        "\n",
        "f1_logreg_CV.fit(X_train_scaled[:data_part], y_train[:data_part])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=1234, solver='liblinear',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100.0, 1000.0,\n",
              "                               10000.0],\n",
              "                         'fit_intercept': [True, False],\n",
              "                         'penalty': ['l1', 'l2']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJLYv4lusYYY"
      },
      "source": [
        "Лучший набор параметров и значение критерия качества на нём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXUJJKDMsYYZ",
        "outputId": "90ead2a6-4332-4511-f5e8-aaa39f9fb1c2"
      },
      "source": [
        "f1_logreg_CV.best_params_ , f1_logreg_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'C': 0.1, 'fit_intercept': False, 'penalty': 'l1'}, 0.7149676603364827)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJcuqnwJnSWp"
      },
      "source": [
        "По сравнению с подобранной в 3 задании (не стандартизированные данные, `C=10`, `penalty='l2'`, `solver`=`liblinear`) качество увеличилось на: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19a6WkAggZks",
        "outputId": "d6a29365-c21a-4226-8cff-c1e5c6c2118b"
      },
      "source": [
        "f1_logreg_CV.best_score_ - logreg_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.002067484393686092"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F__teE7spzxX"
      },
      "source": [
        "* Вторая, с `saga`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "eGpPnx84pzxf"
      },
      "source": [
        "logreg_model = LogisticRegression(tol=0.0001, \n",
        "                                  solver='saga', \n",
        "                                  random_state=1234,\n",
        "                                  max_iter=100)\n",
        "\n",
        "f2_logreg_params_set = {\n",
        "'C': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 1e2, 1e3, 1e4],\n",
        "'penalty':['l1', 'l2', 'elasticnet'],\n",
        "'fit_intercept':[True, False],\n",
        "'l1_ratio':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "}\n",
        "\n",
        "f2_logreg_CV = GridSearchCV(estimator=logreg_model,\n",
        "                         param_grid=f2_logreg_params_set,\n",
        "                         scoring='roc_auc',\n",
        "                         return_train_score=True)\n",
        "\n",
        "f2_logreg_CV.fit(X_train_scaled[:data_part], y_train[:data_part])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSHVYWZ5pzxh"
      },
      "source": [
        "Лучший набор параметров и значение критерия качества на нём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IsT44Ripzxi",
        "outputId": "49f2a15f-7c65-4990-90e3-15639f92afed"
      },
      "source": [
        "f2_logreg_CV.best_params_ , f2_logreg_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'C': 0.01, 'fit_intercept': True, 'l1_ratio': 0.5, 'penalty': 'elasticnet'},\n",
              " 0.7152005810495208)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6IeYQgspzxj"
      },
      "source": [
        "По сравнению с подобранной в 3 задании (не стандартизированные данные, `C=10`, `penalty='l2'`, `solver`=`liblinear`) качество увеличилось на: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rvQAN3lpzxk",
        "outputId": "ff22a1ae-ad18-4328-bb3d-ff622f7d35d5"
      },
      "source": [
        "f2_logreg_CV.best_score_ - logreg_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.002300405106724135"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSMGp4DhsO8x"
      },
      "source": [
        "По сравнению с предыдущей (`liblinear`) качество увеличилось на:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shVNpLEisffG",
        "outputId": "61d4609f-d6f6-4d4b-baad-5474c87bcb22"
      },
      "source": [
        "f2_logreg_CV.best_score_ - f1_logreg_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00023292071303804285"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2zJIW-KhJJa",
        "outputId": "2cfc1195-3235-419e-a13c-d7e108389ac1"
      },
      "source": [
        "f2_lr_test_score = roc_auc_score(y_true=y_test[:test_part], y_score=f2_logreg_CV.best_estimator_.predict(X_test[:test_part]))\n",
        "f2_lr_test_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6336241903413069"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92HLGTWsrWO"
      },
      "source": [
        "Попробую взять для этой удачной модели еще сетку мельче \"возле\" оптимальных `C`, `l1_ratio`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtsF2MQgsqIc",
        "outputId": "2602a129-772f-4cb8-a43b-12ee26556169"
      },
      "source": [
        "logreg_model = LogisticRegression(tol=0.0001, \n",
        "                                  solver='saga', \n",
        "                                  penalty='elasticnet',\n",
        "                                  fit_intercept=True,\n",
        "                                  random_state=1234,\n",
        "                                  max_iter=100)\n",
        "\n",
        "f3_logreg_params_set = {\n",
        "'C': [0.005, 0.008, 0.01, 0.012, 0.015],\n",
        "'l1_ratio':[0.450, 0.475, 0.5, 0.525, 0.550]\n",
        "}\n",
        "\n",
        "f3_logreg_CV = GridSearchCV(estimator=logreg_model,\n",
        "                         param_grid=f3_logreg_params_set,\n",
        "                         scoring='roc_auc',\n",
        "                         return_train_score=True)\n",
        "\n",
        "f3_logreg_CV.fit(X_train_scaled[:data_part], y_train[:data_part])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='elasticnet',\n",
              "                                          random_state=1234, solver='saga',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.005, 0.008, 0.01, 0.012, 0.015],\n",
              "                         'l1_ratio': [0.45, 0.475, 0.5, 0.525, 0.55]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qu8o9uLuUo7"
      },
      "source": [
        "Лучший набор параметров и значение критерия качества на нём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6zCyJSMuUpQ",
        "outputId": "5fa9f344-14d1-491e-aba8-447744204efc"
      },
      "source": [
        "f3_logreg_CV.best_params_ , f3_logreg_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'C': 0.008, 'l1_ratio': 0.45}, 0.7153233027155299)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IZ-34yfuUpT"
      },
      "source": [
        "По сравнению с подобранной в 3 задании (не стандартизированные данные, `C=10`, `penalty='l2'`, `solver`=`liblinear`) качество увеличилось на: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v2gi-XjuUpU",
        "outputId": "b6dea290-17d5-450c-933c-0d4a69837709"
      },
      "source": [
        "f3_logreg_CV.best_score_ - logreg_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.002423126772733264"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMG2eqyiuUpW"
      },
      "source": [
        "По сравнению с предыдущей (`saga`) качество увеличилось на:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OICQOvjUuUpX",
        "outputId": "94344395-663e-405b-88cc-bcf26d7da86c"
      },
      "source": [
        "f3_logreg_CV.best_score_ - f2_logreg_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00012272166600912904"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGu32sBCurum"
      },
      "source": [
        "Небольшое улучшение есть, оставлю ёё. \n",
        "\n",
        "*Итак,* лучшая полученная для логистической регрессии модель:\n",
        "```\n",
        "solver='saga'\n",
        "penalty='elasticnet'\n",
        "fit_intercept=True\n",
        "C=0.008\n",
        "l1_ratio=0.45\n",
        "\n",
        "```\n",
        "\n",
        "Качество: 0.7153233, улучшилось на 0.0001227 в сравнении с моделью из задания 3. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAn4CYT6wPuo"
      },
      "source": [
        "##### 6 SVC\n",
        "\n",
        "**6.2. C-Support Vector Classification**\n",
        "\n",
        "Буду перебирать ядра `kernel` и силу регуляризации `C`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWfftj_3yyuG",
        "outputId": "b36faf9e-fe9f-41ed-8147-3cc44ba197f0"
      },
      "source": [
        "svc_CV.best_params_, svc_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'C': 0.001}, 0.7125971285634678)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_u3ySDlwzyM",
        "outputId": "8ee12a18-fda5-486f-8b74-f99b0fe64856"
      },
      "source": [
        "# Инициализирую модель\n",
        "svc_model = SVC(C=1.0, \n",
        "                kernel='rbf',\n",
        "                gamma='scale',\n",
        "                shrinking=True,\n",
        "                tol=0.001,\n",
        "                random_state=1234)\n",
        "\n",
        "# Тестируемые значения гиперпараметрa \n",
        "f_svc_params_set = {\n",
        "'kernel':['linear', 'poly', 'sigmoid', 'rbf'],\n",
        "'C': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 1e2]\n",
        "}\n",
        "\n",
        "# Кросс-валидация\n",
        "f_sc_svc_CV = GridSearchCV(estimator=svc_model,\n",
        "                      param_grid=f_svc_params_set,\n",
        "                      scoring='roc_auc',\n",
        "                      return_train_score=True,\n",
        "                      verbose=3)\n",
        "\n",
        "f_sc_svc_CV.fit(X_train_scaled[:data_part], y_train[:data_part])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
            "[CV] C=0.0001, kernel=linear .........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, kernel=linear, score=(train=0.691, test=0.722), total=   0.7s\n",
            "[CV] C=0.0001, kernel=linear .........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, kernel=linear, score=(train=0.695, test=0.702), total=   0.7s\n",
            "[CV] C=0.0001, kernel=linear .........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, kernel=linear, score=(train=0.696, test=0.706), total=   0.7s\n",
            "[CV] C=0.0001, kernel=linear .........................................\n",
            "[CV]  C=0.0001, kernel=linear, score=(train=0.702, test=0.676), total=   0.7s\n",
            "[CV] C=0.0001, kernel=linear .........................................\n",
            "[CV]  C=0.0001, kernel=linear, score=(train=0.705, test=0.669), total=   0.7s\n",
            "[CV] C=0.0001, kernel=poly ...........................................\n",
            "[CV]  C=0.0001, kernel=poly, score=(train=0.698, test=0.717), total=   0.8s\n",
            "[CV] C=0.0001, kernel=poly ...........................................\n",
            "[CV]  C=0.0001, kernel=poly, score=(train=0.702, test=0.697), total=   0.8s\n",
            "[CV] C=0.0001, kernel=poly ...........................................\n",
            "[CV]  C=0.0001, kernel=poly, score=(train=0.704, test=0.700), total=   0.8s\n",
            "[CV] C=0.0001, kernel=poly ...........................................\n",
            "[CV]  C=0.0001, kernel=poly, score=(train=0.709, test=0.672), total=   0.8s\n",
            "[CV] C=0.0001, kernel=poly ...........................................\n",
            "[CV]  C=0.0001, kernel=poly, score=(train=0.715, test=0.659), total=   0.8s\n",
            "[CV] C=0.0001, kernel=sigmoid ........................................\n",
            "[CV]  C=0.0001, kernel=sigmoid, score=(train=0.690, test=0.722), total=   1.6s\n",
            "[CV] C=0.0001, kernel=sigmoid ........................................\n",
            "[CV]  C=0.0001, kernel=sigmoid, score=(train=0.694, test=0.701), total=   1.6s\n",
            "[CV] C=0.0001, kernel=sigmoid ........................................\n",
            "[CV]  C=0.0001, kernel=sigmoid, score=(train=0.695, test=0.706), total=   1.5s\n",
            "[CV] C=0.0001, kernel=sigmoid ........................................\n",
            "[CV]  C=0.0001, kernel=sigmoid, score=(train=0.701, test=0.676), total=   1.6s\n",
            "[CV] C=0.0001, kernel=sigmoid ........................................\n",
            "[CV]  C=0.0001, kernel=sigmoid, score=(train=0.703, test=0.669), total=   1.6s\n",
            "[CV] C=0.0001, kernel=rbf ............................................\n",
            "[CV]  C=0.0001, kernel=rbf, score=(train=0.692, test=0.712), total=   1.4s\n",
            "[CV] C=0.0001, kernel=rbf ............................................\n",
            "[CV]  C=0.0001, kernel=rbf, score=(train=0.696, test=0.694), total=   1.4s\n",
            "[CV] C=0.0001, kernel=rbf ............................................\n",
            "[CV]  C=0.0001, kernel=rbf, score=(train=0.698, test=0.698), total=   1.4s\n",
            "[CV] C=0.0001, kernel=rbf ............................................\n",
            "[CV]  C=0.0001, kernel=rbf, score=(train=0.703, test=0.664), total=   1.4s\n",
            "[CV] C=0.0001, kernel=rbf ............................................\n",
            "[CV]  C=0.0001, kernel=rbf, score=(train=0.704, test=0.666), total=   1.4s\n",
            "[CV] C=0.001, kernel=linear ..........................................\n",
            "[CV]  C=0.001, kernel=linear, score=(train=0.699, test=0.727), total=   0.6s\n",
            "[CV] C=0.001, kernel=linear ..........................................\n",
            "[CV]  C=0.001, kernel=linear, score=(train=0.702, test=0.712), total=   0.6s\n",
            "[CV] C=0.001, kernel=linear ..........................................\n",
            "[CV]  C=0.001, kernel=linear, score=(train=0.705, test=0.710), total=   0.7s\n",
            "[CV] C=0.001, kernel=linear ..........................................\n",
            "[CV]  C=0.001, kernel=linear, score=(train=0.709, test=0.684), total=   0.6s\n",
            "[CV] C=0.001, kernel=linear ..........................................\n",
            "[CV]  C=0.001, kernel=linear, score=(train=0.713, test=0.672), total=   0.6s\n",
            "[CV] C=0.001, kernel=poly ............................................\n",
            "[CV]  C=0.001, kernel=poly, score=(train=0.698, test=0.717), total=   0.8s\n",
            "[CV] C=0.001, kernel=poly ............................................\n",
            "[CV]  C=0.001, kernel=poly, score=(train=0.702, test=0.697), total=   0.8s\n",
            "[CV] C=0.001, kernel=poly ............................................\n",
            "[CV]  C=0.001, kernel=poly, score=(train=0.704, test=0.700), total=   0.8s\n",
            "[CV] C=0.001, kernel=poly ............................................\n",
            "[CV]  C=0.001, kernel=poly, score=(train=0.709, test=0.672), total=   0.8s\n",
            "[CV] C=0.001, kernel=poly ............................................\n",
            "[CV]  C=0.001, kernel=poly, score=(train=0.715, test=0.659), total=   0.8s\n",
            "[CV] C=0.001, kernel=sigmoid .........................................\n",
            "[CV]  C=0.001, kernel=sigmoid, score=(train=0.690, test=0.722), total=   1.5s\n",
            "[CV] C=0.001, kernel=sigmoid .........................................\n",
            "[CV]  C=0.001, kernel=sigmoid, score=(train=0.694, test=0.701), total=   1.6s\n",
            "[CV] C=0.001, kernel=sigmoid .........................................\n",
            "[CV]  C=0.001, kernel=sigmoid, score=(train=0.695, test=0.706), total=   1.5s\n",
            "[CV] C=0.001, kernel=sigmoid .........................................\n",
            "[CV]  C=0.001, kernel=sigmoid, score=(train=0.701, test=0.676), total=   1.5s\n",
            "[CV] C=0.001, kernel=sigmoid .........................................\n",
            "[CV]  C=0.001, kernel=sigmoid, score=(train=0.703, test=0.669), total=   1.6s\n",
            "[CV] C=0.001, kernel=rbf .............................................\n",
            "[CV]  C=0.001, kernel=rbf, score=(train=0.693, test=0.713), total=   1.4s\n",
            "[CV] C=0.001, kernel=rbf .............................................\n",
            "[CV]  C=0.001, kernel=rbf, score=(train=0.696, test=0.695), total=   1.4s\n",
            "[CV] C=0.001, kernel=rbf .............................................\n",
            "[CV]  C=0.001, kernel=rbf, score=(train=0.698, test=0.697), total=   1.4s\n",
            "[CV] C=0.001, kernel=rbf .............................................\n",
            "[CV]  C=0.001, kernel=rbf, score=(train=0.703, test=0.665), total=   1.4s\n",
            "[CV] C=0.001, kernel=rbf .............................................\n",
            "[CV]  C=0.001, kernel=rbf, score=(train=0.704, test=0.665), total=   1.4s\n",
            "[CV] C=0.01, kernel=linear ...........................................\n",
            "[CV]  C=0.01, kernel=linear, score=(train=0.707, test=0.734), total=   0.6s\n",
            "[CV] C=0.01, kernel=linear ...........................................\n",
            "[CV]  C=0.01, kernel=linear, score=(train=0.710, test=0.721), total=   0.6s\n",
            "[CV] C=0.01, kernel=linear ...........................................\n",
            "[CV]  C=0.01, kernel=linear, score=(train=0.713, test=0.712), total=   0.6s\n",
            "[CV] C=0.01, kernel=linear ...........................................\n",
            "[CV]  C=0.01, kernel=linear, score=(train=0.715, test=0.694), total=   0.7s\n",
            "[CV] C=0.01, kernel=linear ...........................................\n",
            "[CV]  C=0.01, kernel=linear, score=(train=0.722, test=0.673), total=   0.6s\n",
            "[CV] C=0.01, kernel=poly .............................................\n",
            "[CV]  C=0.01, kernel=poly, score=(train=0.702, test=0.717), total=   0.8s\n",
            "[CV] C=0.01, kernel=poly .............................................\n",
            "[CV]  C=0.01, kernel=poly, score=(train=0.706, test=0.700), total=   0.8s\n",
            "[CV] C=0.01, kernel=poly .............................................\n",
            "[CV]  C=0.01, kernel=poly, score=(train=0.708, test=0.700), total=   0.8s\n",
            "[CV] C=0.01, kernel=poly .............................................\n",
            "[CV]  C=0.01, kernel=poly, score=(train=0.711, test=0.674), total=   0.8s\n",
            "[CV] C=0.01, kernel=poly .............................................\n",
            "[CV]  C=0.01, kernel=poly, score=(train=0.719, test=0.658), total=   0.8s\n",
            "[CV] C=0.01, kernel=sigmoid ..........................................\n",
            "[CV]  C=0.01, kernel=sigmoid, score=(train=0.692, test=0.724), total=   1.6s\n",
            "[CV] C=0.01, kernel=sigmoid ..........................................\n",
            "[CV]  C=0.01, kernel=sigmoid, score=(train=0.696, test=0.705), total=   1.5s\n",
            "[CV] C=0.01, kernel=sigmoid ..........................................\n",
            "[CV]  C=0.01, kernel=sigmoid, score=(train=0.698, test=0.708), total=   1.5s\n",
            "[CV] C=0.01, kernel=sigmoid ..........................................\n",
            "[CV]  C=0.01, kernel=sigmoid, score=(train=0.703, test=0.678), total=   1.5s\n",
            "[CV] C=0.01, kernel=sigmoid ..........................................\n",
            "[CV]  C=0.01, kernel=sigmoid, score=(train=0.706, test=0.671), total=   1.5s\n",
            "[CV] C=0.01, kernel=rbf ..............................................\n",
            "[CV]  C=0.01, kernel=rbf, score=(train=0.693, test=0.713), total=   1.4s\n",
            "[CV] C=0.01, kernel=rbf ..............................................\n",
            "[CV]  C=0.01, kernel=rbf, score=(train=0.696, test=0.695), total=   1.3s\n",
            "[CV] C=0.01, kernel=rbf ..............................................\n",
            "[CV]  C=0.01, kernel=rbf, score=(train=0.698, test=0.697), total=   1.4s\n",
            "[CV] C=0.01, kernel=rbf ..............................................\n",
            "[CV]  C=0.01, kernel=rbf, score=(train=0.703, test=0.665), total=   1.4s\n",
            "[CV] C=0.01, kernel=rbf ..............................................\n",
            "[CV]  C=0.01, kernel=rbf, score=(train=0.704, test=0.665), total=   1.4s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.708, test=0.732), total=   0.8s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.711, test=0.720), total=   0.8s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.713, test=0.711), total=   0.7s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.717, test=0.696), total=   0.7s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.723, test=0.673), total=   0.8s\n",
            "[CV] C=0.1, kernel=poly ..............................................\n",
            "[CV]  C=0.1, kernel=poly, score=(train=0.735, test=0.720), total=   0.8s\n",
            "[CV] C=0.1, kernel=poly ..............................................\n",
            "[CV]  C=0.1, kernel=poly, score=(train=0.737, test=0.705), total=   0.8s\n",
            "[CV] C=0.1, kernel=poly ..............................................\n",
            "[CV]  C=0.1, kernel=poly, score=(train=0.743, test=0.698), total=   0.8s\n",
            "[CV] C=0.1, kernel=poly ..............................................\n",
            "[CV]  C=0.1, kernel=poly, score=(train=0.742, test=0.680), total=   0.7s\n",
            "[CV] C=0.1, kernel=poly ..............................................\n",
            "[CV]  C=0.1, kernel=poly, score=(train=0.753, test=0.650), total=   0.7s\n",
            "[CV] C=0.1, kernel=sigmoid ...........................................\n",
            "[CV]  C=0.1, kernel=sigmoid, score=(train=0.692, test=0.731), total=   1.5s\n",
            "[CV] C=0.1, kernel=sigmoid ...........................................\n",
            "[CV]  C=0.1, kernel=sigmoid, score=(train=0.697, test=0.716), total=   1.4s\n",
            "[CV] C=0.1, kernel=sigmoid ...........................................\n",
            "[CV]  C=0.1, kernel=sigmoid, score=(train=0.697, test=0.712), total=   1.4s\n",
            "[CV] C=0.1, kernel=sigmoid ...........................................\n",
            "[CV]  C=0.1, kernel=sigmoid, score=(train=0.702, test=0.689), total=   1.4s\n",
            "[CV] C=0.1, kernel=sigmoid ...........................................\n",
            "[CV]  C=0.1, kernel=sigmoid, score=(train=0.703, test=0.681), total=   1.4s\n",
            "[CV] C=0.1, kernel=rbf ...............................................\n",
            "[CV]  C=0.1, kernel=rbf, score=(train=0.717, test=0.719), total=   1.2s\n",
            "[CV] C=0.1, kernel=rbf ...............................................\n",
            "[CV]  C=0.1, kernel=rbf, score=(train=0.719, test=0.701), total=   1.2s\n",
            "[CV] C=0.1, kernel=rbf ...............................................\n",
            "[CV]  C=0.1, kernel=rbf, score=(train=0.721, test=0.703), total=   1.2s\n",
            "[CV] C=0.1, kernel=rbf ...............................................\n",
            "[CV]  C=0.1, kernel=rbf, score=(train=0.726, test=0.673), total=   1.2s\n",
            "[CV] C=0.1, kernel=rbf ...............................................\n",
            "[CV]  C=0.1, kernel=rbf, score=(train=0.729, test=0.669), total=   1.2s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV]  C=1, kernel=linear, score=(train=0.708, test=0.732), total=   1.5s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV]  C=1, kernel=linear, score=(train=0.712, test=0.719), total=   1.5s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV]  C=1, kernel=linear, score=(train=0.714, test=0.711), total=   1.6s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV]  C=1, kernel=linear, score=(train=0.717, test=0.697), total=   1.5s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV]  C=1, kernel=linear, score=(train=0.723, test=0.672), total=   1.4s\n",
            "[CV] C=1, kernel=poly ................................................\n",
            "[CV]  C=1, kernel=poly, score=(train=0.806, test=0.706), total=   0.9s\n",
            "[CV] C=1, kernel=poly ................................................\n",
            "[CV]  C=1, kernel=poly, score=(train=0.806, test=0.685), total=   0.9s\n",
            "[CV] C=1, kernel=poly ................................................\n",
            "[CV]  C=1, kernel=poly, score=(train=0.814, test=0.662), total=   0.9s\n",
            "[CV] C=1, kernel=poly ................................................\n",
            "[CV]  C=1, kernel=poly, score=(train=0.812, test=0.663), total=   0.9s\n",
            "[CV] C=1, kernel=poly ................................................\n",
            "[CV]  C=1, kernel=poly, score=(train=0.818, test=0.624), total=   0.9s\n",
            "[CV] C=1, kernel=sigmoid .............................................\n",
            "[CV]  C=1, kernel=sigmoid, score=(train=0.566, test=0.623), total=   0.9s\n",
            "[CV] C=1, kernel=sigmoid .............................................\n",
            "[CV]  C=1, kernel=sigmoid, score=(train=0.569, test=0.611), total=   1.0s\n",
            "[CV] C=1, kernel=sigmoid .............................................\n",
            "[CV]  C=1, kernel=sigmoid, score=(train=0.571, test=0.587), total=   1.0s\n",
            "[CV] C=1, kernel=sigmoid .............................................\n",
            "[CV]  C=1, kernel=sigmoid, score=(train=0.577, test=0.588), total=   1.0s\n",
            "[CV] C=1, kernel=sigmoid .............................................\n",
            "[CV]  C=1, kernel=sigmoid, score=(train=0.567, test=0.626), total=   1.1s\n",
            "[CV] C=1, kernel=rbf .................................................\n",
            "[CV] . C=1, kernel=rbf, score=(train=0.802, test=0.701), total=   1.3s\n",
            "[CV] C=1, kernel=rbf .................................................\n",
            "[CV] . C=1, kernel=rbf, score=(train=0.801, test=0.695), total=   1.2s\n",
            "[CV] C=1, kernel=rbf .................................................\n",
            "[CV] . C=1, kernel=rbf, score=(train=0.803, test=0.696), total=   1.2s\n",
            "[CV] C=1, kernel=rbf .................................................\n",
            "[CV] . C=1, kernel=rbf, score=(train=0.808, test=0.670), total=   1.3s\n",
            "[CV] C=1, kernel=rbf .................................................\n",
            "[CV] . C=1, kernel=rbf, score=(train=0.813, test=0.644), total=   1.2s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV]  C=10, kernel=linear, score=(train=0.708, test=0.732), total=   5.6s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV]  C=10, kernel=linear, score=(train=0.712, test=0.719), total=   5.6s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV]  C=10, kernel=linear, score=(train=0.714, test=0.711), total=   5.4s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV]  C=10, kernel=linear, score=(train=0.717, test=0.696), total=   5.3s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV]  C=10, kernel=linear, score=(train=0.723, test=0.672), total=   5.4s\n",
            "[CV] C=10, kernel=poly ...............................................\n",
            "[CV]  C=10, kernel=poly, score=(train=0.882, test=0.643), total=   2.1s\n",
            "[CV] C=10, kernel=poly ...............................................\n",
            "[CV]  C=10, kernel=poly, score=(train=0.881, test=0.641), total=   1.8s\n",
            "[CV] C=10, kernel=poly ...............................................\n",
            "[CV]  C=10, kernel=poly, score=(train=0.887, test=0.608), total=   1.8s\n",
            "[CV] C=10, kernel=poly ...............................................\n",
            "[CV]  C=10, kernel=poly, score=(train=0.891, test=0.596), total=   1.8s\n",
            "[CV] C=10, kernel=poly ...............................................\n",
            "[CV]  C=10, kernel=poly, score=(train=0.888, test=0.586), total=   1.9s\n",
            "[CV] C=10, kernel=sigmoid ............................................\n",
            "[CV]  C=10, kernel=sigmoid, score=(train=0.555, test=0.604), total=   0.8s\n",
            "[CV] C=10, kernel=sigmoid ............................................\n",
            "[CV]  C=10, kernel=sigmoid, score=(train=0.556, test=0.578), total=   0.8s\n",
            "[CV] C=10, kernel=sigmoid ............................................\n",
            "[CV]  C=10, kernel=sigmoid, score=(train=0.551, test=0.567), total=   0.9s\n",
            "[CV] C=10, kernel=sigmoid ............................................\n",
            "[CV]  C=10, kernel=sigmoid, score=(train=0.556, test=0.572), total=   0.8s\n",
            "[CV] C=10, kernel=sigmoid ............................................\n",
            "[CV]  C=10, kernel=sigmoid, score=(train=0.558, test=0.611), total=   0.8s\n",
            "[CV] C=10, kernel=rbf ................................................\n",
            "[CV]  C=10, kernel=rbf, score=(train=0.959, test=0.634), total=   1.8s\n",
            "[CV] C=10, kernel=rbf ................................................\n",
            "[CV]  C=10, kernel=rbf, score=(train=0.956, test=0.647), total=   1.8s\n",
            "[CV] C=10, kernel=rbf ................................................\n",
            "[CV]  C=10, kernel=rbf, score=(train=0.959, test=0.644), total=   1.8s\n",
            "[CV] C=10, kernel=rbf ................................................\n",
            "[CV]  C=10, kernel=rbf, score=(train=0.959, test=0.614), total=   1.8s\n",
            "[CV] C=10, kernel=rbf ................................................\n",
            "[CV]  C=10, kernel=rbf, score=(train=0.961, test=0.582), total=   1.7s\n",
            "[CV] C=100.0, kernel=linear ..........................................\n",
            "[CV]  C=100.0, kernel=linear, score=(train=0.708, test=0.732), total=  41.2s\n",
            "[CV] C=100.0, kernel=linear ..........................................\n",
            "[CV]  C=100.0, kernel=linear, score=(train=0.712, test=0.719), total=  37.6s\n",
            "[CV] C=100.0, kernel=linear ..........................................\n",
            "[CV]  C=100.0, kernel=linear, score=(train=0.714, test=0.711), total=  38.9s\n",
            "[CV] C=100.0, kernel=linear ..........................................\n",
            "[CV]  C=100.0, kernel=linear, score=(train=0.717, test=0.697), total=  38.8s\n",
            "[CV] C=100.0, kernel=linear ..........................................\n",
            "[CV]  C=100.0, kernel=linear, score=(train=0.723, test=0.672), total=  36.6s\n",
            "[CV] C=100.0, kernel=poly ............................................\n",
            "[CV]  C=100.0, kernel=poly, score=(train=0.937, test=0.617), total=  12.3s\n",
            "[CV] C=100.0, kernel=poly ............................................\n",
            "[CV]  C=100.0, kernel=poly, score=(train=0.939, test=0.592), total=  13.6s\n",
            "[CV] C=100.0, kernel=poly ............................................\n",
            "[CV]  C=100.0, kernel=poly, score=(train=0.939, test=0.593), total=  14.1s\n",
            "[CV] C=100.0, kernel=poly ............................................\n",
            "[CV]  C=100.0, kernel=poly, score=(train=0.945, test=0.567), total=  14.4s\n",
            "[CV] C=100.0, kernel=poly ............................................\n",
            "[CV]  C=100.0, kernel=poly, score=(train=0.944, test=0.565), total=  13.6s\n",
            "[CV] C=100.0, kernel=sigmoid .........................................\n",
            "[CV]  C=100.0, kernel=sigmoid, score=(train=0.550, test=0.588), total=   0.8s\n",
            "[CV] C=100.0, kernel=sigmoid .........................................\n",
            "[CV]  C=100.0, kernel=sigmoid, score=(train=0.554, test=0.593), total=   0.8s\n",
            "[CV] C=100.0, kernel=sigmoid .........................................\n",
            "[CV]  C=100.0, kernel=sigmoid, score=(train=0.549, test=0.571), total=   0.8s\n",
            "[CV] C=100.0, kernel=sigmoid .........................................\n",
            "[CV]  C=100.0, kernel=sigmoid, score=(train=0.559, test=0.557), total=   0.8s\n",
            "[CV] C=100.0, kernel=sigmoid .........................................\n",
            "[CV]  C=100.0, kernel=sigmoid, score=(train=0.555, test=0.609), total=   0.8s\n",
            "[CV] C=100.0, kernel=rbf .............................................\n",
            "[CV]  C=100.0, kernel=rbf, score=(train=1.000, test=0.595), total=   3.7s\n",
            "[CV] C=100.0, kernel=rbf .............................................\n",
            "[CV]  C=100.0, kernel=rbf, score=(train=1.000, test=0.603), total=   3.6s\n",
            "[CV] C=100.0, kernel=rbf .............................................\n",
            "[CV]  C=100.0, kernel=rbf, score=(train=1.000, test=0.593), total=   3.7s\n",
            "[CV] C=100.0, kernel=rbf .............................................\n",
            "[CV]  C=100.0, kernel=rbf, score=(train=1.000, test=0.572), total=   3.6s\n",
            "[CV] C=100.0, kernel=rbf .............................................\n",
            "[CV]  C=100.0, kernel=rbf, score=(train=1.000, test=0.542), total=   3.6s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 140 out of 140 | elapsed:  8.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=1234, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100.0],\n",
              "                         'kernel': ['linear', 'poly', 'sigmoid', 'rbf']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOJB3AuJxew0",
        "outputId": "db2a4cb2-67e2-4239-c3a2-c4e495b6941b"
      },
      "source": [
        "f_sc_svc_CV.cv_results_['mean_test_score']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.69502509, 0.68882725, 0.69498022, 0.68683014, 0.70093589,\n",
              "       0.68894106, 0.6950171 , 0.68697597, 0.70676094, 0.68976575,\n",
              "       0.69717303, 0.68703207, 0.70655425, 0.69065209, 0.70597647,\n",
              "       0.69318816, 0.70622808, 0.6679313 , 0.60683061, 0.68111149,\n",
              "       0.70615594, 0.61492541, 0.58630532, 0.62428559, 0.70613992,\n",
              "       0.58706414, 0.58351985, 0.58103046])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18CwhUkEwzyP"
      },
      "source": [
        "Лучший набор параметров и значение критерия качества на нём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku1nu1ydwzyQ",
        "outputId": "66988e45-e17b-414b-a510-c7b98bc668a0"
      },
      "source": [
        "f_sc_svc_CV.best_params_ , f_sc_svc_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'C': 0.01, 'kernel': 'linear'}, 0.7067609404318833)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MAJEV4KwzyT"
      },
      "source": [
        "По сравнению с подобранной в 3 задании (не стандартизированные данные, `C=0.001`, `kernel='rbf'`) качество изменилось на: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bLFLY6lwzyT",
        "outputId": "cfd8196d-e0b2-4114-8c5d-0d75d832b9a3"
      },
      "source": [
        "f_sc_svc_CV.best_score_ - svc_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0058361881315844855"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fp9JtSKLVYa"
      },
      "source": [
        "*Итак,* SVC всё еще не поддается. Качество улучшить не удалось, наилучшей остается модель из третьего задания. Однако здесь качество хотя бы повысилось относительно модели на стандартизированных данных из 5 задания (она была хуже модели из 3 задания на 0.0148)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWAz5qmi06Lb"
      },
      "source": [
        "##### 6 MLPC\n",
        "\n",
        "**6.3. Multi-layer Perceptron classifier**\n",
        "\n",
        "Буду менять функции активации `activation`, число слоев и количество нейронов в них `hidden_layer_sizes` и силу регуляризации `alpha`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llliDcUg06Le",
        "outputId": "905563a5-e92e-43be-8f9f-2ea7ea636972"
      },
      "source": [
        "# Инициализирую модель\n",
        "mlpc_model = MLPClassifier(alpha=0.0001,\n",
        "                           solver='adam',\n",
        "                           learning_rate='constant', \n",
        "                           learning_rate_init=0.001,\n",
        "                           tol=0.0001,\n",
        "                           max_iter=1000,\n",
        "                           random_state=1234)\n",
        "\n",
        "\n",
        "# Тестируемые значения гиперпараметров\n",
        "f_mlpc_params_set = {\n",
        "'activation':['logistic', 'tanh', 'relu'],\n",
        "'alpha': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 1e2, 1e3, 1e4],\n",
        "'hidden_layer_sizes':[(100,), (50,),\n",
        "                      (50, 10), (100, 50), \n",
        "                      (100, 50, 10)]\n",
        "}\n",
        "\n",
        "# Кросс-валидация\n",
        "f_mlpc_CV = GridSearchCV(estimator=mlpc_model,\n",
        "                       param_grid=f_mlpc_params_set,\n",
        "                       scoring='roc_auc',\n",
        "                       return_train_score=True,\n",
        "                       verbose=3)\n",
        "\n",
        "f_mlpc_CV.fit(X_train_scaled[:data_part], y_train[:data_part])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 135 candidates, totalling 675 fits\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,) ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=0.716, test=0.743), total=   1.7s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,) ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=0.726, test=0.703), total=   1.5s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,) ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=0.719, test=0.730), total=   1.5s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,) ....\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=0.725, test=0.706), total=   1.4s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,) ....\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=0.731, test=0.680), total=   1.5s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,) .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=0.902, test=0.665), total=  15.4s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,) .....\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=0.726, test=0.703), total=   0.9s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,) .....\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=0.719, test=0.729), total=   0.9s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,) .....\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=0.726, test=0.706), total=   1.0s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,) .....\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=0.731, test=0.681), total=   1.0s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10) ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=0.943, test=0.638), total=  11.9s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10) ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=0.948, test=0.632), total=  11.9s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10) ..\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=0.720, test=0.728), total=   1.2s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10) ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=0.950, test=0.620), total=  11.9s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10) ..\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=0.732, test=0.682), total=   1.1s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50) .\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50), score=(train=0.716, test=0.743), total=   2.3s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50) .\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50), score=(train=0.727, test=0.702), total=   2.9s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50) .\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50), score=(train=0.719, test=0.729), total=   2.1s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50) .\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50), score=(train=0.726, test=0.706), total=   3.7s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50) .\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50), score=(train=0.731, test=0.681), total=   2.4s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 10), score=(train=0.719, test=0.741), total=   5.9s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 10), score=(train=0.727, test=0.701), total=   3.5s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 10), score=(train=0.720, test=0.727), total=   3.1s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 10) \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 10), score=(train=0.999, test=0.581), total=  51.7s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 10), score=(train=0.983, test=0.611), total=  45.0s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100,) .....\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), score=(train=0.716, test=0.743), total=   1.6s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100,) .....\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), score=(train=0.726, test=0.703), total=   1.5s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100,) .....\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), score=(train=0.719, test=0.730), total=   1.6s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100,) .....\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), score=(train=0.725, test=0.706), total=   1.4s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100,) .....\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), score=(train=0.731, test=0.680), total=   1.5s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50,) ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), score=(train=0.900, test=0.668), total=  15.5s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50,) ......\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), score=(train=0.726, test=0.703), total=   0.9s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50,) ......\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), score=(train=0.719, test=0.729), total=   0.9s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50,) ......\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), score=(train=0.726, test=0.706), total=   1.0s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50,) ......\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), score=(train=0.731, test=0.681), total=   1.0s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=0.944, test=0.634), total=  12.0s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=0.942, test=0.636), total=  12.0s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10) ...\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=0.720, test=0.728), total=   1.2s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=0.950, test=0.612), total=  12.0s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10) ...\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=0.732, test=0.682), total=   1.2s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50) ..\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50), score=(train=0.716, test=0.743), total=   2.3s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50) ..\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50), score=(train=0.727, test=0.702), total=   2.8s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50) ..\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50), score=(train=0.719, test=0.729), total=   2.2s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50) ..\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50), score=(train=0.726, test=0.706), total=   3.7s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50) ..\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50), score=(train=0.731, test=0.681), total=   2.4s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 10), score=(train=0.717, test=0.741), total=   3.3s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 10), score=(train=0.727, test=0.701), total=   3.4s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 10), score=(train=0.720, test=0.727), total=   3.1s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 10), score=(train=0.979, test=0.600), total=  41.4s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 10), score=(train=0.733, test=0.681), total=   5.0s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100,) ......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), score=(train=0.716, test=0.743), total=   1.5s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100,) ......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), score=(train=0.726, test=0.703), total=   1.5s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100,) ......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), score=(train=0.719, test=0.730), total=   1.6s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100,) ......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), score=(train=0.725, test=0.706), total=   1.4s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100,) ......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), score=(train=0.731, test=0.680), total=   1.6s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50,) .......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), score=(train=0.721, test=0.743), total=   2.5s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50,) .......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), score=(train=0.726, test=0.703), total=   0.9s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50,) .......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), score=(train=0.719, test=0.729), total=   0.9s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50,) .......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), score=(train=0.726, test=0.706), total=   1.0s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50,) .......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), score=(train=0.731, test=0.681), total=   1.1s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10) ....\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=0.717, test=0.742), total=   1.2s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10) ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=0.918, test=0.636), total=  12.0s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10) ....\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=0.720, test=0.728), total=   1.2s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10) ....\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=0.729, test=0.705), total=   1.7s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10) ....\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=0.731, test=0.682), total=   1.1s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50) ...\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50), score=(train=0.716, test=0.743), total=   2.3s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50) ...\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50), score=(train=0.727, test=0.702), total=   2.8s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50) ...\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50), score=(train=0.719, test=0.729), total=   2.1s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50) ...\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50), score=(train=0.726, test=0.706), total=   2.2s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50) ...\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50), score=(train=0.731, test=0.681), total=   2.4s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 10), score=(train=0.717, test=0.742), total=   3.2s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 10), score=(train=0.727, test=0.701), total=   3.6s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 10), score=(train=0.720, test=0.727), total=   3.0s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 10), score=(train=0.726, test=0.706), total=   4.0s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 10), score=(train=0.732, test=0.682), total=   3.8s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), score=(train=0.716, test=0.744), total=   1.7s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), score=(train=0.726, test=0.701), total=   1.6s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), score=(train=0.719, test=0.730), total=   1.5s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), score=(train=0.725, test=0.707), total=   1.9s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), score=(train=0.731, test=0.682), total=   2.4s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.717, test=0.743), total=   1.6s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.727, test=0.702), total=   1.4s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.719, test=0.729), total=   0.9s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.725, test=0.707), total=   1.0s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.731, test=0.681), total=   1.3s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.716, test=0.743), total=   1.5s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.727, test=0.701), total=   1.5s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.719, test=0.729), total=   1.5s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.726, test=0.707), total=   1.6s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.731, test=0.681), total=   1.4s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50) ....\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50), score=(train=0.716, test=0.744), total=   3.9s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50) ....\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50), score=(train=0.726, test=0.701), total=   4.8s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50) ....\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50), score=(train=0.719, test=0.730), total=   4.7s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50) ....\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50), score=(train=0.725, test=0.707), total=   4.7s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50) ....\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50), score=(train=0.731, test=0.680), total=   2.7s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50, 10), score=(train=0.716, test=0.744), total=   4.3s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50, 10), score=(train=0.727, test=0.701), total=   5.0s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50, 10), score=(train=0.719, test=0.730), total=   4.6s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50, 10), score=(train=0.725, test=0.708), total=   4.6s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 50, 10), score=(train=0.731, test=0.681), total=   4.6s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100,), score=(train=0.713, test=0.745), total=   1.6s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100,), score=(train=0.724, test=0.700), total=   1.6s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100,), score=(train=0.716, test=0.729), total=   1.6s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100,), score=(train=0.723, test=0.707), total=   1.9s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100,), score=(train=0.728, test=0.679), total=   2.0s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50,), score=(train=0.713, test=0.744), total=   1.2s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50,), score=(train=0.724, test=0.700), total=   1.0s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50,), score=(train=0.716, test=0.728), total=   1.2s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50,), score=(train=0.723, test=0.706), total=   1.0s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50,), score=(train=0.728, test=0.679), total=   1.0s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.710, test=0.743), total=   1.6s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.721, test=0.698), total=   1.5s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.714, test=0.726), total=   1.6s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.720, test=0.705), total=   1.7s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.726, test=0.677), total=   2.0s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100, 50), score=(train=0.708, test=0.742), total=   3.4s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100, 50), score=(train=0.720, test=0.698), total=   3.2s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100, 50), score=(train=0.712, test=0.725), total=   3.2s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100, 50), score=(train=0.720, test=0.705), total=   4.8s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100, 50), score=(train=0.725, test=0.676), total=   3.9s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100, 50, 10), score=(train=0.317, test=0.288), total=   2.1s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100, 50, 10), score=(train=0.706, test=0.685), total=   1.9s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100, 50, 10), score=(train=0.311, test=0.290), total=   2.3s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100, 50, 10), score=(train=0.290, test=0.302), total=   2.0s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100, 50, 10), score=(train=0.287, test=0.330), total=   2.0s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(100,), score=(train=0.698, test=0.735), total=   0.9s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(100,), score=(train=0.709, test=0.689), total=   0.9s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(100,), score=(train=0.702, test=0.719), total=   0.8s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(100,), score=(train=0.708, test=0.696), total=   0.8s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(100,), score=(train=0.715, test=0.667), total=   0.8s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(50,), score=(train=0.698, test=0.734), total=   0.6s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(50,), score=(train=0.709, test=0.689), total=   0.7s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(50,), score=(train=0.702, test=0.720), total=   0.5s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(50,), score=(train=0.708, test=0.696), total=   0.5s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(50,), score=(train=0.715, test=0.668), total=   0.6s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(50, 10), score=(train=0.695, test=0.732), total=   1.0s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(50, 10), score=(train=0.707, test=0.688), total=   0.9s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(50, 10), score=(train=0.700, test=0.719), total=   0.8s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(50, 10), score=(train=0.706, test=0.693), total=   0.9s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(50, 10), score=(train=0.713, test=0.666), total=   1.0s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(100, 50), score=(train=0.592, test=0.618), total=   3.1s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(100, 50), score=(train=0.358, test=0.340), total=   2.8s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(100, 50), score=(train=0.698, test=0.717), total=   2.7s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(100, 50), score=(train=0.681, test=0.668), total=   2.8s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(100, 50), score=(train=0.699, test=0.653), total=   2.4s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.3s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.8s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.2s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.5s\n",
            "[CV] activation=logistic, alpha=10, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=logistic, alpha=10, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.6s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(100,) .....\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(100,), score=(train=0.696, test=0.736), total=   0.9s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(100,) .....\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(100,), score=(train=0.707, test=0.684), total=   0.9s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(100,) .....\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(100,), score=(train=0.699, test=0.718), total=   1.0s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(100,) .....\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(100,), score=(train=0.706, test=0.694), total=   0.8s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(100,) .....\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(100,), score=(train=0.713, test=0.666), total=   0.8s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(50,) ......\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(50,), score=(train=0.695, test=0.733), total=   0.5s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(50,) ......\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(50,), score=(train=0.708, test=0.687), total=   0.6s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(50,) ......\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(50,), score=(train=0.700, test=0.718), total=   0.7s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(50,) ......\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(50,), score=(train=0.706, test=0.694), total=   0.6s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(50,) ......\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(50,), score=(train=0.712, test=0.667), total=   0.6s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(50, 10) ...\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(50, 10), score=(train=0.695, test=0.734), total=   0.7s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(50, 10) ...\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(50, 10), score=(train=0.706, test=0.687), total=   0.7s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(50, 10) ...\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(50, 10), score=(train=0.700, test=0.719), total=   0.7s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(50, 10) ...\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(50, 10), score=(train=0.704, test=0.694), total=   0.8s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(50, 10) ...\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(50, 10), score=(train=0.712, test=0.665), total=   0.7s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50) ..\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50), score=(train=0.696, test=0.732), total=   1.8s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50) ..\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50), score=(train=0.706, test=0.684), total=   2.1s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50) ..\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50), score=(train=0.692, test=0.706), total=   1.7s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50) ..\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50), score=(train=0.294, test=0.304), total=   1.6s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50) ..\n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50), score=(train=0.287, test=0.334), total=   1.7s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.5s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.5s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.5s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.5s\n",
            "[CV] activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=100.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.6s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(100,) ....\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(100,), score=(train=0.534, test=0.535), total=   0.9s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(100,) ....\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(100,), score=(train=0.442, test=0.412), total=   0.9s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(100,) ....\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(100,), score=(train=0.699, test=0.716), total=   1.0s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(100,) ....\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(100,), score=(train=0.641, test=0.612), total=   0.9s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(100,) ....\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(100,), score=(train=0.300, test=0.345), total=   0.8s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(50,) .....\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(50,), score=(train=0.696, test=0.735), total=   0.6s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(50,) .....\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(50,), score=(train=0.708, test=0.686), total=   0.6s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(50,) .....\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(50,), score=(train=0.699, test=0.722), total=   0.6s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(50,) .....\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(50,), score=(train=0.706, test=0.694), total=   0.6s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(50,) .....\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(50,), score=(train=0.712, test=0.664), total=   0.6s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(50, 10) ..\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   0.8s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(50, 10) ..\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   0.8s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(50, 10) ..\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   0.8s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(50, 10) ..\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   0.8s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(50, 10) ..\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   0.8s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50) .\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   2.4s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50) .\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   2.1s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50) .\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   2.1s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50) .\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   1.9s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50) .\n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   2.0s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.0s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.0s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.0s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.0s\n",
            "[CV] activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=1000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.0s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(100,) ...\n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(100,), score=(train=0.505, test=0.514), total=   0.9s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(100,) ...\n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(100,), score=(train=0.399, test=0.422), total=   1.0s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(100,) ...\n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(100,), score=(train=0.446, test=0.407), total=   0.9s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(100,) ...\n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(100,), score=(train=0.386, test=0.376), total=   0.9s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(100,) ...\n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(100,), score=(train=0.447, test=0.451), total=   0.9s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(50,) ....\n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(50,), score=(train=0.440, test=0.421), total=   0.6s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(50,) ....\n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(50,), score=(train=0.495, test=0.450), total=   0.6s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(50,) ....\n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(50,), score=(train=0.527, test=0.568), total=   0.6s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(50,) ....\n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(50,), score=(train=0.538, test=0.547), total=   0.6s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(50,) ....\n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(50,), score=(train=0.520, test=0.509), total=   0.6s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(50, 10) .\n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   0.9s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(50, 10) .\n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   0.9s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(50, 10) .\n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   0.9s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(50, 10) .\n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   0.9s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(50, 10) .\n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   0.9s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50) \n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   2.0s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50) \n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   2.1s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50) \n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   2.0s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50) \n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   2.0s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50) \n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   2.1s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.4s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.4s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.5s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.4s\n",
            "[CV] activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=logistic, alpha=10000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.4s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,) ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.596), total=  33.4s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.645), total=  32.7s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,) ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.641), total=  33.4s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.620), total=  31.8s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,) ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.627), total=  33.3s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,) .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=0.988, test=0.632), total=  18.7s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,) .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=0.992, test=0.612), total=  18.6s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,) .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=0.993, test=0.637), total=  18.5s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,) .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=0.993, test=0.587), total=  18.5s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,) .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=0.993, test=0.586), total=  18.6s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.624), total=  14.9s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.631), total=  14.9s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.648), total=  15.0s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.578), total=  15.0s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.619), total=  14.9s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.614), total=  21.7s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.646), total=  20.8s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.615), total=  20.9s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.596), total=  20.3s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.610), total=  21.6s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.621), total=  14.2s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.630), total=  14.3s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.620), total=  14.2s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.576), total=  13.9s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.594), total=  14.5s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100,) .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.594), total=  30.0s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100,) .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.636), total=  29.8s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100,) .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.641), total=  30.0s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.620), total=  27.9s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100,) .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.627), total=  29.8s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50,) ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), score=(train=0.988, test=0.633), total=  18.4s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50,) ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), score=(train=0.992, test=0.611), total=  18.4s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50,) ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), score=(train=0.993, test=0.637), total=  18.6s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50,) ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), score=(train=0.993, test=0.587), total=  18.7s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50,) ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), score=(train=0.993, test=0.585), total=  18.7s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.626), total=  14.9s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.631), total=  15.0s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.647), total=  14.9s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.578), total=  14.8s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.619), total=  14.9s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.614), total=  19.6s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.644), total=  20.8s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.614), total=  21.1s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.596), total=  20.5s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.611), total=  21.6s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.621), total=  14.2s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.630), total=  14.1s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.620), total=  14.2s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.576), total=  13.9s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.593), total=  14.5s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100,) ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.601), total=  29.9s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100,) ..........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.649), total=  29.0s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100,) ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.635), total=  30.0s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100,) ..........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.614), total=  27.5s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100,) ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.627), total=  29.9s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50,) ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), score=(train=0.989, test=0.635), total=  18.5s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50,) ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), score=(train=0.990, test=0.606), total=  18.5s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50,) ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), score=(train=0.992, test=0.638), total=  18.6s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50,) ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), score=(train=0.991, test=0.589), total=  18.5s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50,) ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), score=(train=0.992, test=0.580), total=  18.5s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.625), total=  15.0s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.640), total=  14.9s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=0.999, test=0.646), total=  14.9s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.579), total=  14.4s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.615), total=  14.8s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50) .......\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.612), total=  22.0s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50) .......\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.646), total=  21.3s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50) .......\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.605), total=  21.9s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50) .......\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.605), total=  21.4s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50) .......\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.609), total=  21.6s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 10) ...\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.619), total=  14.1s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 10) ...\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.631), total=  14.2s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 10) ...\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.619), total=  14.4s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 10) ...\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.573), total=  14.3s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 10) ...\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.591), total=  14.7s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.617), total=  28.5s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100,) ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.632), total=  29.6s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100,) ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.618), total=  29.8s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.608), total=  27.6s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.621), total=  26.4s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50,) ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.978, test=0.634), total=  18.4s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50,) ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.977, test=0.624), total=  18.4s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50,) ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.980, test=0.629), total=  18.4s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50,) ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.979, test=0.594), total=  18.4s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50,) ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.978, test=0.608), total=  18.4s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.609), total=  14.4s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.999, test=0.630), total=  13.3s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.999, test=0.616), total=  13.5s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.587), total=  12.9s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.998, test=0.601), total=  12.0s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50) ........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.613), total=  22.3s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50) ........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.622), total=  19.3s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50) ........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.600), total=  22.3s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50) ........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.584), total=  23.7s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50) ........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.591), total=  25.4s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50, 10) ....\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.629), total=  18.9s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50, 10) ....\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.661), total=  18.8s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50, 10) ....\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.604), total=  20.0s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50, 10) ....\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.585), total=  17.0s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50, 10) ....\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.605), total=  18.9s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100,), score=(train=0.731, test=0.734), total=   5.8s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100,), score=(train=0.739, test=0.697), total=   4.2s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100,), score=(train=0.728, test=0.733), total=   4.2s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100,), score=(train=0.750, test=0.696), total=   6.7s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100,), score=(train=0.741, test=0.681), total=   4.7s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50,), score=(train=0.734, test=0.735), total=   3.5s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50,), score=(train=0.740, test=0.702), total=   3.3s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50,), score=(train=0.732, test=0.732), total=   3.3s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50,), score=(train=0.754, test=0.693), total=   4.7s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50,), score=(train=0.740, test=0.682), total=   2.8s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.766, test=0.719), total=   3.1s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.780, test=0.683), total=   3.6s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.756, test=0.727), total=   3.4s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.784, test=0.677), total=   3.4s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.792, test=0.665), total=   5.1s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100, 50) ..........\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100, 50), score=(train=0.754, test=0.728), total=   9.8s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100, 50) ..........\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100, 50), score=(train=0.740, test=0.702), total=   4.7s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100, 50) ..........\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100, 50), score=(train=0.736, test=0.731), total=   6.7s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100, 50) ..........\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100, 50), score=(train=0.764, test=0.689), total=   8.7s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100, 50) ..........\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100, 50), score=(train=0.758, test=0.680), total=   8.1s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100, 50, 10) ......\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100, 50, 10), score=(train=0.753, test=0.726), total=   7.9s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100, 50, 10) ......\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100, 50, 10), score=(train=0.757, test=0.698), total=   6.7s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100, 50, 10) ......\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100, 50, 10), score=(train=0.729, test=0.729), total=   6.1s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100, 50, 10) ......\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100, 50, 10), score=(train=0.803, test=0.648), total=  11.2s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100, 50, 10) ......\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100, 50, 10), score=(train=0.785, test=0.664), total=  11.1s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(100,) ............\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(100,), score=(train=0.708, test=0.743), total=   1.4s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(100,) ............\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(100,), score=(train=0.720, test=0.696), total=   1.4s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(100,) ............\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(100,), score=(train=0.712, test=0.727), total=   1.4s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(100,) ............\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(100,), score=(train=0.719, test=0.703), total=   1.4s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(100,) ............\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(100,), score=(train=0.725, test=0.675), total=   1.4s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(50,) .............\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(50,), score=(train=0.708, test=0.743), total=   1.0s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(50,) .............\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(50,), score=(train=0.720, test=0.699), total=   1.0s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(50,) .............\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(50,), score=(train=0.713, test=0.725), total=   1.0s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(50,) .............\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(50,), score=(train=0.719, test=0.704), total=   1.0s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(50,) .............\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(50,), score=(train=0.725, test=0.676), total=   1.1s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(50, 10) ..........\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(50, 10), score=(train=0.706, test=0.740), total=   0.9s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(50, 10) ..........\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(50, 10), score=(train=0.718, test=0.697), total=   1.2s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(50, 10) ..........\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(50, 10), score=(train=0.711, test=0.724), total=   0.9s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(50, 10) ..........\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(50, 10), score=(train=0.717, test=0.703), total=   0.9s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(50, 10) ..........\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(50, 10), score=(train=0.723, test=0.675), total=   0.9s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(100, 50) .........\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(100, 50), score=(train=0.706, test=0.739), total=   1.9s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(100, 50) .........\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(100, 50), score=(train=0.718, test=0.699), total=   2.0s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(100, 50) .........\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(100, 50), score=(train=0.710, test=0.724), total=   2.1s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(100, 50) .........\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(100, 50), score=(train=0.716, test=0.702), total=   1.9s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(100, 50) .........\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(100, 50), score=(train=0.723, test=0.674), total=   2.0s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(100, 50, 10) .....\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(100, 50, 10), score=(train=0.704, test=0.738), total=   2.2s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(100, 50, 10) .....\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(100, 50, 10), score=(train=0.716, test=0.694), total=   3.9s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(100, 50, 10) .....\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(100, 50, 10), score=(train=0.708, test=0.722), total=   3.3s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(100, 50, 10) .....\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(100, 50, 10), score=(train=0.715, test=0.700), total=   3.3s\n",
            "[CV] activation=tanh, alpha=10, hidden_layer_sizes=(100, 50, 10) .....\n",
            "[CV]  activation=tanh, alpha=10, hidden_layer_sizes=(100, 50, 10), score=(train=0.721, test=0.672), total=   4.2s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(100,), score=(train=0.697, test=0.735), total=   1.1s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(100,), score=(train=0.708, test=0.689), total=   1.1s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(100,), score=(train=0.700, test=0.719), total=   1.1s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(100,), score=(train=0.706, test=0.694), total=   1.1s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(100,), score=(train=0.713, test=0.667), total=   1.1s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(50,), score=(train=0.696, test=0.733), total=   0.9s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(50,), score=(train=0.708, test=0.689), total=   1.0s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(50,), score=(train=0.700, test=0.719), total=   0.9s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(50,), score=(train=0.706, test=0.694), total=   0.9s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(50,), score=(train=0.712, test=0.667), total=   0.9s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(50, 10), score=(train=0.696, test=0.734), total=   1.1s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(50, 10), score=(train=0.707, test=0.688), total=   1.2s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(50, 10), score=(train=0.699, test=0.720), total=   1.1s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(50, 10), score=(train=0.707, test=0.694), total=   1.1s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(50, 10), score=(train=0.713, test=0.668), total=   1.2s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50), score=(train=0.582, test=0.600), total=   2.1s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50), score=(train=0.618, test=0.592), total=   2.1s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50), score=(train=0.617, test=0.634), total=   2.1s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50), score=(train=0.624, test=0.616), total=   2.1s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50), score=(train=0.670, test=0.638), total=   2.2s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.3s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.2s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.2s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.2s\n",
            "[CV] activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=tanh, alpha=100.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.3s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(100,), score=(train=0.659, test=0.671), total=   1.2s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(100,), score=(train=0.679, test=0.672), total=   1.2s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(100,), score=(train=0.670, test=0.702), total=   1.2s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(100,), score=(train=0.439, test=0.451), total=   1.2s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(100,), score=(train=0.481, test=0.513), total=   1.2s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(50,), score=(train=0.668, test=0.708), total=   1.0s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(50,), score=(train=0.683, test=0.643), total=   1.0s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(50,), score=(train=0.673, test=0.696), total=   0.9s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(50,), score=(train=0.680, test=0.682), total=   0.9s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(50,), score=(train=0.682, test=0.630), total=   0.9s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(50, 10), score=(train=0.655, test=0.694), total=   1.2s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(50, 10), score=(train=0.624, test=0.620), total=   1.2s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(50, 10), score=(train=0.613, test=0.601), total=   1.2s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(50, 10), score=(train=0.643, test=0.638), total=   1.2s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(50, 10), score=(train=0.606, test=0.583), total=   1.2s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50), score=(train=0.412, test=0.423), total=   2.3s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50), score=(train=0.407, test=0.430), total=   2.3s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50), score=(train=0.497, test=0.489), total=   2.2s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50), score=(train=0.457, test=0.445), total=   2.3s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50), score=(train=0.572, test=0.574), total=   2.2s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   4.0s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.9s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.9s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   4.0s\n",
            "[CV] activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=tanh, alpha=1000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.9s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(100,), score=(train=0.404, test=0.401), total=   1.3s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(100,), score=(train=0.406, test=0.416), total=   1.3s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(100,), score=(train=0.395, test=0.371), total=   1.3s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(100,), score=(train=0.411, test=0.409), total=   1.3s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(100,), score=(train=0.368, test=0.361), total=   1.4s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(50,), score=(train=0.490, test=0.507), total=   1.1s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(50,), score=(train=0.489, test=0.425), total=   1.0s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(50,), score=(train=0.471, test=0.479), total=   1.0s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(50,), score=(train=0.489, test=0.506), total=   1.1s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(50,), score=(train=0.503, test=0.501), total=   1.0s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   1.4s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(50, 10), score=(train=0.426, test=0.446), total=   1.4s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   1.4s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(50, 10), score=(train=0.485, test=0.472), total=   1.4s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   1.4s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50) ....\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   2.4s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50) ....\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50), score=(train=0.520, test=0.511), total=   2.5s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50) ....\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   2.4s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50) ....\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   2.5s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50) ....\n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   2.5s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   4.6s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   4.5s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   4.6s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   4.5s\n",
            "[CV] activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=tanh, alpha=10000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   4.5s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100,) ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=0.999, test=0.639), total=  18.1s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100,) ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=0.997, test=0.626), total=  18.0s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100,) ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=0.997, test=0.620), total=  18.0s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=0.998, test=0.587), total=  20.4s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100,) ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=0.998, test=0.606), total=  21.6s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=0.915, test=0.648), total=   9.9s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=0.923, test=0.640), total=  10.2s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=0.920, test=0.632), total=   9.6s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=0.931, test=0.638), total=  11.9s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=0.933, test=0.635), total=  11.7s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=0.998, test=0.595), total=   9.9s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=0.997, test=0.618), total=  10.9s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=0.996, test=0.600), total=  11.1s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=0.999, test=0.593), total=  10.7s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=0.995, test=0.584), total=   9.0s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.633), total=  15.8s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.671), total=  16.2s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.631), total=  16.5s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.620), total=  14.9s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.613), total=  16.4s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.610), total=   9.6s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.618), total=   8.9s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.584), total=   8.1s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.596), total=   7.2s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.578), total=   7.4s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100,), score=(train=0.997, test=0.654), total=  17.5s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100,) .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100,), score=(train=0.998, test=0.623), total=  18.1s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100,), score=(train=0.997, test=0.618), total=  17.5s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100,), score=(train=0.999, test=0.593), total=  17.6s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100,) .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100,), score=(train=0.999, test=0.613), total=  18.0s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50,), score=(train=0.926, test=0.647), total=  11.1s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50,), score=(train=0.926, test=0.641), total=  10.8s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50,), score=(train=0.923, test=0.637), total=   9.5s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50,), score=(train=0.928, test=0.651), total=  10.8s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50,), score=(train=0.939, test=0.630), total=  12.0s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=0.999, test=0.604), total=  10.5s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=0.997, test=0.613), total=   9.5s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=0.996, test=0.598), total=  10.1s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.594), total=  11.1s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=0.998, test=0.581), total=  11.1s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.619), total=  12.2s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.663), total=  12.9s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.624), total=  11.9s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.615), total=  12.0s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.620), total=  11.9s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.614), total=   7.7s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.633), total=   8.2s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.590), total=   8.7s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.606), total=   7.4s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.576), total=   7.1s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100,) ..........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100,), score=(train=0.997, test=0.639), total=  17.5s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100,) ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100,), score=(train=0.997, test=0.623), total=  18.2s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100,) ..........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100,), score=(train=0.997, test=0.624), total=  17.8s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100,) ..........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100,), score=(train=0.996, test=0.585), total=  16.0s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100,) ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100,), score=(train=0.998, test=0.622), total=  18.1s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50,) ...........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50,), score=(train=0.925, test=0.655), total=  10.7s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50,) ...........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50,), score=(train=0.924, test=0.643), total=  10.3s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50,) ...........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50,), score=(train=0.920, test=0.633), total=   9.5s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50,) ...........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50,), score=(train=0.925, test=0.639), total=  11.0s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50,) ...........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50,), score=(train=0.934, test=0.618), total=  10.9s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=0.997, test=0.620), total=   9.5s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=0.988, test=0.619), total=   7.2s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=0.996, test=0.589), total=   9.8s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=0.998, test=0.614), total=   9.3s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=0.999, test=0.564), total=  11.1s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50) .......\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.612), total=  12.2s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50) .......\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.672), total=  12.6s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50) .......\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.628), total=  12.8s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50) .......\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.615), total=  12.2s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50) .......\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.625), total=  11.9s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 10) ...\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.619), total=   7.5s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 10) ...\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.649), total=   8.6s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 10) ...\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.574), total=   8.3s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 10) ...\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.617), total=   7.4s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 10) ...\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.596), total=   8.0s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100,), score=(train=0.972, test=0.673), total=   9.7s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100,), score=(train=0.989, test=0.637), total=  14.4s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100,), score=(train=0.968, test=0.644), total=   9.9s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100,), score=(train=0.984, test=0.616), total=  12.7s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100,), score=(train=0.976, test=0.621), total=  10.1s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50,) ............\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.910, test=0.654), total=   9.0s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50,) ............\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.910, test=0.641), total=   8.9s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50,) ............\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.913, test=0.642), total=   9.5s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50,) ............\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.907, test=0.653), total=   8.6s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50,) ............\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.914, test=0.643), total=   9.5s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.990, test=0.598), total=   7.6s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.986, test=0.625), total=   7.2s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.982, test=0.628), total=   6.9s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.989, test=0.616), total=   7.2s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.993, test=0.615), total=   8.4s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50) ........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.632), total=  11.9s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50) ........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.673), total=  11.2s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50) ........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.636), total=  12.3s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50) ........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.612), total=  11.5s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50) ........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50), score=(train=1.000, test=0.601), total=  12.6s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50, 10) ....\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.608), total=   9.4s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50, 10) ....\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50, 10), score=(train=0.998, test=0.641), total=   9.6s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50, 10) ....\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.610), total=   7.5s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50, 10) ....\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50, 10), score=(train=0.994, test=0.599), total=   8.9s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50, 10) ....\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.602), total=   8.9s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100,), score=(train=0.799, test=0.724), total=   4.0s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100,), score=(train=0.782, test=0.687), total=   2.6s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100,), score=(train=0.786, test=0.720), total=   3.1s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100,), score=(train=0.803, test=0.686), total=   4.0s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100,), score=(train=0.792, test=0.670), total=   2.8s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50,), score=(train=0.772, test=0.730), total=   2.6s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50,), score=(train=0.778, test=0.682), total=   2.6s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50,), score=(train=0.779, test=0.713), total=   3.4s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50,), score=(train=0.783, test=0.690), total=   2.9s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50,), score=(train=0.776, test=0.668), total=   2.2s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.886, test=0.668), total=   3.5s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.857, test=0.666), total=   2.9s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.860, test=0.676), total=   2.9s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.876, test=0.660), total=   2.9s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.872, test=0.644), total=   3.2s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100, 50) ..........\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100, 50), score=(train=0.956, test=0.670), total=   6.7s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100, 50) ..........\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100, 50), score=(train=0.964, test=0.669), total=   6.8s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100, 50) ..........\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100, 50), score=(train=0.971, test=0.667), total=   7.6s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100, 50) ..........\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100, 50), score=(train=0.951, test=0.631), total=   5.5s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100, 50) ..........\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100, 50), score=(train=0.946, test=0.640), total=   6.3s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100, 50, 10) ......\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100, 50, 10), score=(train=0.998, test=0.613), total=   7.8s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100, 50, 10) ......\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100, 50, 10), score=(train=0.982, test=0.619), total=   5.1s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100, 50, 10) ......\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100, 50, 10), score=(train=0.994, test=0.649), total=   6.8s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100, 50, 10) ......\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100, 50, 10), score=(train=1.000, test=0.618), total=   8.8s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100, 50, 10) ......\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100, 50, 10), score=(train=0.994, test=0.615), total=   6.1s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(100,) ............\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(100,), score=(train=0.709, test=0.743), total=   1.0s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(100,) ............\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(100,), score=(train=0.720, test=0.698), total=   1.5s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(100,) ............\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(100,), score=(train=0.714, test=0.727), total=   1.0s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(100,) ............\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(100,), score=(train=0.720, test=0.705), total=   1.0s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(100,) ............\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(100,), score=(train=0.725, test=0.676), total=   1.2s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(50,) .............\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(50,), score=(train=0.709, test=0.743), total=   1.1s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(50,) .............\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(50,), score=(train=0.721, test=0.700), total=   0.9s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(50,) .............\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(50,), score=(train=0.714, test=0.725), total=   0.7s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(50,) .............\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(50,), score=(train=0.719, test=0.705), total=   1.0s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(50,) .............\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(50,), score=(train=0.726, test=0.676), total=   0.9s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(50, 10) ..........\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(50, 10), score=(train=0.706, test=0.740), total=   0.9s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(50, 10) ..........\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(50, 10), score=(train=0.718, test=0.698), total=   1.1s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(50, 10) ..........\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(50, 10), score=(train=0.710, test=0.725), total=   1.0s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(50, 10) ..........\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(50, 10), score=(train=0.717, test=0.703), total=   0.8s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(50, 10) ..........\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(50, 10), score=(train=0.723, test=0.675), total=   1.0s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(100, 50) .........\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(100, 50), score=(train=0.707, test=0.740), total=   1.8s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(100, 50) .........\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(100, 50), score=(train=0.718, test=0.698), total=   1.9s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(100, 50) .........\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(100, 50), score=(train=0.710, test=0.724), total=   2.7s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(100, 50) .........\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(100, 50), score=(train=0.717, test=0.703), total=   2.6s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(100, 50) .........\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(100, 50), score=(train=0.723, test=0.671), total=   2.1s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(100, 50, 10) .....\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(100, 50, 10), score=(train=0.704, test=0.738), total=   3.9s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(100, 50, 10) .....\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(100, 50, 10), score=(train=0.716, test=0.695), total=   3.6s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(100, 50, 10) .....\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(100, 50, 10), score=(train=0.708, test=0.721), total=   3.6s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(100, 50, 10) .....\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(100, 50, 10), score=(train=0.714, test=0.702), total=   3.5s\n",
            "[CV] activation=relu, alpha=10, hidden_layer_sizes=(100, 50, 10) .....\n",
            "[CV]  activation=relu, alpha=10, hidden_layer_sizes=(100, 50, 10), score=(train=0.722, test=0.672), total=   3.6s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(100,), score=(train=0.695, test=0.733), total=   0.8s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(100,), score=(train=0.707, test=0.688), total=   0.8s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(100,), score=(train=0.700, test=0.719), total=   0.8s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(100,), score=(train=0.706, test=0.693), total=   0.8s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(100,), score=(train=0.712, test=0.666), total=   0.8s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(50,), score=(train=0.696, test=0.733), total=   0.7s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(50,), score=(train=0.707, test=0.688), total=   0.7s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(50,), score=(train=0.699, test=0.719), total=   0.7s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(50,), score=(train=0.706, test=0.693), total=   0.7s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(50,), score=(train=0.712, test=0.666), total=   0.7s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(50, 10), score=(train=0.696, test=0.733), total=   1.0s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(50, 10), score=(train=0.707, test=0.688), total=   1.0s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(50, 10), score=(train=0.699, test=0.719), total=   0.9s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(50, 10), score=(train=0.707, test=0.695), total=   0.9s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(50, 10), score=(train=0.713, test=0.668), total=   0.9s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50), score=(train=0.692, test=0.723), total=   1.6s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50), score=(train=0.694, test=0.670), total=   1.5s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50), score=(train=0.685, test=0.725), total=   1.5s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50), score=(train=0.699, test=0.685), total=   1.6s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50) ......\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50), score=(train=0.713, test=0.672), total=   1.6s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.6s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.5s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.4s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.4s\n",
            "[CV] activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50, 10) ..\n",
            "[CV]  activation=relu, alpha=100.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.4s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(100,), score=(train=0.610, test=0.624), total=   0.8s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(100,), score=(train=0.666, test=0.651), total=   0.8s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(100,), score=(train=0.631, test=0.677), total=   0.8s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(100,), score=(train=0.576, test=0.535), total=   0.9s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(100,), score=(train=0.521, test=0.549), total=   0.8s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(50,), score=(train=0.684, test=0.715), total=   0.7s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(50,), score=(train=0.707, test=0.664), total=   0.7s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(50,), score=(train=0.687, test=0.712), total=   0.7s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(50,), score=(train=0.686, test=0.686), total=   0.8s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(50,), score=(train=0.691, test=0.633), total=   0.7s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   1.0s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   1.0s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   1.0s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   1.0s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   1.0s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50), score=(train=0.390, test=0.377), total=   1.7s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50), score=(train=0.391, test=0.411), total=   1.7s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50), score=(train=0.401, test=0.394), total=   1.6s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50), score=(train=0.540, test=0.530), total=   1.6s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50) .....\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50), score=(train=0.526, test=0.554), total=   1.7s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.9s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.0s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   2.9s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.0s\n",
            "[CV] activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50, 10) .\n",
            "[CV]  activation=relu, alpha=1000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.0s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(100,), score=(train=0.432, test=0.416), total=   0.9s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(100,), score=(train=0.486, test=0.467), total=   0.9s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(100,), score=(train=0.464, test=0.458), total=   0.9s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(100,), score=(train=0.572, test=0.588), total=   0.9s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(100,), score=(train=0.550, test=0.520), total=   0.9s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(50,), score=(train=0.583, test=0.597), total=   0.8s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(50,), score=(train=0.561, test=0.488), total=   0.8s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(50,), score=(train=0.553, test=0.589), total=   0.8s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(50,), score=(train=0.666, test=0.656), total=   0.8s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(50,), score=(train=0.563, test=0.543), total=   0.8s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   1.2s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   1.2s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   1.2s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   1.2s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(50, 10), score=(train=0.500, test=0.500), total=   1.2s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50) ....\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   1.8s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50) ....\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   1.8s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50) ....\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   1.8s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50) ....\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   1.8s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50) ....\n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50), score=(train=0.500, test=0.500), total=   1.9s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.4s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.4s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.4s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.4s\n",
            "[CV] activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50, 10) \n",
            "[CV]  activation=relu, alpha=10000.0, hidden_layer_sizes=(100, 50, 10), score=(train=0.500, test=0.500), total=   3.4s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 675 out of 675 | elapsed: 73.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=1000, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_s...\n",
              "                                     solver='adam', tol=0.0001,\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'activation': ['logistic', 'tanh', 'relu'],\n",
              "                         'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100.0,\n",
              "                                   1000.0, 10000.0],\n",
              "                         'hidden_layer_sizes': [(100,), (50,), (50, 10),\n",
              "                                                (100, 50), (100, 50, 10)]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZD85aKF06Lf"
      },
      "source": [
        "Лучший набор параметров и значение критерия качества на нём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eJwbdwf06Lg",
        "outputId": "7c6933a7-6324-4aad-b5b0-f32cee003db6"
      },
      "source": [
        "f_mlpc_CV.best_params_ , f_mlpc_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (100,)},\n",
              " 0.7127599226102147)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ODu8zSD06Li"
      },
      "source": [
        "По сравнению с подобранной в 3 задании (не стандартизированные данные, `alpha=10000`, `activation=logistic`, `solver=adam`, `hidden_layer_sizes=(100,)`) качество увеличилось на: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAmXv3DB06Lj",
        "outputId": "caca7724-8040-49ae-c2f7-4637eb361b45"
      },
      "source": [
        "f_mlpc_CV.best_score_ - mlpc_CV.best_score_ "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0003869489264983761"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urRsoI9kPfkz"
      },
      "source": [
        "Ура, тут хотя бы немного удалось улучшить!\n",
        "\n",
        "*Итогo,* лучшая модель для MLPClassifier:\n",
        "\n",
        "```\n",
        "activation='logistic'\n",
        "alpha=0.1\n",
        "hidden_layer_sizes=(100,)\n",
        "solver='adam'\n",
        "learning_rate='constant'\n",
        "learning_rate_init=0.001\n",
        "tol=0.0001\n",
        "max_iter=1000\n",
        "```\n",
        "\n",
        "Качество: 0.7127599226102147"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXbGtWONLU_y"
      },
      "source": [
        "#### Лучшие модели по итогам 6 задания\n",
        "\n",
        "Для SVC возьму наилучшую на стандартизированных данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sctu82psLOvt"
      },
      "source": [
        "best_logreg_model = LogisticRegression(tol=0.0001, \n",
        "                                  solver='saga',\n",
        "                                  penalty='elasticnet',\n",
        "                                  fit_intercept=True,\n",
        "                                  C=0.008,\n",
        "                                  l1_ratio=0.45,\n",
        "                                  max_iter=500)\n",
        "best_logreg_model.fit(X_train_scaled[:4000], y_train[:4000])\n",
        "\n",
        "best_mlpc_model = MLPClassifier(activation='logistic',\n",
        "                                alpha=0.1,\n",
        "                                hidden_layer_sizes=(100,),\n",
        "                                solver='adam',\n",
        "                                learning_rate='constant',\n",
        "                                learning_rate_init=0.001,\n",
        "                                tol=0.0001,\n",
        "                                max_iter=1000)\n",
        "best_mlpc_model.fit(X_train_scaled[:4000], y_train[:4000])\n",
        "\n",
        "best_svc_model = SVC(C=0.01, \n",
        "                 kernel='linear',\n",
        "                 gamma='scale',\n",
        "                 tol=0.001,\n",
        "                 random_state=1234)\n",
        "best_svc_model.fit(X_train_scaled[:4000], y_train[:4000])\n",
        "\n",
        "# чтобы не перезапускать ячейки с кросс-валидацией, но иметь под рукой значения качства оттуда\n",
        "best_logreg_score = 0.7153233027155299\n",
        "best_svc_score = 0.7067609404318833\n",
        "best_mlpc_score = 0.7127599226102147"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrA69W0kRUF1"
      },
      "source": [
        "### Добавление категориальных признаков в модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt9o1RMRRUF2"
      },
      "source": [
        "#### 7\n",
        "\n",
        "**Задание 7** (1 балл) \n",
        "\n",
        "Постройте для разных алгоритмов графики [кривых обучения](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html), изображающие зависимость качества на тестовой и обучающей выборках от количества объектов, на которых обучаются модели. Посмотрите на поведение кривых и ответьте на вопросы:\n",
        "* Может ли с ростом числа объектов убывать качество на тестовой выборке? А на обучающей? Почему?\n",
        "* Для каких целей можно использовать знание качества на обучающей части выборки?\n",
        "* Какой из алгоритмов лучше обучается на меньшем числе объектов?\n",
        "* Может ли добавление новых объектов значительно повысить качество какого-то из алгоритмов или при существующем наборе данных для всех алгоритмов произошло насыщение?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFKv7jHkz76q"
      },
      "source": [
        "***Решение задания 7:***\n",
        "\n",
        "Теперь возьму все данные, а не 4000.\n",
        "\n",
        "Пример кода подсмотрен [здесь](https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydWHqqU0iBo1"
      },
      "source": [
        " \n",
        "##### 7 LogReg\n",
        "**7.1 Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xwGDD7jRUF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac27044-c692-4dff-d6f1-91fb0155b413"
      },
      "source": [
        "best_logreg_model = LogisticRegression(tol=0.0001, \n",
        "                                  solver='saga',\n",
        "                                  penalty='elasticnet',\n",
        "                                  fit_intercept=True,\n",
        "                                  C=0.008,\n",
        "                                  l1_ratio=0.45,\n",
        "                                  max_iter=500)\n",
        "\n",
        "\n",
        "\n",
        "lr_train_sizes, lr_train_scores, lr_test_scores = learning_curve(estimator = best_logreg_model, \n",
        "                                                                 X=X_train_scaled, y=y_train,\n",
        "                                                                 scoring='roc_auc',\n",
        "                                                                 train_sizes=[0.2, 0.3, 0.5, 0.7, 1.],\n",
        "                                                                 verbose=3)\n",
        "\n",
        "lr_train_scores_mean = np.mean(lr_train_scores, axis=1)\n",
        "lr_train_scores_std = np.std(lr_train_scores, axis=1)\n",
        "lr_test_scores_mean = np.mean(lr_test_scores, axis=1)\n",
        "lr_test_scores_std = np.std(lr_test_scores, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[learning_curve] Training set sizes: [ 3196  4794  7991 11188 15983]\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.696, test=0.717), total=   0.0s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.701, test=0.717), total=   0.1s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.701, test=0.718), total=   0.1s\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ , score=(train=0.703, test=0.718), total=   0.1s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.705, test=0.720), total=   0.2s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.726, test=0.692), total=   0.0s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.720, test=0.694), total=   0.1s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.712, test=0.694), total=   0.1s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.712, test=0.694), total=   0.1s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.712, test=0.695), total=   0.2s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.726, test=0.704), total=   0.0s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.712, test=0.705), total=   0.1s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.707, test=0.706), total=   0.1s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.708, test=0.705), total=   0.1s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.708, test=0.707), total=   0.2s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.726, test=0.717), total=   0.0s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.712, test=0.718), total=   0.1s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.706, test=0.719), total=   0.1s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.707, test=0.719), total=   0.1s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.705, test=0.720), total=   0.2s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.726, test=0.695), total=   0.0s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.712, test=0.694), total=   0.1s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.706, test=0.695), total=   0.1s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.707, test=0.695), total=   0.1s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.711, test=0.696), total=   0.2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    2.6s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "azNEbcAx52AZ",
        "outputId": "f9dcf7cb-d892-461c-ee15-fdeea629094d"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(lr_train_sizes, lr_train_scores_mean, 'bo-', label=\"train\")\n",
        "plt.plot(lr_train_sizes, lr_test_scores_mean, 'go-', label=\"test\")\n",
        "\n",
        "plt.fill_between(lr_train_sizes, \n",
        "                 lr_train_scores_mean - lr_train_scores_std,\n",
        "                 lr_train_scores_mean + lr_train_scores_std, \n",
        "                 alpha=0.1, color=\"blue\")\n",
        "plt.fill_between(lr_train_sizes, \n",
        "                 lr_test_scores_mean - lr_test_scores_std,\n",
        "                 lr_test_scores_mean + lr_test_scores_std, \n",
        "                 alpha=0.1, color=\"green\")\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('training examples'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('Learning curve for logistic regression')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAG5CAYAAAA3e7gZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZxbdb3/8dcnmSWZztLpylJKiyAioEXKjvzK3gVoL3oRxR0soKBsZZFFRCogyqKICooXpYKISoGWRZC6XEERLwoVZC8tpVDazp7Mknx/f3xP2sw0M5klmSQz7+fDPJqcc3LyyZnaefPdjjnnEBEREZHiFyp0ASIiIiLSPwpuIiIiIiVCwU1ERESkRCi4iYiIiJQIBTcRERGREqHgJiIiIlIiFNxEBDP7sJn9p9B1DCczO93M3jazFjMbn4PzvW5mR+TgPD80s0sH8b6pwXcJD7WGYmdmD5rZZwpdh0ghmNZxEyksM3sdOMU592ihaxktzKwcaAL2d879M0fnfJ1h/Dnq743I6KQWN5FRYCS0wuT4O0wGIsDKQdRhZjZi/+00s7Icn6/k/+6JFJMR+4+PSKkzs5CZXWhmr5jZBjO728zGpe3/lZmtM7NGM/ujme2etu9/zOwHZrbczFqBQ4OuvPPM7F/Be35pZpHg+Flmtibt/b0eG+w/38zeMrO1ZnaKmTkz27mX7zHOzH4aHLvJzO4Ntn/WzP7c49jN58nwHc4Lvm847fj/MrN/9ed6pb3nvUCqW7jBzH4fbD/QzJ4Kvu9TZnZg2ntWmNliM/tfoA3YKcvPrtLMbgi+89rgeWV/rl/wva8Mnk8wswfMrMHMNprZn4Lv+XNgKnB/0D16vplNC85T1td1z1DrZ83sf83sejPbAFwe1P9tM3vDfHfyD80sOoD6e/7d287Mfm1m683sNTP7ctq59jWzv5tZU/BZ1wXbI2Z2R/CzbAh+JpPTfh6npP3cLzGzVWb2jpn9zMzqgn2pa/KZ4Lu8a2YX9/WzEyl2Cm4ixetMYAHw/4DtgE3A99P2PwjsAkwC/gEs6fH+TwCLgRogFZBOAGYD04EPAJ/t4/MzHmtms4FzgCOAnYFZWb7Hz4EqYPeg1uuzHN/bd7gRaAUO67H/F8HzbNcLAOfci0EtAGOdc4cFAW8Z8F1gPHAdsMy6j337FLAwqGVVlrovBvYHZgAfBPYFLoEBX79zgTXARHwr4Vf9V3CfAt4AjnXOVTvnvpXhvQO57vsBrwafsRi4GnhvUP/OwPbAZQOoP/3n9hfgfuCfwXkOB84ys6ODY28EbnTO1QLvAe4Otn8GqAN2wP9MTgNiGT7rs8HjUHygrgZu6nHMwcCuwWdfZma79XEtRIqagptI8ToNuNg5t8Y51w5cDnw01aLinLvNOdectu+DqZaGwFLn3P8655LOuXiw7bvOubXOuY34X6Yz+vj83o49Afipc26lc64t+OyMzGxbYA5wmnNuk3Ou0zn3hwFcg57f4U7g48G5a4C5wTbIcr2ymAe85Jz7uXOuyzl3J/ACcGzaMf8TfOcu51xnlvOdBFzhnHvHObce+Do++MEArh/QCWwL7Bhcuz+5fgxMHsR1X+uc+55zrguI4wPq2c65jc65ZuCbwIkDqH/zzw3YE5jonLvCOdfhnHsVuDXtfJ3AzmY2wTnX4px7Mm37eGBn51zCOfe0c64pw2edBFznnHvVOdcCXASc2OPn/nXnXCwYz/hPfJgWKUkKbiLFa0fgt0E3UQPwPJAAJptZ2MyuDroFm4DXg/dMSHv/6gznXJf2vA3fOtGb3o7drse5M31Oyg7ARufcpj6O6UvPc/8COD7odjwe+IdzLtX61ev16sfnbMfWrWir8C1EvdUykPOtCral9vX3+l0LvAw8YmavmtmF/fz8gV739Bom4lvqnk67lg8F26F/9adv2xHYLnWu4HxfZcvP5WR8694LQXfoMcH2nwMPA3cFXbLfMj+ppKdM17qM7j/3gfy9FylqCm4ixWs1MMc5NzbtEXHOvYnvipqP766qA6YF77G09+dryvhbwJS01zv0cexqYJyZjc2wrxUfEAAws20yHNPtOzjn/o3/xTyH7t2kqc/q7XplsxYfMNJNBdLfO5Dr2fN8U4NtMIDrF7Sonuuc2wk4DjjHzA7vRz19XfeMH5X2/F18l+TuadexzjmXCjv9qT/9fKuB13r8XGqcc3OD7/iSc+7j+O7ca4B7zGxM0Er4defc+4EDgWOAT2f4rEzXugt4u5/fXaSkKLiJFIfyYDB26lEG/BBYbGY7ApjZRDObHxxfA7QDG/Dh55vDWOvdwOfMbDczqwJ6XXPMOfcWfizezWZWb2blZnZIsPufwO5mNsP8xIfL+/n5vwC+AhwC/Cpte1/XK5vlwHvN7BNmVmZmHwPeDzzQz/f3dCdwSVDDBPz4sDuCff2+fmZ2jJntbGYGNOJbEJPB7rfpZZJEluvep6B781bgejObFNSxfdqYtH7XH/gb0GxmF5hZNGgt3sPM9gnO/Ukzmxh8bkPwnqSZHWpme5qfjNKE7zpNZjj/ncDZZjbdzKrx/1/4ZdDtKzLiKLiJFIfl+FaO1ONy/KDt+/DdZM3Ak/hB5AA/w7c8vQn8O9g3LJxzD+IH8T+O78ZLfXZ7L2/5FP6X7gvAO8BZwXleBK4AHgVeYssEimzuxE9A+L1z7t207X1dr2zfaQO+RedcfBg+Hzimx/kH4krg78C/gGfxk0euDD5rINdvF/z1aQGeAG52zj0e7LsKHw4bzOy8DO/NeN376YJUbUFX/KP4wf0D/vk75xL4azsDeA3fovdjfEsx+AkwK82sBf8zPNE5FwO2Ae7Bh7bngT/gu097ui3Y/sfg/HH8RBWREUkL8IrIkAQz9J4DKtXKMXClfv1KvX6RUqMWNxEZMPPrp1WaWT1+XNL9+qXdf6V+/Uq9fpFSpuAmIoNxKr777RX8uKvTC1tOySn161fq9YuULHWVioiIiJQItbiJiIiIlIic3ky4WE2YMMFNmzat0GXkVWtrK2PGjCl0GSVJ125odP0GT9du8HTthkbXb/CG49o9/fTT7zrnJmbaNyqC27Rp0/j73/9e6DLyasWKFcyaNavQZZQkXbuh0fUbPF27wdO1Gxpdv8EbjmtnZr3eD1ldpSIiIiIlQsFNREREpEQouImIiIiUiFExxk1ERERKQ2dnJ2vWrCEejxe6lIzq6up4/vnnc3KuSCTClClTKC8v7/d7FNxERESkaKxZs4aamhqmTZuGmRW6nK00NzdTU1Mz5PM459iwYQNr1qxh+vTp/X6fukpFRESkaMTjccaPH1+UoS2XzIzx48cPuGVRwU1ERESKykgPbSmD+Z4KbiIiIiIlQsFNREREJE1DQwM333zzgN83d+5cGhoa8lDRFgpuIiIiUrKWLIFp0yAU8n8uWTL0c/YW3Lq6uvp83/Llyxk7duzQC+iDZpWKiIhISVqyBBYuhLY2/3rVKv8a4KSTBn/eCy+8kFdeeYUZM2ZQXl5OJBKhvr6eF154gaeffpoFCxawevVq4vE4X/nKV1gYfGjqFpstLS3MmTOHgw8+mL/85S9sv/32LF26lGg0OsRvrOAmIiIiReqss+CZZ3rf/+ST0N7efVtbG5x8Mtx6a+b3zJgBN9zQ9+deffXVPPfcczzzzDOsWLGCefPm8dxzzzF9+nSam5u57bbbGDduHLFYjH322YePfOQjjB8/vts5XnrpJe68805uvfVWTjjhBH7961/zyU9+sh/fum8KbiIiIlKSeoa2bNsHa9999+221tp3v/tdfvvb3wKwevVqXnrppa2C2/Tp05kxYwYAe++9N6+//npOalFwExERkaKUrWVs2jTfPdrTjjvCihW5q2PMmDGbn//pT3/i0Ucf5YknnqCqqopZs2ZlXIutsrJy8/NwOEwsFstJLZqcICIiIiVp8WKoquq+rarKbx+KmpoampubM+5ramqivr6eqqoqXnjhBZ588smhfdgAqcUtRzo6oLwcRsmagSIiIgWXmoBw8cXwxhswdaoPbUOZmAAwfvx4DjroIPbYYw+i0SiTJ0/evO+II47g9ttvZ7fddmPXXXdl//33H9qHDZCCW468+y7U1kJ1daErERERGT1OOmnoQS2TX/ziFxm3V1ZW8uCDD2bclxrHNmHCBJ577rnN288777yc1aWu0hxJJHx4c67QlYiIiMhIpeCWQy0tkKOxhyIiIiJbUXDLoUjEt7qJiIiI5IOCWw6Vl/sWN7W6iYiISD4ouOVYeTls2FDoKkRERGQkUnDLsUjEj3XL9arNIiIiIgpueVBeDhs3FroKERERGYyGhgZuvvnmQb33hhtuoC111/s8UHDLg2gUGhv9orwiIiKSP0ueXcK0G6YR+nqIaTdMY8mzS4Z8zmIOblqAN0/KyqChASZNKnQlIiIiI9OSZ5ew8P6FtHX6oLSqcRUL718IwEl7Dn5V3gsvvJBXXnmFGTNmcOSRRzJp0iTuvvtu2tvbmTt3LldffTWtra2ccMIJrFmzhkQiwaWXXsrbb7/N2rVrOfTQQ5kwYQKPP/54Tr5nOgW3PIlGfXCrr/ddpyIiIjIwZz10Fs+se6bX/U+ueZL2RPdB5W2dbZy89GRuffrWjO+Zsc0Mbpjd993rr776ap577jmeeeYZHnnkEe655x7+9re/4Zxj7ty5/PGPf2T9+vVst912LFu2DIDGxkbq6uq47rrrePzxx5kwYcIAv23/qKs0T8wgFPJdpiIiIpJ7PUNbtu2D8cgjj/DII4+w11578aEPfYgXX3yRl156iT333JPf/e53XHDBBfzpT3+irq4uZ5/ZF7W45VE06icpjB3ru05FRESk/7K1jE27YRqrGldttX3Huh1Z8dkVOanBOcdFF13EqaeeCkBzczM1NTUA/OMf/2D58uVccsklHH744Vx22WU5+cy+qMUtj8z8o6mp0JWIiIiMPIsPX0xVeVW3bVXlVSw+fPGQzltTU0NzczMARx99NLfddhstLS0ArF27lnfeeYe1a9dSVVXFJz/5SRYtWsQ//vGPrd6bD2oHyrNUq1tdHYTDha5GRERk5EhNQLj4sYt5o/ENptZNZfHhi4c0MQFg/PjxHHTQQeyxxx7MmTOHT3ziExxwwAEARKNR7rzzTl5++WUWLVpEKBSivLycH/zgBwAsXLiQ2bNns91222lyQikKhSCZ9IvyDlP3t4iIyKhx0p4nDTmoZfKLX/yi2+uvfOUrwJau0ve85z0cffTRW73vzDPP5Mwzz8x5PSnqKh0G0ai/+XwyWehKREREpJQpuA2DcBi6unyrm4iIiMhgKbgNk1Srm3OFrkRERKS4uVHyy3Iw3zOvwc3MZpvZf8zsZTO7MMP+683smeDxopk1BNt3NLN/BNtXmtlpae/Z28yeDc75XTOzfH6HXCkr87fAyuNdMEREREpeJBJhw4YNIz68OefYsGEDkUhkQO/L2+QEMwsD3weOBNYAT5nZfc65f6eOcc6dnXb8mcBewcu3gAOcc+1mVg08F7x3LfAD4AvAX4HlwGzgwXx9j1yKRmH9eqiq8suEiIiISHdTpkxhzZo1rF+/vtClZBSPxwcctnoTiUSYMmXKgN6Tz1ml+wIvO+deBTCzu4D5wL97Of7jwNcAnHPpt2evJGgZNLNtgVrn3JPB658BCyiR4FZeDs3NEIv58CYiIiLdlZeXM3369EKX0asVK1aw1157ZT8wT/IZ3LYHVqe9XgPsl+lAM9sRmA78Pm3bDsAyYGdgkXNurZnNDM6Tfs7teznnQmAhwOTJk1mxYsWgv0h/dHb68WvZWtKcg1WroKIit5/f0tKS9+84UunaDY2u3+Dp2g2ert3Q6PoNXqGvXbGs43YicI9zLpHa4JxbDXzAzLYD7jWzewZyQufcLcAtADNnznSzZs3KYblbW73aL/fRnxvKNzfD1Km+6zRXVqxYQb6/40ilazc0un6Dp2s3eLp2Q6PrN3iFvnb5nJzwJrBD2uspwbZMTgTuzLQjGNf2HPDh4P3pncF9nbNolZf7uymIiIiIDEQ+g9tTwC5mNt3MKvDh7L6eB5nZ+4B64Im0bVPMLBo8rwcOBv7jnHsLaDKz/YPZpJ8GlubxO+RFJOJb3drbC12JiIiIlJK8BTfnXBdwBvAw8Dxwt3NupZldYWbHpR16InCX6z7vdzfgr2b2T+APwLedc88G+74I/Bh4GXiFEpmY0JNa3URERGSg8jrGzTm3HL9kR/q2y3q8vjzD+34HfKCXc/4d2CN3VRZGNApNTTB+fO4nKoiIiMjIpDsnFFA4DA0Nha5CRERESoWCWwFFo7Bpk19KRERERCQbBbcCMvOtbo2Nha5ERERESoGCW4FFo36SQiKR/VgREREZ3RTcCix1p4WmpsLWISIiIsVPwa0IVFXBhg1qdRMREZG+KbgVgVDI3y6rpaXQlYiIiEgxU3ArEtEovPuuD3AiIiIimSi4FYlw2HeVqtVNREREeqPgVkQiEd/q1u3mXyIiIiIBBbciUlYGHR3Q1lboSkRERKQYKbgVmWgU1q9Xq5uIiIhsTcGtyJSXQ3s7xGKFrkRERESKjYJbEaqo8GPdRERERNIpuBWhykrf4haPF7oSERERKSYKbkWqvNzfTUFEREQkRcGtSEUi0Nzsx7uJiIiIgIJbUSsvh02bCl2FiIiIFAsFtyIWiUBjo1/bTURERETBrYiZ+VthNTQUuhIREREpBgpuRS4a9d2lXV2FrkREREQKTcGtyKnVTURERFIU3EpAJOJb3RKJQlciIiIihaTgVgJCIX/v0qamQlciIiIihaTgViKqqvyCvMlkoSsRERGRQlFwKxGhkA9tzc2FrkREREQKRcGthESj/ubzanUTEREZnRTcSkg47CcotLQUuhIREREpBAW3EhOJ+FY35wpdiYiIiAw3BbcSU1YGnZ3Q1lboSkRERGS4KbiVoMpKWL9erW4iIiKjjYJbCaqogPZ2iMUKXYmIiIgMJwW3ElVR4ce6iYiIyOih4FaiKiv9OLd4vNCViIiIyHBRcCthFRX+bgoiIiIyOii4lbBIxN9Job290JWIiIjIcMhrcDOz2Wb2HzN72cwuzLD/ejN7Jni8aGYNwfYZZvaEma00s3+Z2cfS3vM/ZvZa2vtm5PM7FLvycti0qdBViIiIyHAoy9eJzSwMfB84ElgDPGVm9znn/p06xjl3dtrxZwJ7BS/bgE87514ys+2Ap83sYedcQ7B/kXPunnzVXkoiEWhs1NIgIiIio0E+W9z2BV52zr3qnOsA7gLm93H8x4E7AZxzLzrnXgqerwXeASbmsdaSZbblVlgiIiIyspnLU1ONmX0UmO2cOyV4/SlgP+fcGRmO3RF4EpjinEv02LcvcDuwu3MuaWb/AxwAtAOPARc657Ya5WVmC4GFAJMnT977rrvuyuXX20pnp2/1Msvrx/QqFmuhtra6MB9e4lpaWqiu1rUbLF2/wdO1Gzxdu6HR9Ru84bh2hx566NPOuZmZ9uWtq3SATgTuyRDatgV+DnzGOZcMNl8ErAMqgFuAC4Arep7QOXdLsJ+ZM2e6WbNm5a14gNWrIZn0Y84K4dlnV7DHHrOYMKEwn1/KVqxYQb7/foxkun6Dp2s3eLp2Q6PrN3iFvnb57Cp9E9gh7fWUYFsmJxJ0k6aYWS2wDLjYOfdkartz7i3ntQM/xXfJjnqhkJ+koC5TERGRkSufwe0pYBczm25mFfhwdl/Pg8zsfUA98ETatgrgt8DPek5CCFrhMDMDFgDP5e0blBjnoKmp0FWIiIhIvuQtuDnnuoAzgIeB54G7nXMrzewKMzsu7dATgbtc98F2JwCHAJ/NsOzHEjN7FngWmABcma/vUGqqqvyCvMlk9mNFRESk9OR1jJtzbjmwvMe2y3q8vjzD++4A7ujlnIflsMQRJRTyoa25GerqCl2NiIiI5JrunDDCRKP+5vNqdRMRERl5FNxGmHAYurqgtbXQlYiIiEiuKbiNQNEorF+vuymIiIiMNApuI1BZmV8QuK2t0JWIiIhILim4jVCVlWp1ExERGWkU3Eaoigpob4dYrNCViIiISK4ouI1gFRV+XTcREREZGRTcRrDKSj+7NB4vdCUiIiKSCwpuI5xa3UREREYOBbcRLhKBlhY/3k1ERERKm4LbKFBWBps2FboKERERGSoFt1EgEoHGRr+2m4iIiJQuBbdRwMzfCkutbiIiIqVNwW2UiEZ9cOvqKnQlIiIiMlgKbqOEGYRCvstURERESpOC2ygSjcLGjZBIFLoSERERGQwFt1EkFPL3Lm1qKnQlIiIiMhgKbqNMVZVfkDeZLHQlIiIiMlAKbqNMKORDW3NzoSsRERGRgVJwG4WiUbW6iYiIlCIFt1EoHPaL8ba2FroSERERGQgFt1EqGoX16/1kBRERESkNCm6jVFmZb3Vrayt0JSIiItJfCm6jWGWlWt1ERERKiYLbKFZRAe3tEI8XuhIRERHpDwW3Ua6iAt59t9BViIiISH8ouI1ylZV+dqla3URERIqfgptQUeHvYSoiIiLFTcFNiET8nRTa2wtdiYiIiPRFwU0AvzzIpk2FrkJERET6ouAmgG91a2z0a7uJiIhIcVJwEwDM/K2wGhoKXYmIiIj0RsFNNotGfXdpV1ehKxEREZFMFNxkMzP/aGwsdCUiIiKSiYKbdBON+qVBEolCVyIiIiI9KbgN0ZIlMG0a7LgjHHQQ/OY3ha5oaEIhf+/SpqZCVyIiIiI9lRW6gFK2ZAksXAhtbf71m2/C+ef758cfX7i6hioahQ0boK7OBzkREREpDnn9tWxms83sP2b2spldmGH/9Wb2TPB40cwagu0zzOwJM1tpZv8ys4+lvWe6mf01OOcvzawin9+hLxdfvCW0pcRicPXVhaknV8JhSCahpaXQlYiIiEi6vAU3MwsD3wfmAO8HPm5m708/xjl3tnNuhnNuBvA9INXR2AZ82jm3OzAbuMHMxgb7rgGud87tDGwCTs7Xd8jmjTcyb1+7dnjryIdo1N983rlCVyIiIiIp+Wxx2xd42Tn3qnOuA7gLmN/H8R8H7gRwzr3onHspeL4WeAeYaGYGHAbcE7zndmBBnurPaurUzNu3225468iHcNgvxqtWNxERkeKRzzFu2wOr016vAfbLdKCZ7QhMB36fYd++QAXwCjAeaHDOpVYaWxN8TqZzLgQWAkyePJkVK1YM6kv05ZOfnMS3v70r7e3htK2OI454jZUre2mOy5N4vIWVK1fk9JzOwapV/ib0I1lLS0te/n6MFrp+g6drN3i6dkOj6zd4hb52xTI54UTgHudct0UozGxb4OfAZ5xzSd/g1j/OuVuAWwBmzpzpZs2albtqA7NmwW67+bFub7wBkydDPG488shOnH32TkycmPOP7NXKlSvYffdZOT9vczNMmQJjxuT81EVjxYoV5OPvx2ih6zd4unaDp2s3NLp+g1foa5fPrtI3gR3SXk8JtmVyIkE3aYqZ1QLLgIudc08GmzcAY80sFTj7OuewOOkkeP113zL15JNw113+7gMLF0JHRyEry43KSli/vtBViIiICOQ3uD0F7BLMAq3Ah7P7eh5kZu8D6oEn0rZVAL8FfuacS41nwznngMeBjwabPgMszds3GIQ994TrroO//Q0uvbTQ1QxdRQXE4362rIiIiBRW3oJbMA7tDOBh4HngbufcSjO7wsyOSzv0ROCuIJSlnAAcAnw2bbmQGcG+C4BzzOxl/Ji3n+TrOwzW/Plwxhlwxx3ws58Vupqhq6z0M0xFRESksPI6xs05txxY3mPbZT1eX57hfXcAd/RyzlfxM1aL2vnnw/PP+1a3XXaBAw4odEWDV1npx7rF4xCJFLoaERGR0Uvr4udJOAw33eRvhbVwIaxZU+iKhqaszN/DVERERApHwS2Pamvhttugqws+//mt77JQSqJR3+rW3l7oSkREREYvBbc823ln+P734d//hnPOKe07EZSVQUNDoasQEREZvRTchsFhh8FXvwr33++7T0tVJOKDW2dnoSsREREZnRTchsnpp8N//Rdccw088kihqxkcMz92T61uIiIihaHgNkzM4NprYY894Mwz4aWXCl3R4ESjfoHhrq7sx4qIiEhuKbgNo2gUfvIT3+X4uc+VZsuVmX80NRW6EhERkeGVdMlCl1A09yodNbbfHm69FU44Ab70Jb9Abzic/X3FJBqFDRugrq70ahcREUm6ZLeHc27z865kV7dH0iVJJBN0JbtwuIKHNwW3Ath3X1i82C/Se9VVcMklha5oYEIhPzu2qQnq6wtdjYiIjFa9ha+eASz1OhXAUhx+qQcz27wtZCEM83+a/7OirIKIRWhpbxn279iTgluBnHQSrFwJP/gB7LYbfOQjha5oYNJb3ULqcBcRkSHIRQBLD1+wJYClwld6ACtlCm4F9PWvw4svwqJFfr23D36w0BX1XzgMySS0tPiFhkVERBTA8k/BrYDKy+FHP4K5c/2dFR58ECZNKnRV/ReJ+JvP19T4CQsiIjIyDCWAZep+BAWwXFFwK7Dx4/1M0wUL4AtfgLvv9jd1LwVlZRCL+Va3mppCVyMiIj31FcA2xTYpgJUgBbcisMcecP31cNppcPHFfr23UmnBSrW6VVeXTs0iIqUm1y1gnclONsQ2KICVIAW3InHssf5+pt/9Luy+u1/nrRSUl/ubz6vVTUQku2LpggxZiKryqvx9UckbBbcismgRPP88fO1r8N73wkEHFbqi/olGYe1aGDMGJk4sna5eEZHB6k8ASyQTJFwiYwDrGb5AXZDSPwpuRSQUgu99z7e+nXoqLF8OU6cWuqrsysp8a1s8Dq+9BmPH+rF75eWFrkxEpG+9ha/0ANYzjCmASSEpuBWZmhq47TY45hg/03TpUt+SVQoiEf9obYXGRh/exo71wU5EJJ+yBbD01i8FMCll+pVahHbaCW6+GT71KTjrLLjlltIa+B+N+jsrNDTAxo2++1QL9YpIf/Q3gHUmO1nVsEoBTEYdBbciNWuWn2H6jW/ADTfA2WcXuqKBMYOqKr9I7/r1/i4LkyZpzTeR0aK38JWtBay3AfhAt9sQOedDWkVZBZVUZpN7DwEAACAASURBVDxeZCRScCtip57qZ5p++9vw/vfD0UcXuqKBC4X8UiGJBKxb55cOmTzZhzr9OyvSf865Lc9xg9qei3Okb89FAEtvARtIADMzykL6FSajj/7WFzEzuOYaeOUVOPNMuP9+2HXXQlc1OOGwD3CdnbBmjR8LN2mS71aV0W2woSEXwaO3Y5MuOajnzrktIQm3+Zy9va8j0cFrm17b+vNJO1/admxLrRa8SO8eTN9Oev5JO0Wm7YM9Ry4CmIgMTJ/BzcyqgHOBqc65L5jZLsCuzrkHhqU6IRqFH/94y22xHngA6usLXdXglZf7R3s7vPGGD3MTJmgJkWKS3r3l6N7V5ZzbaqZdZ6KT1Y2rew0vqV/4qTACkExued5tXFKWgJG+PZ/hxR+S9ryX7dn2Z9rec1uq1ag/5xARydbi9lPgaeCA4PWbwK8ABbdhtO22cOut8N//DV/8Ivz856U/U7Oy0j/icXj9dT95QUuI5E7P8UXpASyRTGRc6mDzIO8MwQi2BJueA71T504FDDPrV+hRIAEMwqFwoasQkRKS7df/e5xzHzOzjwM459pM/9oWxMyZcNVVcO65cOWVcPnlha4oNyIRH+BaWqCpCcaN0xIiKb3NrnO4zSGr5/pSqddbza7r0dqUCl/p3VyD7eIyM8rDStwiIsMh26/HDjOLEvyzb2bvAdrzXpVkdOKJfrLCrbf6yQonnFDoinIjNQPVOdi0yT8mTCj9JURSXYYDXeAz1SoGGZY3CAKYmW1u2UqNLQqFQpRZmZY4EBEZwbIFt68BDwE7mNkS4CDgs/kuSnp36aXwwgtw4YWw887woQ8VuqLcMfOLDaeWEEmtAVfIJURSYau3ALbVjDqX2Lyt13FcfsPmli5gc/gqC5V12y4iIpKu1+BmZiGgHjge2B8/8uUrzrl3h6k2yaC8HH74Q5g3D045xd8Wa5ttCl1VbqUvIfLWW0NfQqS3sV6p7QmX4N3Wd7sFsNT2pEt262bMNIA91d2Yel4WKqPCKjSGS0REcq7X4OacS5rZ+c65u4Flw1iTZDFunL8t1nHH+fB2zz2Frig/wmHf2tbZCW+84aiMJJkwMUllZOsAlgpcPQfbJ0l2m+2YaRZiV7KLxvbGbksalJnCl4iIFJ9sXaWPmtl5wC+B1tRG59zGvFYlWe22G9x4I3zhC3DRRXDyyYWuKLvNrVxsGeNFEMBSISuR1uWYDLodu5y/nU1nE/xnPYwZ46gfZ1SmxsNb77e0SW3rS8hCRMu1oJyIiBS/bMHtY8GfX0rb5oCd8lOODMTcuXDOOXDddTB+/PbssUf+PzNT+HI9ZzqyJXAlg7FeXS5YZmLz4PrUgqPm/+e6D7b3gStEebiCitRMx3Kgyi8hsultqKv1M1C1hIiIiIwWfQY359z04SpEBufss/1M0x/9aGcOOQQOOaR/7+s5u9Gv8h7MdHRdJFID7V3CP09r+UqxIIg5P9I+CF8hjKAFzEKECBMOl1GZw5mOkYifgdrSAo1NMK7ez0ANazksEREZ4bLdOaEcOB1IxYEVwI+cc515rkv6wS83keTb1yeZN7ud004bw2/uj7PD1MRWXY++9auLrmCtr/TWL/Bjv1Ivu3U7Etq65asImPm7SjgHDQ3+MW4c1NaW9hIiIiIifcnWVfoDfAfVzcHrTwXbTslnUaNNb92P6Wt9JUgtstqFI7klgOED3MWXvc25Zx/EKZ8P8YM71zCmiu5djxYiRBmV4fIRtdREag24ZBI2bPABbvx4Pyu1SDKmiIhIzmQLbvs45z6Y9vr3ZvbPfBZUynzISu9+3LLkRKr70Y8BS3brfnRsme24pfuRtLFfIUJB6xdmhCgjEu4+43H77d/gmhs3ceYp47n6oilce9OmUdXyFAr5NeASSXj7nS1rwEWjCnAiIjJyZAtuCTN7j3PuFQAz2wlI5L+s0vNO2zqa2ps236rJCAbfB6lhOLof9zuog7MubOI7i+u49aYuTv1yc07OW0rCIageA11dsHatD27jxvk/RURESl224LYIeNzMXsVnkR2Bz/X35GY2G7gRCAM/ds5d3WP/9cChwcsqYJJzbmyw7yH8wr9/ds4dk/ae/wH+H9AYbPqsc+6Z/taUL13JTirDlUQKPMXx459u5cXny7nlphp22bWTw46OF7SeQikr892lHR3w5pu+NW7cOH9fVBERkVKVbVbpY2a2C7BrsOk/zrl+3avUzMLA94EjgTXAU2Z2n3Pu32nnPzvt+DOBvdJOcS0+zJ2a4fSLnHMjdNnZoTGDi77ewGuvlHHZBWPZYdq77LJrV/Y3jlAVFf4Rj8PqNVpCRERESlufo6DM7EtA1Dn3L+fcv4AqM/tiP8+9L/Cyc+5V51wHcBcwv4/jPw7cmXrhnHsMGH19fTlQWQnfvmkjY6od554+joZNGuQVicCYKr+EyKo3/Bi4hDr9RUSkxJhfBLWXnWbPOOdm9Nj2f865vXp7T9pxHwVmO+dOCV5/CtjPOXdGhmN3BJ4EpjjnEmnbZwHnZegqPQBoBx4DLszUCmhmC4GFAJMnT977rrvuylbykLTGO6HnjcSHUVd7nLLK7mulvfBCLRcumsn7d2/giiv/j7Ky3n/Wo03q/u9lZdAZjxMZk7t15kabeKuu32Dp2g2ert3Q6PoNTjKZpCPWQU1NTV4/59BDD33aOTcz075sY9zCZmYuSHdB92dFrgsETgTuSQ9tfbgIWBfUcQtwAXBFz4Occ7cE+5k5c6abNWtWzorN5K/PryaRTBKpKEwf3LpXV7LNTrt327bNTnBJexNfu2A8d969P4suaSpIbcUqmYRYDJreWsnU9+2uJUQGaeVTK9l9n92zHyhb0bUbPF27odH1G5yW9hbWPLuGfGeKvmRbMOIh4JdmdriZHY7vynyon+d+E9gh7fWUYFsmJ5LWTdoX59xbzmsHforvkpVeHPNfMU76bAt3/ayapfdoamW61BIiZn4JkdWroa3NL+orIiJSjLIFtwuA3+PvnnA6vmvy/H6e+ylgFzObbmYV+HB2X8+DzOx9QD3wRH9OambbBn8asAB4rp/1jFpfPr+J/Q5s56qvjeVf/6dR+Vsxv4RIKOSXEFm71rfEiYiIFJs+g5tzLumc+6Fz7qP48WJP9LM7E+dcF3AG8DDwPHC3c26lmV1hZselHXoicJfrMdjOzP4E/Ao43MzWmNnRwa4lZvYs8CwwAbiyP/WMZmVlcNUNG5m0TYLzzhjHO+tG0cq8A5BaQiSR8EuIvPUWtPdrDrWIiMjwyHav0hXAccFxTwPvmNlf0pfx6ItzbjmwvMe2y3q8vryX9364l+2H9eezpbu6sY7rf7iRz54wgfO+NI5blrxLRONSM+q2hMhqfwN7LSEiIiLFIFvTS51zrgk4HviZc24/4PD8lyX58J5duvjGtQ2sfLaCxZeM1ViuLCIRPwZOS4iIiEixyBbcyoIxZScADwxDPZJns46Ic9pXmlh+XxVLfjqm0OUUPTN/u6wxVf4G9qtW+T9Ty4mIiIgMp2zB7Qr8GLWXnXNPBfcqfSn/ZUk+nXx6C4cfHePGb9XyxJ91D6j+MIOqKt8Kt2EDvPEGNDdrBqqIiAyvbJMTfuWc+4Bz7ovB61edcx8ZntIkX0IhuPzqBnbapYuLzqpn9apwoUsqGaklRMrLtYSIiIgMP00vHKWqxjiuu3kjoZDj7NPG0dKilWcHIhzeegmReLzQVYmIyEin4DaKbb9Dgmu+u4k3Xi/j0vPqNW5rENKXEFmzBtatg46OQlclIiIjlYLbKLfP/h2c+9VG/vj7CD/8bn7vvTaSVVT4ABeP+/Fv774LnZ2FrkpEREaaPoObmX3TzMamva43My14O8Kc8Mk25n+0lZ/cXMPvHtTibkORWkKkuVlLiIiISO5la3Gb45xrSL1wzm0C5ua3JBluZnDh5Y18YK8OLr9wLC8+3+e6zJJFpiVEGhu1hIiIiAxdtuAWNrPN60WYWRTQ+hEjUEUFXHvTRmprHed8cRybNqoXfajSlxB5913fhdrSohmoIiIyeNl+Oy8BHjOzk83sZOB3wO35L0sKYcLEJN+5eSMb3w1zwZfrNUYrR9KXEFn3tl9CRDexFxGRwci2jts1wGJgt+DxDefct4ajMCmM9+/ZySVXNvD03yq57pt1hS5nRElfQuTNtf5G9lpCREREBiLrYCbn3IPAg8NQixSJufNjvPhCOT//STW7vK+T4z/WVuiSRpSyMqgu88uGrHnTh7lx43x3tYiISF+yzSptNrOm4BE3s4SZNQ1XcVI4Z57XxP4Hx7nmijqeeVqJIh8qKnxoS19CpKur0FWJiEgxy9ZVWuOcq3XO1QJR4CPAzcNSmRRUOAxXXb+J7bZPsOiMeta9pckK+dJtCZFVsGmTlhAREZHM+v3b2Hn3AkfnsR4pIrV1/rZY7XHj3C+OIxbTbbHyJbWESDTqg9uqVdDUpCVERESku2xdpcenPT5qZlcDGk49ikzfuYsrv7OJ//y7nCsvqdNSFnkWCvklRCojsH69lhAREZHusk1OODbteRfwOjA/b9VIUTrksHa+eFYz37++ll136+TTp7QWuqQRLxwsIZJI+CVEKitgwgTfIiciIqNXn8HNOfe54SpEitvnTmvhPy+U891ra9n5vV0ceEh7oUsaFVJLiHR2+uVDolUwfpwfFyciIqNPn8HNzCLAycDuwOZfFc65z+e5LikyZnD5VQ2sfn0CF51dz+2/Ws+0nTSCfriUl/tHagmRmmqor9cSIiIio022yQk/B7bBT0j4AzAFaM53UVKcolWO79y8kbIyxzmnj6O5WZMVhltqCZFYDN5YrSVERERGm2zBbWfn3KVAq3PudmAesF/+y5Jite32Cb71vU2sWV3GJefWa9mKAolE/E3sm5q0hIiIyGiSLbil7lbZYGZ7AHXApPyWJMVu7307WHRJI39eEeG8L9Uzb9YkZu66LfNmTeLB+zR6frikbmIfjcLGjX4GqpYQEREZ2bLNKr3FzOqBS4D7gGrg0rxXJUXvox9v49GHIvzx91uC2rq1ZVx5ib+/6ZzjdBf14ZK6iX0iCe+s961v48f7babebBGRESXbnRN+7Jzb5Jz7o3NuJ+fcJOfcj1L7zewz+S9RipEZrFm1de6Px0PcdF1NASqScMiPfysrg3XrYM0aPxZORERGjqHex+grOalCStLb68IZt69bG6alRU09hRIOQ3W1f/7mm/DmWn8/VBERKX1DDW767TyKTd62t9HwxlEHTuar54zlL3+s1KzHAikv9wGuq9O3vr39tl9OREREStdQg5tuxDOKnXFOM5FI95HwkUiShWc2cdzxMZ78c4QzTxnP3EMmc91Vtbz4fLYhlZIPlZU+wGkJERGR0jfU36RqcRvFUhMQbrquhrffCjN52wRnnNO8efs5X/UzT5cvjfLLO8aw5KfV7LxrJ/PmtzHn2BgTJ2v643CKRPw9T5ubobERxo2D2lrftSoiIqVhqMHtf3NShZSsOcfFep1BWlEBhx0V57Cj4jRsMn73YJRl91Zx47fq+N63a9n3wHbmzY9x6JFxolVqvB0OZn75kGTSLyHS0OBnoFZX+9mpIiJS3LLd8uqbwLeccw3B63rgXOfcJQDOuTPyX6KMBGPrHf/9iTb++xNtrHotzPL7qli+NMqli+qJViU57Kg4xyxoY+/9OtQCNAy0hIiIjAbObXkkk91f93wkk1sezvkhJckkJB24YHtrh39eSNla3OY4576aeuGc22Rmc/HruokMyo7TE5z+lWZOPbOZfz5dwQP3Rje3xk3eJsHsY9s45r9i7LSzBmLlW2oJkUTCLyFSWQkTJvhWORGR4dBXkHJu62OSSR+qeoatTI/NnxH8mem/S12w3WzLg+B1KLRlW7gMOtuG3lU5VNk+P2xmlc65dgAziwKV+S9LRoNQCPbap4O99ulg0aWN/PH3EZbdW8Udt1Vz+601vG/3DuYtiDH7mBjjxms8XD6llhDp7PRLiESrYPw4Py5ORASyt17Blu09W69SYSu99Sr9uF4/k63DVnrA6vkIhfy/Z+kBLJeKoUciW3BbAjxmZj8NXn8OuD2/JcloFInAUXPjHDU3zsYNIR56IMrypVG+s7iOG66u5YAPtzNvQRuHHBZXmMij8nL/aG/3S4jU1EB9vR+vKCKlobcuwVRASj1vadkSnBKJHq1VDpKJzK1XkDlQpe8LZWi9Sm/BCpd1b+WS/uszuDnnrjGzfwJHBJu+4Zx7OP9lyWg2bnyST3ymlU98ppVXXipj2b1RHryvij+vGMeY6iRHzolxzIIYH9y7QwPq86Sy0j9iMWhugbF1MHasvyuDiAxdb92C6a1XmboC07d1JQbeegU+MHV2+rUds7VehcJbQpgUh/78M/x/QDn+Z/5/+S1HpLv37NLFlxc186Vzmnn6rxU8cG8VDy+Lcu+vxrDdlC7mzo8xb34bU6f1thiwDIWWEJHRrj+D2jMNbu/WghV0D6Zv2+pz6Ht9rVRLFWToGhxE61VzMEFJSk+2WaUnANcCK/B/L75nZoucc/f05+RmNhu4EQgDP3bOXd1j//XAocHLKmCSc25ssO8hYH/gz865Y9LeMx24CxgPPA18yjmn9eBHuHAY9j2wg30P7OCiy43Hfxdh2dIot/2gmh9/v4Y9Z3Qwd34bR82NMbZeS4vkkpYQkWLX18D2noPb00NVb2GrZ+tVb6Gq5/a+Wq/MoKzcH6//38hQZGtxuxjYxzn3DoCZTQQeBbIGNzMLA98HjgTWAE+Z2X3OuX+njnHOnZ12/JnAXmmnuBYf5k7tceprgOudc3eZ2Q+Bk4EfZKtHRo5olWPu/Bhz58dY/3aIBx+I8sBvq7jm62P5zjfr+PCsOHPnxzh4Vlxjs3KotyVEUtPm0/X1X/352Celob/LMmTqItzcWhW0XnV0wOuv++0ZP4veW7By3XolMpyyBbdQKrQFNtD/22TtC7zsnHsVwMzuAuYD/+7l+I8DX0u9cM49Zmaz0g8wMwMOAz4RbLoduBwFt1Fr4uQknz65lU99vpUXny9j2dIqHro/yuO/i1I3NsmRc2Mcs6CNPT7YqX+Ec6TbEiLB/U9XrdqyP9ug5Xz9GPpqxehrX7aw2Nt+M3r9MqEsXzJVT1cwzijTvoHUsrmeLJ830H39CS+JhH/0FrYyjb3qTwtWz6UZ0pdlSD0qKhSwZPTJFtweMrOHgTuD1x8Dlvfz3NsDq9NerwH2y3Sgme0ITAd+n+Wc44EG51zqv+/XBJ8jo5wZ7Pr+LnZ9fxNfXtTE3/5SyQP3Rrn/11Xc84sxTJ3Wxdz5bcw9Lsb2O2g8XC6Ewz7AtRTBWJlUd9hA90GWGy5nO28v+7v6WU/S+Rm8mfb19b6BGNK16eu9bGmZSoW/nsEq361X6nKU0ajX4Ba0bn0X2Ac4ONh8i3Put3mo40TgHudczn6jmtlCYCHA5MmTWbFiRa5OnVFrvBNwWIH+06+rPc66V1cW5LOL0U5T4MtnwCmfC/O//zuZxx7dlh/eOI4f3ljLHntu4rDD3uLgQ95mzJguXbsh0vUbvERHnI1rdO0GQ3/vhkbXb3C6Ekks0ZH3TNEXc338J5WZPeuc23NQJzY7ALjcOXd08PoiAOfcVRmO/T/gS865v/TYPgs4LzU5IQiT64FtnHNdPT+jNzNnznR///vfB/M1+u2vz68mkUwSqSjP6+f0Zt2rK9lmp90L8tml4q03wzx4X5QH7o2y6rVyKisdhxwW58D9X2DORydTXpgfXcnT373B07UbPF27odH1G5z1jS2EG9dwxOGH5fVzzOxp59zMTPuyNTT/w8z2GeTnPgXsYmbTzawC36p2X4bi3gfUA09kO6HzKfNx4KPBps8ASwdZn4wy226f4POnt/Drh9bzs3vWs+C/W/nbExV8/Wt7MefDk/n24lqeX1k+6C4pERGRfMs2xm0/4CQzWwW04ocrOOfcB7KdOGgROwN4GL8cyG3OuZVmdgXwd+dcKsSdCNzlejT9mdmfgPcB1Wa2Bjg5WPz3AuAuM7sSv67cT/r7ZUXAj7XZ/QOd7P6BTs6+sIllv3qHvzy5K/f8Ygx33l7NTjt3Mm9BjDnHtTF5G91qS0REike24NZnF2Q2zrnl9JjM4Jy7rMfry3t574d72f4qfsaqyJCVV8D+B6xnwUmTaGq04Gb3Ub737Vpu+k4N++zfwbwFbRx2VJyqMWqKExGRwsp2y6tVfe0XGUlq6xwfObGNj5zYxupVYZYvrWLZ0ihfu6Ceqy5PctiRceYuiLHvAe26c4CIiBSE7jwoksEOOyY49cvNLDyzmX/+o4Jl90b53YNRlt9XxcRJCWYfG2PegjZ22bUr+8lERERyRMFNpA9mMGPvDmbs3cF5lzTyp8cjLF8a5Re3j+HnP6lm1906mTu/jdnHxpgwUePhREQkvxTcRPqpshKOmB3niNlxNm0M8fADUZYvjXL91XXc+K1aDji4nbkLYvy/w+NEoxoPJyIiuafgJjII9eOSnPjpVk78dCuvvVLG8qVRli2NcvE59YwZk+Tw2XHmLWjjQ/t0aHV3ERHJGQU3kSGa/p4uvnROM6ef1cw/nqpg2b1VPPpQhPt+XcU223Ux97gYc+fHmP4ejYcTEZGhUXATyZFQCGbu18HM/To4/zLjD49FWPbbKP9zSzW3/bCG3ff0S4scNS9O/TiNhxMRkYFTJ45IHkSjjtnHxPjeTzay/I9vc/aFjXR2Gt/6xliOPngy55xez2MPR+joKHSlIiKSzYP3RZk3axJz9t2Fkz5xAEuWFK4WtbiJ5NnESUk++flWPvn5Vl56oYxlS6t48P4of3gsSk1tkqPm+qVFPrBXJ2aFrlZERNI9eF+UKy+pIx73bV3vvBNl4UK/76SThr8eBTeRYbTL+7o4631NnHleE397opJl9/pJDb++awxTpnYxb34bc+bH2GFqotClioiMeIkExGJGrNX8n21GLBairc2It/lt315cuzm0pbS1wcUXK7iJjBrhMBxwcDsHHNxOa4vx+0ciLF9axS031fCj79XywQ+1M29BjCPnxKit09IiIjJ6JZPQHjfa2lLByojHjLZWH7I2B6629PBlxNpC3belnqft6+gYfDfHG2/k8EsOgIKbSIGNqXYce3yMY4+Pse6tEA/eV8Wye6N887KxXPuNOg45PM68+W0c+OF2yisKXa2IyNacg44OaGsNEY9tCUttqaAV/NkWBKbUMW2tW4JYrC3U7fjNz2MDG45fXu6IVjmiUUckmqRqjH9ePy7JtlWOqmBftCq5+bhuf1Y5otGkfz3GsfCk8bzz9tZxaerUXF29gVFwEyki22yb5HOntvDZhS28sLKcB+6N8vADUR57KMrY+gRHz4sxb0GM9++p8XAiMnCdnRCPGe+uryRO2LdY9WytCroLs7VWbX4dhK9ksv//KIVC6SHJh6lINEl1TZKJk4LXqTAVdVSNSRKJbglXqfAVqXJUVSU3b49EHeXlub1mX17U3G2MG0BVFSxenNvP6S8Ftxzq6gLUIiI5YAa77dHJbnt0ctYFTTzx50qW31vFb+8ewy/vqGbaTp3Mmx9jzvwY226n8XAiI0ki4cNVW6plqi1oqQqep/Z17zYMbQ5S6a1V/vgtLVldnalwtW2/aolEkz1Ckn8+tj5BJAhcW1q3Uq+TPVqverRkVTkqKiiZ//icc1yMZzp/xW/eXUyyejWh5il8ZuerOKkQA9xQcMuZceNgw0ZobfWvKyrIeeqX0am8HA45tJ1DDm2nucn8ze6XRvn+9bV8//pa9t6vnWMWtHHY0XGqqzUeTmQ4OAfxeIbWqNQg9wwtWVuCWCjoNtzShZjqNozHQrS3DyzRVFT06PYLuvgmTEwPUMlurVUdrW8yeeq2QWtXcnNrlW/d8n9WRpzu/AI8+NpveKDrfJI1MQCStau5fdNCDnoWTtpz+MObgluORCKw7bZgDmIxaGryIc7M3+MyHC50hTIS1NQ6jv9YG8d/rI03V4dZfl+UZfdW8fWL6rn660lmHRHnmAUx9j2wnTL9v1tGOed812BqEPuWcVb9b61KhayeXYbxmOFc/wNWuGxLl2A06BaMRh11Y5Nss53r0XqV7Na61b21K7ml9arKEYm4Qf1/fd2rb7LNTmMH/sYRKumStHY209LZTEtHE82dTbR0NNHS2cy1T19KPBHrdnxbZxsXP3axgttIUFYGNTX+0dnpQ1xjI8TjfmX9ikoI679gJAe23yHBF77UwilfbOG5f5bzwL1VPLIsysMPVDF+QoLZx8Y4ZkEb791Nt9qS3Hnwvig3XVfD22+FmbxtgjPOaWbOcbHsb+xDatxV95ar7oGpZ2vVhnXvw8rGbtValR7M4jEjkeh/uDJzGQerV41JMn5Cpm6/IEiNSWvpqkqN1/KtXKnwpYlF+eOcI56IbRW4mjuaaOlMPW/0oayX522dLTgG1mPxRmNhppUquOVRebl/1NYGs23aghDXpRAnuWMGe87oZM8ZjZz71Ub+vCLCsnuj/PKOMSz5aTU779rJvAVtzDkmxsTJutWWDN6ypVEWX1pHezBIe93aMr7+1bGsfLac9+/ZmWGQe+bWqm772ozOzoF1DVZGklRWVlBdE9o8tipa5agbm/CtVRkHsG9preo5NivVlVhZWTrjrkaSjkR795auziZaOpr7FcJagmMSru+xvmELU11eQ3VFnf+zvIbtq6dSU15LdXkt1RU1/nlFLdXlNdRUBNvLazjtsY/xTuytrc45ta4w00oV3IZJRYV/1NX5ENfa6rtTYwkoC/t9GksgQ1VRAYcdFeewo+I0bDIeWe67Um+8po7vXVvLvge2M29+jEOPjBOt0ni40aazA1paQjQ3GS3N/s/m5lD356l9zWnHNRvNTSFaWwywHuc07ry9eqvPSl+SIX381bhxSaI7pLdQJTO3YPKV8AAAIABJREFUZAVBq+fswkjUEQ7DuldXss1Ouw/TlZPeJJIJWrvSgtVWgStzS1dL2vP2RDzr54wJwlZ1eS01FbVMjE5meu0uQcCqobqito8QVkckHMUGmcq/POOrXPm387t1l1aVV7H48MJMK1VwG2apMW+VlVBfD+3tPsQ1NkLS+RCn/+qTXBhb7zjhpDZOOKmNVa+FWba0iuVLo1y6qJ5oVZLDjopzzII29t6vQ2MwS0BqMHzL5rDlw1S3gBX8mb6vpdk2H9Me7/u/Ds0c1TWOmtok1dX+z+2mdG3edtfPxvTyRsdvHnonr0sySO4552jras0cuDobaenoGbi27G/pbKK5o4m2rtasn1MZjlCT1tJVW1HHdmOmbA5h6YEsFcJSgau6vIaqsmrCocL9IzVn+vEA3PTPq3m7bS0TKydy3bzrCjK+DRTcCsrMT2qIRPys1HgcWlp8S5wDyssoqSnTUrx2nJ7gi2c1c9qXm3nm6Qoe+G2URx/yrXGTt0kw+9g2jvmvGDvtrPFw+ZJMQmur0dK0pXVr9UsTKftntFsQa2lOhTDf0pXeGpbo6vsfg7JyR01NkppaR3W1/3PSNonNz2tqk9TUJDcHsZoaR3VNkupgX1VV37MIVzwaYd3arX9tbLNtgh2na1ma4daeiAeBKy1kbX7eFLSCZQ5cTfEG2v7aStL1PXyiLFS+VbCaGpmYIXD5lq7uYayO6vJqysOlP8BvzvTjmTP9eNY3thBuXMMRex5WsFoU3IqEGUSj/jF+vA9xqZmp4MfKVZT+330psFAIPrRPBx/ap4PzL2vkj49FWLa0ijtuq+b2W2vYbY8O5s6PMfuYGOPGazxcus5OurdmNVnQ7Zj+3AezlpbUMVuet7ZkmoU4odurSNSHqZpaH7TGjUsydVpXtyDmW8PSnzuqa5PU1OZ/jNYZ52y9EGkkkuSMc5rz96EjVFeyK23MVno345YQ1pLW0tUthAXv6Ux29PkZhqUFKt+CNblqO95TtyuhWILJE3YM9mcOYTXltVSGI4PuYpT8UHArQqGQX5W5qipYiDHuu1JbWv3oEq0RJ7kQicBR8+IcNS/OhndDPPyAv+H9dxbXccPVtRzw4fb/396dR8lZ1/kef3+rqvduskIgCUtggguDC4TFg3duUInx4hFmxnGijIKOctRBPS444eKgos7AqMerZzg6yMVlRKKiA9wBhLhE0WEJKBCCCyEIJBiBhECS7k53VX3vH8/vqXqquqr36qqn83mdU/SzVj/14+nuT37bw5ln9/MXrxqks7PZVzs1yWbGZJ+tcjNiebleH6+xHrsTNzP29pXDV7KZsbcvrg0rL+/fs4WjXrisdF6r/1zHo0ene1Rp2hS9SH9+X53AVd5WHbiSywP5/jG/T1euu6Kv1ryOBRzed9SITvblZsjK/l3duR4yVvu+VR/B9FJwa3HZLPT0RK98vjxHXBziOjrQfF0yZQsWFnnLeft4y3n7eOThHDdd38UtN3bziw3z6ektcsbrBnj92QO89MQhMpnKKSEWHjyPD3x0sKF/vJPNjMk+W7WaFPdWd7YPx+fHGLmYzTkHVQQs5+BDClEQO6gykMXb4mbH3oOK9PRMfLLSHVv3cOiR6WpifN0bBlId1KKpIwYT4eo59tQNXLVGND7PvuE9Y04d0Z7pKNd0tc2ht72Pg7sWJQJXrf5d5eDV09ZHLqNf7jKS7ooUqTdH3N590R+2QkET/crUHbM8z/sv3MM/fGgP99zZzk03dHPrTV1c/70eFi/Nc+yLhrnj5x3s3x+llKef6uLTH+sAqPsHPdnMOCJUJTvR1+jjVb+ZsVLczBiHqnnzixx+ZD7qv1XRr6syiPWGsNbZ6epPmgLDxWH2Du3hycHtPLurUFHrNVbgipfzxeFRv0fGMhUjFHvbDmJx7xEVIay6pisZwnrb++jIpryaWlqWgltKVc8R99unQ43cIGQMOjo1R5xMTTYLp5w2xCmnDbH248ZP13dy0w1dbFjfSfWUEIODGf75kjncvqEj9PEK4ez58Tcz9vRWjmY8bEme5aX+WyPDV7IJMg3NjLPFLY/+oDS6blH3Yi546drSqLuxJGenL41ULE2aGoJXYrnWdBLjmjoi1xuaF6MQtaDzYI7sO2bENBH1ar26ct3q1yUtS8FtFmhvj/7IHnlkNL1If3+YIy4fhbeODs0RJ1PT3eOcefYAZ549wIoXHIbXaCXq7zce2tReqslaeEzUzFg9gjHueB93sJ9sM6NMH3cn73kKxTwFL1DwPIVioXJbMc9Pt/2QrzzwOYaK+wHY0b+dT971Ye7e8QuOnHNMnclSy8v7hscexNCR7azsq9V2EIf2LKms6WqbQ2H38yxZ8qIRwavZU0eINJqC2ywTzxE3d25liMtrol+ZJosOK7BjwXfg1RfDnMfhuSPgx5/h0J1/y/Xrn2r25U3aaOElX8yH9XKIyYevBY+25RP74vPzFceXz4/fb/czT9Ldv6Dy/BHHJd4rnJdPfp/42KrrK29LXku+6tqjfWNNCTGa4eIQNz76HQCylquYcb6v/SCO6FtWEcKi5drNjb1tfeOeOmLH1s0culSd6+XAo+A2SyXniJs3LxqZGj+tQRP9ymQVigVOveAKrt93EbSF/mxzH4Oz/p4XdP2au3ecXCO8DJMP4aEiVCRCT62gUt42XCOoTCy8lENPoSHhZUqeiL5kLEPWcuQyObKWI5vJkrMcWcuSrbst+pqzHJ3ZTrK5yn25TNX5dbe1kctkS+uV55e3fey/L6j5EQzj9jc9TKemjhBpOAW3A0Byjrj586OauD17osl+i66JfmerfDHPQL6f/vxe+of7Gcjvoz+8Bob7w/Je+of3hePCvnw//cNhX76fgeHyeaX+RdX9yXL7+dnw5/nZT6Z2zXF4KQeScjAZT3jpyHSQzfVUnJ/LtI0zvFSHlraa4WX0bdkQvtpGvc5sCEnPPPZ7Fh99PFnL1p22oZX8233/wo7+7SO2L+peTFeuqwlXJHLgUXA7wGQy5RC3cGHlRL8OtGui36aIQlYISMPJgLWP/jhUDYcgNZ59+f5xdeKOtWc66GrrpjvXQ3eul+5cN91tPczvPJjuXDdduR562nrpyvXw75s+V+ddjK++5rpSeEkGr2xVAEuGl2SwSUN4mU57Mh20ZdIzquKCl64d8czGzmwXF7x0bROvSuTAouB2AKs30W/8tAZN9FvbcHE4Ckihpmrf8N5yTVV+X2lffyKIRYGqf+S+UPsVd/Yej45sJ125ELLa4pDVy8KuRVHIausJAayH7rYeuuLlin29dIeg1pnrnlB4uOGRa2vWuhzavZgTDjl13O8j6VP9zMaJjioVkalTcBNg7Il+OzvTOUfccGEoBKQoNO0b3lsKUXGg+tOftpLbd2vlvlKNVjmcxfvGesxMUke2syJEded66Gnr4+DuQ8vhK7EvDlnl2q/KfV257qZPyqlalwNb/MxGEWkOBTcZod5Ev7XmiJvKnE5J7s5wcaiqj1XcByvZPyvZ56rGvqoarbEm2kzqzHaVaqh6cj10tfWEZ/sdlghUYV8pUHWXa7QSNV1dbT10Zbtn5bQE1bUuC9sP5gMn/pP+mIuIzAAFNxlV9US//f1RiBvMw61PXMfn7v/HUl+qeE6nXz99N8vnvSjRAX5fqO3al+if1V/RlNif30fB8+O+rri2qis0AXa39TKnfS6Hdi+uqKHqSTQVlpsXK8PZnm2Pc+QxJ8zKkNUoyVqXHVs3c+gyTcsgIjITFNykZDA/yM6Bnezq38XOgZ3s7N8ZfR3YybMDz1as7+zfxXP7d494j+HiEN/f8h8V2yoDVtS/am7HfA7rXVpzX3VTYTKcRX2yuqa1E3sh+4xCm4jIAcY9vAA8enRkaZtXHRPW88PQ7L8WCm6zlLuzd2hvRQDbNbCLnf3hawhgpZA2sJP+4f6a75W1LPO75rOgawHzu+dz3MHHsaBrAV+//+t1vrvxn6/9ddSfq6OT9vaMHr8lIiITNplwVfe9qHxYXyYTvcyir9ls9Krenlzvy8POhxvzWcerocHNzFYDXyQKqFe5+2VV+78AnB5Wu4FD3H1u2Hcu8LGw79Pu/o2wfQNwGBD3jF7l7umdrn2cil5k9+Ducq1XVW3Y1m1byT+WL4WxXYO7GCrU7kTfme1kfncUxBZ0LeDo+UdHoSyEswXdC0ohbUHXAuZ0zKk5qeb6revZvmfk6MIlfYs5/uiDS/3jBgejx29B9EOTzUbNr2kc7CAiIpVaLVzFTwcyG/mKj5nsvKW+H3ZN7tRp07DgZmZZ4ArgDGAbsNHMbnT3h+Jj3P2DiePfB7w8LM8HPg6sIPr/eG8499lw+Dnufk+jrn0irtl0DRf/+GIef+5xFvctZu0r1/JXLxq7k/ZQYahc89U/dm3Y7sHddWd272vvoy/Tx6G5Q1nSt4SXHPKSKIR1jwxjC7oX0JXrmpbZzde+ci0fXf9RBvLl0YVduS7WvnJtaa64gw6KthcK0UCH4eEQ5AaiwQ6xXDYaFJFTHbCIyLSrDlfuUb/lWuGq6JXhacR70drharZr5J/Jk4Et7r4VwMzWAWcBD9U5/s1EYQ3gtcB6d98Vzl0PrAaubeD1Ttg1m67h/P93fqmJcfue7Xzkto+w+anNvGDhC9g1sKsUyKrD2J6h2g9bNox5XfNKtWHLFyznlK5TSuulMBaC2LzOeXTkOti8cTPHnTSzHcTjgHrZLy7jyT1Pjhpc4x/kzs5otCpE/yobHo6mH4nDXDwRMEQjV+Mwpx9gEZntJlJzNVq4in+HjhauzKLHHipcpY/5WPWWk31jszcCq939nWH9rcAp7j7iYXdmdiRwJ7DU3Qtm9hGg090/Hfb/EzDg7p8LTaULgALwfaJm1BEfwszOB84HWLRo0Ynr1q2b9s+45s41/Gn/n0Y9Jmc55rTNqfma2za3vJ6Lvva19ZG1ibchDu4bpLOnc7IfpaWUflEVo19OxaqKxun+ZZHfP0iuY3aUXTOo/CZPZTd5LVF2Xg5J8XqNxXGz0n/Ky7W2VS9XLFZvq/O7cjb9zZhJxWKRoYEh+uIaiAY5/fTT73X3FbX2tUrD1BrgOncvjOPYc9x9u5n1EQW3twLfrD7I3a8ErgRYsWKFr1y5chovN/LUz2p3rTOM299+Owu6F9DX3jcjD11uRo3bTHGPauXy+eg5q3G/uUIIdEaomWtjUoMgdmzdzKFHz86ymwkqv8lT2U3eaGU3kzVXcdNg2mquZvPfjEbau38v2zZtoxGZYrwaGdy2A4cn1peGbbWsAf6h6tyVVeduAHD37eHrHjP7NlGT7IjgNhOOmHMEjz332Ijti/sWs2zesiZc0exkVp5PrqsL5s6Ntufz5X5zGgQhki5TDVfFYmXXCvW5kgNFI4PbRmC5mS0jCmJrgLdUH2RmLwTmAXckNt8K/LOZzQvrq4CLzCwHzHX3Z8ysDXg98KMGfoZRfebVn6no4wblzvnSeHH/t1qDIOLHdmkQhMj0KhajV6FQGbSmWnM10XA18AwcfrjClRx4Gvbny93zZnYBUQjLAle7+2YzuxS4x91vDIeuAdYl+6m5+y4z+xRR+AO4NGzrAW4NoS1LFNq+2qjPMJZzjj8HYFKjSqUx4l/+AL290dexBkF42K9BECJRCCsUolexGHVJiH8snOgfP23t0N1RGbRmuubKMtDePvX3EUmbhtY7uPvNwM1V2y6pWv9EnXOvBq6u2rYPOHF6r3Jqzjn+HM45/hyeeO4Jil6kLdvW7EuSKplMNHqqowN6eqJt7uUwt+UpyGSjQFcMaS5j5Zq5+A+RyGzgXq4xi8MZlKd4yGSiLgbd3eUuCvE/iOKgJiLNowYjOSCZRf9ab2+HbA6WLG78IAiRmRA3Wxby5WbNZDNmHMw6Oso/A3FTpf6hItL6FNxEAg2CkLQoFKFYKNeaQbnGzEJtcRzK2tsra8x0n4qkm4KbyBimMggim1W/OZm46qbM6o7/cTBLNmcmO/jrnhOZvRTcRCZhvIMg+vv1JAgZKW7CdA/3SDz9BZVN8l1dUUCLmzD1jwERUXATmSZjDYIYHIxq5TQIYvaLBwDkE/3Mks93zGTKfcvmz6/sZ6YBACIyGgU3kQZKDoLo7o62aRBE+iVHZsZfS/uI/r+1tUXP5u3oKDdlxjVmcTDb/WS5L6WIyHgouInMMA2CSIdaAwBi8f/DOJRpAICIzBQFN5EWoUEQMys5AKC6xixuwm5ri5q942CWrDUTEWkGBTeRFqZBEJMX9y2L+5nFz8WMiyQOZvHIzDiQaWSmiLQyBTeRlNEgiMh4H83U0xOVlUZmishsoOAmMgvMxkEQejSTiMhICm4is1QaBkEUiuVHMxUKlU2ZcRiNBwB0dOjRTCIiCm4iB5iZHARRb2Rm9QCA+LmZGpkpIjI6BTcRmdIgCPdofzwAIEmPZhIRmV4KbiJS03gHQZhFYU+PZhIRaTwFNxEZt1qDIHZvh4ULm3tdIiIHCnXvFREREUkJBTcRERGRlFBwExEREUkJBTcRERGRlFBwExEREUkJBTcRERGRlFBwExEREUkJBTcRERGRlFBwExEREUkJBTcRERGRlFBwExEREUkJBTcRERGRlFBwExEREUkJBTcRERGRlFBwExEREUkJBTcRERGRlFBwExEREUkJBTcRERGRlFBwExEREUkJBTcRERGRlGhocDOz1Wb2OzPbYmZra+z/gpndF16/N7PdiX3nmtnD4XVuYvuJZrYpvOeXzMwa+RlEREREWkWuUW9sZlngCuAMYBuw0cxudPeH4mPc/YOJ498HvDwszwc+DqwAHLg3nPss8GXgXcBdwM3AauCWRn0OERERkVbRyBq3k4Et7r7V3YeAdcBZoxz/ZuDasPxaYL277wphbT2w2swOAw5y9zvd3YFvAmc37iOIiIiItI6G1bgBS4AnEuvbgFNqHWhmRwLLgJ+Mcu6S8NpWY3ut9zwfOB9g0aJFbNiwYcIfYCKGC8M4TrNabgf3DbJ54+amfO+0U9lNjcpv8lR2k6eymxqV3+QUi0WGBoYanilG08jgNhFrgOvcvTBdb+juVwJXAqxYscJXrlw5XW9d0xPPPUHRi7Rl2xr6ferZvHEzx510XFO+d9qp7KZG5Td5KrvJU9lNjcpvcvbu38u2TdtodKYYTSObSrcDhyfWl4Zttayh3Ew62rnbw/J43lNERERkVmlkcNsILDezZWbWThTObqw+yMxeCMwD7khsvhVYZWbzzGwesAq41d3/CDxvZqeG0aRvA25o4GcQERERaRkNayp197yZXUAUwrLA1e6+2cwuBe5x9zjErQHWhcEG8bm7zOxTROEP4FJ33xWW3wt8HegiGk2qEaUiIiJyQGhoHzd3v5loyo7ktkuq1j9R59yrgatrbL8H+PPpu0oRERGRdNCTE0RERERSQsFNREREJCUU3ERERERSQsFNREREJCUU3ERERERSQsFNREREJCUU3ERERERSQsFNREREJCUU3ERERERSQsFNREREJCUU3ERERERSQsFNREREJCUU3ERERERSQsFNREREJCUU3ERERERSQsFNREREJCUU3ERERERSQsFNREREJCUU3ERERERSQsFNREREJCUU3ERERERSQsFNREREJCUU3ERERERSQsFNREREJCVyzb4AERERkWZxdxwvfS16ccS2+OtQcajZl6vgJiIiIumRDFajhSwcsHBSWHZ3DIu2OzhONpMlQwYzI2MZ2jJtZCxDxjJkLRvtD+tmxjP2TPM+PApuIiIi0iDuIVzVqNECSuulkOXhxESwMrOK/blMrhSyspYll82VglXGMuQyuVLIMqxiOT4vXo6/pomCm4iIiNStxSp6MdqfWK8IU9HOmsErk8mQIVNRa1VdixUHsXrBqjp4HegU3ERERFJmIv2yajUPFr3I3v17K5oP45CVsaqglcmStWxFrdZotVjJZZl+Cm4iIiINVqsWK14u7a/TL6tW8+Fo/bKSzYVxwKquxXoy+yRHzz+6ImxJOii4iYiIJEymX1Z1X6zqWq5kDVbGMrRn25vaL8swchlFgDTS/zUREUmterVYY/XLqg5WwKj9sqprseJ96pclM03BTUREZsRE+mWNNbqwWIz6aMUhy8wqglV10BqrX1YybIm0MgU3EZFZLtnEV2/beNdL59eYL2u0Wqxos5G17KT7ZSWD15O5Jzl24bHTX1giLU7BTUQkmGyYqRWISuv1jvVQazS0t7Qe7zezUggq1TQljqnovD6edaLmP4BMeNJh/J5xp/SxvpZqquIgZVYaaThb58sSaUUKbiIyYRUhxKFQLIwIL+Op3SntHyUYTVd4qWhqS64njhkr3CQDSnI9ecxEgtC27DaW9C0plUP8/eL3nOp6cpuIzA4KbiIpkgxEyT5BUNV0Re0QVKvv0HiauGrtj/sWOU6+mK+oUZloiKlXuxMvR5cz/WGm+piZlrEMPe09TfneIpJODQ1uZrYa+CKQBa5y98tqHPMm4BNEfw7ud/e3hO2XA2eGwz7l7t8J278O/E/gubDvPHe/r4EfQ2RcISm5v9Yx9ULQWNMIJGuOMplMRXNVdTNV/ALqridDS3VASoavsfbHHs8+zrJ5y6avsEVEpK6GBTczywJXAGcA24CNZnajuz+UOGY5cBFwmrs/a2aHhO1nAicALwM6gA1mdou7Px9OvdDdr2vUtUtrqBWMksvjqV0aKyRV9DMaZeLL5Mg1qB+KRlsfb0iq3la9LCIiB65G1ridDGxx960AZrYOOAt4KHHMu4Ar3P1ZAHd/Kmx/MfBzd88DeTN7AFgNfLeB1ysTUPQiRS9SKBZGzAA+3tm/x6p9SvY3Ss7sPVpIqt4GlSGpVnDantvOsrnLxlW7JCIi0kxW3Ul42t7Y7I3Aand/Z1h/K3CKu1+QOOZ64PfAaUTNqZ9w9x+a2Srg40S1dd3A3UQB7/OhqfQVwH7gx8Bad99f4/ufD5wPsGjRohPXrVvXkM8ZGy4MV3Z2nmGD+wbp7Omc8vvUGiU3orM3jBpwkn2JKrbVKZpax8+kvXv30tvb29RrSDOV3+Sp7CZPZTc1Kr/Jm4myO/300+919xW19jV7cEIOWA6sBJYCPzez4939NjM7Cfhv4GngDqAQzrkI2AG0A1cC/whcWv3G7n5l2M+KFSt85cqVDf0gTzz3BEUv0pZta+j3qWfzxs0cd9JxI7bHM4YXvFCa7LLghdK+5Ii9eF6lXCZHLpOjPdtOLpMrzRCefMjwbKqJ2rBhA42+P2Yzld/kqewmT2U3NSq/yWt22TUyuG0HDk+sLw3bkrYBd7n7MPComf2eKMhtdPfPAJ8BMLNvE9XM4e5/DOfuN7OvAR9p3EdoXclmyvi1Z/+eEdMbxLOJ5zI5unJdpUBW/diWeFJMERERaV2NDG4bgeVmtowosK0B3lJ1zPXAm4GvmdlC4FhgaxjYMNfdd5rZS4CXALcBmNlh7v5Hi1LG2cCDDfwMM6q631jyocZxa2JcS5bL5GjLttGebS/Vki05aEmpViz5jD0RERGZHRoW3Nw9b2YXALcS9V+72t03m9mlwD3ufmPYt8rMHiJqCr0whLVO4PZQA/Q88HdhoALANWZ2MFGUuQ94d6M+w3SImyaTNWNxIKueWDRnUbNke7a91EzZlm0b0UyZzWRHfJ+sZeltV38FERGR2ayhfdzc/Wbg5qptlySWHfhQeCWPGSQaWVrrPV81/Vc6PQbyAwzmB8ud7Y1S6IqDWPy1uplytvUbExERkenX7MEJs8bC7oXM9/nqNyYiIiINo+A2Tbraupp9CSIiIjLLqee6iIiISEoouImIiIikhIKbiIiISEoouImIiIikhIKbiIiISEoouImIiIikhIKbiIiISEoouImIiIikhIKbiIiISEoouImIiIikhIKbiIiISEoouImIiIikhIKbiIiISEoouImIiIikhIKbiIiISEqYuzf7GhrOzJ4GHmv2dTTYQuCZZl9ESqnspkblN3kqu8lT2U2Nym/yZqLsjnT3g2vtOCCC24HAzO5x9xXNvo40UtlNjcpv8lR2k6eymxqV3+Q1u+zUVCoiIiKSEgpuIiIiIimh4DZ7XNnsC0gxld3UqPwmT2U3eSq7qVH5TV5Ty0593ERERERSQjVuIiIiIimh4CYiIiKSEgpuLc7Msmb2azP7r7C+zMzuMrMtZvYdM2sP2zvC+paw/6jEe1wUtv/OzF7bnE8y88xsrpldZ2a/NbPfmNkrzGy+ma03s4fD13nhWDOzL4VyesDMTki8z7nh+IfN7NzmfaKZY2YfNLPNZvagmV1rZp269+ozs6vN7CkzezCxbdruNTM70cw2hXO+ZGY2s5+wceqU3WfDz+0DZvafZjY3sa/mPWVmq8O2LWa2NrG95n07G9Qqu8S+D5uZm9nCsK77rkq98jOz94X7b7OZ/Wtie2vce+6uVwu/gA8B3wb+K6x/F1gTlr8CvCcsvxf4SlheA3wnLL8YuB/oAJYBjwDZZn+uGSq7bwDvDMvtwFzgX4G1Ydta4PKw/L+AWwADTgXuCtvnA1vD13lheV6zP1uDy20J8CjQlbjnztO9N2qZ/QVwAvBgYtu03WvA3eFYC+e+rtmfucFltwrIheXLE2VX854Kr0eAo8PP+v3AixP374j7dja8apVd2H44cCvRxPMLdd9N6N47HfgR0BHWD2m1e081bi3MzJYCZwJXhXUDXgVcFw75BnB2WD4rrBP2vzocfxawzt33u/ujwBbg5Jn5BM1jZnOIfij/L4C7D7n7birLqbr8vumRO4G5ZnYY8FpgvbvvcvdngfXA6hn8KM2SA7rMLAd0A39E915d7v5zYFfV5mm518K+g9z9To/+Anwz8V6pV6vs3P02d8+H1TuBpWG53j11MrDF3be6+xCwDjhrjN+ZqVfnvgP4AvBRIDkTKTSrAAAG/klEQVT6UPddlTrl9x7gMnffH455KmxvmXtPwa21/R+iH75iWF8A7E78QttGVDtC+PoEQNj/XDi+tL3GObPZMuBp4GsWNTVfZWY9wCJ3/2M4ZgewKCzXK6cDrvzcfTvwOeBxosD2HHAvuvcmarrutSVhuXr7geIdRLU9MPGyG+135qxkZmcB2939/qpduu/G51jgf4Qmzp+Z2Ulhe8vcewpuLcrMXg885e73NvtaUipHVAX+ZXd/ObCPqLmqJPwrUvPhVAl9sc4iCr+LgR4OjFrGhtG9NjlmdjGQB65p9rWkgZl1A/8buKTZ15JiOaJm41OBC4HvtlrfPgW31nUa8AYz+wNR1eurgC8SVW/nwjFLge1heTtRvwbC/jnAzuT2GufMZtuAbe5+V1i/jijI/Sk0ARC+xtXg9crpQCy/1wCPuvvT7j4M/IDoftS9NzHTda9tp9xUmNw+q5nZecDrgXNC8IWJl91O6t+3s9ExRP/guj/87VgK/MrMDkX33XhtA34QmpTvJmrxWkgL3XsKbi3K3S9y96XufhRRh++fuPs5wE+BN4bDzgVuCMs3hnXC/p+EX3Y3AmssGvm3DFhO1OF0VnP3HcATZvaCsOnVwENUllN1+b0tjLw6FXguNHPdCqwys3mhJmpV2DabPQ6cambd4V+acdnp3puYabnXwr7nzezU8P/jbYn3mpXMbDVRN5E3uHt/Yle9e2ojsDyM4msn+p15Y7gP6923s467b3L3Q9z9qPC3YxtwQvh9qPtufK4nGqCAmR1LNODgGVrp3puOEQ56NXzky0rKo0qPDjfLFuB7lEe+dIb1LWH/0YnzLyYa9fI7ZtmooDHK7WXAPcAD4YdxHlG/gx8DDxONHJofjjXgilBOm4AVifd5RyjXLcDbm/25ZqjsPgn8FngQ+A+ikVS69+qX17VE/QGHif5Y/v103mvAivD/4hHg3whPvZkNrzplt4Wo39B94fWVse4polGTvw/7Lk5sr3nfzoZXrbKr2v8HyqNKdd+N795rB74VPvevgFe12r2nR16JiIiIpISaSkVERERSQsFNREREJCUU3ERERERSQsFNREREJCUU3ERERERSQsFNRFqCmc01s/dO8tybzWzuGMdcamavmdzVtSYz29vsaxCRmaXpQESkJZjZUUTzFf55jX05Lz/zTwIz2+vuvc2+DhGZOapxE5FWcRlwjJndZ2afNbOVZna7md1I9OQGzOx6M7vXzDab2fnxiWb2BzNbaGZHmdlvzOyr4ZjbzKwrHPN1M3tj4vhPmtmvzGyTmb0wbD/YzNaHc68ys8fMbGH1hZrZKjO7I5z/PTPrNbMjzezhcB2ZcO2rxrjuveGzbjazH5nZyWa2wcy2mtkbwjHnmdkNYfvDZvbxWoVnZhea2UYze8DMPhm29ZjZTWZ2v5k9aGZ/Oz3/q0SkWRTcRKRVrAUecfeXufuFYdsJwAfc/diw/g53P5FoRvf3m9mCGu+zHLjC3Y8DdgN/Xef7PePuJwBfBj4Stn2c6JFdxxE93/aI6pNCkPsY8Jpw/j3Ah9z9MeDy8H4fBh5y99vGuO6exPfbA3waOAP4S+DSxLc9OXyOlwB/Y2Yrqq5pVfjcJxM9MeREM/sLYDXwpLu/NNRk/rBOWYhISuTGPkREpGnudvdHE+vvN7O/DMuHE4WVnVXnPOru94Xle4Gj6rz3DxLH/FVYfiVRaMLdf2hmz9Y471TgxcAvo0c40g7cEc65ysz+Bng3UYAa67qHKIepTcB+dx82s01V173e3XcCmNkPwnXek9i/Krx+HdZ7w/e4Hfi8mV1O1Ax9e52yEJGUUHATkVa2L14ws5XAa4BXuHu/mW0gek5qtf2J5QLQVee99yeOmcjvQiMKUm8escOsG1gaVnuBPWNc97CXOxoX42ty96KZJa+pujNy9boB/+Lu/17jmk4gepbip83sx+5+afUxIpIeaioVkVaxB+gbZf8c4NkQfl5IVPM13X4JvAlKzY/zahxzJ3Camf1ZOK7HzOKm3MuBa4BLgK9O43WfYWbzQ3+9s8N1Jt0KvMPMesM1LTGzQ8xsMdDv7t8CPkvU9CwiKaYaNxFpCe6+08x+aWYPArcAN1Ud8kPg3Wb2G+B3RAFqun0SuNbM3krU/LmDKFAmr/NpMzsvHNcRNn/MzA4DTgJOc/eCmf21mb0d+PY0XPfdwPeJavO+5e7JZlLc/TYzexFwR2i+3Qv8HfBnwGfNrAgMA++ZxPcWkRai6UBERIIQxArunjezVwBfdveXjXVeg6/pPGCFu1/QzOsQkdagGjcRkbIjgO+aWYZo4MC7mnw9IiIVVOMmIiIikhIanCAiIiKSEgpuIiIiIimh4CYiIiKSEgpuIiIiIimh4CYiIiKSEv8fCdmq6IJW4X4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGinV5P1njhF"
      },
      "source": [
        " \n",
        "##### 7 SVC\n",
        "**7.2 C-Support Vector Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhzYK_hFnjhe",
        "outputId": "f1949b61-37cc-451a-92ca-824ebc6cf42e"
      },
      "source": [
        "best_svc_model = SVC(C=0.001, \n",
        "                     kernel='rbf',\n",
        "                     gamma='scale',\n",
        "                     tol=0.001,\n",
        "                     random_state=1234)\n",
        "\n",
        "\n",
        "\n",
        "svc_train_sizes, svc_train_scores, svc_test_scores = learning_curve(estimator = best_svc_model, \n",
        "                                                                    X=X_train, y=y_train,\n",
        "                                                                    scoring='roc_auc',\n",
        "                                                                    train_sizes=[0.2, 0.3, 0.5, 0.7, 1.],\n",
        "                                                                    verbose=3)\n",
        "\n",
        "svc_train_scores_mean = np.mean(svc_train_scores, axis=1)\n",
        "svc_train_scores_std = np.std(svc_train_scores, axis=1)\n",
        "svc_test_scores_mean = np.mean(svc_test_scores, axis=1)\n",
        "svc_test_scores_std = np.std(svc_test_scores, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[learning_curve] Training set sizes: [ 3196  4794  7991 11188 15983]\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ , score=(train=0.688, test=0.711), total=   1.4s\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ , score=(train=0.692, test=0.712), total=   2.8s\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ , score=(train=0.694, test=0.712), total=   6.6s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.696, test=0.713), total=  12.0s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.697, test=0.713), total=  22.4s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.721, test=0.687), total=   1.4s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.714, test=0.688), total=   2.7s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.707, test=0.688), total=   6.5s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.705, test=0.688), total=  11.9s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.703, test=0.688), total=  22.3s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.721, test=0.698), total=   1.4s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.708, test=0.699), total=   2.7s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.701, test=0.700), total=   6.5s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.701, test=0.700), total=  12.0s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.700, test=0.700), total=  22.4s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.721, test=0.710), total=   1.4s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.708, test=0.710), total=   2.7s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.701, test=0.710), total=   6.6s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.701, test=0.710), total=  11.9s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.697, test=0.710), total=  22.3s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.721, test=0.688), total=   1.4s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.708, test=0.689), total=   2.7s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.701, test=0.689), total=   6.6s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.701, test=0.689), total=  11.9s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.703, test=0.689), total=  22.4s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  5.8min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8RrJgENnjhh",
        "outputId": "c0f23076-0bff-4cf2-9361-2728389bb4ca"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(svc_train_sizes, svc_train_scores_mean, 'bo-', label=\"train\")\n",
        "plt.plot(svc_train_sizes, svc_test_scores_mean, 'go-', label=\"test\")\n",
        "\n",
        "plt.fill_between(svc_train_sizes, \n",
        "                 svc_train_scores_mean - svc_train_scores_std,\n",
        "                 svc_train_scores_mean + svc_train_scores_std, \n",
        "                 alpha=0.1, color=\"blue\")\n",
        "plt.fill_between(svc_train_sizes, \n",
        "                 svc_test_scores_mean - svc_test_scores_std,\n",
        "                 svc_test_scores_mean + svc_test_scores_std, \n",
        "                 alpha=0.1, color=\"green\")\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('training examples'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('Learning curve for SVC')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxn-Lp2zrAxl"
      },
      "source": [
        "##### 7 MLPC\n",
        "**7.3 Multi-layer Perceptron classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhJZ7LYrrAx9",
        "outputId": "04500b3a-526d-49a4-b81c-f330e60d53d2"
      },
      "source": [
        "best_mlpc_model = MLPClassifier(activation='logistic',\n",
        "                                alpha=0.1,\n",
        "                                hidden_layer_sizes=(100,),\n",
        "                                solver='adam',\n",
        "                                learning_rate='constant',\n",
        "                                learning_rate_init=0.001,\n",
        "                                tol=0.0001,\n",
        "                                max_iter=1000)\n",
        "\n",
        "\n",
        "\n",
        "mlpc_train_sizes, mlpc_train_scores, mlpc_test_scores = learning_curve(estimator = best_mlpc_model, \n",
        "                                                                       X=X_train_scaled, y=y_train,\n",
        "                                                                       scoring='roc_auc',\n",
        "                                                                       train_sizes=[0.2, 0.3, 0.5, 0.7, 1.],\n",
        "                                                                       verbose=3)\n",
        "\n",
        "mlpc_train_scores_mean = np.mean(mlpc_train_scores, axis=1)\n",
        "mlpc_train_scores_std = np.std(mlpc_train_scores, axis=1)\n",
        "mlpc_test_scores_mean = np.mean(mlpc_test_scores, axis=1)\n",
        "mlpc_test_scores_std = np.std(mlpc_test_scores, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[learning_curve] Training set sizes: [ 3196  4794  7991 11188 15983]\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ , score=(train=0.698, test=0.715), total=   1.3s\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ , score=(train=0.703, test=0.717), total=   2.0s\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ , score=(train=0.703, test=0.720), total=   3.2s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.705, test=0.720), total=   3.7s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.707, test=0.720), total=   5.0s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.731, test=0.690), total=   1.2s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.724, test=0.694), total=   2.6s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.715, test=0.693), total=   3.0s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.714, test=0.694), total=   4.9s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.713, test=0.694), total=   4.4s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.731, test=0.701), total=   1.6s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.716, test=0.704), total=   2.2s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.709, test=0.704), total=   2.6s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.710, test=0.705), total=   3.2s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.709, test=0.707), total=   4.3s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.731, test=0.718), total=   1.4s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.716, test=0.720), total=   2.2s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.709, test=0.721), total=   3.7s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.709, test=0.722), total=   3.2s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.706, test=0.721), total=   6.1s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.731, test=0.692), total=   2.3s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.716, test=0.691), total=   2.1s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.709, test=0.693), total=   3.4s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.709, test=0.695), total=   3.7s\n",
            "[CV]  ................................................................\n",
            "[CV] ................ , score=(train=0.712, test=0.696), total=   4.5s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  1.3min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ4dU-5qrAx_",
        "outputId": "d188a2dd-d4a9-4083-b684-1438026731d5"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(mlpc_train_sizes, mlpc_train_scores_mean, 'bo-', label=\"train\")\n",
        "plt.plot(mlpc_train_sizes, mlpc_test_scores_mean, 'go-', label=\"test\")\n",
        "\n",
        "plt.fill_between(mlpc_train_sizes, \n",
        "                 mlpc_train_scores_mean - mlpc_train_scores_std,\n",
        "                 mlpc_train_scores_mean + mlpc_train_scores_std, \n",
        "                 alpha=0.1, color=\"blue\")\n",
        "plt.fill_between(mlpc_train_sizes, \n",
        "                 mlpc_test_scores_mean - mlpc_test_scores_std,\n",
        "                 mlpc_test_scores_mean + mlpc_test_scores_std, \n",
        "                 alpha=0.1, color=\"green\")\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('training examples'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('Learning curve for MLPClassifier')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPVBeNKXsndD"
      },
      "source": [
        "##### 7 Сравнение и ответ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "RLjucGsBsvUx",
        "outputId": "225430b4-ddfd-4728-a68a-e925af82c10b"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(lr_train_sizes, lr_test_scores_mean, 'bo-', label=\"LogReg test\")\n",
        "plt.plot(svc_train_sizes, svc_test_scores_mean, 'go-', label=\"SVC test\")\n",
        "plt.plot(mlpc_train_sizes, mlpc_test_scores_mean, 'mo-', label=\"MLPClassifier test\")\n",
        "\n",
        "plt.fill_between(lr_train_sizes, \n",
        "                 lr_test_scores_mean - lr_test_scores_std,\n",
        "                 lr_test_scores_mean + lr_test_scores_std, \n",
        "                 alpha=0.1, color=\"blue\")\n",
        "plt.fill_between(svc_train_sizes, \n",
        "                 svc_test_scores_mean - svc_test_scores_std,\n",
        "                 svc_test_scores_mean + svc_test_scores_std, \n",
        "                 alpha=0.1, color=\"green\")\n",
        "plt.fill_between(mlpc_train_sizes, \n",
        "                 mlpc_test_scores_mean - mlpc_test_scores_std,\n",
        "                 mlpc_test_scores_mean + mlpc_test_scores_std, \n",
        "                 alpha=0.1, color=\"magenta\")\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('training examples'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('Learning curves')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-lsjl9psY8p"
      },
      "source": [
        "* Может ли с ростом числа объектов убывать качество на тестовой выборке? А на обучающей? Почему?\n",
        "\n",
        "Если увеличение числа объектов будет делать классы несбалансированными (будем добавлять объкты в осноном одного класса), то качество на будет снижаться. \n",
        "\n",
        "* Для каких целей можно использовать знание качества на обучающей части выборки?\n",
        "\n",
        "Качество на обучающей выборке полезно знать для сравнения с качеством на тестовой и определения переобучения. Если мы видим, например, оценки двух моделей на тестовой выбрке 0.72 и 0.75, мы посчитаем, что вторая модель (с 0.75) лучше. Но если мы увидим для этих моделей соответвующие оценки на обучающей выборке, это может поменять ситуацию. Например, 0.74 для первой и 0.99 для второй. Тогда видно, что вторая, на самом деле, переобучена, и первая лучше. \n",
        "\n",
        "* Какой из алгоритмов лучше обучается на меньшем числе объектов?\n",
        "\n",
        "На меньшем числе объектов лучше обучается логистическая регрессия.\n",
        "\n",
        "* Может ли добавление новых объектов значительно повысить качество какого-то из алгоритмов или при существующем наборе данных для всех алгоритмов произошло насыщение?\n",
        "\n",
        "Визуально по графикам кажется так, что все три модели вышли на плато, но график для логистической регрессии немного поднимается, и, вероятно, на ней качество еще могло бы немного улучшиться на большем числе объектов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XC9Z28dRUF3"
      },
      "source": [
        "#### 8\n",
        "\n",
        "После выполнения данного блока вы получите решение, которое можно отправить в соревнование на [kaggle](https://www.kaggle.com/t/f2f20fc510f042dfa9751a03c6108805). \n",
        "\n",
        "Будьте внимательными, для части матчей из test.csv отсутствуют некоторые данные, для этих матчей все равно требуется что-то предсказать."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa45zh3QRUF4"
      },
      "source": [
        "Пока мы не использовали нечисловые признаки, которые есть в датасете. Давайте посмотрим, правильно ли мы сделали и увеличится ли качество моделей после добавлениях этих признаков. \n",
        "\n",
        "**Задание 8** (1 балл) \n",
        "\n",
        "Преобразуйте все категориальные признаки с помощью метода one-hot-encoding (например, это можно сделать с помощью функции [pandas.get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) или [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) / [OneHotEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) из sklearn). Это задание предлагается делать с использованием *heroes.csv*. Представьте каждую из команд в виде one-hot-encoded вектора с пятью единицами и остальными нулями."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C_9CKpr-i9U"
      },
      "source": [
        "***Решение задания 8:***\n",
        "\n",
        "Так как в 5 задании я масштабировала уже разбитые на две подвыборки данные, то здесь я не придумала, как подклеить к ним новые категориальные признаки, не напутав с индексами :( \n",
        "\n",
        "Поэтому теперь я проделаю всё со стандартизацией заново со всем датасетом: стандартизирую всё в (преобразованном) `train_df` и подклею новые признаки. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMHejvQgRUF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "746d3ffe-ce26-446c-cb9c-b31ee5d3a0ee"
      },
      "source": [
        "heroes_df = pd.read_csv(path_to_data + 'heroes.csv')\n",
        "heroes_df.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mid</th>\n",
              "      <th>player_0</th>\n",
              "      <th>player_1</th>\n",
              "      <th>player_2</th>\n",
              "      <th>player_3</th>\n",
              "      <th>player_4</th>\n",
              "      <th>player_5</th>\n",
              "      <th>player_6</th>\n",
              "      <th>player_7</th>\n",
              "      <th>player_8</th>\n",
              "      <th>player_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "      <td>42</td>\n",
              "      <td>87</td>\n",
              "      <td>15</td>\n",
              "      <td>65</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>34</td>\n",
              "      <td>69</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>69</td>\n",
              "      <td>85</td>\n",
              "      <td>71</td>\n",
              "      <td>24</td>\n",
              "      <td>64</td>\n",
              "      <td>74</td>\n",
              "      <td>68</td>\n",
              "      <td>39</td>\n",
              "      <td>65</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>40</td>\n",
              "      <td>31</td>\n",
              "      <td>67</td>\n",
              "      <td>99</td>\n",
              "      <td>32</td>\n",
              "      <td>7</td>\n",
              "      <td>72</td>\n",
              "      <td>48</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>80</td>\n",
              "      <td>43</td>\n",
              "      <td>101</td>\n",
              "      <td>71</td>\n",
              "      <td>94</td>\n",
              "      <td>69</td>\n",
              "      <td>70</td>\n",
              "      <td>98</td>\n",
              "      <td>24</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>15</td>\n",
              "      <td>75</td>\n",
              "      <td>29</td>\n",
              "      <td>95</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>55</td>\n",
              "      <td>64</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mid  player_0  player_1  player_2  ...  player_6  player_7  player_8  player_9\n",
              "0    0        91        42        87  ...         6        34        69        74\n",
              "1    1        69        85        71  ...        68        39        65        11\n",
              "2    2        17        40        31  ...         7        72        48       104\n",
              "3    3        80        43       101  ...        70        98        24        39\n",
              "4    4        25        15        75  ...        32        55        64        86\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TSiHZSFbKq-"
      },
      "source": [
        "encoder = OneHotEncoder(sparse=False)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WuL77GwI4IW1",
        "outputId": "5a4ea4ac-a28f-4fee-fd81-eb36379a66a9"
      },
      "source": [
        "# вектора для первой команды\n",
        "rcodes = pd.DataFrame(encoder.fit_transform(heroes_df.iloc[:, 1:6]))\n",
        "# вектора для второй команды\n",
        "dcodes = pd.DataFrame(encoder.fit_transform(heroes_df.iloc[:, 6:11]))\n",
        "\n",
        "# подклеиваю к исходным данным\n",
        "heroes_df = heroes_df.join(rcodes)\n",
        "heroes_df = heroes_df.join(dcodes, lsuffix='_d')\n",
        "\n",
        "# убираю исходные столбцы игроков\n",
        "heroes_df = heroes_df.drop(columns=['player_0', 'player_1', 'player_2', 'player_3', 'player_4', 'player_5', 'player_6','player_7', 'player_8', 'player_9'])\n",
        "\n",
        "heroes_df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mid</th>\n",
              "      <th>0_d</th>\n",
              "      <th>1_d</th>\n",
              "      <th>2_d</th>\n",
              "      <th>3_d</th>\n",
              "      <th>4_d</th>\n",
              "      <th>5_d</th>\n",
              "      <th>6_d</th>\n",
              "      <th>7_d</th>\n",
              "      <th>8_d</th>\n",
              "      <th>9_d</th>\n",
              "      <th>10_d</th>\n",
              "      <th>11_d</th>\n",
              "      <th>12_d</th>\n",
              "      <th>13_d</th>\n",
              "      <th>14_d</th>\n",
              "      <th>15_d</th>\n",
              "      <th>16_d</th>\n",
              "      <th>17_d</th>\n",
              "      <th>18_d</th>\n",
              "      <th>19_d</th>\n",
              "      <th>20_d</th>\n",
              "      <th>21_d</th>\n",
              "      <th>22_d</th>\n",
              "      <th>23_d</th>\n",
              "      <th>24_d</th>\n",
              "      <th>25_d</th>\n",
              "      <th>26_d</th>\n",
              "      <th>27_d</th>\n",
              "      <th>28_d</th>\n",
              "      <th>29_d</th>\n",
              "      <th>30_d</th>\n",
              "      <th>31_d</th>\n",
              "      <th>32_d</th>\n",
              "      <th>33_d</th>\n",
              "      <th>34_d</th>\n",
              "      <th>35_d</th>\n",
              "      <th>36_d</th>\n",
              "      <th>37_d</th>\n",
              "      <th>38_d</th>\n",
              "      <th>...</th>\n",
              "      <th>515</th>\n",
              "      <th>516</th>\n",
              "      <th>517</th>\n",
              "      <th>518</th>\n",
              "      <th>519</th>\n",
              "      <th>520</th>\n",
              "      <th>521</th>\n",
              "      <th>522</th>\n",
              "      <th>523</th>\n",
              "      <th>524</th>\n",
              "      <th>525</th>\n",
              "      <th>526</th>\n",
              "      <th>527</th>\n",
              "      <th>528</th>\n",
              "      <th>529</th>\n",
              "      <th>530</th>\n",
              "      <th>531</th>\n",
              "      <th>532</th>\n",
              "      <th>533</th>\n",
              "      <th>534</th>\n",
              "      <th>535</th>\n",
              "      <th>536</th>\n",
              "      <th>537</th>\n",
              "      <th>538</th>\n",
              "      <th>539</th>\n",
              "      <th>540</th>\n",
              "      <th>541</th>\n",
              "      <th>542</th>\n",
              "      <th>543</th>\n",
              "      <th>544</th>\n",
              "      <th>545</th>\n",
              "      <th>546</th>\n",
              "      <th>547</th>\n",
              "      <th>548</th>\n",
              "      <th>549</th>\n",
              "      <th>550</th>\n",
              "      <th>551</th>\n",
              "      <th>552</th>\n",
              "      <th>553</th>\n",
              "      <th>554</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1111 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   mid  0_d  1_d  2_d  3_d  4_d  5_d  ...  548  549  550  551  552  553  554\n",
              "0    0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "1    1  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "2    2  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "3    3  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "4    4  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "\n",
              "[5 rows x 1111 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0gqWBfuCtSx",
        "outputId": "3f1134f2-0b77-4e08-f410-5d1539dac507"
      },
      "source": [
        "rcodes.shape, dcodes.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((49948, 555), (49948, 555))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pazRB3mPC1df"
      },
      "source": [
        "Кодов как-то много"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLCvqW-xB7NO",
        "outputId": "99b8c490-18f3-4398-a257-4b31708f7fd3"
      },
      "source": [
        "max(rcodes.sum(axis=1)), max(rcodes.sum(axis=1)), min(dcodes.sum(axis=1)), max(dcodes.sum(axis=1)), "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.0, 5.0, 5.0, 5.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpOOt4rdC52S"
      },
      "source": [
        "Но в каждом векторе для каждой команды ровно по 5 единиц."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2hGwgIXRUF5"
      },
      "source": [
        "#### 9\n",
        "\n",
        "После кодирования признаков получилось достаточно много и правильно будет заново подобрать оптимальные гиперпараметры для моделей. \n",
        "\n",
        "**Задание 9** (1 балл)\n",
        "\n",
        "Добавьте к масштабированным вещественным признакам закодированные категориальные и подберите гиперпараметры заново. Дало ли добавление новых признаков прирост качества? Измеряйте качество, как и раньше, используя 5-Fold CV. Для этого удобно воспользоваться функцией [cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html#sklearn.cross_validation.cross_val_score).\n",
        "\n",
        "Отличается ли теперь наилучший классификатор от наилучшего в предыдущем пункте?\n",
        "\n",
        "One-hot encoding значительно увеличил количество входных данных. \n",
        "\n",
        "Как изменилось количество параметров у моделей? Наблюдается ли переобучение?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7GtcTvtEIfm"
      },
      "source": [
        "***Решение задания 9:***\n",
        "\n",
        "##### Добавление признаков\n",
        "\n",
        "Как я написала в 8 задании, чтобы аккуратно подклеить новые признаки, мне придется отмасштабировать всё заново. \n",
        "\n",
        "Добавляю новые признаки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVDPZuEokoPM"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "train_df.iloc[:, 2:] = scaler.fit_transform(train_df.drop(columns=['mid', 'radiant_won']))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHT-2h-yRUF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a1f739fa-fafd-463f-8b32-b19c6be0d340"
      },
      "source": [
        "new_train_df = train_df.join(heroes_df.set_index('mid'), on='mid')\n",
        "new_train_df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mid</th>\n",
              "      <th>radiant_won</th>\n",
              "      <th>player_1_lh</th>\n",
              "      <th>player_2_lh</th>\n",
              "      <th>player_3_lh</th>\n",
              "      <th>player_4_lh</th>\n",
              "      <th>player_6_lh</th>\n",
              "      <th>player_7_lh</th>\n",
              "      <th>player_8_lh</th>\n",
              "      <th>player_9_lh</th>\n",
              "      <th>player_1</th>\n",
              "      <th>player_2</th>\n",
              "      <th>player_3</th>\n",
              "      <th>player_4</th>\n",
              "      <th>player_6</th>\n",
              "      <th>player_7</th>\n",
              "      <th>player_8</th>\n",
              "      <th>player_9</th>\n",
              "      <th>rad_gold_sum</th>\n",
              "      <th>dire_gold_sum</th>\n",
              "      <th>rad_lh_sum</th>\n",
              "      <th>dire_lh_sum</th>\n",
              "      <th>rad_gold_std</th>\n",
              "      <th>dire_gold_std</th>\n",
              "      <th>rad_lh_std</th>\n",
              "      <th>dire_lh_std</th>\n",
              "      <th>0_d</th>\n",
              "      <th>1_d</th>\n",
              "      <th>2_d</th>\n",
              "      <th>3_d</th>\n",
              "      <th>4_d</th>\n",
              "      <th>5_d</th>\n",
              "      <th>6_d</th>\n",
              "      <th>7_d</th>\n",
              "      <th>8_d</th>\n",
              "      <th>9_d</th>\n",
              "      <th>10_d</th>\n",
              "      <th>11_d</th>\n",
              "      <th>12_d</th>\n",
              "      <th>13_d</th>\n",
              "      <th>...</th>\n",
              "      <th>515</th>\n",
              "      <th>516</th>\n",
              "      <th>517</th>\n",
              "      <th>518</th>\n",
              "      <th>519</th>\n",
              "      <th>520</th>\n",
              "      <th>521</th>\n",
              "      <th>522</th>\n",
              "      <th>523</th>\n",
              "      <th>524</th>\n",
              "      <th>525</th>\n",
              "      <th>526</th>\n",
              "      <th>527</th>\n",
              "      <th>528</th>\n",
              "      <th>529</th>\n",
              "      <th>530</th>\n",
              "      <th>531</th>\n",
              "      <th>532</th>\n",
              "      <th>533</th>\n",
              "      <th>534</th>\n",
              "      <th>535</th>\n",
              "      <th>536</th>\n",
              "      <th>537</th>\n",
              "      <th>538</th>\n",
              "      <th>539</th>\n",
              "      <th>540</th>\n",
              "      <th>541</th>\n",
              "      <th>542</th>\n",
              "      <th>543</th>\n",
              "      <th>544</th>\n",
              "      <th>545</th>\n",
              "      <th>546</th>\n",
              "      <th>547</th>\n",
              "      <th>548</th>\n",
              "      <th>549</th>\n",
              "      <th>550</th>\n",
              "      <th>551</th>\n",
              "      <th>552</th>\n",
              "      <th>553</th>\n",
              "      <th>554</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.885962</td>\n",
              "      <td>-1.024972</td>\n",
              "      <td>0.310126</td>\n",
              "      <td>1.308403</td>\n",
              "      <td>0.008332</td>\n",
              "      <td>1.423661</td>\n",
              "      <td>-1.702024</td>\n",
              "      <td>1.835383</td>\n",
              "      <td>0.837252</td>\n",
              "      <td>-1.238365</td>\n",
              "      <td>1.573395</td>\n",
              "      <td>0.759007</td>\n",
              "      <td>0.433798</td>\n",
              "      <td>2.512898</td>\n",
              "      <td>-1.299838</td>\n",
              "      <td>1.037951</td>\n",
              "      <td>0.449453</td>\n",
              "      <td>1.934968</td>\n",
              "      <td>0.522062</td>\n",
              "      <td>0.805408</td>\n",
              "      <td>0.808355</td>\n",
              "      <td>1.121018</td>\n",
              "      <td>-0.110565</td>\n",
              "      <td>1.178669</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.294899</td>\n",
              "      <td>-0.147528</td>\n",
              "      <td>0.256604</td>\n",
              "      <td>1.311335</td>\n",
              "      <td>0.813586</td>\n",
              "      <td>-0.934141</td>\n",
              "      <td>0.333935</td>\n",
              "      <td>0.504626</td>\n",
              "      <td>1.876913</td>\n",
              "      <td>-0.669538</td>\n",
              "      <td>0.068543</td>\n",
              "      <td>1.071981</td>\n",
              "      <td>-0.192552</td>\n",
              "      <td>-1.250049</td>\n",
              "      <td>0.169693</td>\n",
              "      <td>0.669657</td>\n",
              "      <td>0.761431</td>\n",
              "      <td>0.321175</td>\n",
              "      <td>0.794057</td>\n",
              "      <td>1.748483</td>\n",
              "      <td>0.667124</td>\n",
              "      <td>-0.318718</td>\n",
              "      <td>0.132491</td>\n",
              "      <td>1.015126</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.518941</td>\n",
              "      <td>3.327967</td>\n",
              "      <td>0.283731</td>\n",
              "      <td>-0.807327</td>\n",
              "      <td>-1.269227</td>\n",
              "      <td>0.838117</td>\n",
              "      <td>-1.098361</td>\n",
              "      <td>-1.106490</td>\n",
              "      <td>-1.086123</td>\n",
              "      <td>2.174597</td>\n",
              "      <td>0.795023</td>\n",
              "      <td>-0.179916</td>\n",
              "      <td>-0.766706</td>\n",
              "      <td>1.519898</td>\n",
              "      <td>-0.722522</td>\n",
              "      <td>-0.750905</td>\n",
              "      <td>1.350722</td>\n",
              "      <td>-1.191756</td>\n",
              "      <td>0.498343</td>\n",
              "      <td>-1.724013</td>\n",
              "      <td>0.613953</td>\n",
              "      <td>0.172925</td>\n",
              "      <td>2.642602</td>\n",
              "      <td>-0.282520</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.071779</td>\n",
              "      <td>0.828382</td>\n",
              "      <td>-0.713382</td>\n",
              "      <td>-1.388677</td>\n",
              "      <td>-0.370567</td>\n",
              "      <td>-0.454991</td>\n",
              "      <td>0.347433</td>\n",
              "      <td>-1.311280</td>\n",
              "      <td>0.733285</td>\n",
              "      <td>0.933520</td>\n",
              "      <td>-0.190914</td>\n",
              "      <td>-1.171001</td>\n",
              "      <td>-0.923294</td>\n",
              "      <td>-0.204786</td>\n",
              "      <td>0.537076</td>\n",
              "      <td>-1.066586</td>\n",
              "      <td>0.276132</td>\n",
              "      <td>-1.124515</td>\n",
              "      <td>-0.784740</td>\n",
              "      <td>-0.976043</td>\n",
              "      <td>-0.529143</td>\n",
              "      <td>-1.078702</td>\n",
              "      <td>-0.372298</td>\n",
              "      <td>-1.011658</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.176438</td>\n",
              "      <td>-1.074570</td>\n",
              "      <td>0.191352</td>\n",
              "      <td>-1.045585</td>\n",
              "      <td>1.056895</td>\n",
              "      <td>0.707169</td>\n",
              "      <td>-0.030513</td>\n",
              "      <td>-0.727893</td>\n",
              "      <td>-1.138106</td>\n",
              "      <td>-0.566114</td>\n",
              "      <td>0.172326</td>\n",
              "      <td>-1.223163</td>\n",
              "      <td>-0.140356</td>\n",
              "      <td>1.363109</td>\n",
              "      <td>-0.775005</td>\n",
              "      <td>-0.645679</td>\n",
              "      <td>-1.353084</td>\n",
              "      <td>0.354796</td>\n",
              "      <td>-1.557880</td>\n",
              "      <td>0.784545</td>\n",
              "      <td>-0.468686</td>\n",
              "      <td>-0.236501</td>\n",
              "      <td>-0.775038</td>\n",
              "      <td>-0.755894</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1136 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   mid  radiant_won  player_1_lh  player_2_lh  ...  551  552  553  554\n",
              "0    0            1     0.885962    -1.024972  ...  0.0  0.0  0.0  0.0\n",
              "1    1            0     1.294899    -0.147528  ...  0.0  0.0  0.0  0.0\n",
              "2    2            1    -1.518941     3.327967  ...  0.0  0.0  0.0  0.0\n",
              "3    4            1     0.071779     0.828382  ...  0.0  0.0  0.0  0.0\n",
              "4    5            1    -1.176438    -1.074570  ...  0.0  0.0  1.0  0.0\n",
              "\n",
              "[5 rows x 1136 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCKWGJpnFVPi"
      },
      "source": [
        "Появились ли там пропуски?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0PQa0unFPQg",
        "outputId": "a0f8e9e3-4332-4366-a6d9-506e34e798c5"
      },
      "source": [
        "max(new_train_df.isna().sum())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvlUv6FWGC9l"
      },
      "source": [
        "Ура, пропуски не появились!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnwazlVtGCWs"
      },
      "source": [
        "nX_train, nX_test, ny_train, ny_test = train_test_split(new_train_df.drop(columns=['mid', 'radiant_won']), new_train_df['radiant_won'], test_size=0.2, random_state=1234)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP-LBR3_IHTR"
      },
      "source": [
        "data_part=4000"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkRhSnSEHDlx"
      },
      "source": [
        "##### 9 LogReg "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOsj1aMoHDmI"
      },
      "source": [
        "**9.1. Logistic Regression Classifier**\n",
        "\n",
        "Оставлю только перебор параметров с `saga` solver-ом."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jnpW7MLHDmU",
        "outputId": "0a0e88c7-f550-4946-a3bd-0e6e9942e300"
      },
      "source": [
        "logreg_model = LogisticRegression(tol=0.0001, \n",
        "                                  solver='saga', \n",
        "                                  random_state=1234,\n",
        "                                  max_iter=100)\n",
        "\n",
        "f9_logreg_params_set = {\n",
        "'C': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 1e2, 1e3],\n",
        "'penalty':['l1', 'l2', 'elasticnet'],\n",
        "'fit_intercept':[True, False],\n",
        "'l1_ratio':[0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "}\n",
        "\n",
        "f9_logreg_CV = GridSearchCV(estimator=logreg_model,\n",
        "                         param_grid=f9_logreg_params_set,\n",
        "                         scoring='roc_auc',\n",
        "                         return_train_score=True,\n",
        "                         verbose=3)\n",
        "\n",
        "f9_logreg_CV.fit(nX_train[:data_part], ny_train[:data_part])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l1 ..........\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l1 ..........\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l1 ..........\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.699, test=0.735), total=   0.7s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.711, test=0.689), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.703, test=0.719), total=   0.7s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.709, test=0.695), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.716, test=0.667), total=   0.7s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l1 ..........\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l1 ..........\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l1 ..........\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.699, test=0.735), total=   0.7s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.711, test=0.689), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.703, test=0.719), total=   0.7s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.709, test=0.695), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.716, test=0.667), total=   0.7s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l1 ..........\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l1 ..........\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l1 ..........\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.699, test=0.735), total=   0.7s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.711, test=0.689), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.703, test=0.719), total=   0.7s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.709, test=0.695), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.716, test=0.667), total=   0.7s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l1 ..........\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l1 ..........\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l2 ..........\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.699, test=0.735), total=   0.7s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.711, test=0.689), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.703, test=0.719), total=   0.7s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.709, test=0.695), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.716, test=0.667), total=   0.7s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l1 ..........\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l1 ..........\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l2 ..........\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.699, test=0.735), total=   0.7s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.711, test=0.689), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.703, test=0.719), total=   0.7s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.709, test=0.695), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.716, test=0.667), total=   0.7s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ..\n",
            "[CV]  C=0.0001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l1 .........\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l1 .........\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l2 .........\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.699, test=0.735), total=   0.5s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.711, test=0.689), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.703, test=0.719), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.709, test=0.695), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.716, test=0.667), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.3s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l1 .........\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l1 .........\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l1 .........\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.699, test=0.735), total=   0.5s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.711, test=0.689), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.703, test=0.719), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.709, test=0.695), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.716, test=0.667), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l1 .........\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l1 .........\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l1 .........\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.699, test=0.735), total=   0.5s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.711, test=0.689), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.703, test=0.719), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.709, test=0.695), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.716, test=0.667), total=   0.7s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l1 .........\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l1 .........\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l2 .........\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.699, test=0.735), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.711, test=0.689), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.703, test=0.719), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.709, test=0.695), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.716, test=0.667), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l1 .........\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l1 .........\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l2 .........\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.699, test=0.735), total=   0.5s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.711, test=0.689), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.703, test=0.719), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.709, test=0.695), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.716, test=0.667), total=   0.6s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet .\n",
            "[CV]  C=0.0001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.1s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.3s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.710, test=0.741), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.721, test=0.695), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.714, test=0.723), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.720, test=0.702), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.726, test=0.672), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.709, test=0.745), total=   0.8s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.720, test=0.695), total=   0.8s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.712, test=0.733), total=   0.8s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.718, test=0.707), total=   0.8s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.724, test=0.681), total=   0.9s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.710, test=0.741), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.721, test=0.695), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.714, test=0.723), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.720, test=0.702), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.726, test=0.672), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.704, test=0.741), total=   0.8s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.720, test=0.692), total=   0.8s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.706, test=0.731), total=   0.9s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.717, test=0.703), total=   0.8s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.716, test=0.686), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.710, test=0.741), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.721, test=0.695), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.714, test=0.723), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.720, test=0.702), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.726, test=0.672), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.4s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.5s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.4s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.4s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.3s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.710, test=0.741), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.721, test=0.695), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.714, test=0.723), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.720, test=0.702), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.726, test=0.672), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.4s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.4s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.4s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.4s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.3s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.710, test=0.741), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.721, test=0.695), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.714, test=0.723), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.720, test=0.702), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.726, test=0.672), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ...\n",
            "[CV]  C=0.001, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.710, test=0.741), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.721, test=0.695), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.714, test=0.723), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.720, test=0.702), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.726, test=0.673), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.709, test=0.745), total=   0.8s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.720, test=0.695), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.712, test=0.733), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.719, test=0.707), total=   0.9s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.724, test=0.681), total=   0.8s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.3s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.710, test=0.741), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.721, test=0.695), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.714, test=0.723), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.720, test=0.702), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.726, test=0.673), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.704, test=0.741), total=   0.9s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.720, test=0.692), total=   0.8s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.706, test=0.731), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.717, test=0.703), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.716, test=0.686), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.710, test=0.741), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.721, test=0.695), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.714, test=0.723), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.720, test=0.702), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.726, test=0.673), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.4s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.4s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.4s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.4s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.3s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.3s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.710, test=0.741), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.721, test=0.695), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.714, test=0.723), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.720, test=0.702), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.726, test=0.673), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.4s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.4s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.4s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.4s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.3s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.3s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.500, test=0.500), total=   0.3s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.710, test=0.741), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.721, test=0.695), total=   0.6s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.714, test=0.723), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.720, test=0.702), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.726, test=0.673), total=   0.7s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.3s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.3s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ..\n",
            "[CV]  C=0.001, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.500, test=0.500), total=   0.2s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.707, test=0.745), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.720, test=0.692), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.710, test=0.735), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.717, test=0.702), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.722, test=0.692), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.750, test=0.752), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.759, test=0.705), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.753, test=0.734), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.756, test=0.718), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.762, test=0.685), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.714, test=0.745), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.725, test=0.699), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.717, test=0.731), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.723, test=0.708), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.728, test=0.681), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.707, test=0.745), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.720, test=0.692), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.710, test=0.735), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.717, test=0.702), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.722, test=0.692), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.750, test=0.752), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.759, test=0.705), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.753, test=0.734), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.756, test=0.718), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.762, test=0.685), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.712, test=0.747), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.724, test=0.698), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.715, test=0.734), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.722, test=0.709), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.727, test=0.685), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.707, test=0.745), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.720, test=0.692), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.710, test=0.735), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.717, test=0.702), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.722, test=0.692), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.750, test=0.752), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.759, test=0.705), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.753, test=0.734), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.756, test=0.718), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.762, test=0.685), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.711, test=0.747), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.723, test=0.696), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.714, test=0.736), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.721, test=0.707), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.726, test=0.689), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.707, test=0.745), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.720, test=0.692), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.710, test=0.735), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.717, test=0.702), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.722, test=0.692), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.750, test=0.752), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.759, test=0.705), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.753, test=0.734), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.756, test=0.718), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.762, test=0.685), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.710, test=0.746), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.722, test=0.695), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.712, test=0.735), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.720, test=0.705), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.724, test=0.691), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.707, test=0.745), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.720, test=0.692), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.710, test=0.735), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.717, test=0.702), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.722, test=0.692), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.750, test=0.752), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.759, test=0.705), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.753, test=0.734), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.756, test=0.718), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.762, test=0.685), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.708, test=0.745), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.720, test=0.693), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.710, test=0.735), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.717, test=0.702), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ....\n",
            "[CV]  C=0.01, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.722, test=0.692), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.707, test=0.745), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.720, test=0.692), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.709, test=0.735), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.717, test=0.702), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.721, test=0.692), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.751, test=0.752), total=   0.6s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.759, test=0.706), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.754, test=0.734), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.756, test=0.718), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.762, test=0.686), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.714, test=0.745), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.725, test=0.699), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.717, test=0.731), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.723, test=0.708), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.729, test=0.681), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.707, test=0.745), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.720, test=0.692), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.709, test=0.735), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.717, test=0.702), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.721, test=0.692), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.751, test=0.752), total=   0.6s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.759, test=0.706), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.754, test=0.734), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.756, test=0.718), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.762, test=0.686), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.712, test=0.747), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.724, test=0.698), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.715, test=0.734), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.722, test=0.709), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.727, test=0.685), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.707, test=0.745), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.720, test=0.692), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.709, test=0.735), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.717, test=0.702), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.721, test=0.692), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.751, test=0.752), total=   0.6s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.759, test=0.706), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.754, test=0.734), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.756, test=0.718), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.762, test=0.686), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.711, test=0.747), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.723, test=0.696), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.714, test=0.736), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.721, test=0.707), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.726, test=0.689), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.707, test=0.745), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.720, test=0.692), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.709, test=0.735), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.717, test=0.702), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.721, test=0.692), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.751, test=0.752), total=   0.6s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.759, test=0.706), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.754, test=0.734), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.756, test=0.718), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.762, test=0.686), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.710, test=0.747), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.722, test=0.695), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.712, test=0.735), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.719, test=0.705), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.724, test=0.691), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.707, test=0.745), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.720, test=0.692), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.709, test=0.735), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.717, test=0.702), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.721, test=0.692), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.751, test=0.752), total=   0.6s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.759, test=0.706), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.754, test=0.734), total=   0.8s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.756, test=0.718), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.762, test=0.686), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.708, test=0.746), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.720, test=0.693), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.710, test=0.735), total=   0.9s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.717, test=0.702), total=   0.7s\n",
            "[CV] C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ...\n",
            "[CV]  C=0.01, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.722, test=0.692), total=   0.8s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.719, test=0.746), total=   2.4s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.729, test=0.700), total=   3.3s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.722, test=0.734), total=   2.9s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.726, test=0.710), total=   2.5s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.733, test=0.686), total=   3.1s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.842, test=0.750), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.850, test=0.692), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.848, test=0.727), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.843, test=0.729), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.848, test=0.689), total=   2.1s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.819, test=0.754), total=   5.2s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.828, test=0.697), total=   5.4s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.825, test=0.730), total=   5.3s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.821, test=0.731), total=   5.3s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.827, test=0.691), total=   4.1s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.719, test=0.746), total=   2.4s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.729, test=0.700), total=   3.4s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.722, test=0.734), total=   2.9s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.726, test=0.710), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.733, test=0.686), total=   3.2s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.842, test=0.750), total=   2.7s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.850, test=0.692), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.848, test=0.727), total=   2.7s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.843, test=0.729), total=   2.7s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.848, test=0.689), total=   2.0s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.774, test=0.753), total=   4.4s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.783, test=0.703), total=   4.4s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.780, test=0.732), total=   4.5s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.778, test=0.726), total=   4.2s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.785, test=0.690), total=   3.2s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.719, test=0.746), total=   2.4s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.729, test=0.700), total=   3.3s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.722, test=0.734), total=   2.9s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.726, test=0.710), total=   2.5s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.733, test=0.686), total=   3.2s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.842, test=0.750), total=   2.7s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.850, test=0.692), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.848, test=0.727), total=   2.5s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.843, test=0.729), total=   2.8s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.848, test=0.689), total=   2.1s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.745, test=0.747), total=   3.9s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.755, test=0.701), total=   3.6s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.753, test=0.733), total=   3.6s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.751, test=0.717), total=   3.7s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.759, test=0.688), total=   3.0s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.719, test=0.746), total=   2.4s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.729, test=0.700), total=   3.3s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.722, test=0.734), total=   2.9s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.726, test=0.710), total=   2.5s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.733, test=0.686), total=   3.2s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.842, test=0.750), total=   2.7s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.850, test=0.692), total=   2.7s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.848, test=0.727), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.843, test=0.729), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.848, test=0.689), total=   2.1s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.729, test=0.743), total=   2.8s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.740, test=0.700), total=   3.8s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.736, test=0.732), total=   3.6s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.736, test=0.712), total=   3.6s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.744, test=0.687), total=   2.9s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.719, test=0.746), total=   2.4s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.729, test=0.700), total=   3.3s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.722, test=0.734), total=   2.9s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.726, test=0.710), total=   2.5s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.733, test=0.686), total=   3.2s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.842, test=0.750), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.850, test=0.692), total=   2.8s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.848, test=0.727), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.843, test=0.729), total=   2.7s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.848, test=0.689), total=   2.0s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.721, test=0.744), total=   2.4s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.732, test=0.700), total=   3.6s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.725, test=0.734), total=   3.5s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.729, test=0.711), total=   2.8s\n",
            "[CV] C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet .....\n",
            "[CV]  C=0.1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.735, test=0.686), total=   3.1s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.719, test=0.746), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.728, test=0.700), total=   2.5s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.721, test=0.735), total=   3.0s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.727, test=0.710), total=   2.1s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.734, test=0.687), total=   2.8s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.842, test=0.750), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.850, test=0.692), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.848, test=0.727), total=   2.5s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.843, test=0.729), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.848, test=0.689), total=   2.1s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.819, test=0.754), total=   5.0s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.828, test=0.697), total=   5.2s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.825, test=0.731), total=   5.2s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.821, test=0.731), total=   5.2s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.827, test=0.692), total=   4.1s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.719, test=0.746), total=   2.7s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.728, test=0.700), total=   2.4s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.721, test=0.735), total=   3.1s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.727, test=0.710), total=   2.1s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.734, test=0.687), total=   2.9s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.842, test=0.750), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.850, test=0.692), total=   2.7s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.848, test=0.727), total=   2.5s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.843, test=0.729), total=   2.8s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.848, test=0.689), total=   1.9s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.774, test=0.752), total=   4.4s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.783, test=0.703), total=   4.3s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.780, test=0.733), total=   4.5s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.779, test=0.725), total=   4.1s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.785, test=0.691), total=   3.3s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.719, test=0.746), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.728, test=0.700), total=   2.4s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.721, test=0.735), total=   3.0s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.727, test=0.710), total=   2.2s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.734, test=0.687), total=   2.7s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.842, test=0.750), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.850, test=0.692), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.848, test=0.727), total=   2.7s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.843, test=0.729), total=   2.7s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.848, test=0.689), total=   2.0s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.745, test=0.745), total=   3.7s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.756, test=0.701), total=   3.9s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.753, test=0.732), total=   3.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.751, test=0.716), total=   3.8s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.759, test=0.688), total=   2.9s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.719, test=0.746), total=   2.7s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.728, test=0.700), total=   2.4s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.721, test=0.735), total=   3.0s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.727, test=0.710), total=   2.1s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.734, test=0.687), total=   2.8s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.842, test=0.750), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.850, test=0.692), total=   2.7s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.848, test=0.727), total=   2.5s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.843, test=0.729), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.848, test=0.689), total=   2.0s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.729, test=0.741), total=   3.3s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.741, test=0.701), total=   3.4s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.736, test=0.732), total=   3.5s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.736, test=0.712), total=   3.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.745, test=0.687), total=   3.0s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.719, test=0.746), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.728, test=0.700), total=   2.4s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.721, test=0.735), total=   2.9s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.727, test=0.710), total=   2.2s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l1 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.734, test=0.687), total=   2.7s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.842, test=0.750), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.850, test=0.692), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.848, test=0.727), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.843, test=0.729), total=   2.6s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.848, test=0.689), total=   2.0s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.722, test=0.745), total=   3.5s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.731, test=0.700), total=   3.3s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.726, test=0.734), total=   3.1s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.729, test=0.711), total=   3.4s\n",
            "[CV] C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ....\n",
            "[CV]  C=0.1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.736, test=0.687), total=   2.8s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.1, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.871, test=0.728), total=   8.3s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.1, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.884, test=0.666), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.1, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.882, test=0.693), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.1, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.874, test=0.718), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.1, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.882, test=0.672), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.1, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.894, test=0.706), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.1, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.905, test=0.654), total=   4.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.1, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.903, test=0.680), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.1, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.896, test=0.707), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.1, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.902, test=0.661), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.893, test=0.709), total=   6.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.904, test=0.655), total=   6.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.902, test=0.682), total=   6.2s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.895, test=0.707), total=   6.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.901, test=0.663), total=   6.0s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.3, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.871, test=0.728), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.3, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.884, test=0.666), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.3, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.882, test=0.693), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.3, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.874, test=0.718), total=   8.4s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.3, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.882, test=0.672), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.3, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.894, test=0.706), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.3, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.905, test=0.654), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.3, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.903, test=0.680), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.3, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.896, test=0.707), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.3, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.902, test=0.661), total=   4.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.890, test=0.714), total=   6.7s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.901, test=0.657), total=   6.7s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.899, test=0.685), total=   6.7s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.891, test=0.709), total=   6.8s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.898, test=0.665), total=   6.7s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.5, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.871, test=0.728), total=   8.3s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.5, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.884, test=0.666), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.5, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.882, test=0.693), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.5, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.874, test=0.718), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.5, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.882, test=0.672), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.5, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.894, test=0.706), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.5, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.905, test=0.654), total=   4.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.5, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.903, test=0.680), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.5, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.896, test=0.707), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.5, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.902, test=0.661), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.886, test=0.718), total=   7.2s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.897, test=0.660), total=   7.2s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.895, test=0.687), total=   7.5s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.887, test=0.711), total=   7.4s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.895, test=0.668), total=   7.3s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.7, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.871, test=0.728), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.7, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.884, test=0.666), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.7, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.882, test=0.693), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.7, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.874, test=0.718), total=   8.3s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.7, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.882, test=0.672), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.7, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.894, test=0.706), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.7, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.905, test=0.654), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.7, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.903, test=0.680), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.7, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.896, test=0.707), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.7, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.902, test=0.661), total=   4.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.881, test=0.723), total=   7.6s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.892, test=0.662), total=   7.7s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.890, test=0.689), total=   7.7s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.882, test=0.714), total=   7.7s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.890, test=0.670), total=   7.8s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.9, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.871, test=0.728), total=   8.3s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.9, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.884, test=0.666), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.9, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.882, test=0.693), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.9, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.874, test=0.718), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.9, penalty=l1 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.882, test=0.672), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.9, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.894, test=0.706), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.9, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.905, test=0.654), total=   4.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.9, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.903, test=0.680), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.9, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.896, test=0.707), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.9, penalty=l2 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.902, test=0.661), total=   3.9s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.875, test=0.727), total=   8.0s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.887, test=0.665), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.885, test=0.692), total=   8.3s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.877, test=0.716), total=   8.1s\n",
            "[CV] C=1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.885, test=0.672), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.1, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.872, test=0.729), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.1, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.884, test=0.666), total=   8.0s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.1, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.882, test=0.692), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.1, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.874, test=0.718), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.1, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.882, test=0.672), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.1, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.894, test=0.706), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.1, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.905, test=0.654), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.1, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.903, test=0.680), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.1, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.896, test=0.707), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.1, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.902, test=0.661), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.893, test=0.709), total=   6.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.904, test=0.655), total=   6.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.902, test=0.682), total=   6.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.895, test=0.707), total=   6.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.901, test=0.662), total=   6.0s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.3, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.872, test=0.729), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.3, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.884, test=0.666), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.3, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.882, test=0.692), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.3, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.874, test=0.718), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.3, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.882, test=0.672), total=   8.0s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.3, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.894, test=0.706), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.3, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.905, test=0.654), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.3, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.903, test=0.680), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.3, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.896, test=0.707), total=   3.8s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.3, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.902, test=0.661), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.890, test=0.714), total=   6.7s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.901, test=0.657), total=   6.7s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.899, test=0.685), total=   6.7s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.891, test=0.709), total=   6.8s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.898, test=0.665), total=   6.7s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.5, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.872, test=0.729), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.5, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.884, test=0.666), total=   8.0s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.5, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.882, test=0.692), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.5, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.874, test=0.718), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.5, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.882, test=0.672), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.5, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.894, test=0.706), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.5, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.905, test=0.654), total=   3.8s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.5, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.903, test=0.680), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.5, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.896, test=0.707), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.5, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.902, test=0.661), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.886, test=0.718), total=   7.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.897, test=0.659), total=   7.2s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.895, test=0.688), total=   7.2s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.887, test=0.711), total=   7.3s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.895, test=0.668), total=   7.3s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.7, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.872, test=0.729), total=   8.0s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.7, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.884, test=0.666), total=   8.0s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.7, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.882, test=0.692), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.7, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.874, test=0.718), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.7, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.882, test=0.672), total=   8.0s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.7, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.894, test=0.706), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.7, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.905, test=0.654), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.7, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.903, test=0.680), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.7, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.896, test=0.707), total=   3.8s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.7, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.902, test=0.661), total=   3.8s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.881, test=0.723), total=   7.6s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.892, test=0.662), total=   7.7s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.890, test=0.690), total=   7.7s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.882, test=0.714), total=   7.7s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.890, test=0.670), total=   7.8s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.9, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.872, test=0.729), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.9, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.884, test=0.666), total=   8.0s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.9, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.882, test=0.692), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.9, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.874, test=0.718), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.9, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.882, test=0.672), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.9, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.894, test=0.706), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.9, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.905, test=0.654), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.9, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.903, test=0.680), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.9, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.896, test=0.707), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.9, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.902, test=0.661), total=   3.9s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.875, test=0.727), total=   8.0s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.887, test=0.665), total=   8.0s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.885, test=0.692), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.877, test=0.716), total=   8.1s\n",
            "[CV] C=1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.885, test=0.672), total=   8.2s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.1, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.901, test=0.693), total=   6.4s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.1, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.912, test=0.644), total=   6.3s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.1, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.909, test=0.668), total=   6.3s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.1, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.903, test=0.699), total=   6.5s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.1, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.911, test=0.649), total=   6.4s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.1, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.901, test=0.691), total=   4.1s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.1, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.912, test=0.643), total=   3.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.1, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.910, test=0.666), total=   3.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.1, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.904, test=0.698), total=   3.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.1, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.912, test=0.648), total=   4.0s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.901, test=0.691), total=   5.7s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.912, test=0.643), total=   5.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.910, test=0.666), total=   5.7s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.903, test=0.698), total=   5.7s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.912, test=0.648), total=   5.7s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.3, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.901, test=0.693), total=   6.5s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.3, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.912, test=0.644), total=   6.3s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.3, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.909, test=0.668), total=   6.5s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.3, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.903, test=0.699), total=   6.4s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.3, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.911, test=0.649), total=   6.4s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.3, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.901, test=0.691), total=   3.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.3, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.912, test=0.643), total=   4.0s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.3, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.910, test=0.666), total=   3.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.3, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.904, test=0.698), total=   3.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.3, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.912, test=0.648), total=   4.0s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.901, test=0.691), total=   5.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.912, test=0.643), total=   5.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.910, test=0.667), total=   5.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.903, test=0.698), total=   5.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.911, test=0.648), total=   5.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.5, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.901, test=0.693), total=   6.5s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.5, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.912, test=0.644), total=   6.3s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.5, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.909, test=0.668), total=   6.4s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.5, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.903, test=0.699), total=   6.4s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.5, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.911, test=0.649), total=   6.4s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.5, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.901, test=0.691), total=   3.8s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.5, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.912, test=0.643), total=   4.0s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.5, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.910, test=0.666), total=   3.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.5, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.904, test=0.698), total=   3.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.5, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.912, test=0.648), total=   3.8s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.901, test=0.692), total=   6.0s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.912, test=0.643), total=   6.0s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.910, test=0.667), total=   6.2s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.903, test=0.698), total=   6.0s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.911, test=0.649), total=   6.1s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.7, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.901, test=0.693), total=   6.4s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.7, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.912, test=0.644), total=   6.3s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.7, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.909, test=0.668), total=   6.3s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.7, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.903, test=0.699), total=   6.5s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.7, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.911, test=0.649), total=   6.4s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.7, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.901, test=0.691), total=   3.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.7, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.912, test=0.643), total=   3.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.7, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.910, test=0.666), total=   3.8s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.7, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.904, test=0.698), total=   3.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.7, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.912, test=0.648), total=   4.0s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.901, test=0.693), total=   6.2s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.912, test=0.643), total=   6.1s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.910, test=0.667), total=   6.2s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.903, test=0.698), total=   6.2s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.911, test=0.649), total=   6.3s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.9, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.901, test=0.693), total=   6.6s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.9, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.912, test=0.644), total=   6.3s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.9, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.909, test=0.668), total=   6.3s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.9, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.903, test=0.699), total=   6.3s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.9, penalty=l1 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.911, test=0.649), total=   6.4s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.9, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.901, test=0.691), total=   3.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.9, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.912, test=0.643), total=   4.0s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.9, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.910, test=0.666), total=   3.8s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.9, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.904, test=0.698), total=   3.9s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.9, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.912, test=0.648), total=   3.8s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.901, test=0.693), total=   6.3s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.912, test=0.643), total=   6.3s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.910, test=0.668), total=   6.5s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.903, test=0.699), total=   6.3s\n",
            "[CV] C=10, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.911, test=0.649), total=   6.4s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.1, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.901, test=0.693), total=   6.3s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.1, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.912, test=0.643), total=   6.3s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.1, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.909, test=0.668), total=   6.4s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.1, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.903, test=0.699), total=   6.5s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.1, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.911, test=0.649), total=   6.4s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.1, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.901, test=0.691), total=   3.8s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.1, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.913, test=0.643), total=   3.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.1, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.910, test=0.666), total=   4.0s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.1, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.904, test=0.698), total=   3.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.1, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.912, test=0.648), total=   3.8s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.901, test=0.691), total=   5.7s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.912, test=0.643), total=   5.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.910, test=0.666), total=   5.7s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.904, test=0.698), total=   5.7s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.912, test=0.648), total=   5.7s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.3, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.901, test=0.693), total=   6.5s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.3, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.912, test=0.643), total=   6.3s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.3, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.909, test=0.668), total=   6.3s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.3, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.903, test=0.699), total=   6.4s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.3, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.911, test=0.649), total=   6.6s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.3, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.901, test=0.691), total=   3.8s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.3, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.913, test=0.643), total=   3.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.3, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.910, test=0.666), total=   3.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.3, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.904, test=0.698), total=   4.0s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.3, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.912, test=0.648), total=   3.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.901, test=0.692), total=   5.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.912, test=0.643), total=   5.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.910, test=0.667), total=   6.1s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.903, test=0.698), total=   5.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.911, test=0.648), total=   5.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.5, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.901, test=0.693), total=   6.4s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.5, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.912, test=0.643), total=   6.5s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.5, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.909, test=0.668), total=   6.3s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.5, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.903, test=0.699), total=   6.3s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.5, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.911, test=0.649), total=   6.4s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.5, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.901, test=0.691), total=   4.0s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.5, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.913, test=0.643), total=   3.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.5, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.910, test=0.666), total=   3.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.5, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.904, test=0.698), total=   3.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.5, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.912, test=0.648), total=   4.0s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.901, test=0.692), total=   6.0s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.912, test=0.643), total=   6.0s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.910, test=0.667), total=   6.1s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.903, test=0.698), total=   6.2s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.911, test=0.649), total=   6.1s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.7, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.901, test=0.693), total=   6.3s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.7, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.912, test=0.643), total=   6.3s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.7, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.909, test=0.668), total=   6.5s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.7, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.903, test=0.699), total=   6.4s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.7, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.911, test=0.649), total=   6.4s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.7, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.901, test=0.691), total=   3.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.7, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.913, test=0.643), total=   4.1s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.7, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.910, test=0.666), total=   3.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.7, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.904, test=0.698), total=   3.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.7, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.912, test=0.648), total=   3.8s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.901, test=0.693), total=   6.3s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.912, test=0.643), total=   6.1s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.910, test=0.667), total=   6.2s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.903, test=0.698), total=   6.2s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.911, test=0.649), total=   6.4s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.9, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.901, test=0.693), total=   6.3s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.9, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.912, test=0.643), total=   6.3s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.9, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.909, test=0.668), total=   6.4s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.9, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.903, test=0.699), total=   6.5s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.9, penalty=l1 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.911, test=0.649), total=   6.4s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.9, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.901, test=0.691), total=   3.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.9, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.913, test=0.643), total=   3.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.9, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.910, test=0.666), total=   4.1s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.9, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.904, test=0.698), total=   3.8s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.9, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.912, test=0.648), total=   3.9s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.901, test=0.693), total=   6.3s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.912, test=0.643), total=   6.4s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.910, test=0.668), total=   6.3s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.903, test=0.699), total=   6.3s\n",
            "[CV] C=10, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.911, test=0.649), total=   6.3s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.902, test=0.689), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.913, test=0.641), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.911, test=0.665), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.904, test=0.697), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.912, test=0.647), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.902, test=0.689), total=   4.0s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.913, test=0.641), total=   4.0s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.911, test=0.665), total=   3.8s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.904, test=0.697), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.912, test=0.647), total=   3.8s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.8s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.904, test=0.697), total=   5.6s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.912, test=0.647), total=   5.6s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.902, test=0.689), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.913, test=0.641), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.911, test=0.665), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.904, test=0.697), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.912, test=0.647), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.902, test=0.689), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.913, test=0.641), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.911, test=0.665), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.904, test=0.697), total=   4.0s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.912, test=0.647), total=   4.0s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.904, test=0.697), total=   5.6s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.912, test=0.647), total=   5.8s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.902, test=0.689), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.913, test=0.641), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.911, test=0.665), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.904, test=0.697), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.912, test=0.647), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.902, test=0.689), total=   4.0s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.913, test=0.641), total=   4.0s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.911, test=0.665), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.904, test=0.697), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.912, test=0.647), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.8s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.8s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.904, test=0.697), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.912, test=0.647), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.902, test=0.689), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.913, test=0.641), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.911, test=0.665), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.904, test=0.697), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.912, test=0.647), total=   5.8s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.902, test=0.689), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.913, test=0.641), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.911, test=0.665), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.904, test=0.697), total=   4.0s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.912, test=0.647), total=   4.0s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.904, test=0.697), total=   5.6s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.912, test=0.647), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.902, test=0.689), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.913, test=0.641), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.911, test=0.665), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.904, test=0.697), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l1 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.912, test=0.647), total=   5.8s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.902, test=0.689), total=   4.0s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.913, test=0.641), total=   4.0s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.911, test=0.665), total=   3.8s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.904, test=0.697), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.912, test=0.647), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.904, test=0.697), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.912, test=0.647), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.902, test=0.689), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.913, test=0.641), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.911, test=0.665), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.904, test=0.697), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.912, test=0.647), total=   5.8s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.902, test=0.689), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.913, test=0.641), total=   4.0s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.911, test=0.665), total=   3.8s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.904, test=0.696), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.912, test=0.647), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.8s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.912, test=0.647), total=   5.8s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.902, test=0.689), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.913, test=0.641), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.911, test=0.665), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.904, test=0.697), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.912, test=0.647), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.902, test=0.689), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.913, test=0.641), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.911, test=0.665), total=   4.0s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.904, test=0.696), total=   3.8s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.912, test=0.647), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.8s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.904, test=0.696), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.912, test=0.647), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.902, test=0.689), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.913, test=0.641), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.911, test=0.665), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.904, test=0.697), total=   5.8s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.912, test=0.647), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.902, test=0.689), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.913, test=0.641), total=   3.8s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.911, test=0.665), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.904, test=0.696), total=   4.0s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.912, test=0.647), total=   3.8s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.912, test=0.647), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.902, test=0.689), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.913, test=0.641), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.911, test=0.665), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.904, test=0.697), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.912, test=0.647), total=   5.8s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.902, test=0.689), total=   4.0s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.913, test=0.641), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.911, test=0.665), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.904, test=0.696), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.912, test=0.647), total=   4.1s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.904, test=0.697), total=   5.8s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.912, test=0.647), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.902, test=0.689), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.913, test=0.641), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.911, test=0.665), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.904, test=0.697), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.912, test=0.647), total=   5.8s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.902, test=0.689), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.913, test=0.641), total=   4.0s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.911, test=0.665), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.904, test=0.696), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.912, test=0.647), total=   3.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.9s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.904, test=0.697), total=   5.7s\n",
            "[CV] C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.912, test=0.647), total=   6.0s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l1, score=(train=0.912, test=0.647), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.902, test=0.689), total=   4.0s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.913, test=0.641), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.911, test=0.665), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.904, test=0.696), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=l2, score=(train=0.912, test=0.647), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.1, penalty=elasticnet, score=(train=0.912, test=0.647), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.911, test=0.665), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l1, score=(train=0.912, test=0.647), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.902, test=0.689), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.913, test=0.641), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.911, test=0.665), total=   3.8s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.904, test=0.696), total=   4.1s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=l2, score=(train=0.912, test=0.647), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.3, penalty=elasticnet, score=(train=0.912, test=0.647), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l1, score=(train=0.912, test=0.647), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.902, test=0.689), total=   4.0s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.913, test=0.641), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.911, test=0.665), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.904, test=0.696), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=l2, score=(train=0.912, test=0.647), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.5, penalty=elasticnet, score=(train=0.912, test=0.647), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.911, test=0.665), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l1, score=(train=0.912, test=0.647), total=   5.7s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.902, test=0.689), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.913, test=0.641), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.911, test=0.665), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.904, test=0.696), total=   4.1s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=l2, score=(train=0.912, test=0.647), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.7s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.7, penalty=elasticnet, score=(train=0.912, test=0.647), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l1 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l1, score=(train=0.912, test=0.647), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.902, test=0.689), total=   4.1s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.913, test=0.641), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.911, test=0.665), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.904, test=0.696), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=l2, score=(train=0.912, test=0.647), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.7s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet ..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=True, l1_ratio=0.9, penalty=elasticnet, score=(train=0.912, test=0.647), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.913, test=0.641), total=   5.7s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.904, test=0.696), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l1, score=(train=0.913, test=0.647), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.902, test=0.689), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.913, test=0.641), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.911, test=0.665), total=   4.0s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.904, test=0.696), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=l2, score=(train=0.913, test=0.647), total=   3.8s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.7s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.1, penalty=elasticnet, score=(train=0.913, test=0.647), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.902, test=0.689), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l1, score=(train=0.913, test=0.647), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.902, test=0.689), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.913, test=0.641), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.911, test=0.665), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.904, test=0.696), total=   4.1s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=l2, score=(train=0.913, test=0.647), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.3, penalty=elasticnet, score=(train=0.913, test=0.647), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.913, test=0.641), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l1, score=(train=0.913, test=0.647), total=   5.7s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.902, test=0.689), total=   4.0s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.913, test=0.641), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.911, test=0.665), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.904, test=0.696), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=l2, score=(train=0.913, test=0.647), total=   4.1s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.904, test=0.696), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.5, penalty=elasticnet, score=(train=0.913, test=0.647), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.911, test=0.665), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l1, score=(train=0.913, test=0.647), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.902, test=0.689), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.913, test=0.641), total=   4.1s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.911, test=0.665), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.904, test=0.696), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=l2, score=(train=0.913, test=0.647), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.7, penalty=elasticnet, score=(train=0.913, test=0.647), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.902, test=0.689), total=   5.7s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.913, test=0.641), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.904, test=0.696), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l1 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l1, score=(train=0.913, test=0.647), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.902, test=0.689), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.913, test=0.641), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.911, test=0.665), total=   4.0s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.904, test=0.696), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=l2, score=(train=0.913, test=0.647), total=   3.9s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.902, test=0.689), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.913, test=0.641), total=   5.8s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.911, test=0.665), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.904, test=0.696), total=   5.6s\n",
            "[CV] C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=1)]: Done 1200 out of 1200 | elapsed: 66.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1000.0, fit_intercept=False, l1_ratio=0.9, penalty=elasticnet, score=(train=0.913, test=0.647), total=   5.6s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=1234, solver='saga',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100.0, 1000.0],\n",
              "                         'fit_intercept': [True, False],\n",
              "                         'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
              "                         'penalty': ['l1', 'l2', 'elasticnet']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX3JV3JHHDmV"
      },
      "source": [
        "Лучший параметр и значение критерия качества на нём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7PFZ-MLHDmV",
        "outputId": "0440690a-80ff-4a45-f0d7-3f2f27f6377e"
      },
      "source": [
        "f9_logreg_CV.best_params_ , f9_logreg_CV.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'C': 0.1, 'fit_intercept': False, 'l1_ratio': 0.1, 'penalty': 'elasticnet'},\n",
              " 0.7209922923280174)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNxasjq3HDmW"
      },
      "source": [
        "По сравнению с наилучшей для логистической регрессии качество изменилось на: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3Zbni7IHDmW",
        "outputId": "09327ad5-8e9c-4968-a478-6c764e1067d9"
      },
      "source": [
        "f9_logreg_CV.best_score_ - best_logreg_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.005668989612487518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgu-DlhaVhB1"
      },
      "source": [
        "Ура, качество немного повысилось! \n",
        "\n",
        "Заметно (по отладочному выводу), что во многих случаях модель сильно переобучалась: качество на тестовой порядка 0.65 при значении на обучающей около 0.91. А так же появилось особенно много ворнингов о том, что алгоритм не сходится, чего не было в задании 6, после масштабирования данных. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JANglyWdHDme"
      },
      "source": [
        "##### 9 SVC\n",
        "\n",
        "**9.2. C-Support Vector Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8u_-OJwHDmf",
        "outputId": "e2d8162f-22e6-4dcd-a412-f42f51fc1ce5"
      },
      "source": [
        "# Инициализирую модель\n",
        "svc_model = SVC(C=1.0, \n",
        "                kernel='rbf',\n",
        "                gamma='scale',\n",
        "                tol=0.001,\n",
        "                random_state=1234)\n",
        "\n",
        "# Тестируемые значения гиперпараметрa \n",
        "f9_svc_params_set = {\n",
        "'kernel':['linear', 'poly', 'sigmoid', 'rbf'],\n",
        "'C': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 1e2]\n",
        "}\n",
        "\n",
        "# Кросс-валидация\n",
        "f9_svc_CV = GridSearchCV(estimator=svc_model,\n",
        "                         param_grid=f9_svc_params_set,\n",
        "                         scoring='roc_auc',\n",
        "                         return_train_score=True,\n",
        "                         verbose=3)\n",
        "\n",
        "f9_svc_CV.fit(nX_train[:data_part], ny_train[:data_part])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
            "[CV] C=0.0001, kernel=linear .........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, kernel=linear, score=(train=0.699, test=0.736), total=  23.9s\n",
            "[CV] C=0.0001, kernel=linear .........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   42.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, kernel=linear, score=(train=0.711, test=0.686), total=  23.8s\n",
            "[CV] C=0.0001, kernel=linear .........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.4min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, kernel=linear, score=(train=0.704, test=0.719), total=  24.0s\n",
            "[CV] C=0.0001, kernel=linear .........................................\n",
            "[CV]  C=0.0001, kernel=linear, score=(train=0.709, test=0.695), total=  23.9s\n",
            "[CV] C=0.0001, kernel=linear .........................................\n",
            "[CV]  C=0.0001, kernel=linear, score=(train=0.716, test=0.667), total=  23.7s\n",
            "[CV] C=0.0001, kernel=poly ...........................................\n",
            "[CV]  C=0.0001, kernel=poly, score=(train=0.744, test=0.737), total=  23.7s\n",
            "[CV] C=0.0001, kernel=poly ...........................................\n",
            "[CV]  C=0.0001, kernel=poly, score=(train=0.750, test=0.681), total=  23.6s\n",
            "[CV] C=0.0001, kernel=poly ...........................................\n",
            "[CV]  C=0.0001, kernel=poly, score=(train=0.748, test=0.710), total=  23.7s\n",
            "[CV] C=0.0001, kernel=poly ...........................................\n",
            "[CV]  C=0.0001, kernel=poly, score=(train=0.754, test=0.692), total=  23.5s\n",
            "[CV] C=0.0001, kernel=poly ...........................................\n",
            "[CV]  C=0.0001, kernel=poly, score=(train=0.755, test=0.665), total=  23.5s\n",
            "[CV] C=0.0001, kernel=sigmoid ........................................\n",
            "[CV]  C=0.0001, kernel=sigmoid, score=(train=0.698, test=0.736), total=  24.5s\n",
            "[CV] C=0.0001, kernel=sigmoid ........................................\n",
            "[CV]  C=0.0001, kernel=sigmoid, score=(train=0.709, test=0.686), total=  24.3s\n",
            "[CV] C=0.0001, kernel=sigmoid ........................................\n",
            "[CV]  C=0.0001, kernel=sigmoid, score=(train=0.702, test=0.719), total=  24.4s\n",
            "[CV] C=0.0001, kernel=sigmoid ........................................\n",
            "[CV]  C=0.0001, kernel=sigmoid, score=(train=0.708, test=0.695), total=  24.5s\n",
            "[CV] C=0.0001, kernel=sigmoid ........................................\n",
            "[CV]  C=0.0001, kernel=sigmoid, score=(train=0.714, test=0.667), total=  24.4s\n",
            "[CV] C=0.0001, kernel=rbf ............................................\n",
            "[CV]  C=0.0001, kernel=rbf, score=(train=0.712, test=0.731), total=  24.3s\n",
            "[CV] C=0.0001, kernel=rbf ............................................\n",
            "[CV]  C=0.0001, kernel=rbf, score=(train=0.720, test=0.682), total=  24.3s\n",
            "[CV] C=0.0001, kernel=rbf ............................................\n",
            "[CV]  C=0.0001, kernel=rbf, score=(train=0.715, test=0.718), total=  24.6s\n",
            "[CV] C=0.0001, kernel=rbf ............................................\n",
            "[CV]  C=0.0001, kernel=rbf, score=(train=0.722, test=0.685), total=  24.4s\n",
            "[CV] C=0.0001, kernel=rbf ............................................\n",
            "[CV]  C=0.0001, kernel=rbf, score=(train=0.726, test=0.661), total=  24.1s\n",
            "[CV] C=0.001, kernel=linear ..........................................\n",
            "[CV]  C=0.001, kernel=linear, score=(train=0.713, test=0.741), total=  22.0s\n",
            "[CV] C=0.001, kernel=linear ..........................................\n",
            "[CV]  C=0.001, kernel=linear, score=(train=0.725, test=0.695), total=  22.7s\n",
            "[CV] C=0.001, kernel=linear ..........................................\n",
            "[CV]  C=0.001, kernel=linear, score=(train=0.718, test=0.726), total=  23.0s\n",
            "[CV] C=0.001, kernel=linear ..........................................\n",
            "[CV]  C=0.001, kernel=linear, score=(train=0.723, test=0.705), total=  22.6s\n",
            "[CV] C=0.001, kernel=linear ..........................................\n",
            "[CV]  C=0.001, kernel=linear, score=(train=0.729, test=0.673), total=  21.3s\n",
            "[CV] C=0.001, kernel=poly ............................................\n",
            "[CV]  C=0.001, kernel=poly, score=(train=0.745, test=0.738), total=  24.0s\n",
            "[CV] C=0.001, kernel=poly ............................................\n",
            "[CV]  C=0.001, kernel=poly, score=(train=0.750, test=0.682), total=  24.6s\n",
            "[CV] C=0.001, kernel=poly ............................................\n",
            "[CV]  C=0.001, kernel=poly, score=(train=0.748, test=0.710), total=  24.8s\n",
            "[CV] C=0.001, kernel=poly ............................................\n",
            "[CV]  C=0.001, kernel=poly, score=(train=0.755, test=0.693), total=  24.0s\n",
            "[CV] C=0.001, kernel=poly ............................................\n",
            "[CV]  C=0.001, kernel=poly, score=(train=0.755, test=0.664), total=  23.9s\n",
            "[CV] C=0.001, kernel=sigmoid .........................................\n",
            "[CV]  C=0.001, kernel=sigmoid, score=(train=0.698, test=0.736), total=  26.1s\n",
            "[CV] C=0.001, kernel=sigmoid .........................................\n",
            "[CV]  C=0.001, kernel=sigmoid, score=(train=0.709, test=0.686), total=  25.1s\n",
            "[CV] C=0.001, kernel=sigmoid .........................................\n",
            "[CV]  C=0.001, kernel=sigmoid, score=(train=0.702, test=0.719), total=  24.8s\n",
            "[CV] C=0.001, kernel=sigmoid .........................................\n",
            "[CV]  C=0.001, kernel=sigmoid, score=(train=0.708, test=0.695), total=  24.8s\n",
            "[CV] C=0.001, kernel=sigmoid .........................................\n",
            "[CV]  C=0.001, kernel=sigmoid, score=(train=0.714, test=0.667), total=  25.6s\n",
            "[CV] C=0.001, kernel=rbf .............................................\n",
            "[CV]  C=0.001, kernel=rbf, score=(train=0.712, test=0.732), total=  24.6s\n",
            "[CV] C=0.001, kernel=rbf .............................................\n",
            "[CV]  C=0.001, kernel=rbf, score=(train=0.721, test=0.684), total=  25.9s\n",
            "[CV] C=0.001, kernel=rbf .............................................\n",
            "[CV]  C=0.001, kernel=rbf, score=(train=0.715, test=0.717), total=  25.1s\n",
            "[CV] C=0.001, kernel=rbf .............................................\n",
            "[CV]  C=0.001, kernel=rbf, score=(train=0.722, test=0.685), total=  24.7s\n",
            "[CV] C=0.001, kernel=rbf .............................................\n",
            "[CV]  C=0.001, kernel=rbf, score=(train=0.726, test=0.661), total=  24.5s\n",
            "[CV] C=0.01, kernel=linear ...........................................\n",
            "[CV]  C=0.01, kernel=linear, score=(train=0.769, test=0.753), total=  21.3s\n",
            "[CV] C=0.01, kernel=linear ...........................................\n",
            "[CV]  C=0.01, kernel=linear, score=(train=0.778, test=0.706), total=  19.7s\n",
            "[CV] C=0.01, kernel=linear ...........................................\n",
            "[CV]  C=0.01, kernel=linear, score=(train=0.772, test=0.738), total=  20.0s\n",
            "[CV] C=0.01, kernel=linear ...........................................\n",
            "[CV]  C=0.01, kernel=linear, score=(train=0.774, test=0.723), total=  20.1s\n",
            "[CV] C=0.01, kernel=linear ...........................................\n",
            "[CV]  C=0.01, kernel=linear, score=(train=0.779, test=0.690), total=  19.6s\n",
            "[CV] C=0.01, kernel=poly .............................................\n",
            "[CV]  C=0.01, kernel=poly, score=(train=0.748, test=0.738), total=  23.6s\n",
            "[CV] C=0.01, kernel=poly .............................................\n",
            "[CV]  C=0.01, kernel=poly, score=(train=0.752, test=0.681), total=  23.5s\n",
            "[CV] C=0.01, kernel=poly .............................................\n",
            "[CV]  C=0.01, kernel=poly, score=(train=0.750, test=0.711), total=  23.5s\n",
            "[CV] C=0.01, kernel=poly .............................................\n",
            "[CV]  C=0.01, kernel=poly, score=(train=0.757, test=0.693), total=  23.6s\n",
            "[CV] C=0.01, kernel=poly .............................................\n",
            "[CV]  C=0.01, kernel=poly, score=(train=0.756, test=0.664), total=  23.8s\n",
            "[CV] C=0.01, kernel=sigmoid ..........................................\n",
            "[CV]  C=0.01, kernel=sigmoid, score=(train=0.699, test=0.736), total=  24.4s\n",
            "[CV] C=0.01, kernel=sigmoid ..........................................\n",
            "[CV]  C=0.01, kernel=sigmoid, score=(train=0.710, test=0.687), total=  25.5s\n",
            "[CV] C=0.01, kernel=sigmoid ..........................................\n",
            "[CV]  C=0.01, kernel=sigmoid, score=(train=0.704, test=0.720), total=  24.7s\n",
            "[CV] C=0.01, kernel=sigmoid ..........................................\n",
            "[CV]  C=0.01, kernel=sigmoid, score=(train=0.709, test=0.697), total=  24.8s\n",
            "[CV] C=0.01, kernel=sigmoid ..........................................\n",
            "[CV]  C=0.01, kernel=sigmoid, score=(train=0.716, test=0.667), total=  24.2s\n",
            "[CV] C=0.01, kernel=rbf ..............................................\n",
            "[CV]  C=0.01, kernel=rbf, score=(train=0.712, test=0.731), total=  24.7s\n",
            "[CV] C=0.01, kernel=rbf ..............................................\n",
            "[CV]  C=0.01, kernel=rbf, score=(train=0.721, test=0.684), total=  24.6s\n",
            "[CV] C=0.01, kernel=rbf ..............................................\n",
            "[CV]  C=0.01, kernel=rbf, score=(train=0.715, test=0.717), total=  24.5s\n",
            "[CV] C=0.01, kernel=rbf ..............................................\n",
            "[CV]  C=0.01, kernel=rbf, score=(train=0.722, test=0.685), total=  24.7s\n",
            "[CV] C=0.01, kernel=rbf ..............................................\n",
            "[CV]  C=0.01, kernel=rbf, score=(train=0.726, test=0.661), total=  24.6s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.860, test=0.716), total=  19.4s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.872, test=0.665), total=  18.9s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.867, test=0.699), total=  19.2s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.861, test=0.718), total=  19.2s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV]  C=0.1, kernel=linear, score=(train=0.867, test=0.674), total=  18.8s\n",
            "[CV] C=0.1, kernel=poly ..............................................\n",
            "[CV]  C=0.1, kernel=poly, score=(train=0.797, test=0.739), total=  22.7s\n",
            "[CV] C=0.1, kernel=poly ..............................................\n",
            "[CV]  C=0.1, kernel=poly, score=(train=0.804, test=0.688), total=  22.5s\n",
            "[CV] C=0.1, kernel=poly ..............................................\n",
            "[CV]  C=0.1, kernel=poly, score=(train=0.798, test=0.715), total=  22.6s\n",
            "[CV] C=0.1, kernel=poly ..............................................\n",
            "[CV]  C=0.1, kernel=poly, score=(train=0.806, test=0.692), total=  22.6s\n",
            "[CV] C=0.1, kernel=poly ..............................................\n",
            "[CV]  C=0.1, kernel=poly, score=(train=0.803, test=0.669), total=  22.4s\n",
            "[CV] C=0.1, kernel=sigmoid ...........................................\n",
            "[CV]  C=0.1, kernel=sigmoid, score=(train=0.719, test=0.747), total=  22.0s\n",
            "[CV] C=0.1, kernel=sigmoid ...........................................\n",
            "[CV]  C=0.1, kernel=sigmoid, score=(train=0.728, test=0.702), total=  21.7s\n",
            "[CV] C=0.1, kernel=sigmoid ...........................................\n",
            "[CV]  C=0.1, kernel=sigmoid, score=(train=0.722, test=0.729), total=  21.7s\n",
            "[CV] C=0.1, kernel=sigmoid ...........................................\n",
            "[CV]  C=0.1, kernel=sigmoid, score=(train=0.726, test=0.714), total=  21.6s\n",
            "[CV] C=0.1, kernel=sigmoid ...........................................\n",
            "[CV]  C=0.1, kernel=sigmoid, score=(train=0.733, test=0.678), total=  21.3s\n",
            "[CV] C=0.1, kernel=rbf ...............................................\n",
            "[CV]  C=0.1, kernel=rbf, score=(train=0.742, test=0.737), total=  22.7s\n",
            "[CV] C=0.1, kernel=rbf ...............................................\n",
            "[CV]  C=0.1, kernel=rbf, score=(train=0.751, test=0.688), total=  22.3s\n",
            "[CV] C=0.1, kernel=rbf ...............................................\n",
            "[CV]  C=0.1, kernel=rbf, score=(train=0.744, test=0.723), total=  22.7s\n",
            "[CV] C=0.1, kernel=rbf ...............................................\n",
            "[CV]  C=0.1, kernel=rbf, score=(train=0.751, test=0.693), total=  22.4s\n",
            "[CV] C=0.1, kernel=rbf ...............................................\n",
            "[CV]  C=0.1, kernel=rbf, score=(train=0.755, test=0.666), total=  22.4s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV]  C=1, kernel=linear, score=(train=0.891, test=0.677), total=  20.7s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV]  C=1, kernel=linear, score=(train=0.901, test=0.624), total=  20.5s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV]  C=1, kernel=linear, score=(train=0.899, test=0.659), total=  20.1s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV]  C=1, kernel=linear, score=(train=0.895, test=0.688), total=  20.7s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV]  C=1, kernel=linear, score=(train=0.897, test=0.641), total=  20.3s\n",
            "[CV] C=1, kernel=poly ................................................\n",
            "[CV]  C=1, kernel=poly, score=(train=0.994, test=0.736), total=  22.2s\n",
            "[CV] C=1, kernel=poly ................................................\n",
            "[CV]  C=1, kernel=poly, score=(train=0.993, test=0.697), total=  22.1s\n",
            "[CV] C=1, kernel=poly ................................................\n",
            "[CV]  C=1, kernel=poly, score=(train=0.993, test=0.714), total=  22.0s\n",
            "[CV] C=1, kernel=poly ................................................\n",
            "[CV]  C=1, kernel=poly, score=(train=0.993, test=0.685), total=  22.2s\n",
            "[CV] C=1, kernel=poly ................................................\n",
            "[CV]  C=1, kernel=poly, score=(train=0.993, test=0.676), total=  22.0s\n",
            "[CV] C=1, kernel=sigmoid .............................................\n",
            "[CV]  C=1, kernel=sigmoid, score=(train=0.649, test=0.678), total=  17.0s\n",
            "[CV] C=1, kernel=sigmoid .............................................\n",
            "[CV]  C=1, kernel=sigmoid, score=(train=0.649, test=0.668), total=  17.3s\n",
            "[CV] C=1, kernel=sigmoid .............................................\n",
            "[CV]  C=1, kernel=sigmoid, score=(train=0.652, test=0.670), total=  17.3s\n",
            "[CV] C=1, kernel=sigmoid .............................................\n",
            "[CV]  C=1, kernel=sigmoid, score=(train=0.654, test=0.662), total=  17.5s\n",
            "[CV] C=1, kernel=sigmoid .............................................\n",
            "[CV]  C=1, kernel=sigmoid, score=(train=0.670, test=0.616), total=  17.0s\n",
            "[CV] C=1, kernel=rbf .................................................\n",
            "[CV] . C=1, kernel=rbf, score=(train=0.948, test=0.746), total=  22.6s\n",
            "[CV] C=1, kernel=rbf .................................................\n",
            "[CV] . C=1, kernel=rbf, score=(train=0.949, test=0.692), total=  22.0s\n",
            "[CV] C=1, kernel=rbf .................................................\n",
            "[CV] . C=1, kernel=rbf, score=(train=0.947, test=0.730), total=  22.2s\n",
            "[CV] C=1, kernel=rbf .................................................\n",
            "[CV] . C=1, kernel=rbf, score=(train=0.948, test=0.706), total=  22.0s\n",
            "[CV] C=1, kernel=rbf .................................................\n",
            "[CV] . C=1, kernel=rbf, score=(train=0.948, test=0.681), total=  22.0s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV]  C=10, kernel=linear, score=(train=0.903, test=0.660), total=  51.4s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV]  C=10, kernel=linear, score=(train=0.912, test=0.622), total=  56.1s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV]  C=10, kernel=linear, score=(train=0.912, test=0.624), total= 1.0min\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV]  C=10, kernel=linear, score=(train=0.903, test=0.670), total=  54.2s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV]  C=10, kernel=linear, score=(train=0.906, test=0.629), total= 1.1min\n",
            "[CV] C=10, kernel=poly ...............................................\n",
            "[CV]  C=10, kernel=poly, score=(train=1.000, test=0.710), total=  24.1s\n",
            "[CV] C=10, kernel=poly ...............................................\n",
            "[CV]  C=10, kernel=poly, score=(train=1.000, test=0.689), total=  24.0s\n",
            "[CV] C=10, kernel=poly ...............................................\n",
            "[CV]  C=10, kernel=poly, score=(train=1.000, test=0.695), total=  24.1s\n",
            "[CV] C=10, kernel=poly ...............................................\n",
            "[CV]  C=10, kernel=poly, score=(train=1.000, test=0.667), total=  24.1s\n",
            "[CV] C=10, kernel=poly ...............................................\n",
            "[CV]  C=10, kernel=poly, score=(train=1.000, test=0.674), total=  23.8s\n",
            "[CV] C=10, kernel=sigmoid ............................................\n",
            "[CV]  C=10, kernel=sigmoid, score=(train=0.584, test=0.604), total=  12.3s\n",
            "[CV] C=10, kernel=sigmoid ............................................\n",
            "[CV]  C=10, kernel=sigmoid, score=(train=0.586, test=0.622), total=  13.6s\n",
            "[CV] C=10, kernel=sigmoid ............................................\n",
            "[CV]  C=10, kernel=sigmoid, score=(train=0.590, test=0.606), total=  11.9s\n",
            "[CV] C=10, kernel=sigmoid ............................................\n",
            "[CV]  C=10, kernel=sigmoid, score=(train=0.580, test=0.578), total=  12.7s\n",
            "[CV] C=10, kernel=sigmoid ............................................\n",
            "[CV]  C=10, kernel=sigmoid, score=(train=0.597, test=0.567), total=  12.7s\n",
            "[CV] C=10, kernel=rbf ................................................\n",
            "[CV]  C=10, kernel=rbf, score=(train=1.000, test=0.711), total=  24.8s\n",
            "[CV] C=10, kernel=rbf ................................................\n",
            "[CV]  C=10, kernel=rbf, score=(train=1.000, test=0.670), total=  25.0s\n",
            "[CV] C=10, kernel=rbf ................................................\n",
            "[CV]  C=10, kernel=rbf, score=(train=1.000, test=0.699), total=  24.9s\n",
            "[CV] C=10, kernel=rbf ................................................\n",
            "[CV]  C=10, kernel=rbf, score=(train=1.000, test=0.699), total=  24.8s\n",
            "[CV] C=10, kernel=rbf ................................................\n",
            "[CV]  C=10, kernel=rbf, score=(train=1.000, test=0.675), total=  24.9s\n",
            "[CV] C=100.0, kernel=linear ..........................................\n",
            "[CV]  C=100.0, kernel=linear, score=(train=0.906, test=0.659), total= 9.1min\n",
            "[CV] C=100.0, kernel=linear ..........................................\n",
            "[CV]  C=100.0, kernel=linear, score=(train=0.917, test=0.618), total=12.9min\n",
            "[CV] C=100.0, kernel=linear ..........................................\n",
            "[CV]  C=100.0, kernel=linear, score=(train=0.916, test=0.614), total= 9.7min\n",
            "[CV] C=100.0, kernel=linear ..........................................\n",
            "[CV]  C=100.0, kernel=linear, score=(train=0.908, test=0.655), total=13.0min\n",
            "[CV] C=100.0, kernel=linear ..........................................\n",
            "[CV]  C=100.0, kernel=linear, score=(train=0.911, test=0.625), total=10.3min\n",
            "[CV] C=100.0, kernel=poly ............................................\n",
            "[CV]  C=100.0, kernel=poly, score=(train=1.000, test=0.710), total=  24.2s\n",
            "[CV] C=100.0, kernel=poly ............................................\n",
            "[CV]  C=100.0, kernel=poly, score=(train=1.000, test=0.689), total=  24.1s\n",
            "[CV] C=100.0, kernel=poly ............................................\n",
            "[CV]  C=100.0, kernel=poly, score=(train=1.000, test=0.695), total=  24.2s\n",
            "[CV] C=100.0, kernel=poly ............................................\n",
            "[CV]  C=100.0, kernel=poly, score=(train=1.000, test=0.667), total=  24.2s\n",
            "[CV] C=100.0, kernel=poly ............................................\n",
            "[CV]  C=100.0, kernel=poly, score=(train=1.000, test=0.674), total=  24.2s\n",
            "[CV] C=100.0, kernel=sigmoid .........................................\n",
            "[CV]  C=100.0, kernel=sigmoid, score=(train=0.582, test=0.597), total=  11.7s\n",
            "[CV] C=100.0, kernel=sigmoid .........................................\n",
            "[CV]  C=100.0, kernel=sigmoid, score=(train=0.585, test=0.617), total=  13.7s\n",
            "[CV] C=100.0, kernel=sigmoid .........................................\n",
            "[CV]  C=100.0, kernel=sigmoid, score=(train=0.586, test=0.609), total=  11.4s\n",
            "[CV] C=100.0, kernel=sigmoid .........................................\n",
            "[CV]  C=100.0, kernel=sigmoid, score=(train=0.577, test=0.569), total=  11.9s\n",
            "[CV] C=100.0, kernel=sigmoid .........................................\n",
            "[CV]  C=100.0, kernel=sigmoid, score=(train=0.597, test=0.570), total=  11.3s\n",
            "[CV] C=100.0, kernel=rbf .............................................\n",
            "[CV]  C=100.0, kernel=rbf, score=(train=1.000, test=0.711), total=  25.2s\n",
            "[CV] C=100.0, kernel=rbf .............................................\n",
            "[CV]  C=100.0, kernel=rbf, score=(train=1.000, test=0.670), total=  25.2s\n",
            "[CV] C=100.0, kernel=rbf .............................................\n",
            "[CV]  C=100.0, kernel=rbf, score=(train=1.000, test=0.699), total=  25.1s\n",
            "[CV] C=100.0, kernel=rbf .............................................\n",
            "[CV]  C=100.0, kernel=rbf, score=(train=1.000, test=0.699), total=  25.2s\n",
            "[CV] C=100.0, kernel=rbf .............................................\n",
            "[CV]  C=100.0, kernel=rbf, score=(train=1.000, test=0.675), total=  25.3s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 140 out of 140 | elapsed: 145.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=1234, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100.0],\n",
              "                         'kernel': ['linear', 'poly', 'sigmoid', 'rbf']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xhiWF79HDmg"
      },
      "source": [
        "Лучший набор параметров и значение критерия качества на них:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxMzP0ESHDmg",
        "outputId": "9e3084f0-2fcb-4c44-b2a7-a80e53652b25"
      },
      "source": [
        "f9_svc_CV.best_params_ , f9_svc_CV.best_score_"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'C': 0.01, 'kernel': 'linear'}, 0.7217649379191164)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm0UrItoHDmh"
      },
      "source": [
        "С наилучшей по итогам 6 задания качество изменилось на:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRr2HD_XHDmh",
        "outputId": "72a1aed0-3164-412f-d825-45d149336fe6"
      },
      "source": [
        "f9_svc_CV.best_score_ - best_svc_score"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.015003997487233134"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eytB3jHpSQkR"
      },
      "source": [
        "Оптимальные параметры не поменялись, но качество повысилось."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "R-BFpflwBZE-",
        "outputId": "1e5b0831-fc0d-462f-f03f-00f7fc6de5c2"
      },
      "source": [
        "fig = plt.figure(figsize=(15,7))\n",
        "\n",
        "f9_svc_test_scores = np.array(f9_svc_CV.cv_results_['mean_test_score']).reshape(len(f9_svc_params_set['kernel']), len(f9_svc_params_set['C']))\n",
        "f9_svc_train_scores = np.array(f9_svc_CV.cv_results_['mean_train_score']).reshape(len(f9_svc_params_set['kernel']), len(f9_svc_params_set['C']))\n",
        "\n",
        "colors = ['blue', 'green', 'magenta', 'orange']\n",
        "\n",
        "for ind, k in enumerate(f9_svc_params_set['kernel']):\n",
        "    plt.plot(f9_svc_params_set['C'], f9_svc_test_scores[ind], label='C: ' + k +' test', color=colors[ind])\n",
        "    plt.plot(f9_svc_params_set['C'], f9_svc_train_scores[ind], label='C: ' + k +' train', color=colors[ind], alpha=0.5)\n",
        "\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('Mean test score for SVC')\n",
        "plt.xscale('log')\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAG9CAYAAABH1NRgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXyU9bX48c83C1nISljCIgQCKASSgSDKVhYFlOJWXBBUFsWLC9Z69Yq3t170tlX7o7UWaimoIAqKorgiVYQUEESDJBAWgWBYJIQtCQnZJ8/vjzNJCCSQwCSz5Lxfr7wgM/M8z5lMMvOc5/v9nmMsy0IppZRSSimllOfzcXUASimllFJKKaWcQxM8pZRSSimllPISmuAppZRSSimllJfQBE8ppZRSSimlvIQmeEoppZRSSinlJTTBU0oppZRSSikvoQmeUkop5eaMMYOMMXuNMfnGmFtdHY9SSin3pQmeUkqp8xhjMowxJcaYlufcvtUYYxljYho5nmHGmMNO2leSMeYBZ+yrET0PzLUsK8SyrI8ud2fGmA7GmA+MMSeMMbnGmDRjzGRjTKAxJscYM6KGbV42xiw/6/sJxphkR9KZaYz5whgz+HJjU0opdXk0wVNKKVWbn4C7K74xxvQGgl0XjncwxvhdwmadgB1OPN5bwCHHfqOAe4Esy7KKgGXAfefswxf5XXjT8f0TwF+BPwJtgI7Aq8AtlxKjUkop59EETymlVG3eovqJ/iRg8dkPMMYEGGNmG2MOGmOyjDHzjDFBjvsijTGfGWOOG2OyHf/vcNa2ScaY/zPGfGOMyTPGfHnuiKHjcc2BL4B2jtGifGNMO2OMjzFmpjEm3Rhz0hjznjGmhWObQGPM247bc4wx3xtj2hhj/gAMAeY69jO3huPVuK3jvhbGmIXGmCOO5/TRWdtNM8bsM8acMsZ8Yoxpd9Z9ljHmEWPMXmCv47axxpgUxzE2GmPia3oRjDHpQBfgU0fMAY7n/4njWPuMMdPOevwsY8xyx3M4DUyuYbdXA4ssyzpjWVaZZVlbLcv6wnHfm8A4Y8zZyfxo5JzhC2NMODKi+IhlWR869lFqWdanlmU9VdNzUEop1Xg0wVNKKVWbb4EwY0wPxwjOeODtcx7zItAdsAFdgfbAs477fICFyChRR6AQODehmgBMAVoDzYAnzw3CsqwzwI3AEccUxRDLso4AM4BbgaFAOyAb+Ltjs0lAOHAFMkI1HSi0LOu3wHrgUcd+Hq3hede4reO+t5BRzDhHzC8DOKY0vgDcCbQFDgDvnrPfW4FrgJ7GmD7AG8B/OI7xT+ATY0xADc8/FjgI3OSIudix78OO53078MdzplXeAiwHIoAlNTzHb4G/G2PGG2M6nnO8jUAm8Kuzbr4XWGpZVhkwAAgEVtSwX6WUUi6mCZ5SSqkLqRjFGwnsAn6uuMMYY4AHgd9YlnXKsqw8ZMreeADLsk5alvWBZVkFjvv+gCRjZ1toWdYey7IKgfeQRLGupgO/tSzrsCPpmQXc7piSWIokTl0ty7JblrXFsqzTddxvjdsaY9oiieZ0y7KyHaNW/3ZsMxF4w7KsHxyxPAMMOGet4guOn1Mh8nP7p2VZmx3HeBMoBq69WHDGmCuAQcDTlmUVWZaVArxG9dHWTZZlfWRZVrnjeOe6A0l0fwf85BhJvPqs+xdX7M8YE4YkjG867osCTjiSPaWUUm5GEzyllFIX8hYyyjaZc6ZnAq2Q0awtjmmGOcAqx+0YY4KNMf80xhxwTBVcB0Q4RgMrHD3r/wVASD1i6wSsOOvYuwA7sibsLeBfwLuO6ZR/Msb413G/tW17BXDKsqzsGrZph4zaAWBZVj5wEhnRrHDonNj/syJ2R/xXOPZzMe0cceSddduBCxzrPI4EdaZlWXHIzysF+MiRtIP8DIY7ppneDqRblrXVcd9JoOUlriVUSinVwDTBU0opVSvLsg4gxVbGAB+ec/cJZOpinGVZEY6vcMuyKpK0/wSuBK6xLCsM+IXjdkP9WTXcdgi48axjR1iWFWhZ1s+O0bXnLMvqCQwExlI1wlXTvqoOVPu2h4AWxpiIGjY7giRtQOW6wSjOGvE857iHgD+cE3uwZVnvXCi2s47VwhgTetZtHS9wrAuyLOsEMBtJHFs4bjuAjPDdg0zPfPOsTTYho43arkEppdyQJnhKKaUu5n5ghGMtXCXLssqBBcDLxpjWAMaY9saY0Y6HhCIJYI6j+Mn/XkYMWUCUo8BHhXnAH4wxnRzHbmWMucXx/+HGmN6O0cLTyLTL8rP21aW2A9W2rWVZmUixl1eNFJDxN8ZUJK3vAFOMMTbHOro/Apsty8qo5TALgOnGmGuMaG6M+eU5SVuNLMs6BGwEXnAUhIlHXqNz10fWyhjzkjGmlzHGz3HMh4B9lmWdPOthbwKPItNBK9fxWZaVi6yz/Lsx5lbHSK2/MeZGY8yf6hqDUkqphqEJnlJKqQuyLCvdsqzkWu5+GtgHfOuYhrkaGbUDKaMfhIz0fYtM37zUGHYjSdR+x5TGdsArwCfAl8aYPMcxrnFsEo0UGTmNTN38NzLtEMd2tzuqYP6thsNdaNt7kYRvN3AMeNwR32pkPdsHSIGSWBxrEWt5PsnANKToTDbyM5xc5x+ItCyIQUbzVgD/64ihroId2+UA+5HRx5vPecwHyIje147k9uz4/ww8AfwPcBwZkXwUuOwefUoppS6Psaw6z+JQSimllFJKKeXGdARPKaWUUkoppbyEJnhKKaWUUkop5SU0wVNKKaWUUkopL6EJnlJKKaWUUkp5CY9rUtqyZUsrJibG1WGc58yZMzRv3tzVYSgX0Ne+6dLXvunS175p0te96dLXvuly19d+y5YtJyzLalXTfR6X4MXExJCcXFu1btdJSkpi2LBhrg5DuYC+9k2XvvZNl772TZO+7k2XvvZNl7u+9saYA7Xdp1M0lVJKKaWUUspLaIKnlFJKKaWUUl5CEzyllFJKKaWU8hIetwavJqWlpRw+fJiioiKXxRAeHs6uXbtcdnxvEBgYSIcOHfD393d1KEoppZRSSnkkr0jwDh8+TGhoKDExMRhjXBJDXl4eoaGhLjm2N7Asi5MnT3L48GE6d+7s6nCUUkoppZTySF4xRbOoqIioqCiXJXfq8hljiIqKcukorFJKKaWUUp7OKxI8QJM7L6CvoVJKKaWUUpfHaxI8pZRSSimllGrqNMFzkqysLMaPH09sbCyJiYmMGTOGPXv2XHCbYcOGVTZtHzNmDDk5OY0RKgAZGRksXbr0krf/4x//6MRolFJKKaWUUs6gCZ4TWJbFhAkTGDZsGOnp6WzZsoUXXniBrKysOu9j5cqVRERENFiMZWVl1b7XBE8ppZRSSinvowmeE6xduxZ/f3+mT59eeVtCQgJDhgyp8z5iYmI4ceIEGRkZ9OjRg2nTphEXF8eoUaMoLCwEID09nRtuuIHExESGDBnC7t27Afj000+55ppr6NOnD9dff31lYjlr1izuvfdeBg0axL333lvteDNnzmT9+vXYbDZefvll7HY7Tz31FFdffTXx8fH885//BCAzM5Nf/OIX2Gw2evXqxfr165k5cyaFhYXYbDYmTpx4WT87pZRSSimllPN4RZuEsz3+OKSkOHefNhv89a+135+WlobNZrvA9jZS6hHU3r17eeedd1iwYAF33nknH3zwAffccw8PPvgg8+bNo1u3bmzevJmHH36YNWvWMHjwYL799luMMbz22mv86U9/4s9//jMAO3fuZMOGDQQFBVU7xosvvsjs2bP57LPPAJg/fz7h4eF8//33FBcXM2jQIEaNGsWHH37I6NGj+e1vf4vdbqegoIAhQ4Ywd+7cej0npZRSSimlVMNrsATPGPMGMBY4ZllWrxruN8ArwBigAJhsWdYPDRWPK9U3EercuXNlwpiYmEhGRgb5+fls3LiRO+64o/JxxcXFgPQBvOuuu8jMzKSkpKRaH7mbb775vOSuJl9++SXbtm1j+fLlAOTm5rJ3716uvvpqpk6dSmlpKbfeeusFE1mllFJKKaWUazXkCN4iYC6wuJb7bwS6Ob6uAf7h+PeyXGikraHExcWxbNkyp+0vICCg8v++vr4UFhZSXl5OREREjcnijBkzeOKJJ7j55ptJSkpi1qxZlfc1b968Tse0LIs5c+YwevTo8+5bt24dn3/+OZMnT+aJJ57gvvvuq/+TUkoppZRSSjW4BluDZ1nWOuDUBR5yC7DYEt8CEcaYtg0VT0MaMWIExcXFzJ8/v/K2bdu2sX79eqcdIywsjM6dO/P+++8DkpClpqYCMtrWvn17AN5888067S80NJS8vLzK70ePHs0//vEPSktLAdizZw9nzpzhwIEDtGnThmnTpvHAAw/www8yyOrv71/5WKWUUkoppbyOvRgsy9VR1Jsri6y0Bw6d9f1hx20ex5Tm8t5b/2D16tXExsYSFxfHM888Q3R0NIDTpjUuWbKE119/nYSEBOLi4vj4448BKaZyxx13kJiYSMuWLeu0r/j4eHx9fUlISODll1/mgQceoGfPnvTt25devXrxH//xH5SVlZGUlERCQgJ9+vRh2bJl/PrXvwbgwQcfJD4+XousqKap3A775tOq8N9QkuvqaJRSDa2sEH5eSfv8D6E07+KPV0p5h8MfE134haujqDdjNWBWaoyJAT6rZQ3eZ8CLlmVtcHz/NfC0ZVnJNTz2QeBBgDZt2iS+++671e4PDw+na9euTo+/rnzKC/G151PmF4llvK5uTaPat28fubmedcKcn59PSEiIq8NQjSi49CCtC9dQXFqKf7MgTjfrRW6zXvr334To330TYZUTWrqHiOKt+FBCaXEx+aEDOB3Q29WRqUamf/NNj49VzBX5yzhm70RhxFBXh3Oe4cOHb7Esq19N97nybORn4Iqzvu/guO08lmXNB+YD9OvXzxo2bFi1+3ft2kVoaGjDRFkXVjDFuQWEBPpAMxfG4QUCAwPp06ePq8Ool6SkJM79nVRe7sAyOBPHhqNXMbhrEeTsgGbbIXoUhPcEY1wdoWpg+nffBORnQOYXUJgFIQOg7Y38uGY2fTv7Qreh+nfexOjffBN0Mhl+7kjm8V4e99q7cormJ8B9RlwL5FqWlenCeC6d8aXc+IO90CPn6Sql6qGsAE7vgYh4ynxCoeMd0GUy+AbBwffhpzflhFAp5ZlKcuDAe7B/kay/6XQndJ4EQW3I94+FomNQpH/jSnm9nFQIbE2JTwtXR1JvDdkm4R1gGNDSGHMY+F/AH8CyrHnASqRFwj6kTcKUhoqlMZSbALBKoLwYfANdHY5SqqHk7gDLDpEJwG65LSQGuj4Ip36ArDWwbx606AdthoNfsCujVUrVVXkpHN8Ax78BjPz9thoIPv6VDznj3xnMcchOhaBo18WqlGpYxafgzCFoOxKOeF5RwQZL8CzLuvsi91vAIw11/MZWTjMwpXJ1XxM8pbxXdioEtXGc3O2uut34QFQ/CI+DY0lw8nvITYPWwyDqarlfeYdyVwegnMqy5MLN0a+kaFJEL4geCc3Cz3touQmAsO6Qs01O/PTvWinvlJMq07AjegOe16ZbKwI4izHgGwz2M2CV65u+Ut6o6AQUHIa2o2p/jF8QtLsRWiTCkVVw5As4tQXa3QAhXRovVuV8JcBa4DsIiglydTTKGQqPyt/omQNy0Sb2V9C804W3iUiA3F2Qlw5h3RonTqVU47EsuZjbvDP4h7k6mkuiCZ4z+QZB2RlZi+dXtwbjSikPUu2K3kUEtobO98Lp3ZD5JexfDOE9JDlsFtnwsSrn2gt8DuQAARC+7fzRHeVBygpkOvWpLfLZ3eEmiOxTt4uzod3kQk5OqiZ4SnmjgoOyFrfNcFdHcsl0mMlJsrKyGD/xPmJ7DSSx/0DGjBnDnj17LrjNsGHDSE6WrhBjxowhJyenMUIFICMjg6VLl17StgMHDnRyNEp5AMuSaVkhseBfx2q5xkhS1/0RiB4Beftgz9/h6BqwlzRsvMo58oHlwBJkFflU4DoIPB5YvZOr8gzldjixGX78m6yZjboGus+QEfe6zrzx8YXw3nLxxl7UsPEqpRpfdir4NoOwHq6O5JLpCJ4TWJbFhAkTmDp1Ku++tQBK80j9MZOsrCy6d+9ep32sXLmyQWMsKyvDz6/q5a5I8CZMmHDRx55r48aNDRKjUm7tTIasz4keWf9tffyg9S8g0gaZX8GxdZCdImt4wntpuXV3ZAEpwJfI1MxhwGDkUzMa7AF22ET1Zj/KveXvl+mYRcchNBba3gCBrS5tX5EJcPI7yN0JLfo6N06llOuUl8qa3LAekuR5KE3wnGDt2rX4+/szffp0KC+D0jwSenWv+1V+ICYmhuTkZPLz87nxxhsZPHgwGzdupH379nz88ccEBQWRnp7OI488wvHjxwkODmbBggVcddVVfPrpp/z+97+npKSEqKgolixZQps2bZg1axbp6ens37+fjh078s4771Qeb+bMmezatQubzcakSZOIjIzkww8/JD8/H7vdzueff84tt9xCdnY2paWl/P73v+eWW24BICQkhPz8fJKSkpg1axYtW7YkLS2NxMRE3n77bYyerCpvlJ0KvgEQduWl78M/DDqOk6IrR76Agx9A8+9lzV5QW+fFqi7PSeAz4CegI3ATcHYe0AzyuufBLiAb0Bm37q0kG478S0bcmkVCp/Hyd3w5n1VB7SCgpbwvaIKnlPc4/aO0R4lMcHUkl8XrErxVq+DoUefuMzoabrih9vvT0tKw2WzyjY+fZPxlBeAXAsZgs9lISUmp8/H27t3LO++8w4IFC7jzzjv54IMPuOeee3jwwQeZN28e3bp1Y/PmzTz88MOsWbOGwYMH8+2332KM4bXXXuNPf/oTf/7znwHYuXMnGzZsICioekGAF198kdmzZ/PZZ58BsGjRIn744Qe2bdtGixYtKCsrY8WKFYSFhXHixAmuvfZabr755vOSt61bt7Jjxw7atWvHoEGD+Oabbxg8eHCdn6tSHsFeAqd3ymjbWSXTL1nzjtB1moziHf0a9s2X9T/R1+n6XVeyAxuBfyOfjjcBfYEa8oC8HnmwBfgWuLHxQlT1YC+B4+vhxCaZfhl9HbQcIJ/Tl8sYOQE8+rUkkLquVinvkLNNLsY2j3F1JJfF6xI8t+AbDPYcKC8B34B6JXcAnTt3rkwYExMTycjIID8/n40bN3LHHXdUPq64uBiAw4cPc9ddd5GZmUlJSQmdO3eufMzNN998XnJXm5EjR9KihTRztCyL//7v/2bdunX4+Pjw888/k5WVRXR09b4//fv3p0OHDgDYbDYyMjI0wVPe5/RuOVl05hU94yNX/sN7Qta/4eRmme7VeihE9Zd1PqrxHAY+AY4BPZGk7QKTMOzBdugNbEWmb2pRTfdhWZCzXdoelOZBZDxEX+/8angR8ZLgZW+DNkOdu2+lVOMrzZe18q0Genw1fK9L8C400tZQ4uLiWLZsWdUNvoFydc9eKFO66ikgoGobX19fCgsLKS8vJyIiosZkccaMGTzxxBPcfPPNldMmKzRvXvfRgLMfu2TJEo4fP86WLVvw9/cnJiaGoqLzF5OfG2tZWVmdj6eUx8hJhWYRENzR+fv2DYR2o6XIQ+YqyPxXVVuF0K7OP56qrhhYA3yHJHR3A3WdhTsAWae3BVmfp1yv4AhkfiENioPbQcc7oXkDLZRsFg4hMfL+0PoXupZWKU+XmyatziLiXR3JZfPs9NRNjBgxguLiYubPny83GB+27Uxn/bok+UVxgrCwMDp37sz7778PyAhbamoqALm5ubRv3x6AN998s077Cw0NJS8vr9b7c3Nzad26Nf7+/qxdu5YDBw5c5jNQykOVnpbiDJEJDXsCF9gSYiZCzASgHH56GzLegeJTDXfMpu5H4O9Icnc18Ah1T+4A2gCxwGZkeqdynbIzcPgTSF8gfzMdboHYaQ2X3FWISJDjFRxu2OMopRpedqpcGAps7epILpsmeE5gjGHp0qWsXr2a2NhY4uLieOZ3fyC6dUuwF1etz7tMS5Ys4fXXXychIYG4uDg+/vhjAGbNmsUdd9xBYmIiLVu2rNO+4uPj8fX1JSEhgZdffvm8+ydOnEhycjK9e/dm8eLFXHXVVU55Dkp5nJztMuUrohEWXBsDYd2h28NSYfPMT462Cqtl0bdyjjzgPeAdIBC4HxgD1H/ChYzi5QFpTotO1Ue5HY5vkrYH2Smyxu7KGdCiT+OMqIX3lHW5OakNfyylVMMpzILCzMb5rG8ExrIsV8dQL/369bMqesdV2LVrFz16uLZXRV5eHqGhZy3YsCwoypI3/oAo1wXmYdzhtayvpKQkhg0b5uowVEOwLNj7qkyjjL3/vLsb/LUvzXOs8UmRqrzR18vUEZ0Kdmks4AfgK6AMGAoMBC5huWPla28B/0AKsUynxoIsqoGc3itTmotPSPPxtqNlJLwB1fg3f/ADyN8HV/2ncwq4KLekn/VeLvMrKcjU4z/PK3bmrq+9MWaLZVn9arpP34kaijHgFywLNsvtWjBBKU9UmCk9s9qPdc3x/UPhilshqp+0VTi0Ak462ioEt3dNTJ7qBPApcADoDIwFnHHtzSCjeB8jbRW6OGGf6sKKT0pid3qPXECNmQhh3VwXT2SCjPTn7YVwz7pAqZRCllPlbJMLRV5SyVoTvIbkGyQJnr0QfEJcHY1Sqr5yUuWKfHica+MI7gCxD0g8R1fDvgXSND36evDX95YLKgM2AOuBZsAtgA3njrT1Br5GWixogtdw7MVwbB2c+Fb+LtuOgqhrXH8BNaSLXIzJTtUETylPlP+TzJhp5x3TM0ETvIbl4y9f9gI9CVPK05Tb5ap82JXg5wY18I2RpC6sR9VJ7uldUr0v6lrXn+S6o4PIqN1xJAkbDTTEW7Ef0B+pxnkM8Pz1+e7FsqoubpTmy/q6Nte5z+eq8YGI3vI3WVYgs3eUUp4jJ1WWYoR2d3UkTqNFVhqabxCUl0F5qasjUUrVR/4+OVlztwXXvgFSgKX7w9C8k6wb2PuqTFdTogj4DHgDKAEmAuNomOSuQj/AH9jUgMdoigoOQ/prcOgj8I+ArtOkQqa7JHcVIhIc07y02o5SHsVeDLm7ZKaOF62h9Z5n4q78gqTMelmB9MxRSnmG7FSZix8S6+pIahYQJS0V8vbBkVWQsbTRCk24tV3ASiAfWRs3HJma2dCCkamfPwDX0bDJZFNQmicjdtmpjrWot7l3gaGgNhAULSMBLfu7OhqlVF2d3iWDMJFudjH3MmmC19CMrwz72gvBCnPfDyelVJWyQjj9I0Rd7f5TH0O7QreH4OR3cCxJRvOiroE2Q+W9p6k4jSR2u4FoYDzQ2HVoBgDJSF+9EY18bG9RXiZTHY+vk2nSrQdDqyEycu3uIhKk+EvRiaZ9kUUpT5KdCs0iIbiBe2Y2Mp2i6SRZWVmMHz+e2NhYEhMTGTNmDHv2OKZM+QbJ1I3yy+tjNWvWLGbPnl3nxy9atIgjR45c0rGSkpLYuHHjJW2rlMfL3QGW3XOu6Pn4QqsBcOVjsk7v5Lfw4xw49YOsX/JmFvA90rA8HRgJTKPxkzuAFkij9GRAZ+XXj2XJRZW9r8rIXfPO0P0RKSTkCckdyDo8Y7QnnlKeoiQXzmTIZ72XDcBogucElmUxYcIEhg0bRnp6Olu2bOGFF14gKytLHuAbKL84ZYWNGpcmeEpdopxUCGwNgdGujqR+/JpDh5shdhoEtIDDn0D6AjhzyNWRNYxjyDq7z5GE7iFgEJfU185pBgIFQIoLY/A0RScgYwlkvCOzXjrfCzF3y++wJ/EPgZCuUm7d2y+sKOUNcrbL36qnXMytB03wnGDt2rX4+/szffr0ytsSEhIYMmSIfGOMo9hKoYzkOcTExPBf//Vf9O7dm/79+7Nv3z4AMjIyGDFiBPHx8Vx33XUcPHiw2vHS09Pp27dv5fd79+6t9j3A8uXLSU5OZuLEidhsNgoLC9myZQtDhw4lMTGR0aNHk5mZCcDf/vY3evbsSXx8POPHjycjI4N58+bx8ssvY7PZWL9+vVN/Xkq5teKTkhB58hW94HbQZSp0HCdVB9Nfh0Mfynpgb1CGVKz8J3ASuA24FxlBc7UrkGTzW2R0UdXOXgRH/iWjdgWHod0N0HU6hLrpute6iEyoGhVQSrmviuq8zTvKFE0v43Vr8B5f9TgpR5176dQWbeOvN/y11vvT0tKw2Wy1b2+zkbLlOym0Yi+qVkI5PDyc7du3s3jxYh5//HE+++wzZsyYwaRJk5g0aRJvvPEGjz32GB999FHlNrGxsYSHh5OSkoLNZmPhwoVMmTKl2jFvv/125s6dy+zZs+nXrx+lpaXMmDGDjz/+mFatWrFs2TJ++9vf8sYbb/Diiy/y008/ERAQQE5ODhEREUyfPp2QkBCefPLJy/jJKeWBcrZJYhcR7+pILo8xMmUs9Eo4vgFObITTu2U9U8sBnlstLANpfXASSABGAe7Ul9Ygo3jvAz8CV7k2HLdklUN2Chz9WtoIRfaF6BHe0WA47EqZUpqdCiGdXR2NUqo2hZlQdBw63OTqSBqEjuA1gpSUFEdPPF9J8s5y9913V/67aZPU1960aRMTJkwA4N5772XDhg3n7fOBBx5g4cKF2O12li1bVvn42vz444+kpaUxcuRIbDYbv//97zl8+DAA8fHxTJw4kbfffhs/Pw896VPKGSzLcWLmaFzsDXybyclz90ekIujRr2HP3yF3t2dNIysEPgEWAeXIiN1tuFdyV6EHEIG2TKjJmYOwb4FMHw6Igq4PygmWNyR3IJ/14T3h9E6wl7g6GqVUbXJS5UJnWE9XR9IgvO5s/kIjbQ0lLi6OZcuWXfhBxoBvsJR+Li+rvHpuzpoCZuoxHWzcuHE899xzjBgxgsTERKKioi74eMuyiIuLq0wiz/b555+zbt06Pv30U/7whz+wffv2OsehlFc5cwBKcqCNF5ZAbBYJne6C/P3SVuHAu5LItrsRAlu5OrraWcBO4AtkbdsgYBjSc85d+QDXAquAn3FNwRd3U3paejbmbAf/MOh4u/Sd8tRp0BcSkQCntsqIeaSHzwRQykBtUJEAACAASURBVBuV2+W9KOxKaWfmhXQEzwlGjBhBcXEx8+fPr7xt27Zt569d83X8Etmriq1UJIbLli1jwIABAAwcOJB3330XgCVLllSt5TtLYGAgo0eP5qGHHjpvemaF0NBQ8vLyALjyyis5fvx4ZYJXWlrKjh07KC8v59ChQwwfPpyXXnqJ3Nxc8vPzq22rVJORkyojXuE9XB1JwwnpAt2mS2JXeAT2/gOOfNHoRaDqJBd4B5nuGIZUxxyJeyd3FfoAgegoXnkZHFsnVV1P75L2Hd0fhYhe3pncATTvBM0iZLq3Usr95O+TGXUR3ldcpYImeE5gjGHp0qWsXr2a2NhY4uLieOaZZ4iOlgp8levzfPzk5NFeUDk1Kjs7m/j4eF555RVefvllAObMmcPChQuJj4/nrbfe4pVXXqnxuBMnTsTHx4dRo0bVeP/kyZOZPn06NpsNu93O8uXLefrpp0lISMBms7Fx40bsdjv33HMPvXv3pk+fPjz22GNERERw0003sWLFCi2yopqO8lLI3SmjCj6ekEFcBuMDLa+Rtgot+koPvT1z4GRytUJQLlOOFCn5O/ATMBp4AGjryqDqKQBIREYfc1wciytYFuTugj1z4egaCO0miV2b4fI56M0q1vDmp8usHaWUe8lOlWnhIR5c0OkivG6Kpqu0bduW9957r8b7UlLOKvriGyxTwMqlSdJTTz3FSy+9VO3xnTp1Ys2aNeftZ9asWdW+37BhA1OmTMHXt+aa4OPGjWPcuHGV39tsNtatW3fe42pa49e9e3e2bdOrj6oJOb0b7MVefUXvPH7B0H4stOgno3g/fwankmV0r3kn18R0FCmi8jPQFRiLrGfzRNcgI3ibkSS1qSg6Jr9P+T9Ju5Euk5pewZHIBBm5zNkOrQa6OhqlVIWyQum5GXW11MbwUprgNbaKnnj2gos/9gJuu+020tPTa0wElVKXIDsVmoW7LrFxpaBo6DJZRjCPfgnpCyEiDqJHyc+kMZQC/wY2AkHA7UAcUpXSU4UBvYAfgKHIlE1vVlYIWWvlIoFvALQbA1H9ZMS4qQmIguAOUi205QDvnY6qlKfJ3QGW3fMrZV+EJniNzfhIkmcvJOOnny75TX/FihVODkypJqw0T6ZTtRrSdE/EjJGkLqw7HP9GWiuc3gOtBslXQ05b3Q98BpxC1q6NQpI8bzAA2IYked46kGOVw6ktktzZC2VEuM3wai2BmqTIBPj5cyjKkosoSinXy0mVwmJBnjTnv/40wXMF3yC50mkv8trqPUp5lJztsmYosglNz6yNjz+0GQaRfWQ0LysJsrfKaF54T+cmwAXAl0AK0qR8EuBtM/naIs/pW2TKprfNCMrPgMwvoDALQmKg7Y0Q1MbVUbmH8DipWJudqgmeUu6g+BScOQTR13v9xVxN8FzBJ0BG8uwFmuAp5WqWJdOogjvItColmoVDxzugxdWQuQoOvu+8E3gL2I60ESgChgC/wDOqY16KAcBSpOBKbxfH4iwlOXD0K8jZIb8rne6EsB5ef9JUL37BMiKeux3ajmyaU1WVcic5qfIe1QTal2iC5woVPfHK8mUesPG2S7pKeZCiLCkK0f6Xro7EPYXESDPqUz9A1hrYN+/ypuBlA58D+4AOwE2Atw/4dANaIusLe+HZ6wrLS6um8GLk96DVQO+vPHupIhKkmmheOoR1c3U0SjVdliWj6c07Sy9OL6cJnqv4BUmCV1YI/iGujkappis7RS6yhPdydSTuy/hIsYzwODiWBCe/h9w0aD287kU0KlofrEUSnDFAP5pGsx6DjOJ9ChwAYlwazaWxrKoiPCW50scuemTjFeHxVKHd5PM+J1UTPKVcqeCgzDxoM9zVkTSKpvDR2iiysrIYP348sbGxJCYmMmbMGPbs2VP7Bj7+8mWve3PhWbNmMXv27Do/ftGiRRw5cqTOj68wb948Fi9eXO/tlPI45XZZfxfWXadL14VfkLRQ6DYdAtvCkZWwd56Uw7+QTGABst6uC/AI0J+m9QmUADRHRvE8TeFR2L9Ipun6BkHsFOh4uyZ3deHjC+G9HW1YilwdjVJNV/Y26cEZ1sPVkTQKHcFzAsuymDBhAlOnTuXdd98FIDU1laysLLp37177hr5BUHpaprw0wPSWRYsW0atXL9q1a3fefXa7vdb+edOnT3d6LEq5pfx0KDsDkTZXR+JZAltD53vlpDXzS9j/JoT3gLajoFlk1eNKgCSkF1xz4E6gB549RfFS+QFXIz+PE8iUTXdXViDTck9tkc+r9mOhRV9dS1ZfkQlw8jsZAW3R19XRKNX0lJdKe4SwHpLkNQH6Lu0Ea9euxd/fv1pilJCQwJAhQy64XUy3XvzXb39P73gb/fv3Z9++fQBkZGQwYsQI4uPjue666zh48GC17dLT0+nbt+pDYu/evdW+B1i+fDnJyclMnDgRm81GYWEhMTExPP300/Tt25f333+fBQsWcPXVV5OQkMC4ceMoKJDefGePFA4bNoynn36a/v370717d9avX3/pPyil3E1OqqwjC+nq6kg8jzGS1HV/BKJHQN4+2PN3OLoG7CWyxu5VZMSqL/Ao0JOmmdxVuBpJ9Da5OpCLKLfDic3w499k7WVUf+g+o+n2tLtcQe2kgFN2qqsjUappOr1HRtCbUKVsrxvBW7VvFUfzjzp1n9Eh0dzQ9YZa709LS8Nmq30EwGazkZKSUuN94RGRbP/+axa/9y8ef/xxPvvsM2bMmMGkSZOYNGkSb7zxBo899hgfffRR5TaxsbGEh4eTkpKCzWZj4cKFTJkypdp+b7/9dubOncvs2bPp169f5e1RUVH88MMPAJw8eZJp06YB8D//8z+8/vrrzJgx47wYy8rK+O6771i5ciXPPfccq1evrvW5KuUx7EVw+kdokSjTqNSl8fGD1r+QUdDMr+DndbAuBfaNhLBeMMVAE+wdX6PmyFTNVGCE43t3k78fjnwBRcchpAu0u0FGbNWlM0ZOLI+ukTVAzSJcHZFSTUtOqhRWaR7j6kgajV6KawS1JXcAd989Eaxy7r7rV2zaJJd1N23axIQJEwC499572bBhw3nbPfDAAyxcuBC73c6yZcsqH38xd911V+X/09LSGDJkCL1792bJkiXs2LGjxm1+9atfAZCYmEhGRkadjqOU28vdAeVlUuVOXT6/MDg1DtZOhczm0OsDGLUQWme6OjL3MgAoA753dSDnKMmGjHdh/2L5u+g0XqbhanLnHBGOsuw521wbh1JNTWm+zDCJjG9SMxC8bgTvQiNtDSUuLo5ly5Zd0rbGL1Cu7tkLMfXoHzRu3Diee+45RowYQWJiIlFRdevf1bx51SXjyZMn89FHH5GQkMCiRYtISkqqcZuAgAAAfH19KSsrq3OMSrm17FQIbAVBbV0diec7BXwG7Ac6doSx08AvBY5+DfvmS9P06OvAzx2HrBpZS6A7kuANwvW9/+wlcHw9nNgkJz/R10HLATIyq5ynWYS0HMlOhVZDtF+gpzkCkcmR0A6pgts0lnF5h9w0sMqrLrI0EU0nlW1AI0aMoLi4mPnz51fetm3btjqtV1v23nvgG8SyZe8xYMC1AAwcOLCyWMuSJUtqXMsXGBjI6NGjeeihh86bnlkhNDSUvLy8Wo+dl5dH27ZtKS0tZcmSJReNVSmvUXwKzhyU0Ts90bp0dmADstbuZ2AsMAVo7SPFJK6cAVHXSiuKH+fA8U2yvqupGwicAVw5mGNZUlVuzxw4th7Ce0L3R6H1EE3uGkpEAhSfhMKfXR2Jqg8L+BjC08JhKfASsAhYj7zvlbswNnVx2akQ3K7JzUbQBM8JjDEsXbqU1atXExsbS1xcHM888wzR0dEAF1yfl52dTXy/Ibzy99d4+f+9AMCcOXNYuHAh8fHxvPXWW7zyyis1bjtx4kR8fHwYNWpUjfdPnjyZ6dOnVxZZOdf//d//cc011zBo0CCuuuqq+j5tpTxXzjbHupimdUXPqX4G5gOrkUbejyJ97c7Ol30Dod1o6PYwBHeAzH/B3n/IdJmmrBPQFim2Yrng+AVHYP8bcOhD8A+F2Pvhil81iea/LhXeUypma7EVz7IDyIITg07AfcC1QDHwNdL+5f8B7wNbgByXRalqUnQMCjOb5FIMvUznJG3btuW9996r8b4LrcF76qmneOnFF6H4mDRbBjp16sSaNWvOe+ysWbOqfb9hwwamTJlSa7uDcePGMW7cuMrvz10/99BDD/HQQw9d8DhnT9ts2bKlrsFTns+y5ASreWc9ob0UxUiz8s1AKDAeuNj1ocCWEDMR8vZC5ir46W0IuxLajoaAFg0dsfsxyCjeB8BeZMpmYyg7I9Nms7eCbzB0uEWK4+goduPwDYCwq2TKWNvROlLqCcqR97vWkN81X/p4dnHcdwaZlp7u+LeijEEUEOt4XGcgoFEjVmfLTpWp5xG9XB1Jo9N3F3dgjHzYlubJ4vY6vOnfdtttpKen15gIKqUuoOCgFJRoM8zVkXiePcDnwGmk5P911P3kxRhpKB/SBU5uhmP/lrYKrQbImiTfJnYW1BP4Cmkj0dAJXrld+rAdS5J+UC0HSOVT38AGPrA6T2QC5GyXix3hTaPhskfbBpxELmSdW6C9OdDb8WUh/S3THV9bge+QeXIdqEr42qNz5xqLVS6zdUK7Nsn135rguVC10TDfIEnw7IXgE3rRbVesWNFwgSnlzbJTpdFpmJ5c1Vk+8AVyhbo1MBW44hL35eMHrQbJgvejX8OxDfKaRF8vtzWV0SRfZKrXl0AmMmWzIeTtgyOroPgEhHaTkaNAT+iy7qVCuoB/iPzOa4Ln3uxAElJY5UrOT/DOZoBWjq9rkUq5h6lK+JKQkcBAZFSvC5L0NcEJDI0m/yc5r27b+MUX3YEmeO7Cxw98moG9APxCms5JjlKNqbxU2iOE9ZQkT12YhVyJ/hIoRXq3DUKSk8vlHwpX3CrNs498AYdWwMnvod2NENzeCQfwAH2BfyOjeOMu8tj6Kj4pax5P75Em2zETZARVuZbxkQsZJzZDWQH4Bbs6IlWbH5A1dWOpvra4LvyQapsxyEyHAuAnqhK+XY7HRVJ9OmfQZcasquSkyiyFsCtdHYlLaILnTvyCoCRXTkL15FMp5zv9I9iLZZqUurATSOuDDOQkZSxS4t/ZgjtA7APyYXx0NexbIOvCoq+XkQ5vFogkeZuB64FwJ+zTXgzH1sGJb+XCYduRUsnUxxlZuXKKiAQ4vhFy0qBlf1dHo2pSCqxDCiLFOmF/wUCc48tCWstUJHvbgWQkiWxPVcLXAedcTGuK7CWQu0supjTRta5N81m7K98gMLkyiqcJnlLOl50KzcKheYyrI3FfduAb5OTGD7gZ6EP9r2DXhzGS1IX1qEpOTu+SdWLenpxcgyR4m4GaCyLXjWVVJcml+U0nSfZEQW0gKFpeL03w3NP3QB5wO85/7zNIIZYooD/ynvszVcVa1iEj+82oPp0zqgFi8Vand8lgSRO+mKsJnjsxPuATJOvwrHCdpqmUM5XmQ366rP/Sv62aHQI+BY4BvYAbgMbMD3wDZMSpRV+ZXpj5FZz6QdaNeev0wgik4MoWYCiXVnGv4LBMcy34WUZEO93ddKa5eqqIBPkdLzqhayLdTTHS3zMWGcFraL5AR8fXcKCIqumc+4EfHY8Lp2p0rwsyKqhqlp0KzSIh+FIXi3s+reXjJFlZWYwfP57Y2FgSExMZM2YMe/bsqfd+5r3+Novffg/sRQ0QpXj22WdZvXr1ebcnJSUxduzY825PSUlh5cqVl3SsnJwcXn311UvaVimnytkuVbWaYD+ciypGqmO+4fj/BOTKtasGfyrWjHW+BzCQsRR+WiInw95oAPJz/6Ge25XmwaGPYN9rUJoLV9wmPe00uXN/Eb3lQlOO9sRzO5uRNXMjXHT8QKAHMi3+MeDXjv+3A3YCy5Hee/ORXnw/IUVdlCjJhTM/yehdE76YqyN4TmBZFhMmTGDq1Km8++67AKSmppKVlUX37vW76jz9oUehKEtG8fwaZrXt888/X6/Hp6SkkJyczJgxY+p9rIoE7+GHH673tko5VU6qnPjq1fLqdgMrkelI1yAnNe4yQzy0K3R7qKrE/95XoeW13lfivz0yUrAZeQ0udum1vKyq1US5HVoPbpqtJjyZfwiExEoZ9zYjmvSJqFspRIoeXYX8XbqDSKCf46scOELV+r1vgPWAP7JWumI6Zyua7nTOnO0yZT0i3tWRuJSO4DnB2rVr8ff3Z/r06ZW3JSQkMGTIkAtuN3PmTHr27El8fDxPPvkkALOee47Zr7wG9iK+/+5b4uPjsdlsPPXUU/TqJY0aFy1axK233srIkSOJiYlh7ty5/OUvf6FPnz5ce+21nDp1CpDE7NprryU+Pp7bbruN7OxsACZPnszy5csBWLVqFVdddRV9+/blww8/PC/GkpISnn32WZYtW4bNZmPZsmWcOXOGqVOn0r9/f/r06cPHH38MwI4dO+jfvz82m434+Hj27t3LzJkzSU9Pr3wOSrlE4VH50tG7KnnAMuBdpHLbA8iUTHdJ7ir4+EqvvO4zZF3ZiU3w4xw4tVU+xL3FAKRi384LPMaypFDQ3ldl+mrzztD9EVlrp8md54lMcIw2ZLg6ElVhIzKaPtzVgdSioq/eUKRdzdPA3cg66WzgX8CrwF+Aj5A+fvkuidQ1KtYiN+8IAU27B4X3jeA9DqQ4eZ824K+1352WlobNZqt9c5uNlJTqQZ08eZIVK1awe/dujDHk5ORU3enrD8CUKVNZ8NrrDBgwgJkzZ553zK1bt1JUVETXrl156aWX2Lp1K7/5zW9YvHgxjz/+OPfddx9z5sxh6NChPPvsszz33HP89a9VT6SoqIhp06axZs0aunbtyl133XVe7M2aNeP5558nOTmZuXPnAvDf//3fjBgxgjfeeIOcnBz69+/P9ddfz7x58/j1r3/NxIkTKSkpwW638+KLL5KWlnbe81eqUeVsA+MLEb1cHYnrWch6r6+Qxf3XI8mFu9cx8Q+BDjdDi36Q+QUc/hhOfQ9tb4TmXrDO4kqkiMImpNLeuVffi05A5irpaxfQUqavhnZt9DCVE4VdJYl5zjYI6ezqaNQZZBS9F9DGxbHUVQDy3lHRCSCXqtG9H6k6H46manSvIzLi540KM6HoOHS4ydWRuJyO4DWCmpKb8PBwAgMDuf/++/nwww8JDj5rtazxJef0GfLy8hgwYAAAEyZMqLb98OHDCQ0NpVWrVoSHh3PTTfLL3Lt3bzIyMsjNzSUnJ4ehQ4cCMGnSJNatW1dtH7t376Zz585069YNYwz33HNPnZ7Pl19+yYsvvojNZmPYsGEUFRVx8OBBBgwYwB//+EdeeuklDhw4QFCQNnRRbsAqlxOo0G7ac+o4sBBpf9AeeBgYjPsnd2cLbgddpsIVv5I1aOmvw6EP5f+ezCANkn8GDp51u70IjvxLRu0KDkO7G2TaqiZ3ns/HH8J7Sm/O8lJXR6PWI2vZhrk4jssRjrReuQN4CngQ6cMXhCSvbwEvOf79Bmne7kUTIchJlbYIYT1dHYnLed8I3gVG2hpKXFwcy5Ytq9c2fn5+fPfdd3z99dcsX76cuXPnsmbNmqoH+AYBlrzp+5x/qSUgoGo6jo+PT+X3Pj4+lJU17Gpby7L44IMPuPLK6s0je/TowTXXXMPnn3/OmDFj+Oc//0mXLl0aNBalLiovXSpotqt9lN3rlSEnLxuQKZi3Agl47hoNYyAyXkZAjq+XaZund8s6tJYDPLfvkQ1Yi4zidSyH7BQ4+rW0zonsC9EjwK+5i4NUThWRINONT++WwivKNU4jvegSkJF0b+CDFGZpBwwBSoADVFXn/Mrx1Zyq6pyxQKgrgnWCcrusvwu7ssFqWHgSHcFzghEjRlBcXMz8+fMrb9u2bRvr16+vdZv8/Hxyc3MZM2YML7/8Mqmp1StpRUS1JTQkhM2bZB8VxVvqKjw8nMjIyMoY3nrrrcrRvApXXXUVGRkZpKenA/DOO+/UuK/Q0FDy8qqujo8ePZo5c+ZgOda/bN26FYD9+/fTpUsXHnvsMW655Ra2bdt23rZKNbqcVHmzD+3m6khc4wAwD+mrFAc8iiQSnprcnc23GURfJ+vQmneRZGjP3yF3t2euz/NHCimkH4TUBXD4E6ko2vVBmXKkyZ33ad4JmkVIWXflOuuQkayhF3ugB2sGdEPWWj8MPIFc7OuCJH0fAX9G1vD9C9iLJIWeIn8flBU0+eIqFTTBcwJjDEuXLmX16tXExsYSFxfHM888Q3R0NECN6/Py8vIYO3Ys8fHxDB48mL/85S/VH+Djy+v//BvTpj+KzWbjzJkzhIeH1yuuN998k6eeeor4+HhSUlJ49tlnq90fGBjI/Pnz+eUvf0nfvn1p3bp1jfsZPnw4O3furCyy8rvf/Y7S0lLi4+OJi4vjd7/7HQDvvfcevXr1wmazkZaWxn333UdUVBSDBg2iV69eWmRFNT57kVwZD+/t3c2ya1KE9LRbiIzg3QP8Crla622aRULMeOhyn8x4OPAuZLwtazE8Selp6PABhL8B+89Ax3HQZQoEtXV1ZKqhGCMnpPnpnj/N2FNlIy1KEpG+lE1FGHKxbxzwJDAdGIm0x/keWIJM53wTmQFyBPeezpmdKsswQnT6OoCxPOwqZ79+/azk5ORqt+3atYsePXq4KCKRl5dHaKhzx7Xzc44T0qwUAqJ48f+9TGZmJq+88opTj+Fu3OG1rK+kpCSGDRvm6jBUTU79IKMgXac1SG8wt3ztLWAX0vrgDFJAZRjuVx2zoVjlcPJ7yFoL5SUQdTW0Hub0KTtOfe3Ly+DERji2HrBgz0DYNRh+00ybGbuZBvmbLzoBe+ZC21HQaqBz960ubgWwA+k3d4HTOLd8v28opcha4IrpnEcdtwdT1Wg9Flnz5w7KCmHXbIjqB+1udPru3fW1N8ZssSyrX033eehChabh81WreeGPv6fMXk6nmC4sWrTI1SEp5VmyU6XiYFA7V0fSOHKRxO5HoC0w0fFvU2J8oOU1sp4pa4300MvZLr3GWvSV+92FZckIc+aXUJIN4T3kJL91pJQ3TwZ+4eogVYMLbAnBHWQ6uSZ4jes48rc2AM9de9YQ/JEELtbxfT6S6FUkfGmO21tSlezFIFU9XSF3B1h2bYV0Fk3w3Nhd4+/mrl/dKE3PA9u414mJUu6uJBvOHJA1Wt7eRLgcmVLzNTKCNwqpyNiU3zL8gqH9WGmrcOQL+PkzOJUsV3ebd3J1dFB0DI6sgvz9ENhappeGOIpStQa6At8BA9FP6qYgMgF+/lz6dQZFuzqapiMJmd0w2MVxuLsQIN7xZSGJcUWytxV5r/IBrqAq4WtH430G5aRCYCudzn4W/dhwd75BsmjUXqQl3pWqj+xtVetbvFkWstbuMJIU/BKIdGlE7iUoGrpMhtydcPRLSF8o/RCjR0IzF8wvKiuEY0kyjdQ3ANqNkWlF517AGwgsBrYjTYyVdwuPk4Q/O1UTvMaSiUzNHIpOha4Pg1yEao2MfJYBh6hK+JKQasCBVJ/O2VCfS8Wn4MwhiL7e+y/m1oMmeO7Op5k0aLYXaIKnVF1ZllzRax7jmpP4xlCKVH77BulxNA5p0Kufb+czBiLiIKw7HP8Gjm+A0z9Cq8EyJa6GVjROZ5XDqS2yNtBeKCOLbYbX/r7eGWm2vAnvqXqqaucXLL+fuduh7UidsdMY1iLvnQNcHYiH80Perzo7vi+g+nTOnY7bW1CV7HVGEkBnyNlW1TpHVdIEz90ZI2/8pXmyEN9T+zsp1ZgKDstVvdZeuoDpJ2TU7hRy8j8KvQJdFz7+0GYYRNrg6FeSbGVvlXVvYT0a7upvfgZkfgGFWRASA21vuPgojUFG8VYgJ0paGM77RSRA7i7p3RnWRNu6NJZDwB7gepyXaCgRjFxs7IVM5zyJvIelU7W22AAdqEr42gOXUujasmTUu3ln8A9zQvDeQ7MFT+AbJAmevRB8dBWwUheVnSIn82GeVZH1ogqBL5E1Dy2A+5APSFU/zSKg4x3Q4mpJvA6850i8boSgNs47TkmOJJI5O2QkueMdEN6z7olkL2A1sBFN8JqC0G5S7TUnVRO8hrYGaRnT39WBeDmDFGJpCVwD2JHlBBWje+uQHq0ByKheRcLXgrrNWig4JOvt2wxzeuieTucAOElWVhbjx48nNjaWxMRExowZw549e+q9n3nz5rF48eLqN/r4yVRNe6FTmvc+++yzrF69+rzbk5KSGDt27Hm3p6SksHLlynof58iRI9x+++2XFKNSl6y8TCpqhfeUNU7ewEKqls0FUoEhwENocne5QmKg639A+19CURbsmyeFLsoKLm+/5aWQlSSl70/vkZOP7o/KNNH6jBL6IidFZ5cpV97LxxfCe0llVXuRq6PxXj85vobQdNrHuAtfoBMwAngA+C/gTuRi1lGkCvQc4BXgE2SNZOEF9ped6p0Xc51AR/CcwLIsJkyYwNSpU3n33XcBSE1NJSsri+7du9drX9OnT6/5Dr8gKMmVEwffy3tHev755+v1+JSUFJKTkxkzZsx595WVleHnV/OvUbt27Vi+fPklxajUJTv9o5wcRXpJueQc4HNgLzKN5T5kbZZyDuMjvfLCe8mUzVPJkJsGrYfXXPzkQiyrqphLSa4kdNGjLm8daCJylXsTcNul70Z5iMgEKcCTuwtaaHUdp7OQ0bswoMbuYapRBQE9HV8W0nS+YnRvB9KA3iAVOStG965AEsXy0rMu5mqmfi5N8Jxg7dq1+Pv7V0vOEhIufnI5c+ZMPvnkE/z8/Bg1ahSzZ89m1qxZhISE8OSTT/L9999z//334+Pjw8jrr+eLLz4jbetmFr21lI8++ogzZ86wd+9ennzySUpKSnjrrbcICAhg5cqVtGjRgpSUFKZPn05ByTWOWQAAIABJREFUQQGxsbG88cYbREZGMnnyZMaOHcvtt9/OqlWrePzxxwkODmbw4PPrBJeUlPDss89SWFjIhg0beOaZZ9i1axfp6ens37+fjh078sILL3Dvvfdy5swZAObOncvAgQPJyMhg7NixpKWlsWjRIj755BMKCgpIT0/ntttu409/+pPzXgSlKuSkylz85jGujuTylAObkZMRA9wIXI3Ou2gofkHQ3lHR8sgXcGRlVVuFkM4X377wKGSukvV2QdHQ5TYZIbxcQUgVzWRkvZDO0vduQe0hIErexzTBc769yPq7m9AzYHdjkKmZLZDPunLgZ6oSvm+A9cioawzQYQ80K4KOXnIx18m879d7Fc6fyhIN3FD73Wlpadhstlrvt9lspKSkVLvt5MmTrFixgt27d2OMIScn57ztpkyZwoIFCxgwYAAzZ84ETOU0zbS0NLZu3UpRURFdu3blpZdeYuvWrfzmN79h8eLFPP7449x3333MmTOHoUOH8uyzz/Lcc8/x17/+tXL/RUVFTJs2jTVr1tC1a1fuuuuu82Jo1qwZzz//PMnJycydOxeAWbNmsXPnTjZs2EBQUBAFBQV89dVXBAYGsnfvXu6++26Sk5PP21dKSgpbt24lICCAK6+8khkzZnDFFVfU/oNVqr7KzkDePqmM6MlV6I4i01OOAN2R1gdeWgzU7QS2hs73ORqQ/wv2v+loQD5a1u6dq6xAGqqf2iLrpduPdX5D9WuRPlObkSRPeS9jZBTv6BpZw1nT75y6NBZSObMFUpxKubeKvnpXAMOAIiCDqoQvMxV8w2BjTNXoXhdkbaXSa8GN4dzkDiA8PJzAwEDuv/9+PvzwQ4KDq5fAy8nJIS8vjwEDpH7vhAkT5ITBKofyUoYPH05oaCitWrUiPDycm266CYDevXuTkZFBbm4uOTk5DB06FIBJkyaxbt26asfYvXs3nTt3plu3bhhjuOeee+r8nG6++WaCgoIAKC0tZdq0afTu3Zs77riDnTt31rjNddddV/m8e/bsyYEDB+p8PKXqJGe7/I1EeOgVvVLgK2A+cBq4A7gbTe4amzGS1HV/FKJHyEWDPXPlpNteIo+xyuHEZv4/e3ce3+R5JXz/d0neV8kGvLEbzGJsmc2JSSBkaZImTZOGNAkJWTudSWemfabJPO30nT7PdJa+0z5vmrTvdDqdtGkTKNnThCw0SQMhkLCYVbbZIewGA0byvsrX88dlAwYbb5JuST7fz8cfsCXf9wHZks59nesc9v7/cG4bpBdD3rcHXtbZH05gGmYVr9W/hxYhqGt2p7fM2jgizW7M7LuFDK5jo7BWHDAVc8HzWw2w4ADMKoTRNtgLvAn8f8B/Y15Hv8DM6BumIm8F7worbYGSn5/Pq6++OqDviYqKorS0lFWrVvHGG2/wy1/+ktWrV/fxXcq8cehoJTb2QvMIm812/nObzUZ7e+B/ohMTL1wiefbZZ8nIyMDtdtPR0UFcXM89hy+O2W63ByVOMcx43JCQDXEjrY5k4A4C72H2IMzGrNTEWxqRsEWZURvOIjj5Zzi91nRoHXE12Y3vQKUDkiZC9q1m5S+QSjDzpLZjGq+IyBXjMOW9HjeMnC/Dm/2hA7N6NxLT0EOEN285xHZAQaFJ/DowyXvX6t5GTElnFKapS27nxyiGzUxRWcHzgxtuuIGWlhaee+65818rKytj3bp1vX5PfX09NTU13HbbbTz77LO43e5utzscDpKTk9m0aRPA+eYt2OPNxtI+ummmpqbidDrPx7Bs2bLzq3ldpk6dyuHDhzl48CAAL7/8co/HSk5Opq6urtdz1dTUkJWVhc1mY9myZfh8vivGJkRANFVB08nwW71rxMw6W4Z5Rn4Usz9EkrvQEZ0CYxdB7uMQlQgnP0Lpdhh3P0x4KPDJHVwoVdqIeTMjIpvDBS3V0HTC6kgiQzlwBrgeeecbCTxuiM+68NxrwzQhW4B5Df0+8ADmYmktZrzQfwE/A/6I6Ubd+9vaiBB5K3gWUErx0ksv8cMf/pCf/vSnxMXFMX78+PP73Xrag1dXV8edd95Jc3MzWmueeeaZy477/PPP881vfhObzcZ1111HamqqGXoOoPte/XrxxRfPN1mZOHEiv//977vdHhcXx3PPPcftt99OQkIC8+fP7zGRu/766/nJT35CUVERP/jBDy67/a//+q9ZtGgRS5cu5dZbb+22uidE0HjLzAq3I0wuz2rM0NcPgRbgOkzbbnlWDl2JY2HSN6HpFJXVu5mcOjW4558HvArswXSdE5ErdTpUvt9ZlTDa6mjCmw9YA2RhSp1FeGs+bS7mZl+hZC8Gs3+9q5F9LRdW9w5gXnvBdKTu2r83DogOTMhWUNoPc9WCac6cOfrSBh67d+9m2jRrf2vr6upITvZve7P6+nqSkpIA+MlPfsLJkyf5xc9/Di1nABWeZWh9CIXHcqDWrFnDwoULrQ5jeNMdsOdZiM+G8YuDdtpBP/YeTDnmQcyqzB2Y0hERNiz5ve/AzEJMBL4R3FMLI6iP+9E3of4ATH3KlAuLwdkKvAs8CAxhfry81oeIk3+Gsxtg2lOmomKgNKaRWVfCdwRzEcAOjOVCOWcm58s5Q/WxV0pt1Vr3OPBDnjFC2Pvvv8+///u/097ezrhx43jhhRdMLb49AdpqTammLYIuNwgxWPVfQFsdZId4eWYHZp7ZGkxJye2YWUzDZE+AGCIbpqPmSkyrd2lCHNmcLrPXqG6/afojBq4d+BTzuzLJ4ljE0OkOU62TPGlwyR2Y19uszo9rMc3NjnAh4fu48yOB86t79obw68ojCV4Iu++++3ocXYA93iR4viZJ8IQAU8YUFQ/JeX3f1yqVmNEHpzCdwG7DDNsVYiCKMM0iNiAJXqRLmgjRSeb5TRK8wdmCKc/7GnIhLRI0HDYXc7P82FExGpP8d10AqMMkel0JXwVk1GSYC7JhRBK8cGSzgz0W2psgKlk6bInhzddiZpY5i0KzjKkV84Z8I5AE3IfsAxGDF4NZ9f0MU+rrtDYcEUDKZkYmnN1k5i1GJfT9PeKCVsxg7InABItjEf7hcYM9DlKmBO4cyYCr80MDp+HcJ+cCd74AkV5C4coeD9oHHTIUSQxzNbtMubIzBMsz9wO/wqy2zAH+BknuxNAVY169N1odiAg4h8u81nsrrI4k/GwCGoAbrA5E+IWv1bzep+YH72KuAjKgObM5OOfzo4AmeEqpW5VSe5VSB5RS/9DD7eOUUquUUmVKqTVKKWkV1V/2OLNy52u0OhIhrOV1Q2w6xOdYHckF9cAbwHJM+cfjmPKOnkdECjEwyUABZiZek8WxiMCKzzAfXnff9xUXNGPmoOUB8s4yMtTuDt2LuSEoYAmeUsoO/CfwZUxD58VKqUsbOz8NLNVaFwL/Avx7oOKJOMpmVvF8zWbTqRDDUasX6g+bJ/xQKFXWmDfd/wnsxsxc+itMZy4h/KkEU4K21epARMA5XNB4AprPWh1J+NiASfJk9S5yeNwQ44QE2XzcH4FcwSsGDmitv9BatwKvAHdecp/pwOrOv3/Sw+1ho6qqivvvv5/c3Fxmz57Nbbfdxr59+wZ0jIULF3LpCAiAlpYWbrrpJoqKinj11Vcv3GCP54Wlr1B57NCgYl6zZg3r168f1PcKERK8ncNsHIXWxgFQDbwIrMCMPPgWZrZdCG4LFBEgA9PKexOmxbeIXI4CcwGr6/lOXFkDJsHLx7S6F+GvrRYaDoXOxdwwEMi3HjmYRs5djgNXXXIfN3A38AtMj6NkpVS61rr64jsppf4S+EuAjIwM1qxZ0+0gqampPQ7oDhatNQ888AAPPPAAv/nNbwAoLy/n0KFDZGVl9esYPp8Pn89HQ0PDZf+W0tJSfD4f69atA7hwu9b8btlrTJqSR7Jz4EO0PvzwQ5KSkigoKBjw9wZKc3PzZY9vqKuvrw+7mCOC1uQ0vIXPlsCpczssCaG+vp41q9aQujMVh9uBtmvOzT5H/fh6kC0zES0Ufu/jbfFklGdw5vdnaJjUYGksw4VVj3tGYyvRR97keKKSN7h9cG52krI/hcr8StrWtPntuKHwOz9cpbaU42w5xPEzM2nfvSbo5w/Lx15rHZAP4B7gtxd9/hDwy0vukw38EVPU9AtMEui40nFnz56tL7Vr167LvhZMq1at0vPmzRvw940bN05/73vf0zNnztQvv/yyvu666/R3vvMd7XK5dH5+vt60aZOuqqrSubm5OiUlRbtcLn3gwIHz3//666/rxMREnTd5ona5XLqxsVFv2bJFL1iwQM+aNUvffPPNurKyUmut9S9+8Qs9bdo0XVBQoO+77z596NAhnZGRobOzs7XL5dJr16712//HUFj9WA7GJ598YnUIw1PDMa3d/6R19TbLQlj/2nqt/1Nr/U9a69e01rWWhSKCLCR+7zu0+fn7VeffRcBZ9rh7yszzXd0ha84fLmq11v+qtX7L/4cOid/54aijQ+u9v9T6wPOWhRCqjz2wRfeSLwVyBe8E3af0jO782sXJZSVmBQ+lVBKwSGvtHdJZt/4dePx8Nd9ZBLN/3uvNFRUVFBUV9Xp7UVERO3b0HFN6ejrbtm0D4Ne//jWNjY3s2LGDtWvX8vjjj1NRUcFvf/tbnn76ad57771u33vPPffwy1/+B0//2z8w56r5tBHFt7/9bVasWMHIkSN59dVX+cd//Ed+97vf8ZOf/IRDhw4RGxuL1+vF4XDwxBNPkJSUxN///d8P4j9FCIt53GYOZOqlW3uDoAP4M2SuzDTNLhYDAezaLESPFGYv3grgEKYdvIhMKVPNeCSvG5LGWx1N6FqLeX6+zupAhN80nYTmMzD6DqsjCSuBTPA2A5OVUhMwid39wAMX30EpNQI4p7XuAH4A/C6A8Vimt+QOuGyQ+eLFiwFYsGABtbW1eL195bsKVBT4Gtm7/xAVFRV86UtfAkzZZ1eJaGFhIQ8++CB33XUXd9111+D/MUKEgo52qKm48KYnmHyYuoOdUDelzow+CHIIQpxXAKwC1iMJXiTruphVsxOybzOfi+68wDZgFjIfMpJ43aDskGLBxdwwFrAET2vdrpT6W+BDwA78Tmu9Uyn1L5glxXeAhcC/K6U05rrL3wz5xFdYaQuU/Pz87s1PBiAxMbHb5+qS2vpLP++RPQ462tG+NvLz89mwYcNld3n//fdZu3Yt7777Lj/+8Y8pLy8fVLxChIS6fdDeZFbXg8mHGX+wG7gZzrWek+ROWCsK09JsNXAa0+BHRCaHC85th9o9pvGK6O5TzKr2AqsDEX7T4QNvuRlsHhVvdTRhJaBz8LTWK7XWeVrrXK31jzu/9r87kzu01m9orSd33ucvtNYtgYwnUG644QZaWlp47rnnzn+trKzsfFOUgehKFD/77DNSU1NJTU294v2Tk5OpazTDzqdMGsOZM2fOJ3htbW3s3LmTjo4Ojh07xvXXX89Pf/pTampqqK+vN99rYXMaIQbN44boZEiaELxztgOvYpK7LwPzgndqIa5oDmbe4uXX9kQkSRwHManm+U90Vw3sAOYCKRbHIvyn/gC0N8rsu0EIaII3XCileOmll/j444/Jzc0lPz+fH/zgB2Rmmv68V9qfd6m4uDhmzpzJE088wfPPP9/n/R999FGe+NZfU1RyC77Wet54/XW+//3v43K5KCoqYv369fh8PpYsWUJBQQEzZ87kO9/5Dg6HgzvuuIO33nqLoqKiQSWjQliivQHq9pvRCCpIT2FtwMvAPuAOLu8HLISVEoAioAyotzgWEThKmVW8+oPQJhdnu/kEc5HjWqsDEX7lcUNUAiRNsjqSsCMTmvwkKyuL1157rcfbetuDd/jw4W6f99aCdeHChSxcuLDH2xYtWsSiRYvMwPOWcxQVTmPt2rWX3e+zzz677Gt5eXmUlclcHRFmvBWgO4J3Ra8Vk9wdxkzqnBmc0woxICXAFqAUGe4cyRyFcHqtKVsbKWUEAFRhxtLMBxL7uK8IH+1NZjtG2myw2a2OJuzICl6ksMWa1Yz2RqsjESKwvG6Iz4K4IGw2agGWY5K7ryHJnQhdaZhOrlswK84iMsWNgITR5nlQGJ8AcUjZfKSp3WUaqjmkPHMwJMGLFEqBPd6s5OkOq6MRIjCaT0NjZXBW75qBZcAxzFTPwsCfUoghmQc0YvYiicjldEFTFTSdsjoS650A9mB+9qUHR2TxuCFupLmgKwZMErxI0tVhyNdkbRxCBIq3zKxUB7qDXBOwFDgJ3AvkB/Z0QvjFGCAH2Ahoi2MRgZOab9rGS7MV0z02AdkXHWlazkHDUbN6159u8uIykuBFEhUNtigp0xSRSXeApwySJ0FUADdaNAIvYlrO3wdMDdyphPArhVnJqAb2WhyLCJyoBEieDDXlw7ti5zBwELP3TsbVRBZvWWdTIRkHMliS4EUSpcCeAB1tpm5ZiEjScBjaagNbj18PvACcBRYDeYE7lRABMQ1wICMTIp3TBW31UP+F1ZFYQ2NW75IxY0JE5NDarE4nTjBjQcSgSIIXaexdZZqyiicijGcH2OPMwNNAqMMkdx7gQSA3MKcRIqBswNXAEcz+JBGZkiebbRnDtUzzIHAUM9Q82uJYhH81HoNWj8y+GyJJ8PykqqqK+++/n9zcXGbPns1tt93Gvn37BnSMhQsXsmXLlsu+3tLSwk033URRUdH5QehdXnjhBSorKy98wWYHe6xpL6t734Tx61//mqVLlw4oPiEs42uBmt3gmGHKkP2tBvg9UAssAYI4P10Iv5uJ6Sooq3iRyxYFqTOgdrd5fhxOulbvHMAsi2MR/udxgy0aUqZZHUlYkzl4fqC15oEHHuDxxx/nlVdeAcDtdlNVVUVeXv9qvHw+X6+3bd++Heh5nt4LL7zAjBkzyM7OvvBFezz4vPjamrDHJPR4zCeeeKJfcQkREmp3m9LjQJRnejB77pqBh4HR/j+FEEEVC8zGJHhezBthEXmcLqjeDDW7IG0YzXDZA1QCdwEyHi2ydLRDzU5InQ72GKujCWuygucHn3zyCdHR0d2SJpfLxfz586/4fePHj+f73/8+s2bN4vXXXwdg2bJlFBUVMWPGDEpLSzl9+jRLlixh8+bNFBUVcfDgwfPf/8Ybb7BlyxYefPBBioqKaGpqMsf8f37ErHm38PprL/Ob3/yGuXPn4nK5WLRoEY2NpnTzRz/6EU8//TRgVg6///3vU1xcTF5eHuvWrfP3f5EQQ+NxQ2yamf/kT+cwZZktSHInIktXV8FNlkYhAik+B2LTh9dMvA7M3LsRyOiaSFS714z7csiDO1SRt4JX+QE0+3k2TFwmZN/a680VFRUUFRX1entRUVGPq28A6enpbNu2DTBlk42NjezYsYO1a9fy+OOPU1FRwW9/+1uefvpp3nvvvW7fe8899/DLX/6Sp59+mjlzLuwyTh8xgm2la8HXTHVDFN/85jcB+OEPf8jzzz/Pt7/97cviaG9vp7S0lJUrV/LP//zPfPzxx73/fwgRTK01psHKqIX+bZd8FrNy5wMeATL9d2ghLJcCzAC2AddhSjZFZFHKrOKdWg2tXogZBku1OzEdjr+OLFFEIq8bopMhSfZJDJX8egRBb8kdwH333dft88WLFwOwYMECamtr8Xq9Az7ffffdZ7ppak1F2Tbmz59PQUEBy5cvZ+fOnT1+z9133w3A7NmzOXz48IDPKUTAeMvMflKnH6/oncas3GngUSS5E5GpBLM6vc3qQETAdK10eMusjSMYfJjVu0xgusWxCP9rb4C6A+ZnWkl6MlSRt4J3hZW2QMnPz7+s+Ul/JSZ2n+elLlmhuPTzfh/TFgPKzqOP/yVvr3gHl8vFCy+8wJo1a3r8nthYM0TGbrfT3i4jFkSION8ueRzEOP1zzFOYIeZ2zMrdCP8cVoiQk4VpGLQRU7Ip+5UiT4wDksab58mR8yN7KLQbU1a/GDPzUUQWb+dcR+me6ReSIvvBDTfcQEtLC88999z5r5WVlQ1qL1tXovjZZ5+RmppKauqVZ4AkJydTV1d3+Q1KQVQ8dfV1ZGWMoq2tjeXLlw84HiEs1VQJLWf994RfiSnLjAYeQ5I7EflKMN1hd1kdiAgYhwtaqqEpguditAOfAjnIfNJI5S2D+CyIG2V1JBFBEjw/UErx0ksv8fHHH5Obm0t+fj4/+MEPyMw0dV9X2p93qbi4OGbOnMkTTzzB888/3+f9H330UZ544onzTVa6scfzr//rf3JVSQnXXHMNU6dOHdC/SwjLedyd7cD9UI9zHJPcxWKSu7ShH1KIkDcZcyFjPaYkWUSe1OnmeTKSZ+Jtw4yzuRFZvYtEzaehsVJW7/wo8ko0LZKVlcVrr73W42297cG7dK9bb+WTCxcuZOHChT3etmjRIhYtWtTzMW3RfOuv/oJv/dU3IHZkt9KNH/3oRz2ed8SIEbIHT4SGDh/UlEPKVDPgfCiOAn8AkjBlmVdeGBcicijMKt67mOHn4y2NRgSCPdbMDKupgKxbAjMr1EptwFrMz6703ohM3jKz785RYHUkEUNW8CJdVIKZK6LbrI5EiIGp2wftTUOffXcIWIbpKvgYktyJ4ccFJGJW8URkcrrM82Xdfqsj8b9SoB64AVm9i0S6AzxlkDwJohL7vr/oF0nwIp093vzZ3nTl+wkRajxuiE6C5NzBH+MgsBxwYrplJvslMiHCSxQwF9iHGQ8iIk/SRPN8GWllmi3AZ5hS47EWxyICo+EwtNUO/WKu6CZiEjytZXNBj5TNlLf5mkxHwhAmj6E4r73RXIkeSrvkfcBLmP1Hj2DKM4UYruZiEr0NVgciAkLZILXAPG+2N1odjf9sAJqA660ORASMx23ep6ZI9xx/iogELy4ujurqakkQemOPN0vgHS1WR9IrrTXV1dXExck0XgF4K0D7Bn9FbzfwKpCBSe6k6kMMd4mYUk030GBxLCIwnC7zvFnT87zbsNOISfCmAdkWxyICw9cKNbsgNR9s0VZHE1EiYifu6NGjOX78OGfOnLEshubm5tBNTrSG9lpQlSFd3xwXF8fo0aOtDkOEAq8b4jMhPmPg37sTeBPzhmAJEKK/lkIEXQmwFdgMLLQ2FBEAXc+ZHjekz7U6mqFbD7Qiq3eRrHY3dLRJ98wAiIgELzo6mgkTrG2ttGbNGmbOnGlpDFdU+Sc4txXy/n7oHQmFCKTms9B4wnSDG6gy4C3MXo0HMCMRhBDGCMwMsc3ANZh5kCKyOFxw8iPzPBoXxoM+64FNQAEQAmPRDpw7wMbqjUypm0JWcpbV4UQOjxtinJAwxupIIk5ElGiKfnC4TDfNSCndEJHL6x5cu+TtmORuPPAgktwJ0ZN5mBLNMqsDEQHhKDAjkbxh/gCvA3yExEpzxekKXip/iT11e/jvrf/N89uep6yqjPaOdqtDC29ttdBwyKzeKWmP6m+S4A0X8VkQNzLyOmyJyKK1+RlNyjUd4fprC7ACmIhZuYsJTHhChL1xQBZmb5NsW4880cnm+dPrDvnGar2qwTynzwTSrA1lx6kdvLnrTUanjOae0fdw66RbaWxr5I+7/8izG55l9aHV1LbUWhtkuPKUmZ9RR6HVkUQkSfCGC6XMKl7DUWg5Z3U0QvSsq13yQOrxNwHvYUrPFiNlZ0JcicKs4p0FInBkmsA8f7bWQMMRqyMZnE87/1xgaRRsqdzC23veZoJzAksKl5AUlcTVo6/mb4v/locKH2J0ymjWHVnHzzf+nNd2vsZh72Fp9tdfWpuLEIljINbiLD5CRcQePNFPzkKoWmVKNzIWWh2NEJfzuMEeCylT+nf/9cBHmC5r9wD2wIUmRMSYDvwZs4onnckjT8pUsMeYN9BJ462OZmDOATswYz1SrQtj4/GNfHDgA/LS87g3/16ibBfeLiulyE3LJTctF0+Thy2VW9h2chu7zuxiVOIo5mbPxZXpIsYupSS9ajoJzWcg5ytWRxKxZAVvOIlOgcQJ5k20XGUSocbXCrUDaJe8DpPczUCSOyEGwg5cDRwCTloci/A/W7R5Hq3ZZToUhpM1mJ/P+daFsPbIWj448AHTR07nvvz7uiV3l3LGO/lS7pd4suRJ7pxyJ3Zl5/397/Oz9T/jT/v/xNnGs0GMPIx43aDs5udUBISs4A03Thccewsaj0LiOKujEeKC2t0myXMWXfl+GlPCswYoBO5CLlUJMVCzML9HG4C7LY5F+J/DBee2Q+2egTesssppoBzT4XUAW7D9RWvN6kOrWXd0HYUZhdw19S5sqn8vLtH2aGZmzaQos4gTdScoPVHKlsotbDqxiVxnLsU5xUxOn9zv40W0Dp+ZdZsyBaLirY4mYkmCN9ykTAP7+2YVTxI8EUr60y5ZA6uAzzAb8O9AkjshBiMOk+RtAm4CUqwNR/hZ4jiISTXPq+GS4H2CaZB1TfBPrbXmo4MfseH4BmZlzeIreV8ZVDKmlGJ0ymhGp4zm5tyb2XZyG1sqt/Byxcs44hzMyZ7DrKxZJEQnBOBfESbqD0J7g8y+CzB5azTc2GNMklezM/xKN0Tk6k+7ZI0pyfwMmAN8FXkGE2Iorur8c5OlUYhA6GqsVn8Q2uqsjqZvlcBuoAQI8qKO1pr397/PhuMbuCrnKu7Iu8MvK21JMUksGLeAv7v677g3/16ccU4+/uJjntnwDG/veZvKuko/RB+GvG6ISoCkSVZHEtFkBW84crrMVb3aveCYYXU0QvTdLlkDfwJKMW9Kb8V0AxRCDJ4D03BlK6ZjocyOjCyOQji9FrzlMHKe1dFc2SeYxK4kuKft0B2s2LMCd5Wba8dey40TbkT5eSabTdmYPnI600dO53TDaTaf2Iy7ys2OUzsYnTKa4pxipo+cfsW9fhGjvcm890ybDTbZOB9Icv17OEqccKF0QwirnW+XPLbndskaMwahFFO6I8mdEP5TAjQD260ORPhd3AhIyDHPr6EBhX+oAAAgAElEQVTsKGZkx7UE9SKDr8PHm7vexF3l5vrx1wckubvUqMRR3J53O0+WPMmXJ32Zpram8zP1Vn2xiprmmoCe33K1u6Cj3awui4AaBpcLxGWUMlf2znwObfUDGygthL91tUsefcflt3UA72DaZi8ArkeSOyH8KQcz/HwjUIxc9o00DhdUroSmUxCfaXU0l9PAakxTleLgnba9o53Xd77O3uq93Jx7M/PGBHeFMy4qjqtGX0VxTjFfeL5gc+VmPjv6GZ8d/YypI6ZSnFPMeMf4gCecQedxQ9xIiM+yOpKIJwnecOUohNPrOks3glwTIcTFvG6wRV3eLrkDeAvTVe164LrghybEsFACvILZAyVdyyOLYwac/NDMvw3FBO8QcBi4DejHdBx/aPO18UrFKxz0HOS2ybdRnBPEzPISF8/U8zZ7z8/U2312NyMTRjI3Zy6uDBexURFQP91yDhqOQuZNve+1F34j1+qGq7iR4VG6ISJbh89cZEiZAva4C1/3AW9gkrubkOROiECaAqQD6zErKiJyRCVA8mST4OkOq6Pprqsrciqmo2sQtLS3sLx8OV94vuDOKXdamtxdyhHn4KaJN/FkyZPcNfUuou3RrNy/kmc2PMPK/Ss503DG6hCHxlvWWUEWJl1dw5ys4A1noV66ISJf/QFob+xej9+OSe72ALcQ9E33Qgw7CjP4/H3gGDDW2nCEnzldZh5e/ReQHEKdC/cBJzAdkYPwbrS5vZk/lP2ByrpK7p52NwUZoZloRNmiKMosMjP1as1Mva2VWyk9UcpE50SKc4rJS88Lr5l6WneO5+rsASECLox+OoTfOWaAspurKkJYwbMDohIhKdd83g68iknubkeSOyGCpQhIwKziiciSPNkMlA6lxmpde+/SMD97AdbY1siLO17kZN1Jvj796yGb3F0qJyWHr037Gk+WPMmNE26kurGaVype4Rcbf8G6I+toaG2wOsT+aTwGrR5w9tIpW/idrOANZxeXbmTeBOF0NUiEv/YmqN0H6cWmXXIb8DJmT8ZXCVrJjhACs/9pDrAOqMaUbIrIYIuC1Bng2Q6+FrCHwH6unUAVsIiALzXUt9az1L2Uc03nuH/G/UxOnxzYEwZAYkwi88fN55qx17D37F5KT5Sy6tAq1hxew4xRMyjOKSYnJcfqMHvncYMt2sxhFkEhCd5w11W6UXcQUsLvSU+EsZoK0D7zM9gKvAQcAe4kKFd0hRCXKAY+x3TUvN3iWIR/OV1QvRlqdkHaTGtj6QDWAKOAAI/irWmuYal7KXWtdTxY8CATnBMCe8IAsykb00ZOY9rIaZxpOMPmys3sOLUDd5WbnOQcinOKyR+VH1oz9TraoWYnpE4LjYsLw4Qs2Qx3XaUb0mxFBJvHDfEZoDLgD5hZSHcjyZ0QVkkCCjFjSRotjkX4V3wOxKaHxmt9GXCWgI+98TR5+P2O31PfWs+SwiVhn9xdamTiSG6bfBtPlTzFbZNvo8XXwlt73uKZDc/w8Rcf4232Wh2iUbsXfM0y+y7IQijFF5boVrrR3L2ToRCB0lINjcch7WZYpuAkcA8w3erAhBjmSjBDz7dgZk+KyKCUWcU7tRpavRDjsCYOH2b1LhuYGrjTnG08y1L3Utp8bTxS9AjZydmBO5nFYqNiKc4pZm72XA55D1F6opTPj37O50c/Z8qIKRTnFDPBMcG6mXreMohOhqTISrBDnSR4ApxFF5VuyMYnEQQeN7QreL8ATgP3YVq1CyGsNQqYBJQC85B3CZHEUWgSPG8ZjLIoe98GeIGvELDVu6r6Kpa6lwLwaNGjZCRlBOZEIUYpxUTnRCY6J1LTXMOWyi1sPbmVPWf3MCJhBMU5xcGfqdfeAHX7YUSJ9HkIMvnfFhCfDbEjQqvDlohcWsNpN2zLhTPJsBhJ7oQIJfOAeswcShE5YhyQNN681msLBh62AWsxYzhyA3OKk3UneWHHC9iUjcdmPjZskrtLpcalcuPEG3my5Em+NvVrxNpjWbl/JT/b8DPe3/d+8GbqeSvM/EWnlGcGm1ybExeVbqwybWxjnFZHJCLZ6SOwuQbO3QQPABOtDkgI0c0EIAPYgNkTa1FllwgAhwuOr4CmE5AwOrjn3gLUYcrxA/AzdazmGMvLlxMXFcfDrodJi0/z/0nCTJQtClemC1emixO1J9hcuZntp7azuXIzExwTKM4pZsqIKYGbqed1Q3wWxI0KzPFFr2QFTxiOztkkHpmJJwKoFnjLDc2xcM9USe6ECEUKs4p3GjhocSzCv1Knm733wa7YacGM4MgFxvn/8Ie9h1lWtoyE6AQeK3pMkrse5KTkcNfUu/ju1d/lpok3ca7pHK/ufJWfb/w5a4+s9f9MvebT0Fgpq3cWkRU8YcSkmg2wXrepzbdqM66IXF7gxTaI2gnz8mFitNURCSF6MwP4GDP4fJLFsQj/scdCylQzpibrVjODNBg2YTqz3uD/Qx84d4BXKl7BGefkYdfDJMcm+/8kESQxJpFrx17LvDHz2Fe9j9ITpaw+tJpPD39K/qh8M1MvOWfoTVm8ZWbfXWqAZ2GIHkmCJy5wuuDY26a7YeIYq6MRkcQDvAj4dsOcVpgsV/SECGl24CpMkncKyLQ2HOFHDpfZG1W3H1ID2MqySxPmQsFUwM+zuPec3cPrO19nZOJIHip8iMSYRP+eIILZlI2pI6YydcRUzjaeZfMJM1OvrKqM7ORsM1NvZD7R9kFcjNUdpiIseRJEJ/k/eNEnKdEUF6RMA1s0eHZYHYmIJNXA7zElOje4Id0BiQGo0RFC+NdsIAazF09EjuRc86Y7WDPx1mOe/6/372ErTlfw2s7XyEzK5BHXI5LcDcGIhBF8efKXebLkSW6ffDttvjbe3vM2z2x4hj8f/PPAZ+o1HIa2Wpl9ZyFZwRMX2GMhdRrU7ITsL5s6fSGG4gxm5U4DS2rh3BfglBJgIcJCPDAT0xzjJkAq3yKDskFqAVSXQnsjRCUE7lwNmPLMfEzjHj/ZcWoHK/asYGzqWB4oeCC4rf8jWGxULHNz5jInew6HvYcpPVHKhuMbWH9sPXnpeRTnFDPRObHv8k2P28xVTskLTuDiMvIOXnTncJll9dq94Mi3OhoRzqqApZiGDY8ClJvW3F0NfYQQoe9qzEy8TZgkT0QGpwvObjAXdNPnBu48n2HGI/hx9W7zic28v/99cp253DfjPmLsMf47uADMTL0JzglMcE6gprmGrSe3srVyK3ur95Ien25m6mW6iIuKu/ybfa1Qu9tcRLDJXnurSImm6C5pAkSnBK90Q0Smk5iVOzvwGDBCmyt6iWMgNt3a2IQQ/ecEpmFW8VotjkX4T3wmxGcEtptmLbAZM2rDT0/7G45t4P3975OXnsfigsWS3AVBalwqN0y4ge+WfJe7p91NfHQ8fzrwJ57Z8Azv7XuP0w2nu39D7W6T5DnlYq6VrriCp5RKAJ4Cxmqtv6mUmgxM0Vq/F5ToRPApm/mlPLMe2hsgSmraxQCdAJYBscAjQBrQdMq0TM75iqWhCSEGoQTYBWzHNF4RkcHhgpMfQfNZiBvh/+OvxZTnX+enwx1Zy+pDq5k+cjqLpi3CHqwOoAIwM/UKMwopzCiksq6S0hOl7Di1gy2VWxjvGG9m6qVPwe5xm3nKCWOtDnlY62sFr6s1Qknn5yeAfwtoRMJ6jkLTAclbbnUkItwcw5RlxmNW7rpGEXncoOyQKmW/QoSdMZ0fG4EOi2MR/uMoMPuhvQGYf+sBtgGzAMfQDqW1ZtUXq1h9aDWuDBf3TL9HkjuLZSdnc9fUu3iy5Em+NPFLeJu9vLbzNf5rw085fGINTUmTZa+9xfpK8HK11v8HU0GN1roRs6NGRLK4UZCQHfxBqCK8HcGs3CVhkruuF/UOn7lYkDIFouItC08IMQQlmDfte6wORPhNdDIk5ZoET2v/HnsN5h3mgqEdRmvNhwc/ZN3RdczOms1dU+/CpmR3UahIiE7gmrHX8J2rvsPiGYuZZGvisOcLfrl/HW/uepNjNcfQ/v7ZEv3SV5OVVqVUPGaRHaVULmZFT0Q6hwsq/wRNVaZOX4gr+QJ4GZPUPUz3bnv1B025r1PaJQsRtqZi9uNtAKZbHIvwH6cLjr4JDUcgabx/jnkGKMNcFBhC51WtNe/te4+tJ7dyVc5V3Drp1qEP3xYBYVM2pqTnMeVcJvWpX6M5ZgrbT26n/HQ5WUlZFOcUM2PUjMHN1BOD0tdlkH8CPgDGKKWWA6uA7wU8KmE9xwyzHy8QpRsishwAXsKUYz7K5S/onh2mDXfSpGBHJoTwFxumo+axzg8RGVKmgj3Gv43V1gDRwLWDP0SH7uDtPW+z9eRWrh17rSR34aD5FDSfISnjGm6ddCtPzXuKr+R9BZ/2sWLvCp7Z8AwfHfwIT5PH6kiHhV5X8JRSNsz1ursxT+sK+B9a67NBik1YKSoRkiebBC/zRpPsCXGpvcBrwCjgIeDScUrtTWbkRvockD0TQoS3mcAnmFW8MRbHIvzDFm32Rtfsguzbht7W/hSwE9NYZZDj9XwdPv64+4/sPLOTGybcwPyx8yW5CweX7LWPsccwJ3sOs7Nmc6TmCKUnStl4fCMbjm1gcvpkinOKyXXmymMbIL0meFrrDqXU97TWrwHvBzEmESqcLvPmvP4LSJbVF3GJ3cDrQBawBNNY5VI1O0H7wFkU1NCEEAEQA8wBPsfsx3NaG47wE0chnNsOtXtM45WhWI15LSjp6449a+9o5/Wdr7O3ei83597MvDHzhhaPCI4r7LVXSjHeMZ7xjvHUttSytXIrWyq38IfqP5AWn0ZxTjFFmUU9z9QTg9bXsszHSqm/V0qNUUqldX0EJTJhveQ8sMdJsxVxuQpMcpeD2XPXW+8Ur9s07YnLDFpoQogAugrzzmGj1YEIv0kcDzGp4BnilozjwD5gHjCI9+ptvjZeLn+ZvdV7uX3y7ZLchZN+7rVPiU3h+gnX892S77Jo2iISoxP54MAH/Gz9z3h377tU1VcFKeDI11eTlfs6//ybi76mgYmBCUeEFFuU2YvncYOvBeyxVkckQoEbeBsYCzyIuarfk5Zz0HAMsr4k7ZKFiBTJwAzMTLyF9H5xR4QPpcwq3pnPoK0eopMGd5zVQCKDmpXY0t7CS+UvcbTmKHdOuZOZWTMHF4Owhtc9oL32UbYoCjIKKMgo4GTdSUpPlOKucrP15FbGpY6jOKeYqSOmyjiMIbhigqe1nhCsQESIcrigeoupz0+TJ9xhbxvwLjABuJ/ekzswT/hKDb3kRwgRWkowF3q2MqRGGiKEOFxwep0psxs5iPrKQ5huyrdy5deFHjS1NbG8fDmVdZUsmr6IGaNmDPz8wjq+ZrOdJ232oPbaZyVncefUO/lS7pfYcWoHm09s5vVdr5Mck2z28GXPJilmkBcdhrErJnhKqWjgW1yYZLIG+G+tdVuA4xKhImE0xKabN+uS4A1vmzG7cSdh1vavtBdfa7PymzQRolOCEp4QIkgyMXU8mzDJnlxkD39xIyAhx7zWDzTB05jVuxTMHs0BaGhtYFnZMs40nOHe/HuZOmLqwA4grFezEzrazUWCIUiITmDemHlcPfpqDpw7QOmJUj45/Alrj6xl2shpFOcUMyZljDRl6ae+SjT/C/M27lednz/U+bW/CGRQIoQoZWqqT62GVi/EOPr+HhF5NmIGpkwBvk7fzxyNR83PS8YNAQ9NCGGBecAfMPtxZcRlZHC4oHIlNJ2C+AHsmz6AGZ1xB32/NlykrqWOpe6leJo9LC5YzKQ0aeYWljxuiBsJ8Vl+OZxN2chLzyMvPY/qxmo2V25mx6kdVJyuIDMpk+KcYgpGFchMvT701WRlrtb6Ea316s6Px4C5wQhMhBBHoflTZuINT59jkrvpwL307wXc4zazlVLkaqwQESkXMx5lPWYFR4Q/xwzT5n4gr/Vdq3dOYADNkmuaa3hhxwvUtNTwYMGDktyFq5Zz0HDUvE8MwMpaekI6t066lSdLnuSOvDvQWvPO3nfOz9Q713TO7+eMFH29VfMppXK11gcBlFITAV/gwxIhJcYBSePNm/aR86VhxnDyKWbuVQHwNfq+JATQ0WZKNlKmmyRPCBF5FKY8cwVm/5W0Xgt/UQkXzb+9qX/zb3cDJzGvD/0s1fU0eXjR/SJNbU08VPgQY1JlqGLY8pZdaNITQDH2GGZnz2ZW1iyO1hztNlNvUtokinOKmZQ2Sco3L9JXgvc/gU+UUl9gns7HAY8FPCoRehwuOL4Cmk6YfXkismlMYrcWU351J/1L7sDMUvK19NkuWQgR5gqAVZhVPEnwIoPTZZ7D+zP/tgPzOjES87PQD2cbz/Lijhdp72jnkaJHyE7OHmLAwjJamwSva8xGECilGOcYxzjHOOpa6th60szUW16+nLT4NOZmz6Uos4j4aGnv21cXzVVKqcmYnTcAe7XWLYEPS4Sc1OmmNt/jlgQv0mngY0xp5izMvoqBXBTzuM2TfeL4AAQnhAgZUUAxpkTvNKZkU4S35MlmULXH3XeCVw6cwZTu9+MCYFV9FUvdSwF4tOhRMpIyhhqtsFLjcVOiOWpB3/cNgOTYZBaOX8j8sfPZfXY3pSdK+fDgh6w+tJqCjAKKc4rJTBq+M3j76qL5N8ByrXVZ5+dOpdQ3tNa/utL3iQhkjzX7qWoqIOsWMyNPRB4NfIhpqjIXuI2BJXdtdWbgqZTyCjE8zAHWARswK/0ivNmiIHUGeHZcef6tD9NXPQuY1vdhK+sqWeZeRrQ9moddDzMiYYT/YhbW8LrBFg0p/fgBCCC7zc6MUTOYMWoGp+pPUXqilPKqcrad3MbY1LEU5xQzbcS0YTdTr69rLt/UWnu7PtFae4BvBjYkEbKcLmhvgrp9VkciAkEDKzHJXQkDT+7AzFDSOuD1+EKIEJGAaa5RBtRbHIvwD6ercy/1rt7vswPwANfT5+vEsZpjvLjjRWKjYnms6DFJ7iJBRzt4KyB1Wu8XASyQmZTJV6d8lSdLnuSW3Fuoa6njjV1v8OzGZ1lzeA11LXVWhxg0fS3D2JVSSmutAZRSdgY8wlJEjKSJEJ1sSjdSp1sdjfCnDuA9zCDza4EbGXhyB+aKXsJoM1NJCDE8XA1sAUoBmYwS/uJzrjz/th3TgGsMMPnKhzrkOcTLFS+THJPMw66HSY0Lzl4tEWB1+8yA8yHOvguU+Oh4SsaUdJup9+nhT81MvRFmpt7Y1LER3ZSlrwTvA+BVpdR/d37+V51fE8ORsoGjAM5uhPYGiEq0OiLhDx2YTnhu4DpgIYNL7ppOQVMV5Nzux+CEECEvHbNTfwswHzM9V4SvvubfbgFqMZ0zr/BaceDcAV6peIW0+DQedj1MUkxSAIMWQeVxmwv+SROsjuSKlFJMTp/M5PTJnGs6x+YTm9l+ajs7z+wkIzHDzNTLKCAmAjt+91Wi+X3M9ulvdX6sAr4X6KBECHMWge4wS/Mi/PmAP2KSuxvoV7lNrzxuM0MpNd9f0QkhwkUJ0Igp3RPhr7f5t62YPZcTOj96sfvMbl4uf5kRCSN4tOhRSe4iSXsD1O3vnH3X3/ba1kuLT+OWSbfwVMlTfHXKV1FK8e6+d3lmwzN8eODDiJup11cXzQ7g18CvlVJpwGittczBG87iRkF8lindGHGV1dGIofABb2DmGN0MzBvCsXSHeSOQkmdmKQkhhpexQA5mD+8cBn+hSISGGAckjgNPWfemWaVAA1csxa04XcEfd/+R7ORsHix4UFrWRxpvhXnND9NRSNH2aGZlzWJm5kyO1R6j9EQpm05sYsPx7jP1bGGUvPbkitErpdYopVI6k7utwG+UUs/29+BKqVuVUnuVUgeUUv/Qw+1jlVKfKKW2K6XKlFK3DfyfIILO6YLGSmg+bXUkYrDagdcwyd2XGVpyB1B30FzVC9F6fCFEgHUNPq8G9loci/APpwtazkJTpfm8GTM+Jw+z/64H209u581dbzImZQwPFT4kyV0k8rrNhf648J6LopRibOpY7pl+D9+9+rssHL+QqvoqXip/if/Y9B+sP7aeprYmq8MctL7S01StdS1wN7BUa30Vpv1Cnzobsvwn5u3jdGCxUurSzhw/BF7TWs8E7gdk/EI4SJ1hluUvLd0Q4aENeAXzJuwrgD8WYr1us3KX3MeOeyFE5JoOODAjE0T4S51uxiZ43ObzDUATva7elZ4oZcXeFUx0TmRJ4RJio0Knu6Lwk+Yz5gJ/mK7e9aZrpt7fXf13fH3610mJTeGjgx/xsw0/452971DdUm11iAPWV4IXpZTKwoyxfG+Axy4GDmitv9Bat2LeUl46JUcDKZ1/TwUqB3gOYYXoJDMA1VNmlulF+GgFXgIOYn4b5/jhmL5mqN1jEv9hNmdGCHERG+aC0RHghMWxiKGzx3XOvy2HBp9J8PKBHmZHrz+2npX7VzIlfQqLCxYTbZdOOxHJ6zYX+FNnWB1JQNhtdvJH5fPYzMf41pxv4cpwUV5VzufVn9M5UCBs9JXg/Qtm7PEBrfVmpdREYH8/j50DHLvo8+OdX7vYj4AlSqnjmAlc3+7nsYXVHC5oq4WGw1ZHIvqrBVgOHMZ0P+uh+/Wg1Ow0M3Ei7IqeEGIQZgGxyCpepHB0zr/9dL+p/ljY/WatNZ8e/pSPDn5E/sh87s2/lyhbXw3aRVjSHebCfvIkc6E/wmUkZXDHlDt4at5TXDvi2rAbqaAClZEqpe4BbtVa/0Xn5w8BV2mt//ai+zzZGcPPlFIlwPPAjM7mLhcf6y+BvwTIyMiY/corrwQk5qGor68nKSnyf+C7KO1jTP2rNEaN5mz8AqvDsVQ4PPa2Vhuj/jyK2LOxnF1wloYJDX47dmbjSmy6hcqEuy5sxB8mwuGxF4Ehj33vnJudpOxK4cSiE7QntVsdjl8Nu8dddzDW8wZJm6dxOuF6zs4/e+Emrdnm3UZ5TTm5Sblck35N2DemuJJh99hfIq69kszGjzgTfx0N0aE9HsHfQvWxv/7667dqrXusxQrkZZYTdN+GO5rLiza+AdwKoLXeoJSKA0YA3bp3aK2fA54DmDNnjl64cGGAQh68NWvWEIpxBdTxRrMPb1oJ2IdvrX3IP/ZNwB8wxdCPw4RpfnxibjkHe9dA5lfJG3Wt/44bJkL+sRcBI4/9FcwEfgEToidctuIT7obl476iDbJLGbV4IowwpXlaaz448AF1qo578u/h9sm3h90Kx0ANy8f+YsfegtopjJ+2BGzDqwQ3HB/7QF5q2QxMVkpNUErFYJqovHPJfY7S2bRFKTUNiAPOBDAm4U9OF3S0Qe1uqyMRvWkEXgROAfcB0/x8fG+ZWbVzFPj5wEKIsJUKzAC2YTovivDlBXa6IMsHaidgkrv39r3HphObuHr01cMiuRv2fK3mvV5q/rBL7sJVwBI8rXU78LeYPXy7Md0ydyql/kUp9dXOuz0FfFMp5QZeBh7V4baLcThLGAOxaRc6bInQUg+8AJwFFmNaW/uT1uaxT5wAMal+PrgQIqyVYPb9brM6EDEknwIdGZCXAR43HbqDt/a8xdaTW5k/dj635N4iyd1wULvHJHmy1z5s9DUH7/9VSjku+typlPq3/h5ca71Sa52ntc7VWv+482v/W2v9Tuffd2mtr9Fau7TWRVrrjwb7DxEWUMpswG44DK01VkcjLlaHSe48wIPApACco/EYtHrkCV8IcbksYAJm8LnP4ljE4FQDbmCOgiwXHQ1Heafs95RVlXHDhBu4ceKNktwNF143xDghYazVkYh+6msF78taa2/XJ1prDyDDyMUFzkKzkiMz8UJHDfB7oBZYgnmTFQgeN9hjIMXfdZ9CiIhQgnke2mV1IGJQ1mA6NcyH9pRpVJzZSc2ptdySewsLxg3v5mrDSlst1H9h3u9JQh82+krw7Eqp890zlFLxmAbIQhgxTkgcZ97sS3Wt9byYlbsG4CFgXIDO09FmxiOkTDNJnhBCXGoypm3aeszUWxE+qoAK4CpojWvlpT3vcqBVc70jnZLRV1sdnQgmb7l5f+eQap1w0leCtxxYpZT6hlLqG8CfMS0bhLjA6YKWs9Akc+otdQ6zctcMPEL3Hrb+VrvPDDiX8kwhRG8UZhXvJGb4uQgfnwCx0FLcwvKy5RzyHGJ63v2MjU+BBnkwhw2twbMDEjt7LoiwccUET2v9U+DHmN5704B/1Vr/n2AEJsJI6nSwRUmzFSudxSR3bZjkLjvA5/PsgOgUSBwf4BMJIcKaC0jErOKJ8HAC2GOSu6X7lnKs9hiLpi9i6oS7TMWGbMkYPppPQfMZWb0LQ33OwdNa/wn4UxBiEeHKHgcpU6GmHLJuAZvd6oiGl9PAUkwJ1KPAqACfr60e6g/CyHkQwUNthRB+EAXMxeznOosp2RShbTW0xrTyYtyLVNVXcW/+vUwdMdXcljLdlOdnf1na5Q8HHjcouxmPIMJKX10065RStZ0fzUopn1KqNljBiTDicEF7E9TtszqS4eUUZs+dAh4j8MkddNbjd8gVPSFE/8zFJHobrA5E9OkItOxt4d1R73K6/TSLCxZfSO7AlOX7WqB2r3UxiuDo8JnX+5QpEBVvdTRigPoq0UzWWqdorVOAeGAR8KugRCbCS3IuRCdJmWYwVWJ2xEZhVu6CdWXc64aEHIgbGaQTCiHCWiKmVNONaQAlQpOGxg8bKa0tZX/ufpYULmFS2iUzdhLHm7mn8lof+eoPQnuD7LUPU/2ur9LG28AtAYxHhCtlg9QCqNsP7Y1WRxP5jmPKMmMxK3fpQTpvUxU0nZLVOyHEwJQA7cBmqwMRvfHu9FJWWsbBGQd5cNaDjHeMv/xOSoGjEOoPmHJ9Ebm8bohKgKRADNIVgdZXiebdF33co5T6CaZHnxCXc7pA+8BbYXUkke0osAxIwCR3ziCe2+s2ybxjRhBPKoQIeyOAPEyC1ydWEUIAACAASURBVGZxLOIyZxvOUrqslIaEBm6+92bGpF6hDbPD1Tn/tjx4AYrg8jWbMtzUGdJXIUz1tYJ3x0UftwB1wJ2BDkqEqfhM8+GV0o2AOQz8AUjGlGWmBvHcusN0T0vOM1f1hBBiIOZhSjSlCWNIOVV/ihUrVpB0NomZi2eS7eijDXPcCFOmL6/1katmJ3S0S3lmGLtiF02t9WPBCkRECIcLTn4IzWfNi4Dwn4PAK4ADMwohKcjnr//ClORkyxO+EGIQxgFZmGYrszDNoYSlKusqWbZ9GXO2zaEwv5Ckq/r5wuJwQeVKU7YfnxHYIEXwedwQOwLiAz1zSQRKXyWacUqpv1FK/Uop9buuj2AFJ8KQo8DU6MuVPf/aD7yM2Wv3KMFP7sA84UfFQ/JkC04uhAh7CrOKdxbznCYsdbTmKC/ueJHso9nMi51H0s1J/e/M4JhhyvXltT7ytHqg4ahZvVNyFSZc9fWrvAzIxJRnfgqMxpRpCtGz6CSzIdfjNjX6Yuj2YFbuRmFW7hItiMHXArW7O+vx+xyfKYQQPZsOpCAjEyx2yHOIZe5lJEUlcc/pe4gfHQ8DGXUWlWDK9b1lpnxfRA5P2YVmOiJs9ZXgTdJa/y+gQWv9InA7cFXgwxJhzemCtlpoOGx1JOFvJ/AapqzpYcywEitIPb4Qwh/swNXAIeCkxbEMU/ur97O8fDnOeCffsH2D+Np4uIGBl8w6XaZsv/6LQIQprKC1WZXtGochwlZfCV5XryuvUmoGpqVDMEYpi3CWMgXssTInZ6jKgTcw6+YPAXEWxuJxQ2w6xOdYGIQQIiLMwox4kVW8oNt9ZjevVLzCyISRPDrjURLWJ0AOpsPpQCVPNmX78lofORqPQ8s5uZgbAfqqtXpOKeUEfgi8g9n5878CHpUIb7ZoSM2Hmgrw3Qb2GKsj8jutNVUNVZRXlbOleguxx2JJi08jPSEdZ5wT+1DbCu8AVgDjgcWAlf+FrR5oOAKZN0o9vhBi6OIwSd4m4CZMyaYIuPKqct7a8xbZydksKVxC3LY4qAG+yuAa3tiiTNm+Z4cp47fH+jliEXRet3kPlzLN6kjEEPXVRfO3nX9dC0y89Hal1COdpZtCdOd0wbltZt9WBF0Jqm2ppayqjLKqMk43nMau7BxrOEbLwZbz91EoHHGO8wlfWnya+Xt8Oo44R9/J31bgXSAXuB+IDuA/qD88nT3NpR5fCOEvV2ESvE3AlyyOZRjYfnI77+x9h3GOcSyesZhYHWve2Y2nh3d3A+AohOrNULML0mb6J1hhjY52M8c4dZok6xFgqN0S/gcgCZ64XMJYiHGa0o0wT/Ba2lvYdWYXZVVlHPYeRqMZkzKG2yffTv6ofDZ1bOKqa67iXNM5qhurzZ9N5k/3KTctvgvJn03Zzid/XUlfVyLoiHNg22yDlZhymXsZ+m/oUHXV4ydNkHp8IYT/ODANV7YCCzAlmyIgSk+UsnL/SnKdudw/436i7dHwOVCPeZ0ZSmFGwmiITTPNViTBC291+8yAc0d4v2cTxlDfPkq9luiZUuAshNNrTcOV6PCqwfF1+DjoOUhZVRl7zu6hvaOdtPg0rht/HYUZhaTFp52/r1KKhOgEEqITGJ0yuttxtNY0tjV2S/q6ksCjNUdp9bWev+/YXWPJ35ZP2+Q26mbVkV6Vfj4JTI1Lxab627/aj7rq8UctCP65hRCRrQSoALZjGq8Iv1t/bD0fHfyIKelT+Hr+14myRUEL8BkwCRg7xBMoZRKCqk+g1QsxjqEHLazhcUN0srmgK8LeUBM86YMveudwQdWnpsRv1LVWR9MnrTWVdZWUVZVRcbqChrYG4qPimZk5k8KMQkanjEYNcA+aUorEmEQSYxIZkzrmsvM1tDVwrukczZ80E7U3iqrpVey8ZifVZ6ppPXUh+bMrO444x/mSz66Vv7T4tMAmf1KPL4QIlBzM8PONQDH9n8Em+qS1Zu2RtXxy+BPyR+Zz97S7L2wP2Ag0YTpn+oOz0CR43nIYNd9PBxVB1d4AdfthRImZbyjCnqzgicCJTYPEsSZJGHlNyDbo8DZ7z++rO9t4FruyM2XEFAozCpmcNnnoDVN6oZQiKTqJpPVJpqnKdTDxromU2ErQWlPfWt9t5a9r9e+Q5xBtHW3nj2NXdpzxzm7lnueTv9jUASel50k9vhAi0Eowcz53M7A5bKJXWmtWHVrFZ0c/oyiziK9O+eqFi4BNwHpgGpDtpxPGOCFxnFkBGnltyL7WiyvwVph5hmG+pUZcMNQE73O/RCEil9MFx9+FppOQ4K9Xk6Frbm9m5+mdlFWVcaTmCADjUsdRkldC/qh84qKCMJNAA6uBdUARppNZ52uwUork2GSSY5MZ5xjX/du0pq61rlvS15UIHvQcpL2j/fx9o2xROOOclzV7SYtPIyU25crJn9TjCyECbQqQjkk6piOXjYdIa80H/5e9N42O6zzvPH+39g2FqkKhsBD7RhAEAcpcJFGiRIkStdmJ03Fsx0ns+CQnXzqZmaTTPdPLOXN6untOryfT3aenT2dmkra8xFY7tuM4kmzZMrVL1EaAAEEsJECCJPaVqH258+FBVaGwLwVUAbw/nntquW/duiSB+97/+zzP/xl4lQ/ufMDJ8pO80PhC5nX+HSACPJHlL3a3w+0fQ/Au2LR2OvuO2Q6wloFF64R2UFhX4CmK8n8C/1ZV1dnF127gH6iq+s8AVFX9w90/RY19jbMFdK/IxSPHAi+eiNM/3U/nWCe9k73E1Them5cna5+kraQNl2UPawdU4DXkpuYk8AKbvrFRFAWn2YnT7KTGVZN52EXxt9zsZTo4zcD0wArxtzzdMykEC0wFKFo+voaGxm6jIPV3fwcMs/OasPuYhJrgJ30/4ZORT3i44mEu1F/IFHcLiGvpMbLf0biwBe6+LFE8TeDtL0ITELgLZc/k+kw0sshGEbznVFX9J8kXqqrOKIryPNIXT0NjYwxWaXw+ewVKL8AupTuuhaqq3J6/naqrC8aC2I12TpafpL20nTJH2fZTGLd9UsCryET7IPAsWVu1Xir+at2ZwkxVVebD8yvMXiYDk/RN9RFX46mxNlTOhT4hUNhGbPD1DCHoMDn2/t9MQ0Pj4HIc+CWy4KUJvG2RUBP86NqP6Bzr5LHqx3ii5omV1+m3gDhwbhdOQG8BZ7P0vy17Zs/neo0dMNshdXeuY7k+E40sspHA0yuKYlZVNQygKIoVzcxYY6u42mG2GxYGROztAdPB6VRd3XRwGoPOQLO3mfaSdurcdbtWV7chKvATxBr8DNL/aY+0kqIoFFoKKbQUUufObHyUUBMi/hZFX3ziHayTJq6oDu4Ov5ch/kx606ptHjxWD3ajXRN/GhoaW8OIZDK8BUwhKZsamyaeiPPXPX/N1YmrPFn7JI9Vr+J6PAd8hIhpz8rdWcHVLrVc9/qhsHmXvkQjq6iqGOE56sHoyPXZaGSRjQTet4FfKIryl4uvv47W905jqzjqwWCX1I1dFHiBaCBVVzc8P4yCQo2rhrNVZ2kpbsFsyPHaRAL4MWKochZxMMsTLZTsz+eyuKinHgKfgOMZjjX8AQk1wVxoboXZy9jCGNcmr5FQE6njmPXmFemeSSFoM9o08aehobE6p5H6sPeRlHWNTRFLxHip+yX6pvp4tuFZHqpYo9/Em4uPj+/iyRQszvWzHZrA2y/4h6SVVdmFXJ+JRpZZV+CpqvpvFEXpAJ5afOtfqKr6090/LY0DhU4vof+pDyEWlLTNLBFLxOib6qNzrJP+qX7iahyf3cdTdU9xzHeMQkueNOdOAD8EriDF7Y+RN+JuBaFxMcUpfw4Q8ee2unFb3SuGJtQEs6HZFWYvIwsj9Ez2rBB/q5m9FNmKsBqsmvjT0LifcQBtyALYE4Att6ezH4jEI3y367vcmLnBZ5s+y8nyk6sPnEZ6DZ4CdnNKVHTgaoOpS1mf6zV2iZkOccneo+wqjb1jMy6anyIJFOricw2NreNuh8n3JT+/6NSODqWqKrfmbtE51kn3RDehWAiHycHpQ6dpL22nxF6SX2IhDvwA6EaWSvK9JeBMMh+/dcOhOkWXEmwNnoaMffFEPC3+lkT/7szfoXu8G3VJG02LwbJqymeRtQirUbtJ0NC4L3gYucv4CFkE01iTcCzMt698m+G5YT7f/HmOlx5fe/BFQI9kjuw27naYfC8rc73GLhOPwPxVKGyVfrcaB4qNXDS/CPw75PKgAP9ZUZR/qKrq9/fg3DQOEpZSsd+d6dj2RX8yMJmqq5sNzWLUGTlSfIT2knZq3bW71+x7J8SA7wPXgGeQG5h8Rk3AbCcUNEqqzQ7Q6/QU2YooshXRSGPGvngizkxoJiPyNx2cZnh+mK7xrgzxZzVYV4i+pKjUxJ+GxgHCBzQAl5Aa5Z02cjqgBKNBvtX5LUYWRvhCyxc46lungeA4kjlyBomS7jaWErCW7Giu19gj5q+JyNN63x1INrp8/lPglKqq4wCKohQDP0duWTU0No+igPs4jPwMwlNg3lwVvT/ip2u8i46xDu7eu4uCQp27jidrn6TZ24xJb9rlE98BMeB7QD/wPFJjku8sDEL0HpTv7gVfr9PjtXnx2rwrDBViiRgzwZl0vd9i9O/m7E2ujF3JEH82o23VyJ/H6tmbXoYaGhrZ5QzwIiJKHsjxueQh/oifb3Z+kwn/BF86+iUOezdIrbsImIBH9uDkQOZ6VxuMvLaluV4jB8x2gMkFNs269iCykcDTJcXdIlOkWjFraGwR1zEYfU1W9kqfXHNYNB6ld6qXzrFOBqYHSKgJSh2lPFP/DK2+VgrMBXt40tskCnwXuAF8DjiR29PZNLMdYndd0JSzUzDoDBTbiym2F6/YlxR/y1s9DM4O0jHWkTHWbrSvavbisXpyb7ijoaGxOrVACfAe4viYR9n2ueZe+B4vdrzIbGiWrxz7CvWe+vU/MAJcRdoi7GVNo6sNRn8u2SAl2e6orpEVovOwcAN8j4ko1zhwbCTwXlUU5afAXy2+/hLw8u6eksaBxVggjpqzHXLRX3JRUVWVodkhOsc6uTpxlXA8jNPs5EzlGdpK2vDZs92VdReJAN8BbgK/ityk7AfiYZjrkXQNXX7mRq0n/qLxKDOhmRVN3m/M3ODy6OWMsQ6TY81WD3kdFdbQOOgoSBTvh8B1JGVTg9nQLC92vMhCZIHfavstalw1G3/odcDK3pcGGAvAUSeLub5zmoDIR2avSIsEV1uuz0Rjl1jzLk4Rl4r/hPguJW0h/lxV1R/uxYlpHFDc7XDrr8F/Exw1jPvHU3V18+F5zHozLcUttJW0Ue2qzs+6uvUII81FbgN/D9hPfUPneyARlV5G+xCj3ojP7lt1MSASj2RE/pLRv+vT17kcyRR/BaaCFa0eiqxFuK1uTfxpaOwFrUgxyHtoAg/p6/qNy98gHA/z1favUuGs2PhDt5DygKfJTfdiVzsM/wACt8BenYMT0FgTVRXxba/UUmgPMGsKPFVVVUVRXlZV9RjiAaihsXOczYRVGBz4HhdjhYwujKJTdNS767lQf4HDRYcx6vepm1MI+BZwF/gC0JLb09kyM5fB7AHbJm4e9hkmvYkSRwkljpIV+yLxSIboS0b/+qf7+XQ00zi4wFSQIfrGQmMk1MT+W4jQ0Mhn9MCDiMgbQ1I271Mm/BO82PEicTXO19q/RllB2cYfUpHonQNZos8FzmbQmxaFhCbw8orQqLRDOvTZXJ+Jxi6yUR7WJ4qinFJV9cM9ORuNA0skHuHa5DU6Rjsw3u2lODaOvuwLPNfwHK2+VuymnTk25pwg8E3kZuSLwH7r8RqZhYWhFamz9wMmvYlSRymljtIV+8Kx8Aqzl6nAFL2TvfijfoZGh7j57k0aPA00ehpp8DRozp4aGtngBNKc+z3g8zk+lxwxujDKNzu+iaIo/O7x3918qcIgMAQ8hxis5AK9CZwtMNctPVU1G/78YaYDFD0UruO+qrHv2UjgPQj8lqIoNwE/kh2vqqqqJe1qbEhCTTA4I+YX1yavEYlHcFlcnK75HMcDlzlf/6gYr+xTgkEYGoKRATvxLtDPAl+GZR0B9geznfKo2SVnYDaYKSsoW3XVPBgN8l3/d3F5XPRP99M51olO0VHprKSpqInGokaKbcX51ZNRQ2O/YEVcND8CzgP7wFsrm9yZv8O3Or+FUW/ka+1fo8i2yVS6ZPSukNybe7nbJTNkvndTfVXziVgMJiZgZCS9dXWVEw5DYyNUV4Nen+uz3AaJuNTfOQ9rjegPOBsJvGf25Cw0DgyqqjLmH6NjtIOu8S7uRe5hMVg45jtGW0kbVYVVYorWOy4X/n0k8BIJuHsXrl+HgQG4fRuMYah8vY43HTD/PJTNQOMMuN25PtstkMzHd9SIZbLGprAardTaazl35BwJNcHde3fpm+qjb6qP1268xms3XsNlcYnY8zRS667FkKfmNRoaeclDSE+8S4jIu0+4NXeLb3d+G5vRxlfbv4rbuoUJpQ+pAf8Vct9H0F4DpkKZX/JY4EUiMDoqW1LMTUxAPC77zWYoLQWbLc6lS/Dee/JeXR00NYngc+xFj8FssHAdYn7NXOU+YN1ff1VVb+7ViWjsb+bD8ymzlHH/OHpFT2NRI20lbTQVNa28sXW1wcRbYtVrdObmpDfBvXsw0A83u2C0G3QzYAtArQXOWsFnhKEqP3MvFHFrHj5d9Jj1euWi39gIVVVgyPVEux7BO9KvqPjRjcdqrIpO0VHhrKDCWcGTtU8yH56nf6qfvqk+Ph35lEt3LmHUGalz19FY1EhTURNOc/7+3Gto5AVu4AgSxTtL7tIN95AbMzf4qyt/hdPs5GvHv7a164QK/BLwAPmQjJHsiTfxDkQXwJh7FRQIZAq50VGYmpJ1TgC7HcrKoKFBHsvKZMFWUeDixTHOnDnC4CD09UF/P/T0yOfKy2W+b2qS53mbuDHbAQYbFOzHVCONrZDPt50aeU44FqZnsoeO0Q6GZodQUal0VvJC4wsc9R3FZlyn8Y67HcbflFSB4r3qwLoBYYiNwWgXjHTBdD9ERsAWBJ8emj3g8YCrAUylgBcogsDMbR7/e1U8jkwUAwNy4f/wQ1npM5lkpa+xUSaNwsIc/z2XM9MhbREK95srTP7iNDs5UX6CE+UniCViDM0OpaJ7vVO9AJQ6Smn0iNg75DykGbVoaKzGw0gvt8vA6Ryfyy7TP9XP97q/h8fq4avtX8Vh2qIgugqMIg7O+ZI+6GqD8bcW5/q969egqrJAu1TMjYzA3Fx6TGGhCLhjxyRCV1YGBQXrizOTCQ4flk1VYWxM5vu+PnjzTXjjDRGJyQXe+nqwWHb/77sp4iFJl3V/BnT58gOisVtoAk9jS8QTcW7M3KBjrIPeyV6iiSgeq4fHax6nraQNj9WzuQOZi8Sid6YDvGf2brkrDswAU7Kpk9KxYaof5m7D7KykYio6cJeD6wQUN4OrHpRioAipBVlyupGLkdTzoiLZHnxQ0j6GhuTi398P167JmJKS9MW/oiLHefyJGMx1gfMI6LXm37uBQWegwdNAg6eB5xqeYzIwmRJ77wy/w1u33sJmtNHgaaCpqIkGTwMWQ77cEWho5JjKxe094CRwQNdBrk5c5a+v/jU+u4/faf+d9RdIVyOBRO98SJuJfMFSDLZDEjnaJYGnqjAzkxmVGxkBv1/2K4rMy5WVcPq0CDlJudzZ9yqKHKe0FM6elehgcoG3txcuXwadTrJ4kqmcXm8Oo3tzV2XO12rt7ws0gaexIaqqMrIwkqqr80f9WA1Wjpcep62kjQpnxfaMJFztcOcnYtlr3YT186ZPGFggJeKYXPJ8BmIRmQxmZmBsAaYVCFjBWA2+Z6GyTTbTDi/+JpNc1JuaZAKanEyLvXffhbfflpW9+vp0dG/P8/jv9UMsqF3w9whFUVKN2h+peoRgNMj1mev0TfUxMD2QMmqpKqxKRfe8Nq9m1KJxf/Mw8BLQi6RsHjA6xzr50bUfcajgEL/V9lvbW+DpROa6L5F/ItjVDndfhuAYWHfW8yKRkLl0aVRudBTCYdmv04HPJ/NuMipXWirz8W5js0Fbm2yJhNTpJ1M5f/Yz2dzudCpnTc0el2/MdIDZC9byPfxSjVyhCTyNNZkNzabq6iYDk+gVPYe9h2kraaPR04h+pyH+wqNw9xW56GxH4IWBaTIFXHILp4epepgzwN0w3ArAzQXwWyDeDJVNIqzq63fXGEVRoLhYtjNnZDK6cSMt+Lq7ZVwyj7+xUZ7rdnuinukAYwE46nb5izRWw2q00uprpdXXSkJNcGf+Dn1TffRP96eMWtwWd6pur8ZVoxm1aNx/NCP1eO9y4ATeJyOf8Le9f0u1q5qvHPsKJv02lEgcuAiUk58telytMPKqRPGsFzb9sVhMUiCXRuXGxuR9AKNRMmLa2tJCzufLj5r3ZOSuqgqeekpSQ5OpnJ9+CpcuyfknyzcaG3e5fCMyI+lKpefzuEBQI5vkwa+BRj4RioXoHu+mc6yTm3PisVNdWM3DTQ9z1Hc0u6ljBqtY9c5egdKnV88JT5CRUpkRkbu3ZJyC2EJ7gUqJyN1cgL5p6BsFf0CGldWLoGtoyG16pNkMR47ItjSPv78/ncdvs8l5JvP4d5pOsoJYAO71gfchyUnVyCk6RUdlYSWVhZWcrzvPXGiO/ul++qf6Vxi1JNswaEYtGvcFOsRR8xVgGEnZPABcunOJl/tfpsHTwJeOfgmjfpu94j4BZoHPklE+kDcYbFDQtDjXP7XqfBMOrzQ/mZiQSBhItktZGZw6lTY/KSrag0XQLFFYCCdPyhaNpss3+voknRNErCZTOSsqsvx3m1lshaS5Z943aAJPg3ginurj1TfVRywRw2vz8mTtk7SVtOGy7KJ1vrtd8sLHr0O4aWVK5TQi8pLYkDq4+sXHRaOTeCEMj0j++8CATA4gxc71DekonT0P+6kvz+MPBqUVQ1LwdXbKmIqK9EpfaWkWFuFmr4CakPQZjbyj0FLIyfKTnCw/STQeZWh2iP7p/hVGLU1FTTQVNVFeUK4ZtWgcXB5Aasze40AIvHduvcNrN16j2dvMF1q+sP3IfBRpCF+FzIv5irsN5q/BwiB+XX1GVG5kBKan00MdDhFwhw+n0yxdroMTeDIa03P5c89JymkylfOdd+Ctt8BqlfuWpsUsI+tOWtapqkRPHbXStkLjvkATePcpqqpye/42nWOddE90E4gGsBvtnCg7QXtpO2WOsuzX/URYJaWyASI2CHbAQpOMMyA2z8VIOk7Rkm1JFGt6erEn3WUYHBRTk2RaxPnzclHMihDaY6xWaG2VLZGQyS8p9l5/XTaHIz1B1NVt06VrtgOspTuuidDYfYx6I41FjTQWNfJcw3NMBCYklXOqn7dvvc2bN9/EZrSl6vbqPfWaUYvGwcKEmKy8g2R17Kdeo0tQVZU3br7BxaGLtPpa+bXmX9tZucNHSDbLr5N30TtVhfn5xYjc3SZcoxZuvdXBJxNpJep2yzx9/Hg6zbLgPmpqv7R845FHIBSS+5q+PlmsvnJFxlRWpmv3fL4t3tcEbkN4GnyP7drfQyP/0ATefcZ0cDpVVzcdnMagM9Dsbaa9pJ06d93O6+oSSKrIaimV88vGFgJePfiOgfljqAuCzwpOVi0Sj0RgsDfdaDy54ud2Q3u7ROhqayX98aCg08GhQ7KdOwcLC+noXk+P5PInRW1S8BUXb+LiH5qAwF0of3Yv/hoaWURRFHx2Hz67j0erHiUYDTIwPZCK7nWMdaSMWpLRvSJrkWbUorH/eRCJ4L0PPJfjc9kGqqry8xs/553hdzheepxfOfwrO4u6R4C3kMhdTXbOcbuoqszJy81PAovlEYpi4ERZK/XFHRQfD1Nabqa0dIeRqQOIxQJHj8qmqnDnTjqV8xe/kM3pTKdy1tZuwkBmtgN0RnHL1rhv0ATefUAgGkjV1Q3PD6OgUOOq4WzVWVqKWzAbtqiIVCDA6i6V00jBdxILkkZZS0ZKJR4gWW4QaIeBD6CoG1wn01+zWJuWTLscHoZ4XC5mNTXw0EMSpfNssjPDQcDhEDHb3p526UpG9157TbbCwrTYW/PiP9shdRCF+eSnrbEdrEYrx0qOcazkGAk1we3526km6z+7/jN+dv1nuC3ulNirdlVrRi0a+5MCpAXAp8A5YB+JA1VVeWXgFS7ducSp8lM83/j8zhdd3kfm4iezcYabJx6X+rilaZajo7IIC1Lb7vNBc3O6Xq6kBIyRdrj+EVT2gPv43p70PiRZmlFRAU88IX39lpZufPSRGMrU1KQF3wqzuEQMZrugUGuFdL+hzfIHlFgiRt9UH51jnfRP9RNX4/jsPp6qe4pjvmMUWjaRhx1ldZfKSSC0ZJweEWxFwGFWplRuNIdZy6RXzmwHfstJbtwQQXf9ukSsQNI2koKusjI/XLJyzVKXrvPnJRUm2YMnefHX6+XinxR8RUVI3d1MJxQ0gHGv+zJo7CbJyF1VYVWGUUvfVB8fj3zMB3c+wKQ3pY1aPI0UmO+jfCiN/c/DQAfwMfBojs9lkyTUBD/p+wmfjHzCwxUPc6H+ws7FXRBxFT0MHMrCSa5BNJp2skwKubExEXkgC4hLUyzLyiSLZFUDM0MFmD3i3qwJvC1TUACf+YxssRjcupWu3Xv5ZRnj9abFXlUV6Bf6pMG5Vmt/36HdJh8gVFXl1tytVF1dKBbCYXJw+tBp2kvbKbGXrJxUEsAcq6dUzi37AicSgTtGWsB5kVTLbWaZxONw+7bC5I12GP05Px+eJhj3YLNJymVyu59y8reL05m++MfjcvFPrva9+qpsHg+01Q3R5pjHeewZ7QJwwFlu1DI4O5iK7l2bvAZAmaMsw6hFS+XUyGtKgTrgA0Ts5cgJebMk1AQ/7PkhV8av8Fj1YzxR80R2fsfeQxZanuCvUQAAIABJREFUsxi9C4VYYX4yOSnZNCDplGVlstiarJfzeLbg9qgoIjTGfgmRWTDtooHbAcdgkPr7ujp49lmYmkqncn7wgfTaNZvhXG0HVcUFFNbWoi3n3l9o93cHgMnAZKqubjY0i1Fn5EjxEdpL2ql110qOfwC4zeoplbElBzMjoq2alSmVWWoUOjubjtDduCH2yBZ9GxeqfsGzD3bgPfoEZWX7x/44H9HrJT2zthYuXJCm7sno3mR/B5/oLFx65zA1tenonkubaw80Rr0xJeSeV59n3D+eiu69efNN3rj5BnajPdVzr85dpxm1aOQnZ4BvAV1AHgcm4ok437/6fXomezhfe56z1Wezc2A/kp7ZCmzTI2thITMqNzIi80QSp1MEXEtLOjLndGbBtMzdJgJv9gr4svTvoUFRkWwPPZTus3ujz09itJ/Xbz3Ejbd1qT67TU3y/6mt5R1sNIG3T/FH/HSNd9E51smde3dQUKgvqOdpx9M0qo2YJk3QS1rQBZd8WEc6pbKBtIgrAuxk3Ykr2fMlKeomJ+X9wkJximxogNpaJ5aROgh3QPk57cqTZdxu6R906jMR4t1XGQu3EZ000NcnK34gaTVJsVdVlbsegRq7j6IolDhKKHGU8GjVowSiAa5PX5cWDJO9XB69jE7RUV1Yneq5pxm1aOQN9YAPSVFsI+/cIwGi8Sgvdb9E/3Q/zzY8y0MVD2Xv4G8jJRTnNh6qqrKourzH3L0lfWQ9HigvhxMn0m0Jdq2lkMkN9mpJ0yx+VJvrd4FUn93iLtS7CRoK27k2JAu8b7wBFy9mOnHX1x8sczoNQRN4+4hoPErvZC89Az2M3hzFMmehPFLOOfUclbFKLH6LGKAkKUBE21Ey6+LcbDulcjOoKoyPp90ub96UlEGjEaqrpdFnQ4OsNmVc213tMPwDCNySCUAj+8z3oCdKeUs75fbM1I7+/szUjrq69ASgpcgebGxG2wqjlr6pPvqm+vjp9Z/y0+s/xWP1pOr2NKMWjZyiIOmZfwMMIimbeUQkHuGvrvwVQ7NDfK7pc5woP5G9g88DHwLHkcXZJSQScj1fnmYZWqyZ1+mkRquuLtP8ZFttdnaCux1u/xiCd8G2iwWE9zuznSjWUkqqSyiphscfB79f7sv6+tJO3Hq9LOo2NclWVJTrE9fIBtoMna8EgSlQJ1VGh0a5PXibqdtTmGZNVFDBCccJSuwl2B32zAhcMq3Sg6Rb7tXpLjbnToq65OqgzwenT4ugq67ewBzF2Qx6k6zsaQJvd5jpkBVUm3QKVhSZ8L1eePhhcUG7cSMt+Hp65GOlpWmxV1Ghpc8eZJYatTxV9xSzodlU3d5Hdz/i/dvvY9KbqHfXS28+zahFIxccA36BRPHySOCFY2G+feXbDM8N8/nmz9NemuUc0jcBFWKPwMSylgSjo5IxAzLXlpRIlkwyKufzyUJrzilsgbsvy3ykCbzdITQBgTtQ9kzG23Z72ok7Hhd38mTt3k9/KpvHk07l3PC+TSNv0f7bckkMadi6ikulf9bPmH+MsYUxQokQ0cIo3govFQ9X4KvxofPqRMw5yEl6SiIh/VmSaZd37kjkzmqV1cGGBgn7O51bOKjeBM4WmOuG8uekb4tG9ojMgX8QfI+vmRZjMom1dXNzOhKbFHvvvANvvSX/x/X1MgE0NOxiKo9GXuCyuDh16BSnDp1KGbUko3s9k7ICUF5Qnmqyrhm1aOwJBuA08DowjqRs5phgNMg3O7/J6MIoX2j5Akd9R7Ny3EhExNtEH9i+A4Nu+Pi/pp0szWYRcSdOpM1PvN48TrPXW2RBd65LBMhO++9qrGS2U1ohuY6tOSTpsl1TA08/Lam8SVfOjz+WjB6TKTObZ0v3dBo5RRN4u42KpFSs5lI5S0ZKZcgS4rbxNv2Gfu6W3yVUGKKkqoTmpmYO+w5j1OdW8CRt+AcGJMoTColOOHRIQv8NDZLHv6PojrsdZi7DfC+4tB5tWWW2U1Sbe3MryooiK8AlJfDoo/L/nWyyPjAAXV0yJlm43dgoz7V7+4PLUqMWVVUZ94+nxF7SqMVhctDoaaSxqJF6d/3W+2xqaGyWk0ij7/eAX83tqfgjfl7seJHJwCRfOvolDnsPb+s4weBK85OpKbl0N1+DQ7Mw/wQ8XJtOs3S79+F119Uu/dnu9UNhc67P5mChqhIdddRvqRWSyyUZV6dPSyR4cDAt+K6J6TKlpek2DIcOadk8+Ywm8LKELqKDO6x0qZxCiqGTmJDI2yGgDaKuKP26fi5HLtPv70dFpbygnPaSdlp9rdhNuQuPRKNitZ8UdRMT8r7TKQW8DQ2ysmPNZrNZew2YCuXipAm87JG84NurJUVzG1gscPSobKoqNx7J6F6ycNtuT4u9rP9saOQVS41azlafJRANMDA9kIrsfTr6KXpFT7WrOhXdK7JpxR0aWcSG1KJ9ApyHXPnA3wvf4xsd32AuNMdXjn2Fek/9hp9RVSllWForNzICc0vaExUWioA7dgwOmaAiAubHQXlm7ePuGwrqwWCH2Q5N4GUb/xBE56HswrYPYTSma/KWZvP09Ukmz5tvgs0m94FNTZLVo833+YUm8LLBj6DqR1VQs/haQYxMipD3ltbIFUCCBIMzg3SOddIz2UMkHsFlcXG2+ixtJW14bd7VvmXXUVVxuEzW0Q0NSTNNg0HysB94QH6Zi4t3cbVQUcDVBhNvQ/QeGLXanqwQvAvhSSg+k5XDJSN35eUSvQ0E0m0Yenvh8mVZ2ausTAs+n28frjJrbBqb0UZbSRttJW0k1ATDc8P0TfXRP92fMmopshal2jBUF1aj11KzNHbKQ8BHwCWy2hNus8yGZnmx40UWIgv8dttvU+1aWT+uqtKCYLn5id8v+xVFjC0qKyV6kkyztNmWHOR/IAJ2nzR335Bk+uDUhxALgkFTB1ljpgP0ZnBuL4q8nOXZPMFger4fGIDOzsz5vqlpl+8TNTaFJvCyQRNMn5im5umadM+4Zfctqqoy5h+j80YnV8aucC9yD4vBwjHfMdpK2qgqrMpJ3UooJOmWSVGXXD30esXtsr5e8rP3tDDb1Q7jb0mfnCwJkvuemQ7QGaS4fRew2aCtTbZkfWYyuvfzn8vmdKbFXm2tZst8kNEpOqpd1VS7qnm6/mlmQ7Mi9qb6U0YtZr2ZOnddqg2Dw6S14dXYBkXAYUTknQX2cK6aDk7zjcvfIBwP89X2r1LhrCCRkIXS5WmW4bB8RqeTxa6mprT5SWmp1DqtySjQDTyGtDI6KLjbYfJ9qbsvOpnrszkYxCMwfxUKW3fNx8BqlajysWPp+T6Zypmc712uzPk+L8x97jM0gZcNWmB+fB5WyTKYD89zZewKHWMdjPvH0St6GosaaStpo6moac+txhMJmWySaZd37sh7SVv8xx4TUZfTptcWrzhrzXZoAi8bJOJSzO5sluL2XSa5kldZCU8+KWlIydW+ri4p3tbrJSqcnABWtMzQOFC4LC5OHzrN6UOnicQjDM4MpqJ7S41akvV9ZY4yzahFY/M8DFwDLgOn9uYrJ/wT/PdPX2R2Ps5jhV/j8ptlvDICY2OS+QJyU1tSIgtfSSHn823DlfCXgAVp8H6QsJSCxSdzvSbwssP8NRF5m6y13ylL5/vz58WrIZnKefkyfPih/LzX1qZr93J6f3kfoQm8XSAcC9Mz2UPHaAdDs0OoqFQ6K3mh8QWO+o5iM9o2PkgWuXcvHaG7fl3C64oiE86jj0ra5aFDeea45T4Od/4OgqNgLc312aSIJ+Jcn7lO13gX3ePddE90Mzkxydu6tzniPUJLcQsNnoacG+JkcK8fYgGJjOaAggJJ733ggUxb5v7+tC2z250We3seMdbYU0x6E4e9hznsPZzKbEhG994YeoOLQxdTRi1NRU3Uues0oxaN9alC6trfB06Kd1kikbnF4xu/t5kx3d1OBidG+fHNFwn4dbSpv8t7+LBYZE49dSptflJUlAUTittAL1JjuNf96nYbRREhMvIahKfArNXo7pjZDjC5wFaVk693OsXN9cQJWegYGkoLvv5+GePzpVM5Kys1o5bdQhN4WSKhJuif6qdjrIPeyV6iiSgeq4fHax6nraQNj9WzZ+cSi4k5SlLUjY3J+w6H/EIlWxjY9lZnbo3Co3D3VUktzIHAS6gJbs3dSgm5rokuusa7uDZ5jVAslBpX66olEAzwi1/+IvWeQWegwdPAEe8R2YrlsdnbnBvTnNkOcdIq2Ljwf7dZbss8N5cWe59+CpcupVf7koLPvT1PGI19gKIolDpKKXWU8lj1Y/gjfgamB1KRvaVGLcno3l5eSw8aqipbtkVPtsbs5NhFI3D4Clzpg4ld1AndwxH89f8dt9PEV499jcOVRZSVSVRiV4LOryNpmQ/uwrHzAVcbjP5cXJ5Lnsj12exvovOwcAN8j+VFSozBIPebDQ3w7LPiBpsUeu+9J62XLBbZn5zv8/q+dJ+hCbws8Patt3np9kuUKqVYDVaOlx6nraSNCmfFnqQZqSpMT6cjdIOD4oCp10NVldxI19dLqkge/M5vDoMNnE0wdwXKnpaC7F1AVVVGFkbSQm68i66JLq5OXGUhspAaV+GsoNXXyvna87T6Wmn1tXLEewS7yc7Fixc5eeYkvZO99Ez20DPRQ89kD1cnrvLj3h8TV+Op41QVVqWEX0txS0r87Zq7YCwA831QdHrX/g13QmGh1HqePCkLEzdvpgXfyy/LGK83ffGvqtKarh5k7CY77aXttJe2E0/EGZ4fTjVZf3XgVV4deJUia1FK7FUVVu2pUUssJsYYwSBMTJi5dSt3gma7Y3KBosh8pNNlbsvfW22M2bzxGL0edO1QEgGvBcbPbf27UBJE1SBhNUAkESScCBBKBIgkAoTiAcKJIKF4gKGu13n0aCtfO/41XJZdzjUbBG4AzyIO3AcRYwE46mQx13duH92k5CGzV+SG0NWW6zNZgaLIXO71wpkzaf+HpOBLtl06dCidyllaqv047ATtVikLqKpKibmEL7d+mUZP457ccITDIuSSom5mRt73eNJulzU1GxRu5zuudpjrgXvXwdm448NNBiZXCLnu8W5mQjOpMT67j1ZfK18//vWUkGspbtlwIneYHJwoP8GJ8hMZ70fiEQamB1KiLykA37z5JsFYMDWu2FacEntLo347XiSY6wY1vmf5+DvBYJCFiPp6We2bnk6LvQ8/lBW/pU1XGxpEIGocTPQ6PTWuGmpcNTxd/zQzwRn6p0XsXbpzifduv4dZb6beU09TURMNnoYtG7VEIuIA6/evfFztvUgk/dmhoTK6u7Pw99xAeKwlaIzGTYiezQijXRiz/L09u0lzAT+Fw/VxgiVBAtEAwag8JrdgbMnrUCA1Zun1eDkGnQGb0YbNaKOqoIyvP/B1nOZd7visItE7J9Lv7yDjaofhH0DglrTy0dg6qVZIlfsi1dVigZYW2VQV7t5Np3K+/rpsBQXpVM66un1+P5sDNIGXBc5WnyU+GKfZu3u9XFRV3LiS5ijDw7IiazJJOtuZM3LDe6DS2QoaJZI327ElgTcXmqN7onuFkBvzj6XGuCwuWn2tfPHoF1NC7mjxUYrtxVn9K5j0JlqKW2gpznSvTKaApoTfRA9XJ6/yUvdLGYLTYXLQ7G2WaN8S8VfnrtucQc/MZbCW5FUd42bxeODBB2WLRNK5/EubrpaUpKN7FRV5VkeqkVXcVneGUcuNmRup6N7ViauAgs9aTqWtiTJTIw61jGBQWVe0RaOrf5deLz0dbTZ59HgyX9ts8PHHYzz8cM2OhJFWe7Ix8UR8dXG2ingLR8O0jrQy/hfjXH386qrHM+qMKbFmNVpxWVzp1wZr6vnSMUadMbXQdnHh4u6LO4ABYBj4LAf/Ts3ZDHpTulerxtYJjUJoHA69kOsz2TLJyN2hQ3DuHCwspOf67m745JN0eUdS8Hm0TP0NOeiXjX3NwoJE55JbsmdOWVla0FVWHuCbWp1erH5nPoF4aIUDZCAa4OrE1RVCbnh+ODXGbrRz1HeU5xufzxBy5QXlOXXp0ym6VHTiucbnUu+rqsq4fzwj1bNnsodf3PgFL3a8mBpn0pto9DSuiPodLjqM1bjYTyg0CYE7O2p2mi+YTJlNVycn0xPAu+/C22/LimB9fTq659Bc9/c1qippPKtH2EwEAs34/c3YFlTu+UcZDvTzSaKPeS4Cv8REAUU0UkQTxYY6nHZTSpwVF6fF2nLhZrfLz9tGl4exsSD1uS9r3VfEErE1xdla4i0cD695PJPelCHOPF4P9ofsnL5ymnpfPWavOVOsGaz5ZYC1FsnonRt4IMfnshfoTeBskYyT8ud2zd7/QDPTCcriPdM+x+HINGa7dSudyvnqq7IVFaVTOaurD/B98A7QBF426Af7gB2akKbm2wwjJx0Gk2mXIyPyvt2eTl2rr7/Pblzd7cQm3mXwxt/wUSiRIeRuzNxARQXArDfT7G3mserHMoRctasaXR7Wnq2FoiiUOEoocZRwruZcxr758DzXJq9xdeJqSvxdHr3MD3p+QEJNyOdRqHXXcsR7hM85bZwyhYk6z3K4YHb360X2CEWRG/TiYlnoCIcll3/pih9IE/ZkdK+8XIuW5BpVldq11VIf10qPTCRWP5bJlBZkhYUKZWVlPGIvw25/DMXkZyIxwEi4jzuhblTdJ+gMeryumlTPPc2oZedE49FVhdl64i0Sj6x5PLM+U4x5bd4NI2urZjEcAoahZrgGdqft5+7TA4wAv8aKnroHFne7ZJzM94Jr/4uUPUVNiEmNs+nANYzX6yVLrbYWnnkmXbrR1yembO+9l27zlRR899U98jpoAi8b/As49c0lzXcKgeLFzbfk+fLNBzMGGFgUdYODkoqW7Cty/rwIurKy+6PQNJaIcX1aWhB0jXfRPdFN1/gVnor1spBQ+ct50Ct6moqa+EzZZ/hq+1c5WnyUVl8r9Z76Pe8puNc4zc5UitpSQrEQ/VP9y6J+VxmYusqb0Tjfee/HAJQ6SlfU+B0pPrLve46ZzXDkiGyqKq6xSbH35pvwxhsiBJJOXXnvILtPSCREhG0k1pY+qurqx7JY0tEzl0tSddaLsK1vtGMH2oG0UUvfVB99U328MvAKrwy8gtfmFbHnadxzo5Z8Q1VVoonopqJqS8dEE2vktwIWgyUlxBwmBz67L0OYrRBrBmv2/g8KgaPAJ8Dj7L/WAgmk750XOJbjc9lL7DVgKpQ0TU3gbY171yHmz1krpL1keenG4GA6utcjLVVTi7tNTfJ8H9/e7IiDfUe8V/xD6KrvorWkFSaQbXzx8QbwATAJxFZ+1A20maCxAFQvGMvAWg36ADCNuGgtF4b7/OY0oSa4OXtzmZDromeyJ7XCq6BQ566j1dfKMdcpHjL4+dPmP6a+9JTWE2sZFoOFYyXHOFay5G5gYZDE9b/ktushvhyKZxi8fOvKt5gPz6eGFpoLVzV4qXHV7LsbX0UR563SUjh7ViJG16+nBV9np4ypqEhH9zSnLiEe37xY8/slfXItwWa1pgVZUZEsWK0l1my23UuvWWrUcqH+AtPB6VTd3ge3P+Dd4Xcx6800eBpSRi05aWWSJVRVJRKPbKpebemYWGKVyWmRpdEzp9lJqaN0w8hazrMmzgBXEJG335qDdyH3Dr8B3E9ZB4oi7o8T70B0QVr7aGyO2Q7xKyjYuRndfsJkgsOHZVu6uNvXl17ctdvTc319vSwm3i9oAi8bHIPJqUk4t3JX8ofu+gDc6oSZXrDcA2cYKq1QbpCFusJ7oCRFYd/i41oLpHbWjAiu+r4dyMENrKqq3L13d4WQuzpxFX/UnxpX6ayk1dfKhfoLqYjckeIj6YbwkTno/b/AGANN3G2OmQ50BitVlU9TpTPyucOfS+1KtoZYavDSM9nDy/0v85eX/zI1zmKw0FTUlCH8WopbaPQ07huRbbVCa6tsS526+vsznbqS0b26uoMzASQt/Tcr2kKh1Y+jKCLCkoLM51tfrNls+ZsO67F6eLDiQR6seDBl1JJsst490Y2CwiHnoVR0r9RRmrPotqqqhOPhdYXZauJtaVuWpSgoGdEzl8VFubF83ciaxWDJvVjbDmVADdL4/EH2T5pjHInelbJ/00t3gqsNxt8Su//ih3N9NkIceAP4LrRebYV/BjxDTu6pViUegvlr4P6M+Bbcpyxf3A0EJDOuvx96e+HyZZmXqqrSqZxe78Fe3NUE3i4QCKSNUQYGxCwFFh3/PiurCBv281KBeVZGBJdvo0Dn4vO1atEtrC3+Vnu/gC1fvCb8EyuEXNd4F3PhudSYEnsJrb5Wfv8zv58Sci3FLRRaNvC6NxWCvXaxT87jB/s3MhvEIzB/VYqtVylWVxSF8oJyygvKOV93PmPfTHBmhcHLpTuXeKn7pVS9o07RUe+uXxH1a/Y274273DZZzakrGd3r6ZFG68kJILniV1ycPz9u0eja9v2rPYbXuB7odJmCrKxs/XRIiyV/BdtOMOlNNHubafY2o6oqowujqVTOXw7+ktcHX6fAVJCq26tz12HSb6/AWlVVQrHQlurVAtFAqrZ2OTpFlxE9c1vdHHIeWjOyZjVa969Y2y5ngO8AV9k/qY6XgRngK+SPgNhLLMVgOyQRqVwKvATwLvA94H8AY4AdnCYnPAe0Af8I+CKQaz+YuauQiO2LVkh7ic0GbW2yJRJw+3Y6lfNnP5PN7U6nctbUHLweuwfsr5MbEgkYGzPz+usi6EZGJFpgtYqYa2iQx4KCLRxUQWoJCoGGTYxXgQVWCsDVhGHP4vtrtf0xI2HFVcRfwBXgpukmvUovV9QrXIpc4oOFD5gITqQ+7ra4afW18putv5k2PPEdxWvzbuEfYBnudhj+IQSGwV61/ePcD8xfE5G3jQu+2+rmTOUZzlRm5jUFogH6pvoymrj3TPbwSv8rGbU4hwoOpYRfqrVD8RGKbcV5V+fncEB7u2zJCSAZ3XvtNdkKC9Nir7Y2e314VDWzB9tmRNtmLf3d7vUjbBZL/ojWfEFRFMoKyigrKOPxmsdZiCwwMD1A31QfXeNdfDzyMQadgRpXDY2eRuo99cxF5xieG95UvVowFlxXrC0VY0XWIiqdlWtG1qwGEWv59vuUdzQi89i7QCs7FkyqKr+HU1MmAgGZ37P6XxBDIkUVyLnfr7ja4O4rEByTFj97hQp8hIi67wG3kcXxF4AvyeN777zH43ceh38L/DbwT4A/AX4PyFVG6UwHmL1gLc/RCeQ/yYXbqip46imYm0uncn76qZi1GI3pHruNjQejx64m8LLA978Pr7xSRm2t1PacOyeirqxsD1e+FSTyVgDUbfIzflaPCo5DdCyK/46f6N0ouk4d1lkrtpANGzaOLP75PJ8HIGaIEXKFUL0qpjITplITSrGydrTQxdZrC5xHQPeTxT45msBbl9kOMLnBlr1/J5vRxvHS4xwvPZ7xfjQe5cbMjRVRv7/49C8y0nA9Vs+qBi9VhVV5EVVYOgGcPw/z8+n0js5O+OijzD48jY1SW5ZEVSVitpUIW2yNsiejMVOQFRevLdY2a+mvsTUcJkfq5z2eiHNr7laGUQvA0J0hPv3004zP6RV9hhgrthevEGfLI2tmvVkTa7uBAjwM/C1wE0nZXIKqyo3exMTmN0ljlsUvs1kWUzye9ONmnrtca9Scfoxk7fwa92f0LomrFUZ+Kq6Q1qd397tUpFbzu4iou4FE5J4B/jXwK8g9VXK4UYXfBb4K/B0i9P4X4J8Df7i4+Xb3lDOIzID/JpSe1yaBLVBYCCdPyhaNpnvs9vVJOidIxl0ylbOiIqenu20Uda0q+Tzl5MmT6kcffZTr08hgcBDeeOMSX/7y6X1XvxOOhbk2eW1FauXg7GBqjFlvpqW4heOFxzlpPMkx5RhNiSaKA8XoJnVrRwvnV/1KqYfwsrn6QR/gQQTh8A/FQvnIP8irPjkXL17k3LlzuT4NIToP1/4MfI9ByRM5Ow1VVbk9fzsd7Vsi/iYDk6lxNqONw0WHpb7P25ISfw2ehrzpV5Xsw5OM7k0sBqvdbhga6qOioolAQMatxlJL/6WPa4m2bEUJNXaH6eA0N2dv8snHn/D4mcczxJtJb9LEWo6Ix8VCfakgmxqFuh/DXQVe9WTum5xcOyput8vCitebbsmS3EZH+ygtbWJ6GmZm5DuXP0+WZaxFYWGm6CsuhF+/DQkv3Dy3tnC02e6T+/ihv4LgXWj+Y9iNBcBriKD77uJzPfAk8GVEYLtX/9iqc/27wL8DfoRE/L4O/ANgL3pkjr0BY7+UfyfTAQg55Zhkj91kKuetW5LdY7VCItHJP/7Hbbk+xRUoivKxqqonV9unRfCyQG0t3LwZyGtxF0vEUkYCSRHXNd7FwPRAqijfoDNwuOgwpw6d4uvHv55Krax312/PTTGMuIeuV0M4Dny6+Hx2jePogCKgsR0e6oCZPrAcXVsUFnH//mTPdMpVKsd2yYqiUFlYSWVhJRfqMxutTwYmVxi8vH3rbb5z5TupMQadgQZPw4qoX7O3ec9dDpf24blwQW7kkr0qJydjNDauH2E7aHn99zseqweP1cOcY44Gz2by5zW2QzQqN1ubja5NT6/eN/Fx4FkzXC8HQ6lE4U+dWinckpvXu34blYsX73LuXNOG554UfMsfV3te3As3puD/DsPQ3619XJNp7cjgepFDl2ufXYfc7bKYuzAIBVlSSoOkRV0HEiV9DPifgF9n+5G3M8APEaH4H4D/D/hvi8f8R8Cqt95ZQFUlW8dRq4m7LLG0x+4jj0jE/vp1EXzXruX67LbOfvqV19gECTXB4MxghpDrnujm2uS1jBYEDZ4GjvqO8hstv5ESck1FTds2EVgVM9J09tAmx0dJC8JVRWENhJ1wrwP+5qi0kVgNBYn6bdZUxkvuC6WzQfKCb68gpwDxAAAgAElEQVQEc/42cvbavJytPsvZ6rMZ7y9EFuid7E3V9yWjfz/u/XGGM2BVYVW6vm+J+CuyFS3/ql3B7ZYbxFOn4OLFcc6dux/t7jQ0tkYwuHmxNjkJs2ss+CmKpEcnb8RaWlaPtKUEmxVM/wX+t3bgc6sfM9sYjeI269uMaAgB/xGohD/9TYn+rScGlz4fHoaODnl+7976X1NYuL2U0pxEDQuaQG+R+WwnAu828BIi7C4tvvcQ8GdIG4rN3ptshmbg/0HSNf8T8F8Rg5YnEaF3geym3gZuQ3hasnU0dgWLBY4ele3ixbVuOPOXXRV4iqI8i1y69MD/q6rqv162/8+AZB6ZDfCpqurazXM6KCRT4JYLuasTVwlEA6lx1YXVHPUd5dn6Z1NCrtnbnG5BkE8YEXvrsrUG6GC0DSbehe8sgOKAKTY2lrkGvIWMXd3nQOoCt+I0mo9pdMERCE1AxR7dxWQZh8nBifITnCg/kfF+JB5hYHogI82zZ6KHN4beIBhLOwUV24pX7edX4azQ0uY0NLKIqoqgSIqxzYg2v3/1YxkMmQLtxIm1xVpxsYiOLfdNbEeiNk8ibYPyifcQw7MnREgVFMhWtcUS6mhURPFmhOH0tJhKJZ+vVQ8MIlY3KwaXvrejqKHOILV4Mx1QHgb9FtryjAHfR0TdW4vvPQD8G8T1smab57RZypH6vX8C/DkiJp8l+86bsx1SquI8koWDaRxEdk3gKYqiB/4L8DSyjvKhoig/VlX1anKMqqp/vGT8HyG/hvuO69eht9eB1yspFCaTFGAvfW40bm8VTFVVxv3jK4Rc13hXRrPqUkcprb5W/uAzf5ASci3FLXltW78tXO0w/na6T04Jsm2GOBL1Wy1VdKkwHEAm3cnFz6yGk5T4a/I0ibX1U2QUZO85sx0yMToPVkTJpDfRUtxCS3Hm3yuhJrg5e3OFwctL3S8xE5pJjSswFdDsbV4h/urcdRh0WhLDQSCeiBOOhwnHwiseI/HIzvYtvo6FY9Rdq+OBTx/gSP8Rxn3j/KsH/xX97f3onOm2BUnXy62+NuqMOVuISCREHGwlwrZWGw6LJVOQHT68MgVy6WuXaw8iRA8jJiYfsmq/2pwRQOaaFtZZ2NwcRmP633QrJN1BNysM79yBK1fk+UZRQ6dzeymldjsornaY+gjme8B9fP0vmgZ+gKRf/hJZyG0B/g/EAXP9jNrdwQn8KZIC+h3Szpv/lLTz5nYXGxIxmO0CZ/PWxK/GhqiqLHhEoxAOqwTCUWYDfobGAxt/OM/Yzbub08CAqqo3ABRF+S7wq0hXmtX4TeB/38Xz2TX++T+Hb35z40Rro3Gl8Es+N5lAb58h6u4mXNhFsKALv72be5Yuwoa0KYUl4aFYbaVJ+W3KDEc5ZGyl0nwUj7UIUxRMk2C+B2PDMLOG2Fzr+ZZXRXOBpRhs5dvrk6MnHYHbDAmkLnC9GsIx8F30iaOWETiL9Ml5HjjC3rmhJeIiep2HwWDdoy/dPVRVLrCRSPoxuaVf64hEarFHa2mLPE+zHl5wQ8SuMhkc52agh+FQD3cjPYyMXeVHd3/Oi7yY+g69asIZb6QwcgRn+Aj2wBGs/iOY7x0mEbGu8Z2Zr1X1YZxOuam1Wrf2uJ3P5Pp3VFVVooloSghF4pFVxdF290US2zveWi0ItoNBZ8CsN2M2mKnwV3Ch7wJP9j7JI9cewRl0EtPHuF55nc9e+iy2t21E9BE+qvmI15pe49W6V3nf+/62fu/1in5zYtCwsWg062xEAlbCCzb8c1YCszbuzViZn7IxO2llesK4QrCtZRLkcKSFw6FDcPz4+hE2uz0PjUC8yE3+h8Aj5E9K/jtIaULu/LBQFPk/djh2FjVcTQwufy8pDGdm1ja4gWTUsII/uuBBNXTw/vjxFWLQZ4HDvVD9HrgugRIDtQGUf4yYpbTu5F8li5hY6bz5PyOpnH+f7Tlv3uuTBud53PtutTl86Ty61r7NPkYiEImqBCMhAjE/wViAYNxPKBYglPATTgQIq/IYxU9EDRBV/ETxE1MCxHR+4roAcZ2fhD5AwiCPGP1gXHw0+UEnF0br5IP87hefz/G/6tbYNRdNRVG+ADyrqurvL77+HeBBVVX/cJWx1cD7QIWqqiumGUVR/gD4A4CSkpIT3/3ud3flnLfLwICDmzdVDAYbkYhCLKYjGlWIRnWp50vfCyUCTOsHmDX1MW/p5Z61F7/9GlHLaOqYStSBaeYIhpmj6CZbYOIo6ugx4vOlxKJ6otHsO0vpdCoGQwKjUcVoTGAwqJhMCQyGpc9lX3L/0kejUT6fOW75MdPP0/uWfjY9fvk+o1GVFJbIVYpCl7hj/xWi+tzXmvln/ZQPlVN0qQjPBx4cN6QhTqgkxNSDU0w/OM3MAzMkrNm7CV2ONXaLksDrjNnOEzRUrtgfj0MspiMWUzJ+JmMxJePnMx7P/HldbfzK18mf9fTjemPS35vet9p37ArmORRfD/qSqyjFPajeHhJF10g4B0G3+P+jKhj91VjuNWH1N2EPNOIINuKMNGDBicGgpn4nQqEYiYSZSERHNKojHNYRiegIh/WLAjT5Ov3+plESoI+APgyGMOjD6ExBTNYQBksIozWIwRzCYA6hN4cwmIPoTGH0pjA6YwidMYxiDKEYwyiGMIohAoYQqi4M+giqPoyqi5DQhUnooiSUCHEixBcfY0SIqVHiRIkmokQSEaLqOndl28CoGDHqFjfFiElnwqgzYlAMGHWLr5eOWRyXfG5STKu+n3y+4vNLP7vaPtWIq9eF5wMPRe8XUdAvIfmwN8z06WmmHpxi5sQMcXucwEyA8sFyPJc8eD5M/96HPWGmTkwxcnKE28dvc89xj3AiLFs8TCgRSj1f+n44ESYUDxFJRFaMCcXCBKIRgrEI4USYSCJElDAxJbS9f/iEAV3cij5hwYAFExZMOjMWvRmrwYTNZMZuMlJgMWE1mDDrzVh0Fkw6ExZ9+tGsM6c3vTym9ussmPVm9Ep+rBxaRiyU/rSUyYcnWTi8gc3lOiwsLOBw7LzpmT6g59APDhGoDjB5dnLjDxwgVBVCIT3z8wbu3TNw756R+XkDCwvJRwPz80bqHJc4UvQ+f/7GH3J3wkvinoEnAga+hKyhWpAOGMnWdZ8ANluMgoIYTmcUh0MeCwpii1sUpzOGwyGPS9+zWOIbLkxk6//e2eWk8nuVFL9dTNwUZ/TZUYa/OEzo0Mrf53icJfOyzI1lkZ9jTkzSFfsK0ah+xf7MeXble0vn3Hh85dy8/Plq+6NRXeqz8pi5Px7XyRxmDGQKJuMSEbXe682OVbamYZSEEX3chj5hRZ+wYVCtGFQrRtWKEQsG1YZJsWDCikmxYFYsmHQWio2F/P0nH9rx/322eeKJJ9Z00cwXgfe/IuLujzY6bj62SYDV7XNDsVCqBcHS1Mqh2aHUGIvBQktxi6RVFh9NNQavdFaum66TDCNHIpIqk1zR2MnzbB4rHF57RXgnGI1Q6AjwJ8/9ezpuP8R7Qxc2HaFcGi3d6mfWe/722+9w6tQj6ajOLbC+Ac63wfkhGIIQN8DUUbjTDsOtMOmBaGytyNTqr9cb80T9S5Q4bvLf3vgTQmH9iv2ructli6X/rkZjbl9vNMZoXL03ZSgWon+qP6OJe89ED31TfYTj6Vy0UkdpRprnzes3qamvWT/Vb1lUKhgNE4zITXs4Flk2Nkx0cYuzTmHMVknoIG6GmBnipiXPlz+usS9uxqiYMChmjDozRsWMSW/GpJNIl9lgwmIwYzGasRjM2ExmrCYzNvOiWLDI5rCYcVjNFFjNOKxGbDZl3WjmnvT4mwB+Cry8+DiNOPeeQe4in0fqZ5adx4pr/l3gZ8CrwGuLx1GAE0gNzjOIwYNBUuI2mwo5MSF9GVdD0SXwloZw+4K4fQFc3iDOogAOdxC7K4DVGcTiCGCyBzFaA+jMQcKJzAbsy5u0r9i3+Hrp78FWMOqMKyKMq0Ynd5jiajVY13d7VpGaqCgSOdnmz1XW2uK8jDTW/kPEFExjJZEZ6PqPMHgevn8WfgwEIO6D+WfgzqMwfAim14kiLn2+XtTQYNi4vnB4+Br19c2bii5tJhJVPg+/Mwa/MicJRj+xwH82w6XE2nO31RTgT1/497w/8BCvXbmw6t9l0+hiGO1+DNYARps86q1+9BY/eksAxexHZw6gmPwoprS4Uo1+VEMy6iWRr2RELKZIhEwiZVtfgDLrLFgNdqwGGzaDHZvJjt1ow26yYzfZKDDbsZttOIx2bIvv24w27EZ7xvPl+5LXne22X8qrdlhLyFWbhDvA0lBCxeJ7q/Fl5JK7L4nGowz5h3ip+6UMITcwPZBKHTLoDDR7m3mo4iF+74HfSwm6OnfdtloQKIrcrBqNkhKTj8Tj6YtUdkWojdKCJhqbO7Fef4pwRLdinN8vF/WNjpsdHllzjxF4FHg+Bs91wAMdUmh6HZnfXwEuIjX2ICl4mxUzZrMU4zusQU439zJ07xSPPa7fUzGl1+dhOtY2sBgsHCs5xrGSYxnvxxNxBmcHVxi8fOvKt9I1sH2Zx1qa4rf00aQ3pZ7bLWY8emfmvlU+YzZsb9/S7zIbzBh0BqJRsX0OBjf3uKmxgczX86uMWe+maiMUZe101m2nxZrBNwyln0LRJbB3yyJw3AuxC6C8AIbnQLdJU9ZUw2w/TDTJ4s3kedBfhpJPoW4A6v8l6P8lzCnwSwX+LiFacnjZsZbWURUXQ13d+umQbrcOnc6GeJTtrotsQk0QjAb/f/bOMjqu62rDzxUzmJlBlkFmxpghicPYMDacfME20IYa5jaMDTfgxJwYYmZbBtlyzMxisOh+P95RZDsGwYyGzrPWLFuj0cwZje69Z+/97nf/KfA71dcnfcwJjz2Sd+Skjyt1fK4oIYEhpw0GEzIT6L+sPyuCVpDdLPuMQePJ7ssrziOvMI8AK4DAgEACrAAsrIr1T6ajnsAumODuZBQCvwJfxcP+plCSDCv6w18suBQCB0B8oMbVlVeJaduQm1v+XsM9e2DdOv2/LMGScNLntqyTXytP9W9kpCN51RC+SYJZhTBmE4xIhXMzYGNjmNPbZnObAuxgBVclQQqqGoYuJSF0IyVFjWlj/ZeiE4KqQnIpsCVJPGrnkF8smWJecQ75xbnkOeSMOYU5FJYUUuj4deed9J2d8D6x/gicIoMjiT4uiKpfFlQF/Tm4Kv2ZkwVepV9HBEcQ4Iq5h36KKyt4QWjrMxQFdkuBy23bXnfC4xJQzrO5XY7FeGIF7+JvL+bblG8BCLACNILgmGpchzodaF2jtccMbvYJMtbD9q+h+ZUQXblZVMdWQSsbeB49Cps2baR9+zblCo4iD0LsAoiaB2HzISAP7DAoGQTWaAgYR8UHpB5eBrsnQuubIbyKnfqGcmHbNvtz9jNn3hwGDxh8XMBlLlDHU1Sk48QpAWUFfubYBE48cikf7bjVQS22i1GSZTKSdx17AQoNPXUgGRICO3dmk5cXddqB2RERjkAtXhfC/tmQtA/iHArBrEaQ1Q8YCZGjIaaubyRMqkpxSTF5RXl/BH6nCyTP+PUx9+cfzeeSXy9hf9h+Pun8CXmFeRSWOEd2HGAFKOizAsv+7wgAT7xv1LpRtNvbjk8HfUpueO4fjzv2sc6+z6nPc4r3VZH7/vQ6JQHEL46nzs91qDGlBsHpwRTFFJF92RzsgRM40Ptc7JgGVV5jhYNxdA5LT4cZMxYycGAfQkIgKMimOCCPAkefV05hDrmFueQUOP4tzDnu/yd+78T7cwpzCMgK4II5F3DD3BtokNmAVXVX8Xy/5/m2/bcUBUrRcUMMBFrwTsaf1xloBf4pkDplUFWJClhYUJjfOlJ7YwXPZQGe44XHAK+i6vOHtm0/bVnWP4Fltm3/5HjME0CYbdsPlec5PTHA+3XLr8xaOosLB15IQq0EwoO93+TC4ykpgg0vQVQraHKBW5dS6QM/H5hD2Q6ztBLUmjJp2EDUaHA6Nn8AxUeh9a1md1jNeOpJ3++xoWQlFP8MTIGgpWoHKYqFjD5wqAfsS4LMkMoFkpKgHyIhodZpK2wnHZhtA+tRWnMa8BtwFB3nAymTc1anSZM/MR9JaG8G6kNRSVGFgsa1qWtp3rw5xXYxJXYJxSX6t8Qu+eO+Y+8/8b7wjHAGTR7EllZbSO6SXOnnqch9x95f3vucaVx0KqwSi747+3LJuku4aN1F1MupR3ZwNhMSJvB1+6+Z1moaVnAB/xcHK47CFCcZGZYGfBUNFHPzcikOLP4j6VBRQgNDzxxUBUcSbUfTd15fBn4zkFrba5FVP4vUq1I5cn4qLfOmklNrACU1e/4pEHPqHGPDcXjqtd5tAZ4r8MQADzz3w/dpdk+CtJXQ7n63WgU77bPfTFmwNwsFgBFodtMYVHpodsLPHD0MqW9A/eFQ+9RSUYNrMMe9B5GBZF2l2ue9jvu7UZYw6YHSjU7AaZ99Lkr0lAZ8Gxz3N0aB3ihU/jMTYp1DPvAyUtudX/Efr/Ln/h36jO8Cqu7X4TJs28bGrnKg+Kf7SkoIXxVO/IR4ak6sSejeUIpDizk85DB7x+zlwOADFIYVHhek1k+bR/jRfWyoNZZicO56KhA079+/n5aNW562ynWqqll4cHjFx/KUUOa8OQ/oPQMunQcX3QcNPPiPxwfx1Gu9u3rwDAbXEp8Eh5dCRgrU8MoRisfTEjXc344E8bPRZnUyMNHxmHaUjWHojwbBWhbEdar25RoMbsUG1lEW0M0DioBYFBiNcfxbz10LLCcRKIgb5fh6Owr0pgHfAO+joLQ3ej8jUdDqGeaU3kcY0BVYgmaXVueo2P3AWnTu9vD9uWVZWFgEWAFVnxdqA2vQnLqvgS2oQX0k6qk7J5A60XWoc6p5AZntYdsXJDXtplFAbqLaN/kBwNmO23wbJqyGb1rBQ1FwHZqnV9GWDkPFKSkiuDjd3auoMKZZxOC9hDeE0JqaiedrhKNA7g00eD0VeAVl9d9EG5NaNry0Gpa2hH3unLDuZ9g2bP0cJjSjy8Hb4Pe35fZmcD3ZwATgFqAp0BF4EEhDQ4XnAIfQJvJqPD+4OxlN0VCg79B7mQs8hGScjwG9gLpocuwnlFUqDeWnNwo6Flfz684CQpFDqz+wAc17SwSSUCWqJfABCnZ/Bq4AznT5imoJQZFKaPorSdvgygx4M0m/s/fRbMdLkGGPwTWkrYbpfWif9jhUg2zZmZgAz+C9WJaqeNnbfHuDbaET+d2U2bj/BNywXf7QTyRBE8o2u7ORLZbB+WRthlmjYOGVEFqLIDsXlt4K39eHeZfCnqkaOm9wDjbaJL4CDEdGkeOBz4HuwHvIinIV8CwwAN/SpZTa8D6FbMoOoPc+BgUL1wANgM7o2J+JAkHD6YlDQcdyqu/3tRv9LfdBCTxfZSvwL/Q32Q4FeHWBf1M2SuQ65HxUXgICIa4jZKZCUXn8Hn2QtGS1oiS1VXC3FbgfSbu7Ixn3NI53ijJUnuKjsPoxmNoNcnewO/I8vK0p2gR4Bu+mVJqYttq966hOIpFk475kuCcEpiTAi8ga8BVgCFALuBBlSve4baW+Q0khrPsXTO4AhxZC9zdhxGKW1v4QRi2DVjfCvl9g9miY0ARWPSSnV0PFyUWyy9tRtr8dkiLtAe5EQcxh4HvgBjSAx1+oDVwOfIp+HytQYBuP+sqGoiD4bOAtVP03nJy+qB9vZTW93iwkx/W8WclVZxf6++sFtAAeRkHsq47vzQZuhVMpMMtFfBLYxZCx7syP9TWKCyAzBWLbQ4DDjb0BCqR3oMroBiTz7gJ8Ac4co+p3HFwIU7rA2ieh2eUwNoWD4YO9zsTOl3Kd7mPblzTNmg7FvSHwTJaHBqcSEgdRzSTTrDPQ6w7ASlNSqN7DuPbQKBjaA/cBWcAMyvqSvnM8vjNlvXuOYcuGcnJoESy5CdLXQOPzodvrENFQ37MsqNFNty4vwp5JsOVjWP8ipDwHNXtCi2ug6aUQUpGUtZ9ROhhyMtoMlhoMDUVZ6pMZDPk7AWgz1wVJOLNQEDHVcSvt221JmVnLEDy+96vaaIiUD4uAnpw53V2UB3sm0ixzEuS2gYgG5X+t7SjYHoEkmr7AfuB/SA4913FfF+A54GKcf7yG1YOwOrrW1zypp4TvkrlBQV580p+/F4vOkXeiwO55JOF8BCXGrkdJYcOZKcyG1X+H1NchojEMngINRp355zwUU8FzBocW0DzrY5jUHnZPdvdq/I/4znD0COTucvdKqo/MDZIQxJ1wwo9GErZ3UWZvNcryxaIT/wBUBbgE9e/sr74lex0FGbD0rzC9ryTAAyfAgO/KgrsTCQxVADjoJxi/G7q8BMV5eo7v68G8S2DPFI348HeOIqv6e4C2QCu0QdmM7OunoSrdTyjz38wtq/QuooFzkBRuMxq78gZyi/zY8b0ayJX3OSAZI+fqi4aOn6rYXlIot+YFV8L3dWDexTTL/gQmJkDqm+WTY9uo6hyNXFy9mSNIHjgMVZBuR8fpP1Gf+ArgAVxzvJa2ZOTslHu0P5GerGR2RJNTPyYUuBYZT/2ElA13oSTGY8BB1y/Tq9k7XQqd1NegzW0wdq1XB3dgAjzn0P0NVtV8EQJC4LexMGe8+sIM1UNMO8kWfNFs5VSkOU74kU1P/RiL4/vyDgHfImvwOah/px7S7z8GLARM+5hMVHb8Dya1g03vQNs7YWwKNDqn/M8RXhfa3Qujk2HUCmh1C+yfAbPHSMK58gFVYP2J7cDblAUaI4D/IEnX68DvKCh51fE9I4aoPBaap3k7quQdQZX9u9GG/CFU1W+AzgNfovODv9EG/S0uoCzYtUtg/2xYcrMSM7+Ngz2TVYU/awaL63wKtXrD8jtgem84suL0r7EF/e0PRD2V3kYm8BkwFvXS3YjezyPIGXMd8Cj6XbqauI4K9NL9qCWjMAuyt6gdpTwKpVLnzXmO2wDgSRTo3YaSP4Yyjh6BRdfCrJFS4A2bC93fgGDvN64zAZ6TSA/tps1c5+dg36/aHK59Corz3b003ycwFGLbQfpa/6iOFGZB9ubyn/BLieP4vrwVwNNoI/00ymbXQfKO/+KfGb+cHfDbOTDvIkmCRiyGbq9W/mRvWRrh0f01GL8HBnwPNXrAhpdV8Z/aEzb+WxcZX6MASQbvRxLiZqgatwZlmksDjynAHaiKZ3ANoahy9zyq3O0GPgIGISfDy9Gx3xNt1ufjHz08Acj0ZLcNKUth+b3wY2OYMQS2/hfqj4SBP8F5+6DXe1DvLPKCGsOQadD3C8jdAdN6wPJ7dF4+ERsF1nFoNIO3kIOkl+ejv4ur0HiHe4BlKBHzJNChmtcVHANRLZTg9LIZzpUmfY3e68nkmWeiH/AjqlBfgUypjPNmGTu+g0mJsPUzaP8IjF4Fdfq7e1VOwwR4ziQwBBIfgLHroeHZsPpRmNRRznoG1xKXpGA6a6O7V+J6qnLCL8VC/RKPoCzfQTSjaBwaFv0XlK3thVzQlqKhq75KSRGsf1kn+/0zJa8cucS5vR6BIdD4PBg0QRLOri9DyVFYdhv8UB/mXiQ5mDcnKXYjCdf5yOjnLOA1VCl6GW00tqBRH2NRn52h+imt3H2FnDkXA0+gCtMzyLmz1KjpPST39kUyUiDoUWjeBpJ7wu9vQo3u0PdLuOAA9PsCGp2tY/dYLAuaXQbjNkDLGyH1VZ07dv5wfOCRipJpg/D8uYX5KBi4DAV1lyJVx80o4N+KEgTdcK+ZYFwSFKQruPZ1bBvSVkFEI42EqiwJ6Ly8DY2TKXXeHIZcTf0kVv6DvH0w90KYdyGEN5BRWtLTPuehYawWXEFkY+j/Dez9BZbdLme9RudBt1dOL6kzVJ6o5qqypCVDbKK7V+M6nHXCP5EaKKt3CQrkVlBm1PIPtPmrjYwaxiAJXQ3nvbxbObIcFt8EaSugwVjo8Zbrj9PwupBwj25pq2TMsu1z2Pk/VQ6bXwnNr4a46k6RV5AitAmcgv5eSlXSjdBGcQwK8rxf7eK7BKLKXU8k1U5DVaepqBey1KipHWVmLQPxXqv/7G2w/SvY/qWkflYARA6BnQ/BZedDvQqYIYXEQ8+3dawuvRnmnq/kbvc31S81C7maViEX51IKUULvKxTcZaL1/gUFeAPwvMA0JkEBd1qy7++n8vdD/gFoONY5z9cA9d8+gvr0X0HHdBLqnbwY344KbBu2fqKKe3EedP4XJNwHAb75pk0Fz5XUHw5jVkPSs7B3GkxsB+uekTmGwblYAZIsZv0ORTnuXo3ryN+nE35VqndnIoDj+/IOIMnmCLSJvwwFe/3QfK4VeGd1rzBbJ/ppPSFvj5Iyg36u/k1DfGfJQMfvhgE/QK1esOFVmNwRpvaQmYMnmQrsRwY9l6C/g4Eosx+HNg9rUMXnHeBcTHDnbcSjyt376HNcC7yEgvb/oACvhuPfV1BV1tMrAHn7IfUNGSb91BySH9bg7G6v67gb9StkXw/LK+l0W7sPjFoOnZ+HfTNUzZv1EuwvknOpJ+20ipHpy02oB3sMMAG4AAX1e1Gv7GA8L7gDBXcxiRqXUOLjA1/TksEKhFgnJ/pKnTe3Ah8i06srkEz+DSTR9TWyt6rPbtG16uUckwyJD/pscAeeddrxTQJDof1DMG49NBgDyX/Txm3PNHevzPeIT1KDfPpad6/EdbjqhH86alHWl7cfBX1/Rz1WjyLJTkPUV/UtcqXzdHb9rE1Y6mvQ6mYdn00ucu+YjcAQaDweBv4I5+2Brq+CXSQzhx/qS1Kye2L1b2qKkZX8Yyjwr4fkfXOQFPN/yLhjNsoCd8Db5sEaToWF+ifvRVKu0p7Jm5HRxr1oYHhTFDB8h+cc/wXpsPlDmDkcfmwAy+9U8i/pWThnK4xYAG3vgPB6Gh3RCViF5jBWhoBgSLwfxqVAnSGw7/+gZbYUVf4AACAASURBVHeou9h576mylCAp/h3oXD0UWeqPQsHdfrTRH4l3GMHEJylRnpnq7pW4DrtEFeaYNhDkonL5sc6bE1AS505kyPI4vtGHX1IMG16DSY4Ztj3+DcNmQ0xbd6/M5fhu6OppRDaBAf9TYLf8Dpg9ChpfoD6cyNNY3xrKT1gdCK8vyVutXu5ejfMpKVb/XUxb153wz0QgmqPXG0k39yMZ12Qk8fnY8Zi+KDM8Bjl5esqGP3ePNno7v1OQPPxrZd89jbDakHCXbmmrYMsnDgnndxBWF5pdofl6cR1d8/qHKPtcS0cWBKDP/Sn0uSZhUoT+RgQKCkrdw7ejv4+pyJTjPcrOEaVyzm5U399JUY6SINu/dIwkKYColpD4iHrmTiff74OGni9DVenKEtkUYn6CZT9A0zvhlz7Q+hZIekbOx9WFjd7LV8A3aOB4GOp9vRQdw97aAxvZDEJilfD0dBl7ZcnarL/nE0chuYIA5G58Duq3fAGNvngeuA7N2G3h+mU4nYwUWHQ9HF4E9UdLTu1H+20T4FU3DUZC3TWw4SW5bO6ZAh0ehYR7/9zIbag48Ukytck/oIDPl8h2nPBdKc+sKHWRw9pVqB9rMWW9ew87bg3RoOrRqKk7xg3rLCnWyIPkh7XpS3pG2ntvOObiO0O3ztDleZ0vtnysQawbXob4ro5B6pdBWK3Kv0Zp32VpL91itEGsRVmg7kt9lwbnUFq5uwn1cy1CAd80VPF9DPV0jUAB3wigvpPXUFygFojtX8Lun3SODG8ArW9TUFeje/kq83WQRG0JSlBVdndUBPxmQez5cO5wWPMobHxDBixdX4Gml7hOKWAjifRXKODegipyI9E81HPwDcm0ZSm5dXCBpPbBUe5ekfNJT4agCIhuXb2v289xW4+k2e8hye5FSNbZrXqXUymKCyDlOVj3lLwZ+vwXml3uXoWOGzD5V3cQGCpL1nHrZcOc/DBM6SRTFkPViOuofrw0H5yJV3rCj/JQP/kgdGF4GgULu9FIhj4og3wB2uydhTKE66ie3p201fBLP7lV1uwJY9ZC+4e9I7g7loBgzeIb+L0knN1eA2xVJH9sAHMvkPS0vBLONPS5XIM23T2QLKfE8e9iVKH9FGX8TXBnOB3ByJTjKeS6ewD4HCUHZqK/swZo/t5DyICkoJKvVVIM+2bC4hvhh3ow5xwFec2ugKGz4Nwd0O1lqNmjYpu6vkA2CpIqywogA53nQqLVXztyCUQ0hAWXwaxRqs44kw1IUZGIKuvPo2D1A3QM/4xk9r4Q3JUS52jJyPDBlozifMjcIJVJgJsaIdtxvPPmFLzDefPwMo0uWfMYND5fM2ybX+F3wR2YAM+9RDbVZm3wZFmjzxoB8y6G3F3uXpn3EhSpjFf6ap38fYWiPPUbxHV03wm/ojRA8o5vkeRvNpJ6HKKsV6sZcAvwE9pYOZOiXFj1EEztpupnn89gyHSIbunkF3IDYbU1gH30Cs3fbHMHHJynje6PjTTPK+2EYcA2crl8Fm3EayOjlJ9QT86nwD4U2D2OXBXNFcJQWWqj+XqfUjZ381lkxvMSCoBqoKrSW5x5ALNtw6HFsPxumNAYZg5V1a7BGBg0Ec7bCz3fgbqDK3+ObI5UCQup3Aa2EPWmNuV4SVuNbo6Zmq+rD2hyB1j7tCoNlWUrqsp1RpvxfzjW/h9klDINnX8r6Rvj8YTVhogGvpnMzUjRntAT1Dqlzps7UOIgBVWEu6A+Tk+Z6lOUCyvvh+m94OghGDgB+n3pe0quCmAkmp5Ag9Ewdi2sfxHWPQ17JkOHx6Dt3d5XZfAE4pMUDGVv9Y3NPECm44RfHXp8VxCMZkENQpuSnahvZzLK8r8DhKDelzFIztmWyvfu7Z0OS26BnK3Q4jrJG505VsKTiO8E8S/J8nnPVNj6seZ5pb4CMV0g9xqYfTlMqKWNNmjo8kPod90TcyUwuJYAtCHsgv7uslAFb6rj9rPjcS1R395I5D4ZhUyztn+p0QbZWyAgRONMml2mf4Oc2EhmoSreDyjgrKhYYilKVF3En89dAYEydWl8Piy/C1b/XX21Pd+GOuVs+tuFqu5fIykpqN/xVcdrNqjger2duCTJ1vP2a/SMr5CWDKG1JDX2FEqdN+9E1+wXUFX4EZS4vQ6IdNPa9s+GxTcokdvqJrnZhsS6aTGeg8nPegqBYdDh7xqSXm8YrHoQpiTJctlQMaLb6PeZ7kOZvbRkZSzDnd3A4iYaAzeijdRhNHfrDhSA3Isy0i2B24FJlN/ZLv8AzL9CdsiBITB0NvT+wHeDu2MJCNYMrhrfwZ49sOB1SA6AorugdwO45zz4eALsKoTlSEpXlV4jg6GyRKPK3b9RILUR2bMnAB8B12+Bq56BNzvKdXrdc5Km9/4Izj8g5UuTi5wb3JXSwbG+hRX8uaPIqbIVquCdioiGMlwbNBGKc+HXQbDoulOPQtmPKpwD0XnzPlQpfA5V8RYCd+F/wR3IYMUKkGLHVyhIg5ztSlR7oqwwFAVznuC8WZABS26GGUP09dCZquKb4A4wAZ7nEdVMNumDJsoMYuYwmHcp5O5298q8h4Agnfgz1vvGzMGjRyBnh7KVnnjCryohSK71IrpobEUbvw5oszcOSblGA68Dm07yHHYJbP4AJiZoWHiHxyVdrDuoWt6CW8lBFZBbkeS1A3BfLZhzB2Qtg7qrIfFOaLEQgsfDooaa/+eL0iaD92EBrYHr98KLr8F3veHVlnDh3yA3Fj5+E27dA1dMg39eA9/FSubtKgKBXijw3F+Bn1uEElFnlfPxDcfC2HXQ7gHY+qnOXVs+kRT1COp/GoYCt9tRIuyfQCqSuz6Ajnd/xhdbMkql9XGd3LuOM1HqvDnPceuP/j6bALchgx9XUjrqaPP70O7/NHO67hAXv6h3YQI8T6X05N/xH7B7AkxsCykvVE2z70/EJclsInO9u1dSddKTFdjFe/gJ31k0Q8HKT2hTM83x9RaUqW4NtHH8fxpwYD38OlgSjbiOCuw6PSEzI1/ERhWPVylztjwH+AxJL99B/RKrkRx2aEfo/iKM36lB7nUGwe//himdYXJnDVXPP+Ce92Lwb44egU3vwYyz4IeGsOJusI9C5+fg3G3wwDz4+DZ4rY7k3T+jvr46SFr8GLJ1d3YfUDeUeCpvFS8PWICUBxWppAVFQpfnYPRKiGgNi66BV86CzhukcNiOJHBrUPLrUXTuM5QRnwSFWWrJ8HZsW9f7qGbeVYXqh6p5Kej4fA9dpy9FahFnkn8Q5l+mfvPQmjBiEXR5wTXVfC/HBHieTGAYdHxMgV7ds2DVA9qU7Z/l7pV5PhGNILSG91cpbFvvIbI5BLtjvoCbCUNBzCsoc70JSblaAR/mw3uPw9Qk2LUWct+HFrMgNsGNC3YRecjF7E504WwL3IN6GW8HfkXB8A/Isr7xSZ4jIBgajoMB38qFs/ubum/FPdpczxkPO380SSSDaynMhm1fwOyz5YC55CYZi3V4VC0Ko1dC4gMyIQMFTNcg6/8DqFL2BJIWP40qB7WAC9HGcocT1hiO+gXXoH7BMzEfOYJWtICQg/rprusI58+D99+B2FXwTBJMfQzW58OTqCpvODm+1JKRt1tJD2/ttW+HnFu34XznTduGrZ/DpHaaB9vxnzBymZxyDSfFdF94A1EtYNBPKkkvv0vZzqaXQZcX5SJl+DOWpZPk/llQkF69A2adSe4Orb9ueXU/Pk5pX95Fs2HxzZC9EQ5eAR+8DGscblkJlBm1DEA9A97IFsrm0s0E8tHG8yzUpzgauf5VhtCa0OY23dLXwdZPYOtnsGuCmvtLB6nHd3bCGzH4PcVHYe9U2PYl7P5ZvWcRjaDNnTJLie9aPvl5qXyyF6repaH+3amomv+d43HtKDNrGYiOm4rSGxmZLEEus6ciGznPdkCVxTOR71jvV6gimYvGlNwUAJfeBEnnwsp7YfuTMPlL6Pkf9eUbTk5pS0ZaMjQ46t3KjbRkJd1iE929kqpR6rz5CPAuStCORI6vDyBDoIpEHzk7YektMiCs2Rt6vQ9x7Z29ap/DVPC8iUZnq5rX4XHY+b1km+tfLv/cK3+jVNKYXpWhRm4mLVlmITE+WJWqDEcPy5BgxhCgCIZMg7v+C8l1VOF7BfUAvAkMR3P3xlMmW/RkjqJK3L0oSC0NZlNRVW4KqtJNBP5K5YO7E4lrL5fR8Tth0CT1Mfz+H5jSBSYnwYZXjITTUHFKimHfr7Doevi+nirE+2dAi6th2Bw4dzt0fVEjBCrbWxyPKnfvo+N7LRrB0Aj18Y5CEuZRSNK8nvJXEeJRoLiM08/rmwcUA4NP85hCdPxejUYZnIeO9b8gN9GdwGtoZmhEXej3uUa6AMwcDguulFOk4eT4QktGSZFm+sUkeHeQeiylzptbUWUvH0k4WyMlTs4Zft4u0bVoUns5ZXZ9FYbPM8FdOTEVPG8jKFz9Rc3/ogHHK++DLR9C97f8w1CiIoTES+aTtgpq9/c+g5KSQshYBzGJZlyGbctSfMU9qmgmPiRJV6nu3kK9KW2Au9GFYyZlFbAJjudpj6p7Y1DfQHC1vos/s4OyNc5A6w5F/Ua3onW2rqa1BARBwzG6HT0iW/otH8OKe2HlA5o31uIaWdP7+9+j4eTYNhxapLEGO76B/P0QFA2Nz5PqpN5QVShcgYWO7/YoSZIL/IYqe1ORpBkkXy6t7g1Fc/lORR/UV7QK9fydSAYajdAZJZOOpdjx+l+hyuIRtOG9AM2fPIvTn3/qD4exa2DdM5DyL9g9Sf16LW+Qc6ShjGNbMrxVdZD1u+bdesLsO2dT6rx5DUpQPofaDZ5ASczb0dzMY8ncqL76g3NVwe75LkQ5K6vpH5gAz1uJbimnzd2lss3B0PRyZUR9xUrfGcQnwa6fpG2PaOTu1VSMzFRJm3zxhF8RsjbB0ltVDajZG3q9KzOV0xEJnO242ShzXxpIvYpm+ESjKt8YtOFr6LJ3UEYh6teZ7FjPWsf9TYGrHGsZgvvmCZUSWgPa/FW3jBS5+237DHb/JHln08sdEs4u3pc4MTgX25ZKonRWXc42CAhVv2fTy5QYCKqMRrKKRCAZ82jH19spC/a+Rv16gUiKWRrwdeN4XVNjx20h6iU6Ma6a4/i3NLdagsxWvga+RS6ckcC5yHBiBBWTjAeGQad/6nhbeoss4bd8otl5ZzoH+hOlLRkHZss635sMSkpJS4bgaLXk+CqlzpvnoOvg88h58wUUAN4LNCuCDS/B6schMBx6fahrjbnOVBgT4HkzlgWNzlF2I+VfkPKcAr5O/4A2dygj7+/EtpduOy3Z+wK8tGRdqCKbuXsl7qG4ADa8CGuf1HDj7m9B61sqnr22gETH7T5kmjCDsiDre8fjkijr3euD886Oeygb6v4LkIky9wPQaIgxSJLpqdev2ERVDpKehn2/qKq36R3Y+IY2mc2vUc+eLw0aNpyZrE0K6LZ/qSSAFQj1hsv5ufF4zzOFaoqkzjehRMsiygK+Rx23migIG+m41UPngm+QVLrdMc93BFiJgsKNqFL3DRpGHgaMRUHdGBRsVoXYBBg6S72yK/8PpnSFhHtlwhbk7myQhxDfST336auhzgB3r6ZiFOVC1kao1dt/qrOlzpvr0XXwXWDSKrj/eohbAY3Ogx5vmYJFFTARgC8QFKEsX/OrYNmdklRt/lAHR52B7l6dewkMhZh20rbXH+k9QW9hNmRv8k5pqTM4uEDZ6oy10PgC6Pa68wyFolFf3nhU3VtLWbD3PPAskm0dW92rV4HnL0KmC5Mdt1WO+xsiadZoJA3zsP3vGQkIggajdStIg+1fK9hbeZ8cfuuPVqa14Tjf6SExHE/ubn3u27+CI0t1X+0B0OPf0PhCCDtRZ+WhlCZYBgBPoeHMv1Bm1vKl43FJKNDLQdW60gDPBj5GiaKPkGtgsOOx/0IVimgnr9myHBLpcTre1j8PO76G7v+WrNrfCYmHyCYK8Lztupm+Vv1m3uqeWRXaAe/mw7VPwvbnILMWvPo/iL1AhizD8Nzkp4fjJbtdQ7mIbgWDJ8kJb/ld8OsgaHalZoSEV2SH6mPEJ0lClPU7xLY78+M9gfQ1kj752wm/IB1WPQyb3oaIxjDwJ5kLuQoL6Oi4PQikI/ODUjnnt47HdaWsd68nknYdywHKqnTTkbtfINAXBYxjHK/hKxeqkHhVU1vfAhnry1w4502EkBrQrFTCWU53RIPncvQw7PifKnUH5gC2PtcuL0CTSyDyZDM5vIzayPzhciSzTKasuvcyStoEA/+DFjVbaEbdJiQ5G4aqf+chYxZXE1YLejtka0tugd/GKrju9ppx1Y5Pktt43l7v+l2kJ2uP5o8qiIPzYfH1aklpeQ20fAmyapTNea2s86bBuGj6HJYlecy49dD+b2p0n9gWNrwmlyZ/JKoFBEd510y89GSIaKiLuT9g27D9G5jYDja/C23vgbEprg3uTkYccuX7AEkrV6BZW+HAMyhgq4M2gh9Bs4+bKeCrixzyZqN+m2+AQyjr/xDQCd8J7k4kth10/hecuwMGT4X6IzS8emp3mNwR1r8IefvcvUpDRSjMgq3/hdlj5YC59BbI3wcdH4dxqTB6ObT7P98I7k4kAM3Aewgdz4dRoqcrkAyNv2msYO9cNMpkGuofqo7g7ljqDITRq6DTU7BnIkxMgNQ35F7qr8S2l9LAm2bi5R9SZdzfkrmFWbDsDvhlABTnyxG790dQu4YCuso6bxr+wMTDvkpQBCQ95ZBt3gEr7i5z26zT392rq16sAIjrJHe3otwy50VPJW+fbg38RHaTsx2W/lW9kvFdYfBEWae7Gwtt9LqgeT5HkIxrMsrsfwlNraYyaXgSSS+74L9ps4BAaDBSt4L0YySc98Oqh6D+KIeE82wj4fREivNhzxRV6nZPhOI8VdET7pFZSnxn/6zGxqCkTxwwD5Y3WE73Pd01FqGpW1cmN9sOf4Oml+ocuvxO2Pop9HwHanR18+LcQGAYxLSVAqbeCJ2TPJ30ZIdJjB+Z5uyZqhaM3J3yi0h6Wkn4YzmV8+Y/kOvmbfzZedNwHP66FfEfYtrAkKkw4Dv1zfw6ABZe7X8zdeKSpHFPX3vmx7qbtGQZFsR1cPdKXEtJEax/CSYmwoHfoOvLMHKxZwR3J6MG6qH7BNgLrIYFPyyQa97f+bMDnz8TEgetb4aRC2HcBmj3gMaVzLsIfqgPS2+Hw0tVuTW4j5Ii2DsdFl0L39eFuedr3lSL6zRv6txtmpFYw7il0gsIhJqLaqqi39vdCzqG6Ja6zvf9UpvmaT1g+d2qkvgbcUlK5GZvcvdKzoxtq2cwqtWfAxxf5Ohh7T9nj1aiffg86P7a6d97qfPmfDRzsh8K8pqiQG+L65ftrZjtiD9gWdD4fMk2Ex9WhnZiW4ecw09km+F1pXH3dOmGXQIZaxSYe3qlsSocXgbTesoRru5ZkmMm3OM9JjgBQEcojC1090o8n5i20PkZDbYeMk2VvC0f6POf3AFSXlDPjKF6sEvU97L0dvixIcwaCTu/1zViyDQ4bw/0eBNq9/MfR7/yEA10AKvE0iYzzN0LOgHLgmaXKqHS6mZIfV2S953f+1ciJaqlnEW9oSUjZ5vGOvj6KCTbhh3fwqRE2PYFtP87jF4JtftW7HlKnTdTgMuQ82Zr5Fa7wslr9gHM2dufCIrURmvMGqjZU3KOqd3lWOgPxCVJ655/0N0rOTVZm+Wg6at6/MIsZZan91JPT///waCf5H5m8G0CAtWf1+8LOG+vZGTBsXIE/LGR+r22fyOpoMG52LYqqCsfhAnN4Zf+CrLrDIIB38P5+9X/Un+E9yRZ3MFgyGybqWqepxISJ1fTEQs0s3LuBfDbOZLC+wMBgZI7ZqZqcLgnk5bscPpu6+6VuI7cPVIGzLtYku9RyyDpSclpK0s71J+3FY0+mowUNMNRG4Uf5TNOhwnw/JGYtsrU9v8WCg7DL/0k0ck/4O6VuZa4jspIe3IVLz1ZQ4GjW7t7Jc5n10/K4KW+Dq1ugbHrockFRvrlj4TEQaubtAkdtwESH5JUaf4l8H199RMdWuJflQdXkPk7rPmnjrspXWDDy5J+9/kMzj8A/b+BxudVbbPlT8TDkT5HZLLi6dTqrc10lxdg/0xJ4VNegBI/UB3EJ4FdDBnr3L2SU1NSCJkpmjMa4A1/UBXEtmHzBzr37J0KnZ+HEYucW61siEYb7UQ9euuQ82ZXNOrETwRqp8IEeP6KZUGTC7XJTnxQjmk/t4WNb/muC1dwlOQbaaslU/I0ivMhcwPEdvSO5vDykrtbWeQ550JwHAyfrxmNIbHuXpnBE4hpqyb7c7bBkOkyF9rykaq8k9pDyvPKAhvKR85OOZdO6QYT28CaJyCsLvR4W5XTwZOg+ZUQ7OxBbQaPIyBYbqfjUqDeUFXLp3aX4ZgvE1YPwup4djI3cwMUF/imWid7C8wcBotvkDnT6NWQeL/r1AGxlDlvvg/kUea8+SZ+67xpAjx/JzhKFudjVsvcYtntatA+uNDdK3MN8Z2hMFPad08jI0U9kb6ixy8phtQ31QeyZzIkPQujV0DtPu5emcETCQiE+sOh3+dw3j7o+R6E1oBVD8KExjBrtJw5jYTzz+QfhN//A78MhAlN5FxqBUKXl2D8Thg2W6Y3/jJ2xXA8kU1h4ATJcY8ehul9Ycmtcrv1RSxL19GcnXD0iLtXc3LSkqVkiHS3FasTKSmGDa/ApA4y0erxNgydCTHVpEgKBa5HPXo/AvWBO5AhyxNodJEfYQI8g4htB2f9Av2+hvz98EtfWHS9Z/erVYaYNpIjeWIDdloyhNaCcC8a0Hoq0pIl/V1+h6RCY9ZC+4d8U4picD4hsdDqBrmsjdsoc6iMdTD/Ukk4l9wKhxb7t4SzMBO2fKrA9weHrLXgMHR6Es7+HUYtgXb3ap6mwWBZkuOOWw9t79S80YkJsO1L3zyO4jrqPXtiFa8wC7I3a3yTr7QopK/VvnHFvTJOG5eipJI7jJoC0JzKBRzvvNkEv3LeNAGeoQzLgqYXO2zN79c8nZ/bKDPsK7LNgGANQ81cL3mEp1CQpib4+CTvPuEX5crIYWo3yTT6fq5+z+iW7l6ZwVuJaa2Znudug7N+hYbjYOsnML23+jvW/UsyYH+gKA92fAdzL9RYg0VXS+rV7n4YnaxESoe/Q3Qrd6/U4KkER0O3V2HkUpleLLgcZo2SwZcvERwDUS2UbPS0ADZ9jdbkC2qd4gJY8w+Y2tVxzf8CBv0MEY3cvTJxrPPmpZQ5b16GzztvmgDP8GeCozX7aEyy5h8t/asszQ8tdvfKnEN8kk5KmevdvZIy0lY7hp12cvdKKs+eaZJmrH9eA63HbYBml3t3wGrwHKwA9RH1/QzO3we93lfFO/lhyRJnjYJtX3m+c15FKSnUYOCFVyuom3chHJwHLW+E4QvgnC3Q+VmI96FqgMH11Ogq04tur8OhhRpZsvZpz0p8VpW4JMlQc3e4eyVllDraRjSSy6k3c2iJkrlrnoDGF2ncUbPLPPM81A74kDLnzUn4vPOmCfAMpyY2Ec6aoeGp+XuVMV98I+R7uZA5ojGExHuOTNO2JSOJbOadxiN5+2H+5TB7FASGwLDfHJvvGu5emcFXCY6BltfD8LmSIyY+AhnrYcFlkisuuVl9xJ6WuS8vdgkcmKvk2g8NNBh41wRocpGk9ON3QffX1c/qiZspg3cQEAht75Bss8E4WP13mNIZDsxx98qcQ0yCrkmecq0HtcDkH/Du6l1RDqy4D37pI/XRoJ/VOx1W290rOzOnct7sBnyFTzlvmgDPcHr+GJ6aCgn3wZaPNST993e8V7b5RwP2Vg0ZdTe5jkZwbzvh2yWw6T31cez8Djo+IZlYnYHuXpnBn4hupblK525VQqrhObD1M/WDTEyAdc9C7i53r/LM2DYcWSGDlAlN4deBOt/WHQoDf3TMqvsA6g0zs+oMziWiIQz4FgZNguI8+HUQLLrO+5O5gSEQ085hYOYh4yHSkmWAFNve3SupHPtmwuROGrnS8ib12jUc5+5VVZwTnTdzkWzTh5w3TYBnKB/B0dD1RRi9Ss3LS29RRe/wUnevrHLEJzkqZ2vcvRKd8AOCISbR3SspPxkp2gQsuUm/yzGroePjGtpqMLgDKwDqnQV9P3VIOD+A8HqQ/Aj82ARmjoRtX6hP1JPI2ACrn1AwOrUbpL4GcZ3Vv3r+Aej/FTQ61xxbBtfTcAyMXecYnfQZTEpQksFbK+HgaMnIh8yN7l6JkqIZa2T2FhTh7tVUjIJ0KbhmDgUCYOhs6PkfqSm8GR923jQBnqFixLWHobO0+cjdBdN6SQ519LC7V1YxQuIhsomkke68eJUUyR0wNlHZRk+nOB+SH5WMJyMFen2ov4eYtu5emcFQRnAMtLxOcuGzN0GHRyErFRZcIQnn4pvg4AL3Hfs5OzTfb0oXmNQO1v5TPTk939OIiME/q381OMo96zP4L0ERGp00egVEt4VF18KMIUpEeCORzXQ+8AQ3zazNUJjtfbPvdk2QodWWD6HdA0ro1h3k7lU5l2OdN+cCfSlz3rwDwvaGuXFxlcMEeIaKY1nafJydCgn3wOYP5La56T3PHCB+KuKTNAYiz41DlDNTFTR5gzxz/yxJM9Y9BU0ukYlKy2tND5DBs4luCZ3+ITOSoTOh0XjY9rnGeExsK2OJnGowYcg/ABvfgl/6S4K56kEICIWur8J5u2HoDI2GML2rBk8grqN6XHu+I5XJlE5K7nmbiZEVIAOirE0KrtxJejIEhUN0Nc2Fqyp5+2HeJTBnPITWhhGLoctzeg++TH/gJ9SfdynwDnR8uKPXGbGYAM9QeYJjoOtLDtlmB8n1pveBw8vcvbLyEdtevSzubMBOT9bvMbKZ+9ZwJvIPwcJrYMZZCuCHkfdlqAAAHBhJREFUTJeToTc0VBsMpVgBUHcI9PlEEs7eH2nm5Oq/w4RmMHM4bP3cuRLOggxJ3GaOlFnKstt1X9LTcM5mGLkIEu6C8PrOe02DwVlYAdDqJiXzmlys5N7kTrDvV3evrGLEJTnkkWvdt4bifI00ie0ocxtPxrYdEt1E2PUjdHoKRi2Dmt3dvbLqJZE/nDc3PLABvCyXbQI8Q9WJ6yA9dp/PNMttWk8NIj56xN0rOz2BYXLZyljrHsOYwmxlFeM7uWcY6JmwbQ1SnpSgikf7R2DMGqg/3N0rMxiqRnC0RnkMm61Aq8NjOhYXXgnf11OvycH5lZNwFuXBjm9hzvmOWXXXQtbv6msaswbGrtGxFNXC2e/KYHAN4XWh73/l4ApKhsy/QhUebyCsNkQ0cG8yNyNFLRmertbJ2Q6zx8DCq7Q/Gr0KOvxNPgH+SkPISsxy9yoqjLHiMjgHy4LmV0LDs2HN47DxDdj5LXR+Dlpc65kBDCizl75WG7DYhOp97Yy1yip6oh4/83dYeivsnwG1+kDPdxXIGwy+RlQL6PQEdHxM9vBbP4HtX8Lm9yGqFbS4GppfpZ7dU1FSCHt/0c/t+hGKsiGsHrS+BZpeBjV7GimzwfupN0wJinXPQsq/YM9k9eu1utFzr/GlxCXBnimSSofVqf7XT0vW3M7wBtX/2uXBLoHf/wOrHgJszUdsc5vnf66GU2I+OYNzCYmFbq/CqJWyJ158A0zvK/tvTyS6JQRFuqcBOy1ZWUVPkjoWF6gnaXJHOLIUevwHhs8zwZ3B97ECoO5gSTfP2we9P5bxyepHJeGcMQy2/lczoEAbov2/wZJbZNzy21jYMwmaXqpxDeN36VxYq5cJ7gy+Q2CYelpHJ0N8Zzlq/9LfMxypT0dcBx3j7qjiFaSrMhbfyTPPBRkbNJZl2e1Qqy+MWav5iCa482pMBc/gGuI7wbA50nGvuh+mdofWt0LSU3Kw9BSsAIjrBIeXqPemuqyL8/ZD3l5oMLp6Xq88HJyvPsqMFA1U7vaa6Q0y+CfBUarctbgasrfqPLblY1j4F1gaBfVH0Gf/HNh7CAIjNMag6WVQf6R3uOEaDFUlNkGmRVs/g5X3yRE24V6NywmKdPfq/kxQpMxN0ldDvaHVG7ykr9a/cZ2q7zXLQ0khrH8B1vxDv5/eH0ut4IlBqKHCmPDc4DosC1pcpSHpbW6HTW/LbXPzR57lthmfBHaxxhVUF+nJjuDSAypjBWkadfFLf/UFDpoI/b8xwZ3BABDVXPLNczZp7EKTi+DgArJC2kDfL+GCA9DvC2h0tgnuDP7FH9f4DdD8agULk9rD7onuXtnJiU+CwiwlbaoL21bVMKoZhMRV3+ueiSMr5JeQ/DdoeA6MTVFCywR3PoMJ8AyuJyQOur8Oo5ZDdBtYfJ2CiSMr3b0yEV5PTeTVJd2wS5TRi27t3kynbcP2r2FiO/UbJdynIbcNx7pvTQaDp2IFQJ2B0PtDOH8va2s8Dc0u9cxqhcFQnYTWhN4fSLUTGAG/nQ1zL4Tc3e5e2fFEt5HEtDpbMvJ2a06wp/TaF+XBqocV3OXtgwHfw4BvtQ8y+BQmwDNUH/GdNVen98dyrJvWHZbdIX26u4lL0uD2/EOuf63sLaqUxXd2/Wudcg3bYPZYmH+p+oxGLoOuL5rBygaDwWCoHHUGyHUx6Wn1o05sB6mvu8el+mQEBEk1k7Eeio9Wz2umJcuBMjaxel7vdByYC1M6yyCn+dUwLgUan+fuVRlchAnwDNWLFSAZwNmp0Pqv8Pu/NWx4yyfulW3GdZQ0oVQr70rS3DjstKQI1r8oGc3BORqyPGIx1OhS/WsxGAwGg28RGOIYqbNWDszL74LpveDIcnevTMQlqfcsc73rX6ukSG7ZMQkQGOr61zsVhZmw9K8yUikp0LiL3h94lh+CwemYAM/gHkLiofsbqhxFtoBF1+jk4645NcHRENVS0o3KzL4qL8VHHcNOOyibWJ0cXiqzm5X3O+yu12vIsqcPXTUYDAaDdxHdEoZMVZ9q7i5JApfdpWDDnUQ0gtAakFYNydys3yWJdOfsu92TldD9/W1oezeMXavrv8HnMQGewb3U6AIj5kOvDyAzFaZ21UWgIKP61xKfpNfN2ea618hIUfawOk/4hVmw7E6Y1guOHoQB38HAHyGycfWtwWAwGAz+hWWpT3XcBmh1s+bjTkyEnd+7NpF6pjXFdYKcra7fZ6Qlq+0hqoVrX+dk5B+CBVdqfEtwDIxYAN1eMT3DfoQJ8AzuxwqAltfJbbPVLY6LQFvZL1fnRaBURuHKKmJ6shrSwxu67jWOZeeP6oPY+KYksWNToPH5xinLYDAYDNVDSBz0+DeMWKhh33MvgN/O0Ww4dxCfpL2FK2f3FeWqghfXqXpHMpSap01K1L8dHoNRK6BW7+pbg8EjMAGewXMIrQE93oJRSyGyGSy8SrLN6hqgGhAMse0hM0UDv51NQbrMTeKTXB9g5e6COefB3PMUUI5YAD3e1CB6g8FgMBiqm1q9YNQy6PIi7J+pal7KC1K1VCch8RDZxLUtGelrNX6pOt0zc3fDnPEyT4tsBqNXaCi9O/v/DG7DBHgGz6NGNwUkvd5XI/SULrD8nuqRbcYnKbjL3OD8566OYaclxZDqkMHsnQadn9MF1WTvDAaDweBuAoKg3X0wbr16wVY9AFO7wcGF1buO+CTIPwh5e13z/OnJZSOYXI1dApveVdVu3y8KoEcslHmcwW8xAZ7BM7ECoOX1MG4jtLwRUl+DiQmw9XPXyjYjmkhO4uw5OdUx7DRtFUzvA8vvhNp91Uyd+IAqkwaDwWAweAqRTWDQBBjwAxSkwS/9YMkt+n91ENtewaYrZuLlH1I1rTqqd1mbYMZQWHIzxHeFMasVQBvzNL/HBHgGzya0BvT8D4xcAhGNYeGVMGOw5A+uwLKU2cve4ly3r9xdrht2WpQjZ8yp3SF3O/T9AgZPcU9jt8FgMBgM5aXxePWGt70bNr+nRO62L1zffx8YBjFt1QLi7Dl96ckOMxcXVtBKRx5N7ghpK6DnuzB0JkS3ct1rGrwKE+AZvIOa3WHkIp3E0tdqWOeK+1xjuRznggbsdBcNO90zBSZ10Im+xbUafdDsMmOiYjAYDAbvIDgaur0MI5dKRbPgCpg1UtUpVxKXJDOUbCe+jm2rHSOqpRw0XUHaaql1Vt4P9UYoQG51o7nuG47DBHgG78EK0Ens7I2Sb254xZHt+9K52b7QGhohkLbKOc9bUqSgNLad85qd8/bBvEth9hgIDIdhc6DXe1q7wWAwGAzeRo2uMGIRdHsDDi1S8nLNk5of6wqiWmpsgDOds3O2yy/AFaOQio/C6sfUs5izHfp9rZFHEdXkym3wKkyAZ/A+QmtCz3d0IQhvCAsuhxlnQfo6571GnKMBO39f1Z8rayMU5ztHnlnaTD2xHez6ATr+E0avhDoDqv7cBoPBYDC4k4BAaHu7Zuc1OgfWPCbFzv7fXPNacR01g7cozznPmZ6sRG5MgnOer5SDC2U4t/ZJaHqpTGqaXmyqdoZTYgI8g/dSq6eCvB5v66Q6pbMkC4VZVX/u2PZgBaqKV1XSkiVBiWpetedJX6exEUtuhvjOMGYNdHzUWCAbDAaDwbeIaAD9v4FBk5QgnTEYFl0rAxNnEp+kcQYZTkgQlxTqeWITnWduVpgNy++WCU1Rtn4ffT9TottgOA0mwDN4NwGB0PpmuW22uEa9aBMTNOCzKvLKoHDnNGAX5VR92GlxPiT/HaZ2gYz10PsjNVPHtKn8ugwGg8Fg8HQajoGx6yDxIdj6X5iUAJs/cl5bRlg9CKvjHDfNzA0as+QsM7W9v8hEJfU1aH2rnLEbjnHOcxt8HhPgGXyDsFrqQRuxUCfs+ZfCzGEKiCpLfOeqN2Cnr5WssrJ6/H0zYFJHWPc0NLlUspUW1xhZhsFgMBj8g6AI6Pys2hGi28Li61TRq8r1vZRS5+ycnXD0SNWeKy1ZY5Aim1bteQrSYNF1MGsEBISox77HWxAcU7XnNfgVJsAz+Ba1emukQo9/w5EVMLkTrHxQMoeK4owG7PRkCK+vDGFFyD8EC69WkApw1q/Q91MIq135tRgMBoPB4K3EdYDhcx1u2mtgShIkP1r1/rm4jgr0qlLFK8yC7M0OtU4VErA7v4eJibD1U0h8GMYkmx57Q6UwAZ7B9wgIlJzh7I3Q/CpY/7xkmzu+rZiso6oN2PkHIHdPxap3tg1bPpEMZdsX0P5vGlxab2jFX99gMBgMBl+i1E173AZocgmse0oyxr2/VP45g2MgsrnGD1RW+pm+Rj9bWbVO3j6YeyHMvQDC6ylR3fkZzeszGCqBCfAMvktYbej9AQxfoP/Pu1iSh4wN5X+OqjRgpyXrYlTeYaeZG2HmUFh0jWQoo1dB0lPqBzQYDAaDwSDC6shs5KxfdZ2dNQLmX65AqTLEJ0kambuzcj+fngwRjSpufmLbsOVjmJQIuydC0jMK7mp0rdw6DAYHJsAz+D61+8DIZdD9TTi8FKZ0glUPywDlTFS2Adsu0bDT6FaSeZ6O4gLN+pncSbLSHm9LhhLXvmKvaTAYDAaDP1FvqFQuHR6Hnd9JrfP727oGV4SYdhAYUrmWjLx9kLe/4tW77G0a6L7oWjlvjl4F7R92ngOnwa8xAZ7BPwgIhDa3SbbZ7ApI+Zdmye343+klGcc1YB8u/+tlb5Um/0xuWgfmabzDmseg0bmabdP65so7bhoMBoPB4E8EhkGnJxToxXeBpbfC9H6SXJb7OUIU5GWs07iDipCWrLFKseVMypYUQ+rrMLkDHFoI3d+SkUqsk2fnGfwas4s0+BdhdTRmYPg8CKkB8y6CWaMkjzwVpU3T6RW4WKQn66IT0/bk3y9Ig8U3wa8DoDhXs236fy1DFoPBYDAYDBUjpq1GCPX+RO7XU7vCygfKp9YBJXOL80+/HzgRuwQy1mhsUVDEmR+fsV7X/eV3Qe0BGgHR5q8mqWtwOuYvyuCf1O4Ho5ZBt9fh8CJl0pL/dvILQXA0RLVQlq48DdjFR3USj+sAAUHHf8+2YdtXqh5u+RDa/Z9O8Ga2jcFgMBgMVcOyoMVVZSOF1r8Ak9qrv+1MRDaT4UpFWjKyNsul+0xqnZJCWPuUFDuZqdDnMxg8GSKblP+1DIYKYAI8g/8SEARt74BxqdD0Mlj3jOyJd/7w50AuLgkK0iFn+5mfN3O9TuYnnvCzt8LsMbDgMohorACzywtn7tEzGAwGg8FQfkJrQq/3JX0MioTfzpZDZe6uU/+MFQDxnSBrU/mrfumrZYQW3frUjzm8DKZ2h9WPQqPxasVofqWZZ2twKS4N8CzLGmVZVqplWZssy3roFI+52LKsFMuy1lmW9YUr12MwnJTwetDnE10IQmJh7vkKxDJ/L3tMTII0+uXJ7KUlQ2gNOWqBgr2U55VFPDgPur0GIxZpkLrBYDAYDAbXUGcAjFopd8o9k6We2fCa+uBORlySwyRtzZmfu/ioErqxHdTnfyJFuZKITu8FRw/CgB/UilHRubgGQyVwWYBnWVYg8BYwGkgELrMsK/GEx7QGHgb62bbdHrjbVesxGM5InQEwagV0fRUOznfINh/VSTowRA3UGSmnb8AuSFelLi5J2blDS5S5W/Ug1B+pzF3bO09+MTAYDAaDweBcAkPkTjl2HdTuDyvuhmk9VVk7kbDaENGgfG6aGSlQUnRy98z9s2FykiSiLa6HsSnQeHyV34rBUF5cWcHrCWyybXuLbdsFwFfAuSc85kbgLdu20wBs2z7gwvUYDGcmIAgS7oKzU6HJxRqiOikRdk2A2E6OjN1p5uiVZv2imsGyO2B6b7lvDvgeBv5QVtUzGAwGg8FQfUS1UN9bv68hb48qa8vuhMLM4x8XlwR5eyH/DFvS9GRJQcMblt1XkAFLboEZQ4ASOGsG9HoXQuKc/nYMhtPhygCvIXDsxMhdjvuOpQ3QxrKs+ZZlLbIsa5QL12MwlJ/w+hqiOuw3CIqCOeNh2W2q3p0qs2fb+t7RQzC9L2x8C9rcDuNSoPF51bt+g8FgMBgMx2NZ0PRimbC0uhU2vvnnkUlxHdSPd7oqXkG65tjFJ5X10u2eqFaMze9Bwn0wZg3UO8vlb8lgOBmWXR5XwMo8sWVdCIyybfsGx9d/AXrZtn37MY+ZCBQCFwONgDlAR9u20094rpuAmwDq1q3b7auvvnLJmqtCdnY2UVFR7l6GwQVYdhENc36gWdbHBNhHyQhpT0r8ExQGxgNln310wXrapT1LRPFOsoNakhp3H1kh7dy8eoMrMce9/2I+e//EfO6+RXTBetqmv0RU0WYOh/bi99i7yQ+qR53cGYSUHGZX5IV/jDA49rOPPZpM/NGV7Iq6EMsuolXmG9TNm0l2UHNS4+43134fw1OP+yFDhiy3bbv7yb7nygCvD/CEbdsjHV8/DGDb9rPHPOZtYLFt2x85vp4BPGTb9tJTPW/37t3tZctOopt2M7Nnz2bw4MHuXobBleTukexy1/cQVg96vguNzmb2rBkMrr8WVj0EdhF0/Ack3g8Bwe5escHFmOPefzGfvX9iPncfpKRIg8fXPCaDlY5PqGd+5w/Q/C8Q3RI45rO3bVX+gqIgMBSWO2Se7f8GiQ+r58/gU3jqcW9Z1ikDvKCT3ekklgKtLctqDuwGLgUuP+ExPwKXAR9ZllULSTa3uHBNBkPliWgAA7+DFffDtv/CnHOgwVi6HtoEe1Mhug20vUtDSw0Gg8FgMHg+AUHQ7l5ocqGCtVUPwtbPZMiSvvqPAO8P8nZD9hY4skzO2DV7Qa8PIK69e9ZvMJwElwV4tm0XWZZ1OzANCAQ+tG17nWVZ/wSW2bb9k+N7IyzLSgGKgftt2z7sqjUZDE6h6cUQGCbZxoaXCSsJhi4vQWEG1B/h7tUZDAaDwWCoKJFNYOCPsPNHWH4HbHpbQVztvhBWV4+xS2Dds7D5fSAQur4Cbe4wztgGj8OVFTxs254MTD7hvseO+b8N3Ou4GQzeQWwH2DMVavaEc+9i8fzFDAjPAErk0mUwGAwGg8E7aTwe6g2F5ffAlg9kwtL9TcKLiuHXwXBwLsR2hEE/mmu+wWNxaYBnMPgkQeEQ00bSjXrDsLEg63eo1euPZmyDwWAwGAxeSnA09HoPQuJh53ew4Ap6YkFQJDQ8B7q8aII7g0djAjyDoTLEJUHGesjeTGTRVrCLdZ/BYDAYDAbvx7Kg4VgIioCgGPZunEWDxLFQnPPnvjyDwcMw5QaDoTJEt9ZJPz2ZqMLNEF4Pwuu6e1UGg8FgMBicRXwSYEGtXmyKuV1zbuM6GbWOweMxf6EGQ2UICIS4jpCxntDiQ6Z6ZzAYDAaDrxESL/OV9GSj1jF4FSbAMxgqS1wS2CXYlqVgz2AwGAwGg28RnwT5B4krWC2ljlHrGLwAE+AZDJUlvD6E1yM3qDEER7l7NQaDwWAwGJxNTCIEBBFYkmeqdwavwQR4BkNlsSxocS2Hwga6eyUGg8FgMBhcQVA4xLQ1ah2DV2ECPIOhKgSGYlvGjNZgMBgMBp+l/kj2hw/T+ASDwQswAZ7BYDAYDAaDwXAqgmPID2ro7lUYDOXGBHgGg8FgMBgMBsP/t3cvIZJdZRzA/x8GXWThwick4gNUDD4QxY0IEaJEkPhEI64kKCMouFPRfVwPiGOC0tloDEFlYkbcSHDjwokoOBmUGBAjSNSFC3Hh43PRPSROMtNV3XXrVp37+0Et5t57Dl/xv6dPfX2rGRiEBg8AAGAQGjwAAIBBaPAAAAAGocEDAAAYhAYPAABgEBo8AACAQWjwAAAABqHBAwAAGIQGDwAAYBAaPAAAgEFo8AAAAAahwQMAABiEBg8AAGAQGjwAAIBBVHfPXcNaquovSf6wwqUvTPL3Cc5f6/iLk/x1hbq27bj3OdfcJxm76hjZH5oq+9POu6vZn+Sc7Kcdv6ncj7tG9tPPO0r2u5p7Ivt1r7HXTz/3XNkv5XPeK7v7Jc95pruHfCW5Z4rz1zl+ce73fJL3OdfcJxm76hjZT5v9aefd1exPck72047fVO6yn3/eUbLf1dxlv7nsrfn9z34pn/Ou9xr5K5oPTXT+uHG7Zsp6TzP3ScauOkb2h6aq97Tz7mr2Jz23i0bJflO5H3eN7KefV/bTk/1619jrp597ruyX8jnvmvbuK5q7qqoudvfb566D7ZP9csl+uWS/THJfLtkv1z5mP/ITvG27Z+4CmI3sl0v2yyX7ZZL7csl+ufYue0/wAAAABuEJHgAAwCA0eAAAAIPQ4AEAAAxCgwcAADAIDd6WVNWNVXWxqt4/dy1sT1W9oarOVdWDVfXZuethe6rqg1V1b1V9r6reO3c9bEdVvaaqvlVVD85dC9M72tvvO1rrn5y7HrbHWl+ufdjfNXjHqKpvV9VTVfWbq47fXlW/rarHq+pLK0z1xSQPTFMlU9hE9t19ubvPJPlYkndOWS+bs6Hsf9jdn05yJsnHp6yXzdhQ7k90913TVsqU1rwPPpzkwaO1fsfWi2Wj1sneWh/Lmtnv/P6uwTveQZLbn3mgqp6X5OtJ3pfkliSfqKpbqupNVfWjq14vrar3JHksyVPbLp5TOcgpsz8ac0eSh5Nc2G75nMJBNpD9ka8ejWP3HWRzubO/DrLifZDk5iR/PLrsP1uskWkcZPXsGctB1s9+Z/f3G+YuYNd198+q6lVXHX5Hkse7+4kkqar7k3ygu+9O8qyvYFbVrUluzOHN8c+qutDd/52ybk5vE9kfzXM+yfmqejjJd6armE3Z0LqvJF9L8uPu/uW0FbMJm1rz7Ld17oMkT+awyftV/NJ8762Z/WPbrY4prZN9VV3Oju/vfhidzE15+jd2yeEP+JuudXF3f6W7v5DDD/f3au722lrZV9WtVXW2qr4ZT/D23VrZJ/l8ktuSfLSqzkxZGJNad82/qKrOJXlrVX156uLYmmvdB99P8pGq+kaSh+YojMk9Z/bW+iJca93v/P7uCd4WdffB3DWwXd39SJJHZi6DGXT32SRn566D7eruv+Xw7zJYgO7+R5JPzV0H22etL9c+7O+e4J3Mn5K84hn/vvnoGOOT/XLJfpnkTuI+WDLZL9feZq/BO5lfJHltVb26qp6f5M4k52euie2Q/XLJfpnkTuI+WDLZL9feZq/BO0ZVfTfJz5O8vqqerKq7uvvfST6X5CdJLid5oLsvzVknmyf75ZL9MsmdxH2wZLJfrtGyr+6euwYAAAA2wBM8AACAQWjwAAAABqHBAwAAGIQGDwAAYBAaPAAAgEFo8AAAAAahwQOAFVXVy6vq/qr6fVU9WlUXqup1c9cFAFfcMHcBALAPqqqS/CDJfd1959GxtyR5WZLfzVkbAFyhwQOA1bw7yb+6+9yVA9396xnrAYBn8RVNAFjNG5M8OncRAHA9GjwAAIBBaPAAYDWXkrxt7iIA4Ho0eACwmp8meUFVfebKgap6c1W9a8aaAOD/aPAAYAXd3Uk+lOS2o/8m4VKSu5P8ed7KAOBpdbhfAQAAsO88wQMAABiEBg8AAGAQGjwAAIBBaPAAAAAGocEDAAAYhAYPAABgEBo8AACAQfwPOGgoBRIYJGcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNL0YIU2HDmi"
      },
      "source": [
        "При больших `C` - слабой регуляризации - наблюдается переобучение со всеми ядрами.  Меньше всего переобучается с линейным ядром. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRistjOJHDmi"
      },
      "source": [
        "##### 9 MLPC\n",
        "\n",
        "**9.3. Multi-layer Perceptron classifier**\n",
        "\n",
        "Немного уменьшу сетку параметров."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15zFoRr1HDmi",
        "outputId": "759b92e7-58b9-43e9-9083-ab747e4a1c94"
      },
      "source": [
        "# Инициализирую модель\n",
        "mlpc_model = MLPClassifier(alpha=0.0001,\n",
        "                           solver='adam',\n",
        "                           learning_rate='constant', \n",
        "                           learning_rate_init=0.001,\n",
        "                           tol=0.0001,\n",
        "                           max_iter=1000,\n",
        "                           random_state=1234)\n",
        "\n",
        "\n",
        "# Тестируемые значения гиперпараметров\n",
        "f9_mlpc_params_set = {\n",
        "'activation':['logistic', 'tanh', 'relu'],\n",
        "'alpha': [1e-4, 1e-3, 1e-2, 0.1, 1],\n",
        "'hidden_layer_sizes':[(100,), (50,),\n",
        "                      (50, 10)]\n",
        "}\n",
        "\n",
        "# Кросс-валидация\n",
        "f9_mlpc_CV = GridSearchCV(estimator=mlpc_model,\n",
        "                          param_grid=f9_mlpc_params_set,\n",
        "                          scoring='roc_auc',\n",
        "                          return_train_score=True,\n",
        "                          verbose=3)\n",
        "\n",
        "f9_mlpc_CV.fit(nX_train[:data_part], ny_train[:data_part])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,) ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.662), total= 1.3min\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,) ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.3min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.614), total= 1.4min\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,) ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.7min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.623), total= 1.3min\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,) ....\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.665), total= 1.3min\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,) ....\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.640), total= 1.3min\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,) .....\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.665), total=  54.2s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,) .....\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.613), total=  55.2s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,) .....\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.627), total=  52.6s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,) .....\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.667), total=  52.6s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,) .....\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.643), total=  52.5s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10) ..\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=0.932, test=0.658), total=  41.2s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10) ..\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=0.940, test=0.608), total=  40.8s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10) ..\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=0.944, test=0.647), total=  42.2s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10) ..\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=0.935, test=0.700), total=  39.2s\n",
            "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10) ..\n",
            "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=0.935, test=0.645), total=  41.8s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100,) .....\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.667), total= 1.4min\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100,) .....\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.625), total= 1.4min\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100,) .....\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.634), total= 1.4min\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100,) .....\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.672), total= 1.4min\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100,) .....\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.642), total= 1.4min\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50,) ......\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.669), total=  57.3s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50,) ......\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.621), total=  57.5s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50,) ......\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.634), total=  54.6s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50,) ......\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.674), total=  57.3s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50,) ......\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.644), total=  55.2s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10) ...\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=0.932, test=0.660), total=  44.1s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10) ...\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=0.937, test=0.616), total=  45.7s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10) ...\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=0.944, test=0.650), total=  46.8s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10) ...\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=0.934, test=0.701), total=  43.2s\n",
            "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10) ...\n",
            "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=0.935, test=0.646), total=  45.9s\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100,) ......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.673), total= 2.4min\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100,) ......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.646), total= 2.4min\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100,) ......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.656), total= 2.1min\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100,) ......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.677), total= 2.3min\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100,) ......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.661), total= 2.3min\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50,) .......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), score=(train=1.000, test=0.674), total= 1.4min\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50,) .......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), score=(train=1.000, test=0.639), total= 1.4min\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50,) .......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), score=(train=1.000, test=0.660), total= 1.3min\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50,) .......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), score=(train=1.000, test=0.695), total= 1.4min\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50,) .......\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), score=(train=1.000, test=0.656), total= 1.4min\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10) ....\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.658), total= 1.5min\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10) ....\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.625), total= 1.5min\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10) ....\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.628), total= 1.5min\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10) ....\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.675), total= 1.5min\n",
            "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10) ....\n",
            "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.639), total= 1.6min\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), score=(train=0.904, test=0.695), total=  47.8s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), score=(train=0.912, test=0.645), total=  30.6s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), score=(train=0.910, test=0.671), total=  31.1s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), score=(train=0.906, test=0.697), total=  41.4s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100,) .......\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), score=(train=0.909, test=0.654), total=  39.0s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.905, test=0.693), total=  31.4s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.916, test=0.642), total=  30.1s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.917, test=0.658), total=  42.3s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.907, test=0.696), total=  32.3s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50,) ........\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), score=(train=0.911, test=0.653), total=  30.9s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.915, test=0.681), total=  26.1s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.926, test=0.630), total=  25.6s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.925, test=0.649), total=  27.7s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.917, test=0.690), total=  19.8s\n",
            "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10) .....\n",
            "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.921, test=0.647), total=  22.9s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100,), score=(train=0.765, test=0.754), total=  16.0s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100,), score=(train=0.782, test=0.708), total=  20.5s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100,), score=(train=0.768, test=0.738), total=  16.0s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100,), score=(train=0.776, test=0.724), total=  19.4s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(100,), score=(train=0.783, test=0.690), total=  20.4s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50,), score=(train=0.771, test=0.756), total=  13.3s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50,), score=(train=0.790, test=0.707), total=  16.8s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50,), score=(train=0.786, test=0.738), total=  18.5s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50,), score=(train=0.780, test=0.725), total=  16.3s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50,), score=(train=0.793, test=0.690), total=  19.1s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.733, test=0.750), total=  13.3s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.751, test=0.704), total=  17.1s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.737, test=0.731), total=  14.1s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.741, test=0.713), total=  11.6s\n",
            "[CV] activation=logistic, alpha=1, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=logistic, alpha=1, hidden_layer_sizes=(50, 10), score=(train=0.750, test=0.681), total=  14.0s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.662), total=  28.2s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.610), total=  28.2s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.625), total=  28.1s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.669), total=  27.8s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.640), total=  27.5s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.663), total=  20.8s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.616), total=  20.9s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.633), total=  20.7s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.667), total=  20.3s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.648), total=  20.5s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.651), total=  27.0s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.599), total=  22.7s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.622), total=  29.6s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.659), total=  20.7s\n",
            "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.643), total=  29.2s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.663), total=  27.9s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.613), total=  27.8s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.627), total=  27.7s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.670), total=  27.8s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.640), total=  27.8s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.664), total=  21.0s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.619), total=  21.5s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.634), total=  20.5s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.668), total=  20.6s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.648), total=  20.9s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.652), total=  27.0s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.600), total=  20.2s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.625), total=  30.2s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.660), total=  21.6s\n",
            "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.644), total=  29.7s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100,) ..........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.673), total=  37.9s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100,) ..........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.628), total=  36.7s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100,) ..........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.642), total=  37.3s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100,) ..........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.682), total=  37.6s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(100,) ..........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.649), total=  37.3s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50,) ...........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), score=(train=1.000, test=0.671), total=  23.4s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50,) ...........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), score=(train=1.000, test=0.631), total=  25.1s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50,) ...........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), score=(train=1.000, test=0.644), total=  23.7s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50,) ...........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), score=(train=1.000, test=0.675), total=  23.4s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50,) ...........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), score=(train=1.000, test=0.651), total=  22.9s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.659), total=  32.3s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.613), total=  24.1s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.635), total=  30.3s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.671), total=  24.6s\n",
            "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n",
            "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.653), total=  32.3s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.676), total= 1.0min\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.638), total=  55.9s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.654), total=  53.1s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.689), total=  50.6s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.649), total=  52.0s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50,) ............\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50,), score=(train=1.000, test=0.675), total=  39.4s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50,) ............\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50,), score=(train=1.000, test=0.651), total=  35.0s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50,) ............\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50,), score=(train=1.000, test=0.663), total=  35.8s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50,) ............\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50,), score=(train=1.000, test=0.678), total=  39.0s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50,) ............\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50,), score=(train=1.000, test=0.659), total=  40.0s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.994, test=0.643), total=  30.6s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.624), total=  24.2s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=0.988, test=0.627), total=  36.3s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.678), total=  35.3s\n",
            "[CV] activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=tanh, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.640), total=  31.6s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100,), score=(train=0.894, test=0.707), total=  16.3s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100,), score=(train=0.906, test=0.654), total=  13.0s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100,), score=(train=0.896, test=0.687), total=  10.3s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100,), score=(train=0.893, test=0.706), total=  10.0s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(100,), score=(train=0.900, test=0.661), total=  12.6s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50,), score=(train=0.904, test=0.702), total=  13.3s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50,), score=(train=0.908, test=0.653), total=  10.7s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50,), score=(train=0.909, test=0.678), total=  12.1s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50,), score=(train=0.895, test=0.708), total=   6.8s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50,), score=(train=0.900, test=0.664), total=   7.4s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.651), total=  26.9s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.638), total=  36.0s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.635), total=  25.0s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.661), total=  31.9s\n",
            "[CV] activation=tanh, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=tanh, alpha=1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.639), total=  31.8s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.690), total=  14.7s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.634), total=  13.9s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.658), total=  13.9s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.690), total=  14.1s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(100,) ........\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.651), total=  14.0s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.694), total=  11.9s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.635), total=  11.9s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.660), total=  11.7s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.686), total=  11.8s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50,) .........\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.651), total=  11.9s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.680), total=   6.3s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.630), total=   6.4s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.659), total=   6.3s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.681), total=   6.6s\n",
            "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10) ......\n",
            "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.650), total=   6.4s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.690), total=  13.6s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.636), total=  13.6s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.660), total=  13.4s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.691), total=  13.5s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100,) .........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100,), score=(train=1.000, test=0.651), total=  13.6s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.695), total=  11.4s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.638), total=  11.5s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.660), total=  11.4s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.687), total=  11.5s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50,) ..........\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50,), score=(train=1.000, test=0.653), total=  11.4s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.680), total=   6.3s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.632), total=   6.2s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.658), total=   6.2s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.680), total=   6.5s\n",
            "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10) .......\n",
            "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.650), total=   6.2s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100,) ..........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.697), total=  21.4s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100,) ..........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.648), total=  19.4s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100,) ..........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.668), total=  20.5s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100,) ..........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.696), total=  21.3s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100,) ..........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100,), score=(train=1.000, test=0.654), total=  20.1s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50,) ...........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50,), score=(train=1.000, test=0.701), total=  13.5s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50,) ...........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50,), score=(train=1.000, test=0.646), total=  13.6s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50,) ...........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50,), score=(train=1.000, test=0.666), total=  13.4s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50,) ...........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50,), score=(train=1.000, test=0.690), total=  12.7s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50,) ...........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50,), score=(train=1.000, test=0.654), total=  13.0s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.683), total=   6.4s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.636), total=   6.3s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.662), total=   6.4s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.680), total=   6.5s\n",
            "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10) ........\n",
            "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.651), total=   6.4s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.699), total=  28.7s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.652), total=  28.8s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.689), total=  29.6s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.698), total=  28.8s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100,) ...........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.663), total=  29.1s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50,) ............\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50,), score=(train=1.000, test=0.709), total=  24.0s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50,) ............\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50,), score=(train=1.000, test=0.650), total=  22.0s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50,) ............\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50,), score=(train=1.000, test=0.673), total=  21.9s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50,) ............\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50,), score=(train=1.000, test=0.690), total=  23.0s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50,) ............\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50,), score=(train=1.000, test=0.652), total=  19.7s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.691), total=  17.8s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.641), total=  18.0s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.670), total=  19.7s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.678), total=  18.9s\n",
            "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10) .........\n",
            "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.651), total=  17.7s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.711), total=  15.7s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.667), total=  12.3s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.707), total=  17.0s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.697), total=  17.3s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(100,) .............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(100,), score=(train=1.000, test=0.668), total=  13.6s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50,), score=(train=1.000, test=0.718), total=  16.2s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50,), score=(train=1.000, test=0.671), total=  12.9s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50,), score=(train=1.000, test=0.692), total=  15.2s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50,), score=(train=1.000, test=0.699), total=  17.5s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50,) ..............\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50,), score=(train=1.000, test=0.663), total=  14.5s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.683), total=  14.3s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.642), total=  16.5s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.672), total=  14.9s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.686), total=  15.1s\n",
            "[CV] activation=relu, alpha=1, hidden_layer_sizes=(50, 10) ...........\n",
            "[CV]  activation=relu, alpha=1, hidden_layer_sizes=(50, 10), score=(train=1.000, test=0.660), total=  11.8s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 225 out of 225 | elapsed: 121.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=1000, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_state=1234, shuffle=True,\n",
              "                                     solver='adam', tol=0.0001,\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'activation': ['logistic', 'tanh', 'relu'],\n",
              "                         'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
              "                         'hidden_layer_sizes': [(100,), (50,), (50, 10)]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HvM4WRlHDmk"
      },
      "source": [
        "Лучший набор параметров и значение критерия качества на них:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9PE9SyPHDmm",
        "outputId": "a6aeed76-beab-4a4f-80f2-7de6ce3a2f27"
      },
      "source": [
        "f9_mlpc_CV.best_params_ , f9_mlpc_CV.best_score_"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'activation': 'logistic', 'alpha': 1, 'hidden_layer_sizes': (50,)},\n",
              " 0.7232876883871493)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rB7nJoMHDmm"
      },
      "source": [
        "По сравнению наилучшей по итогам 6 задачи качество изменилось на: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmcUTEPyHDmn",
        "outputId": "76f1f8bf-6753-438a-a532-1521dc30fdb3"
      },
      "source": [
        "f9_mlpc_CV.best_score_ - best_mlpc_score"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.010527765776934594"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8og-gNgxSe82"
      },
      "source": [
        "Оптимальные параметры поменялись. Качество улучшилось! \n",
        "\n",
        "Переобучение наблюдалось в основном с `relu` и на маленьких `alpha` с `tanh`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP8g4WVbD9hm"
      },
      "source": [
        "#### Лучшие модели по итогам 9 задания"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogXW4Z7cESky"
      },
      "source": [
        "best9_logreg_model = LogisticRegression(tol=0.0001, \n",
        "                                        solver='saga',\n",
        "                                        penalty='elasticnet',\n",
        "                                        fit_intercept=False,\n",
        "                                        C=0.1,\n",
        "                                        l1_ratio=0.1,\n",
        "                                        max_iter=500,\n",
        "                                        random_state=1234)\n",
        "best9_logreg_model.fit(nX_train[:4000], ny_train[:4000])\n",
        "\n",
        "best9_mlpc_model = MLPClassifier(activation='logistic',\n",
        "                                 alpha=1,\n",
        "                                 hidden_layer_sizes=(50,),\n",
        "                                 solver='adam',\n",
        "                                 learning_rate='constant',\n",
        "                                 learning_rate_init=0.001,\n",
        "                                 tol=0.0001,\n",
        "                                 max_iter=1000,\n",
        "                                 random_state=1234)\n",
        "best9_mlpc_model.fit(nX_train[:4000], ny_train[:4000])\n",
        "\n",
        "best9_svc_model = SVC(C=0.01, \n",
        "                      kernel='linear',\n",
        "                      gamma='scale',\n",
        "                      tol=0.001,\n",
        "                      random_state=1234)\n",
        "best9_svc_model.fit(nX_train[:4000], ny_train[:4000])\n",
        "\n",
        "# чтобы не перезапускать ячейки с кросс-валидацией, но иметь под рукой значения качества оттуда\n",
        "best9_logreg_score = 0.7209922923280174\n",
        "best9_svc_score = 0.7217649379191164\n",
        "best9_mlpc_score = 0.7232876883871493"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWUcQwiz4KFg",
        "outputId": "bd94f8c4-90b4-426b-a2d9-3b0e6472e240"
      },
      "source": [
        "print('LogReg score:', best9_logreg_score)\n",
        "print('SVC score:', best9_svc_score)\n",
        "print('MLPClassifier score:', best9_mlpc_score)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogReg score: 0.7209922923280174\n",
            "SVC score: 0.7217649379191164\n",
            "MLPClassifier score: 0.7232876883871493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyj36Wms4uL4"
      },
      "source": [
        "По итогам 9 задания наилучшее качество у MLPClassifier. На втором месте SVC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo5u4JyGRUF6"
      },
      "source": [
        "### Смешивание моделей (blending)\n",
        "\n",
        "Часто на практике оказывается возможным увеличить качество предсказания путем смешивания разных моделей. Давайте посмотрим, действительно ли такой подход дает прирост в качестве.\n",
        "\n",
        "Выберите из построенных моделей двух предыдущих пунктов две, которые дали наибольшее начество на кросс-валидации (обозначим их $clf_1$ и $clf_2$). Далее постройте новый классификатор, ответ которого на некотором объекте $x$ будет выглядеть следующим образом:\n",
        "\n",
        "$$result(x) = clf_1(x) * \\alpha + clf_2(x) * (1 - \\alpha)$$\n",
        "\n",
        "где $\\alpha$ — гиперпараметр нового классификатора."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2colG80RUF6"
      },
      "source": [
        "#### 10\n",
        "\n",
        "**Задание 10** (2 балла)\n",
        "\n",
        "При реализации своих моделей хорошей практикой является создание sklearn-совместимых классов. Во-первых, такая реализация будет иметь стандартный интерфейс и позволит другим людям безболезненно обучать реализованные вами модели. Во-вторых, появляется возможность использовать любой функционал пакета sklearn, принимающий на вход модель.\n",
        "\n",
        "Создайте классификатор, который инициализируется двумя произвольными классификаторами и параметром $\\alpha$. Во время обучения такой классификатор должен обучать обе базовые модели, а на этапе предсказания замешивать предсказания базовых моделей по формуле, указанной выше. \n",
        "\n",
        "Для создания пользовательского классификатора необходимо отнаследоваться от базовых классов *[BaseEstimator](http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html), [ClassifierMixin](http://scikit-learn.org/stable/modules/generated/sklearn.base.ClassifierMixin.html)* и реализовать методы *\\_\\_init\\_\\_, fit, predict и predict_proba*. Пример sklearn-совместимого классификатора с комментариями можно найти [здесь](http://scikit-learn.org/stable/developers/contributing.html#rolling-your-own-estimator) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHiEcYblprjB"
      },
      "source": [
        "**Решение задания 10:**\n",
        "\n",
        "Пример кода класса смотрела [здесь](https://scikit-learn.org/stable/developers/develop.html) (в \"Rolling your own estimator\").  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZh1YBeiRUF7"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.base import ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
        "\n",
        "class MyBlendedModel(BaseEstimator, ClassifierMixin):\n",
        "\n",
        "  def __init__(self, estimator1, estimator2, alpha=0.5):\n",
        "    self.estimator1 = estimator1\n",
        "    self.estimator2 = estimator2\n",
        "    self.alpha = alpha\n",
        "  \n",
        "  def fit(self, X, y):\n",
        "    X, y = check_X_y(X, y)\n",
        "    self.estimator1.fit(X, y)\n",
        "    self.estimator2.fit(X, y)\n",
        "\n",
        "    self.X_ = X\n",
        "    self.y_ = y\n",
        "\n",
        "    return self\n",
        "\n",
        "  def predict_proba(self, X):\n",
        "    check_is_fitted(self)\n",
        "\n",
        "    est1_prob = self.estimator1.predict_proba(X)\n",
        "    est2_prob = self.estimator2.predict_proba(X)\n",
        "\n",
        "    return (self.alpha*est1_prob + (1 - self.alpha)*est2_prob)\n",
        "\n",
        "  def predict(self, X):\n",
        "    probas = self.predict_proba(X)\n",
        "\n",
        "    return np.array([int(x[1] > x[0]) for x in probas])\n",
        "    "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4ZQUXwNqZ2i"
      },
      "source": [
        "Проверю на работоспособность на наиболее удачных моделях логистической регрессии и MLPClassifier (по итогам 6 задания, без новых признаков):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2axt9yZ4qEYA",
        "outputId": "23a046b3-f552-43bf-a115-3bddac32af12"
      },
      "source": [
        "best_logreg_model = LogisticRegression(tol=0.0001, \n",
        "                                  solver='saga',\n",
        "                                  penalty='elasticnet',\n",
        "                                  fit_intercept=True,\n",
        "                                  C=0.008,\n",
        "                                  l1_ratio=0.45,\n",
        "                                  max_iter=500)\n",
        "\n",
        "best_mlpc_model = MLPClassifier(activation='logistic',\n",
        "                                alpha=0.1,\n",
        "                                hidden_layer_sizes=(100,),\n",
        "                                solver='adam',\n",
        "                                learning_rate='constant',\n",
        "                                learning_rate_init=0.001,\n",
        "                                tol=0.0001,\n",
        "                                max_iter=1000)\n",
        "\n",
        "blended = MyBlendedModel(estimator1=best_logreg_model,\n",
        "                         estimator2=best_mlpc_model,\n",
        "                         alpha=0.5)\n",
        "\n",
        "blended.fit(X_train_scaled[:1000], y_train[:1000])\n",
        "b_y_pred = blended.predict(X_test_scaled[:100])\n",
        "b_proba_pred = blended.predict_proba(X_test_scaled[:100])\n",
        "\n",
        "roc_auc_score(y_true=y_test[:100], y_score=b_y_pred)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7043269230769231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFE5ciy0stPB",
        "outputId": "20439593-74d6-4aa6-b0d4-8a2fed7e1487"
      },
      "source": [
        "b_proba_pred[:2]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.41112373, 0.58887627],\n",
              "       [0.6934433 , 0.3065567 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV5qb8LdsHKz",
        "outputId": "a4887877-a4ad-4a30-fe88-b2ea56937108"
      },
      "source": [
        "b_y_pred[:2]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oco_XsUYs-30"
      },
      "source": [
        "Работает!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzAGE4I3RUF7"
      },
      "source": [
        "#### 11\n",
        "\n",
        "**Задание 11** (1 балл)\n",
        "\n",
        "Подберите по сетке от 0 до 1 значение $\\alpha$ для этого классификатора. Если класс реализован правильно, то вы cможете использовать *GridSearchCV*, как в случае с обычными классификаторами.\n",
        "\n",
        "Изобразите на графике среднее качество по фолдам и доверительный интервал в зависимости от $\\alpha$.\n",
        "\n",
        "Дал ли этот подход прирост к качеству по сравнению с моделями, обученными по-отдельности? Поясните, почему даже простой блендинг моделей может влять на итоговое качество?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeVdgNzJJWcm"
      },
      "source": [
        "***Решение задания 11:***\n",
        "\n",
        "Использую показавшие наилучшие разультаты в 9 задании модели: SVC и MLPClassifier. Использую такое же количество объектов (4000), как и в предыдущих заданиях. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUiYyJ1UtZQ8",
        "outputId": "2914e867-e512-46fd-9c8f-c4cffda56ce2"
      },
      "source": [
        "# Инициализирую модель\n",
        "best9_mlpc_model = MLPClassifier(activation='logistic',\n",
        "                                 alpha=1.0,\n",
        "                                 hidden_layer_sizes=(50,),\n",
        "                                 solver='adam',\n",
        "                                 learning_rate='constant',\n",
        "                                 learning_rate_init=0.001,\n",
        "                                 tol=0.0001,\n",
        "                                 max_iter=1000)\n",
        "\n",
        "best9_svc_model = SVC(C=0.01, \n",
        "                      kernel='linear',\n",
        "                      gamma='scale',\n",
        "                      tol=0.001,\n",
        "                      probability=True,\n",
        "                      random_state=1234)\n",
        "\n",
        "blended_model = MyBlendedModel(estimator1=best9_svc_model,\n",
        "                               estimator2=best9_mlpc_model,\n",
        "                               alpha=0.5)\n",
        "\n",
        "# Тестируемые значения гиперпараметрa \n",
        "blended_params_set = {\n",
        "'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "# Кросс-валидация\n",
        "blended_CV = GridSearchCV(estimator=blended_model,\n",
        "                          param_grid=blended_params_set,\n",
        "                          scoring='roc_auc',\n",
        "                          return_train_score=True,\n",
        "                          verbose=3)\n",
        "\n",
        "blended_CV.fit(nX_train[:4000], ny_train[:4000])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
            "[CV] alpha=0.0 .......................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... alpha=0.0, score=(train=0.760, test=0.754), total= 1.6min\n",
            "[CV] alpha=0.0 .......................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.8min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... alpha=0.0, score=(train=0.794, test=0.702), total= 1.7min\n",
            "[CV] alpha=0.0 .......................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.8min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... alpha=0.0, score=(train=0.781, test=0.738), total= 1.8min\n",
            "[CV] alpha=0.0 .......................................................\n",
            "[CV] ....... alpha=0.0, score=(train=0.778, test=0.724), total= 1.7min\n",
            "[CV] alpha=0.0 .......................................................\n",
            "[CV] ....... alpha=0.0, score=(train=0.786, test=0.689), total= 1.7min\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.781, test=0.756), total= 1.7min\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.789, test=0.703), total= 1.7min\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.778, test=0.736), total= 1.7min\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.783, test=0.725), total= 1.7min\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ....... alpha=0.1, score=(train=0.789, test=0.690), total= 1.7min\n",
            "[CV] alpha=0.2 .......................................................\n",
            "[CV] ....... alpha=0.2, score=(train=0.777, test=0.756), total= 1.7min\n",
            "[CV] alpha=0.2 .......................................................\n",
            "[CV] ....... alpha=0.2, score=(train=0.791, test=0.705), total= 1.7min\n",
            "[CV] alpha=0.2 .......................................................\n",
            "[CV] ....... alpha=0.2, score=(train=0.778, test=0.738), total= 1.8min\n",
            "[CV] alpha=0.2 .......................................................\n",
            "[CV] ....... alpha=0.2, score=(train=0.776, test=0.724), total= 1.7min\n",
            "[CV] alpha=0.2 .......................................................\n",
            "[CV] ....... alpha=0.2, score=(train=0.790, test=0.691), total= 1.7min\n",
            "[CV] alpha=0.3 .......................................................\n",
            "[CV] ....... alpha=0.3, score=(train=0.781, test=0.756), total= 1.8min\n",
            "[CV] alpha=0.3 .......................................................\n",
            "[CV] ....... alpha=0.3, score=(train=0.789, test=0.705), total= 1.8min\n",
            "[CV] alpha=0.3 .......................................................\n",
            "[CV] ....... alpha=0.3, score=(train=0.781, test=0.738), total= 1.7min\n",
            "[CV] alpha=0.3 .......................................................\n",
            "[CV] ....... alpha=0.3, score=(train=0.777, test=0.724), total= 1.8min\n",
            "[CV] alpha=0.3 .......................................................\n",
            "[CV] ....... alpha=0.3, score=(train=0.785, test=0.690), total= 1.7min\n",
            "[CV] alpha=0.4 .......................................................\n",
            "[CV] ....... alpha=0.4, score=(train=0.777, test=0.755), total= 1.9min\n",
            "[CV] alpha=0.4 .......................................................\n",
            "[CV] ....... alpha=0.4, score=(train=0.788, test=0.705), total= 1.7min\n",
            "[CV] alpha=0.4 .......................................................\n",
            "[CV] ....... alpha=0.4, score=(train=0.784, test=0.737), total= 1.9min\n",
            "[CV] alpha=0.4 .......................................................\n",
            "[CV] ....... alpha=0.4, score=(train=0.781, test=0.725), total= 1.8min\n",
            "[CV] alpha=0.4 .......................................................\n",
            "[CV] ....... alpha=0.4, score=(train=0.784, test=0.689), total= 1.7min\n",
            "[CV] alpha=0.5 .......................................................\n",
            "[CV] ....... alpha=0.5, score=(train=0.776, test=0.755), total= 1.8min\n",
            "[CV] alpha=0.5 .......................................................\n",
            "[CV] ....... alpha=0.5, score=(train=0.786, test=0.705), total= 1.8min\n",
            "[CV] alpha=0.5 .......................................................\n",
            "[CV] ....... alpha=0.5, score=(train=0.776, test=0.738), total= 1.7min\n",
            "[CV] alpha=0.5 .......................................................\n",
            "[CV] ....... alpha=0.5, score=(train=0.777, test=0.724), total= 1.7min\n",
            "[CV] alpha=0.5 .......................................................\n",
            "[CV] ....... alpha=0.5, score=(train=0.783, test=0.689), total= 1.7min\n",
            "[CV] alpha=0.6 .......................................................\n",
            "[CV] ....... alpha=0.6, score=(train=0.775, test=0.754), total= 1.8min\n",
            "[CV] alpha=0.6 .......................................................\n",
            "[CV] ....... alpha=0.6, score=(train=0.781, test=0.706), total= 1.7min\n",
            "[CV] alpha=0.6 .......................................................\n",
            "[CV] ....... alpha=0.6, score=(train=0.775, test=0.738), total= 1.8min\n",
            "[CV] alpha=0.6 .......................................................\n",
            "[CV] ....... alpha=0.6, score=(train=0.776, test=0.723), total= 1.7min\n",
            "[CV] alpha=0.6 .......................................................\n",
            "[CV] ....... alpha=0.6, score=(train=0.785, test=0.691), total= 1.7min\n",
            "[CV] alpha=0.7 .......................................................\n",
            "[CV] ....... alpha=0.7, score=(train=0.772, test=0.754), total= 1.8min\n",
            "[CV] alpha=0.7 .......................................................\n",
            "[CV] ....... alpha=0.7, score=(train=0.782, test=0.706), total= 1.7min\n",
            "[CV] alpha=0.7 .......................................................\n",
            "[CV] ....... alpha=0.7, score=(train=0.774, test=0.737), total= 1.7min\n",
            "[CV] alpha=0.7 .......................................................\n",
            "[CV] ....... alpha=0.7, score=(train=0.777, test=0.724), total= 1.7min\n",
            "[CV] alpha=0.7 .......................................................\n",
            "[CV] ....... alpha=0.7, score=(train=0.783, test=0.690), total= 1.8min\n",
            "[CV] alpha=0.8 .......................................................\n",
            "[CV] ....... alpha=0.8, score=(train=0.772, test=0.754), total= 1.8min\n",
            "[CV] alpha=0.8 .......................................................\n",
            "[CV] ....... alpha=0.8, score=(train=0.780, test=0.706), total= 1.7min\n",
            "[CV] alpha=0.8 .......................................................\n",
            "[CV] ....... alpha=0.8, score=(train=0.776, test=0.738), total= 1.8min\n",
            "[CV] alpha=0.8 .......................................................\n",
            "[CV] ....... alpha=0.8, score=(train=0.774, test=0.723), total= 1.7min\n",
            "[CV] alpha=0.8 .......................................................\n",
            "[CV] ....... alpha=0.8, score=(train=0.780, test=0.689), total= 1.6min\n",
            "[CV] alpha=0.9 .......................................................\n",
            "[CV] ....... alpha=0.9, score=(train=0.770, test=0.753), total= 1.8min\n",
            "[CV] alpha=0.9 .......................................................\n",
            "[CV] ....... alpha=0.9, score=(train=0.780, test=0.706), total= 1.8min\n",
            "[CV] alpha=0.9 .......................................................\n",
            "[CV] ....... alpha=0.9, score=(train=0.773, test=0.738), total= 1.7min\n",
            "[CV] alpha=0.9 .......................................................\n",
            "[CV] ....... alpha=0.9, score=(train=0.774, test=0.723), total= 1.7min\n",
            "[CV] alpha=0.9 .......................................................\n",
            "[CV] ....... alpha=0.9, score=(train=0.781, test=0.690), total= 1.8min\n",
            "[CV] alpha=1.0 .......................................................\n",
            "[CV] ....... alpha=1.0, score=(train=0.769, test=0.753), total= 1.7min\n",
            "[CV] alpha=1.0 .......................................................\n",
            "[CV] ....... alpha=1.0, score=(train=0.778, test=0.706), total= 1.7min\n",
            "[CV] alpha=1.0 .......................................................\n",
            "[CV] ....... alpha=1.0, score=(train=0.772, test=0.738), total= 1.7min\n",
            "[CV] alpha=1.0 .......................................................\n",
            "[CV] ....... alpha=1.0, score=(train=0.774, test=0.723), total= 1.7min\n",
            "[CV] alpha=1.0 .......................................................\n",
            "[CV] ....... alpha=1.0, score=(train=0.779, test=0.690), total= 1.7min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  55 out of  55 | elapsed: 109.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=MyBlendedModel(alpha=0.5,\n",
              "                                      estimator1=SVC(C=0.01, break_ties=False,\n",
              "                                                     cache_size=200,\n",
              "                                                     class_weight=None,\n",
              "                                                     coef0=0.0,\n",
              "                                                     decision_function_shape='ovr',\n",
              "                                                     degree=3, gamma='scale',\n",
              "                                                     kernel='linear',\n",
              "                                                     max_iter=-1,\n",
              "                                                     probability=True,\n",
              "                                                     random_state=1234,\n",
              "                                                     shrinking=True, tol=0.001,\n",
              "                                                     verbose=False),\n",
              "                                      estimator2=MLPClassifier(activation='log...\n",
              "                                                               n_iter_no_change=10,\n",
              "                                                               nesterovs_momentum=True,\n",
              "                                                               power_t=0.5,\n",
              "                                                               random_state=None,\n",
              "                                                               shuffle=True,\n",
              "                                                               solver='adam',\n",
              "                                                               tol=0.0001,\n",
              "                                                               validation_fraction=0.1,\n",
              "                                                               verbose=False,\n",
              "                                                               warm_start=False)),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
              "                                   0.9, 1.0]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='roc_auc', verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q08gzCTtZRR"
      },
      "source": [
        "Лучший параметр и значение критерия качества на нём:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO77LL_FtZRS",
        "outputId": "14f8d279-23d9-4737-bdb4-c7e9211ff78b"
      },
      "source": [
        "blended_CV.best_params_ , blended_CV.best_score_"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'alpha': 0.2}, 0.722764242913763)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK1_JTyltZRT"
      },
      "source": [
        "График среднего значения качества:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "ri9sXbvDtZRT",
        "outputId": "0e003b4f-c4c9-4da4-b3e1-02e3e7c1d2c9"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(blended_params_set['alpha'], blended_CV.cv_results_['mean_train_score'], 'bo-', label='train')\n",
        "plt.plot(blended_params_set['alpha'], blended_CV.cv_results_['mean_test_score'], 'go-', label='test')\n",
        "\n",
        "plt.fill_between(blended_params_set['alpha'], \n",
        "                 blended_CV.cv_results_['mean_train_score']-blended_CV.cv_results_['std_train_score'], \n",
        "                 blended_CV.cv_results_['mean_train_score']+blended_CV.cv_results_['std_train_score'], \n",
        "                 color='blue', alpha=0.1)\n",
        "plt.fill_between(blended_params_set['alpha'], \n",
        "                 blended_CV.cv_results_['mean_test_score']-blended_CV.cv_results_['std_test_score'], \n",
        "                 blended_CV.cv_results_['mean_test_score']+blended_CV.cv_results_['std_test_score'], \n",
        "                 color='green', alpha=0.1)\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('alpha'), \n",
        "plt.ylabel('roc_auc score')\n",
        "plt.title('Blended model')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d44ZnBGHtZRU"
      },
      "source": [
        "Оценка качества на части (1000 элементов) тестовой выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebvbUXqxtZRV",
        "outputId": "43fd3350-a6d4-4dd0-9dac-ea4d4a5288a2"
      },
      "source": [
        "b_test_score = roc_auc_score(y_true=ny_test[:1000], y_score=blended_CV.best_estimator_.predict(nX_test[:1000]))\n",
        "b_test_score"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6838480342147062"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdSVUgSQjhlu",
        "outputId": "81732a71-a302-4b0d-e79a-1d074ea14af5"
      },
      "source": [
        "print('По сравнению с \"чистым\" SVC качество изменилось на:', blended_CV.best_score_ - best9_svc_score )\n",
        "print('По сравнению с \"чистым\" MLPClassifier качество изменилось на:', blended_CV.best_score_ - best9_mlpc_score )"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "По сравнению с \"чистым\" SVC качество изменилось на: 0.0009993049946465105\n",
            "По сравнению с \"чистым\" MLPClassifier качество изменилось на: -0.0005234454733863414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf5SbK11JemM"
      },
      "source": [
        "*Вывод:* по сравнению с лучшей моделью из 9 задания (MLPClassifier) качество увеличить не удалось. `alpha=0.0` (т.е. только MLPClassifier) не оказалось выбрано при переборе по сетке, предположительно, потому что я забыла указать такое же `random_state` для модели MLPC, как и в 9 задании, и она отработала немного по-другому, показав в данном случае чуть меньшие результаты.\n",
        "\n",
        "Наилучший парметр: 0.2. Т.е. 0.2\\*svc + 0.8\\*mlpc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6tb40gFRUF8"
      },
      "source": [
        "### Сравнение построенных моделей\n",
        "\n",
        "![](http://cdn.shopify.com/s/files/1/0870/1066/files/compare_e8b89647-3cb6-4871-a976-2e36e5987773.png?1750043340268621065)\n",
        "\n",
        "После того как было построено много моделей, правильным продолжением является сравнение их между собой.  Воспользуйтесь диаграммой размаха (\"ящик с усами\") для сравнения алгоритмов между собой. Эту диаграмму можно построить при помощи [boxplot](https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.pyplot.boxplot.html) из matplotlib либо через [обертку](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.boxplot.html) над ней из pandas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7jOzZxNRUF9"
      },
      "source": [
        "#### 12\n",
        "\n",
        "**Задание 12** (2 балла) \n",
        "\n",
        "Для каждого типа классификатора, а так же смешанной модели, выберите тот, которых давал наилучшее качество на кросс-валидации и постройте диаграмму размаха. Все классификаторы должны быть изображены на одном графике.\n",
        " \n",
        "Сделайте общие итоговые выводы о классификаторах с точки зрения их работы с признаками и сложности самой модели (какие гиперпараметры есть у модели, сильно ли изменение значения гиперпараметра влияет на качество модели)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw5C88grJliX"
      },
      "source": [
        "***Решение задания 12:***\n",
        "\n",
        "Проведу 5-fold кросс-валидацию выбранных моделей на всех обучающих данных, с добавленными категориальными признаками *heroes* и стандартизированными признаками по *gold* и *lh*.\n",
        "\n",
        "А так же вычислю значение качества каждой модели на тестовой выборке."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0PyRRqMRUF9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e92d67d3-7aa2-4e2f-811e-d70e1a74d10c"
      },
      "source": [
        "len(nX_train), len(nX_test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19979, 4995)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnBs99X7KP7_",
        "outputId": "99b0b8ee-e3c5-4499-c848-8ef5309a6785"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "the_best_logreg_model = LogisticRegression(tol=0.0001, \n",
        "                                        solver='saga',\n",
        "                                        penalty='elasticnet',\n",
        "                                        fit_intercept=False,\n",
        "                                        C=0.1,\n",
        "                                        l1_ratio=0.1,\n",
        "                                        max_iter=500,\n",
        "                                        random_state=1234)\n",
        "\n",
        "best_logreg_cv_scores = cross_val_score(estimator=the_best_logreg_model,\n",
        "                                        X=nX_train, y=ny_train,\n",
        "                                        scoring='roc_auc',\n",
        "                                        verbose=3)\n",
        "\n",
        "the_best_logreg_model.fit(X=nX_train, y=ny_train)\n",
        "best_logreg_test_score = roc_auc_score(y_true=ny_test,\n",
        "                                       y_score=the_best_logreg_model.predict(nX_test))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  ................................................................\n",
            "[CV] .................................... , score=0.750, total=  21.6s\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   21.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .................................... , score=0.724, total=  18.7s\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   40.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .................................... , score=0.732, total=  22.9s\n",
            "[CV]  ................................................................\n",
            "[CV] .................................... , score=0.759, total=  21.9s\n",
            "[CV]  ................................................................\n",
            "[CV] .................................... , score=0.729, total=  23.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.8min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds8jLfQeL7KD",
        "outputId": "0532908a-7b4a-4013-8ace-6553667f67bd"
      },
      "source": [
        "# SVC\n",
        "\n",
        "the_best_svc_model = SVC(C=0.01, \n",
        "                         kernel='linear',\n",
        "                         gamma='scale',\n",
        "                         tol=0.001,\n",
        "                         random_state=1234)\n",
        "\n",
        "best_svc_cv_scores = cross_val_score(estimator=the_best_svc_model,\n",
        "                                     X=nX_train, y=ny_train,\n",
        "                                     scoring='roc_auc',\n",
        "                                     verbose=3)\n",
        "\n",
        "the_best_svc_model.fit(X=nX_train, y=ny_train)\n",
        "best_svc_test_score = roc_auc_score(y_true=ny_test,\n",
        "                                    y_score=the_best_svc_model.predict(nX_test))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  ................................................................\n",
            "[CV] .................................... , score=0.746, total= 8.6min\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  8.6min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .................................... , score=0.718, total= 8.6min\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 17.2min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .................................... , score=0.727, total= 8.7min\n",
            "[CV]  ................................................................\n",
            "[CV] .................................... , score=0.753, total= 8.7min\n",
            "[CV]  ................................................................\n",
            "[CV] .................................... , score=0.724, total= 8.6min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 43.2min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTUzrkGPML6B",
        "outputId": "d51bd9e3-a0c1-45b4-8303-2a367327be37"
      },
      "source": [
        "# MLPClassifier\n",
        "\n",
        "the_best_mlpc_model = MLPClassifier(activation='logistic',\n",
        "                                    alpha=1,\n",
        "                                    hidden_layer_sizes=(50,),\n",
        "                                    solver='adam',\n",
        "                                    learning_rate='constant',\n",
        "                                    learning_rate_init=0.001,\n",
        "                                    tol=0.0001,\n",
        "                                    max_iter=1000,\n",
        "                                    random_state=1234)\n",
        "\n",
        "best_mlpc_cv_scores = cross_val_score(estimator=the_best_mlpc_model,\n",
        "                                      X=nX_train, y=ny_train,\n",
        "                                      scoring='roc_auc',\n",
        "                                      verbose=3)\n",
        "\n",
        "the_best_mlpc_model.fit(X=nX_train, y=ny_train)\n",
        "best_mlpc_test_score = roc_auc_score(y_true=ny_test,\n",
        "                                     y_score=the_best_mlpc_model.predict(nX_test))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  ................................................................\n",
            "[CV] .................................... , score=0.728, total=  19.8s\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .................................... , score=0.702, total=  23.1s\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   42.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .................................... , score=0.711, total=  14.2s\n",
            "[CV]  ................................................................\n",
            "[CV] .................................... , score=0.731, total=  22.1s\n",
            "[CV]  ................................................................\n",
            "[CV] .................................... , score=0.703, total=  20.7s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.7min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOqnyrhvMc16",
        "outputId": "afa5732b-bb93-4254-fb0c-385161a1cf96"
      },
      "source": [
        "# Blended\n",
        "\n",
        "best12_mlpc_model = MLPClassifier(activation='logistic',\n",
        "                                  alpha=1.0,\n",
        "                                  hidden_layer_sizes=(50,),\n",
        "                                  solver='adam',\n",
        "                                  learning_rate='constant',\n",
        "                                  learning_rate_init=0.001,\n",
        "                                  tol=0.0001,\n",
        "                                  max_iter=1000, \n",
        "                                  random_state=1234)\n",
        "\n",
        "best12_svc_model = SVC(C=0.01, \n",
        "                       kernel='linear',\n",
        "                       gamma='scale',\n",
        "                       tol=0.001,\n",
        "                       probability=True,\n",
        "                       random_state=1234)\n",
        "\n",
        "the_best_blend_model = MyBlendedModel(estimator1=best12_svc_model,\n",
        "                                        estimator2=best12_mlpc_model,\n",
        "                                        alpha=0.2)\n",
        "\n",
        "best_blend_cv_scores = cross_val_score(estimator=the_best_blend_model,\n",
        "                                       X=nX_train, y=ny_train,\n",
        "                                       scoring='roc_auc',\n",
        "                                       verbose=3)\n",
        "\n",
        "the_best_blend_model.fit(X=nX_train, y=ny_train)\n",
        "best_blend_test_score = roc_auc_score(y_true=ny_test,\n",
        "                                      y_score=the_best_blend_model.predict(nX_test))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  ................................................................\n",
            "[CV] .................................... , score=0.734, total=38.0min\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 38.0min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .................................... , score=0.707, total=37.7min\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 75.7min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .................................... , score=0.717, total=37.8min\n",
            "[CV]  ................................................................\n",
            "[CV] .................................... , score=0.738, total=38.1min\n",
            "[CV]  ................................................................\n",
            "[CV] .................................... , score=0.709, total=37.6min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 189.2min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "LJfnSIbbxc4Z",
        "outputId": "15d58315-8462-41a5-d27b-807bb018bdca"
      },
      "source": [
        "bp_df = pd.DataFrame({'LogReg':best_logreg_cv_scores,\n",
        "                      'SVC':best_svc_cv_scores,\n",
        "                      'MLPClassifier':best_mlpc_cv_scores,\n",
        "                      'Blended (SVC+MLPC)':best_blend_cv_scores})\n",
        "\n",
        "bp_df"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogReg</th>\n",
              "      <th>SVC</th>\n",
              "      <th>MLPClassifier</th>\n",
              "      <th>Blended (SVC+MLPC)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.749650</td>\n",
              "      <td>0.746260</td>\n",
              "      <td>0.727697</td>\n",
              "      <td>0.733943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.724294</td>\n",
              "      <td>0.717570</td>\n",
              "      <td>0.702306</td>\n",
              "      <td>0.707333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.732396</td>\n",
              "      <td>0.727441</td>\n",
              "      <td>0.711424</td>\n",
              "      <td>0.717307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.759023</td>\n",
              "      <td>0.753296</td>\n",
              "      <td>0.730817</td>\n",
              "      <td>0.738104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.729497</td>\n",
              "      <td>0.723568</td>\n",
              "      <td>0.702739</td>\n",
              "      <td>0.709450</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     LogReg       SVC  MLPClassifier  Blended (SVC+MLPC)\n",
              "0  0.749650  0.746260       0.727697            0.733943\n",
              "1  0.724294  0.717570       0.702306            0.707333\n",
              "2  0.732396  0.727441       0.711424            0.717307\n",
              "3  0.759023  0.753296       0.730817            0.738104\n",
              "4  0.729497  0.723568       0.702739            0.709450"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "Ep2wjac7MwpB",
        "outputId": "79026f43-79c9-4709-f760-98424eabc067"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "bp_df.boxplot()\n",
        "\n",
        "plt.title('Boxplots')\n",
        "plt.ylabel('roc_auc CV score')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'roc_auc CV score')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdeyTFT1ODkr",
        "outputId": "74a6dfce-233b-4cea-b822-69031355cc6b"
      },
      "source": [
        "print('Logistic Regression test score:', best_logreg_test_score)\n",
        "print('SVC test score:', best_svc_test_score)\n",
        "print('MLPClassifier test score:', best_mlpc_test_score)\n",
        "print('Blended model test score:', best_blend_test_score)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logidtic Regression test score: 0.6936169151099785\n",
            "SVC test score: 0.6934831042075666\n",
            "MLPClassifier test score: 0.6709310735870114\n",
            "Blended model test score: 0.6768584633630883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgg7Iv6Ry7QT"
      },
      "source": [
        "*Вывод:*\n",
        "\n",
        "На большем количестве данных выше всего качество у логистической регрессии. А так же она обучается быстрее всего из четырех моделей, что позволяет провести с ней больше экспериментов с разными наборами признаков и параметров, получив оптимальные комбинации за разумное время. \n",
        "\n",
        "SVC обучается дольше всего, а так же сложна в настройке (что усложняется и тем, что она долго обучается). Однако на большем количестве данных она дала не самый худший результат из четырех.\n",
        "\n",
        "Качество MLPClassifier-а упало на большем количестве данных. В ходе выполнения заданий эта модель показала себя, как самая чувствительная к масштабу признаков.\n",
        "\n",
        "Смешанная модель показала себя плохо, т.к. была настроена на \"большую долю\" (0.8) MLPC, а он в результате проявил себя плохо, хуже чем SVC.\n",
        "\n",
        "Если бы я еще успевала поучаствовать в конкурсе, я бы попробовала: \n",
        "- добавить признаки из оставшейся части датасета\n",
        "- более тщательно подбирать параметры логистической регрессии и MLPC\n",
        "- смешать логистическую регрессию и MLPC\n",
        "- SVC бы не трогала, я его теперь боюсь: он долгий и капризный, по первому опыту... :( "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp3NDKjHRUF-"
      },
      "source": [
        "Не забудьте продолжить участвовать в соревнование, воспользовавшись всеми полученными наработками."
      ]
    }
  ]
}